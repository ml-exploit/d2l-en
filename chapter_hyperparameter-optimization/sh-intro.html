<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>18.4. Multi-Fidelity Hyperparameter Optimization &#8212; Dive into Deep Learning 1.0.3 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d75fae25" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=fb9458d3" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css?v=6319a5cd" />
    <script src="../_static/documentation_options.js?v=baaebd52"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/d2l.js?v=e720e058"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="18.5. Asynchronous Successive Halving" href="sh-async.html" />
    <link rel="prev" title="18.3. Asynchronous Random Search" href="rs-async.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index.html"><span class="section-number">18. </span>Hyperparameter Optimization</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">18.4. </span>Multi-Fidelity Hyperparameter Optimization</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_hyperparameter-optimization/sh-intro.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="###_ALTERNATE_VERSION_BASE_LINK_###">
                  <i class="fas fa-book"></i>
                  ###_ALTERNATE_VERSION_###
              </a>
          
              <a  class="mdl-navigation__link" href="###_CURRENT_VERSION_BASE_LINK_###/d2l-en.pdf">
                  <i class="fas fa-file-pdf"></i>
                  PyTorch
              </a>
          
              <a  class="mdl-navigation__link" href="###_CURRENT_VERSION_BASE_LINK_###/d2l-en-mxnet.pdf">
                  <i class="fas fa-file-pdf"></i>
                  MXNet
              </a>
          
              <a  class="mdl-navigation__link" href="https://d2l.ai/d2l-en.zip">
                  <i class="fab fa-python"></i>
                  Notebooks
              </a>
          
              <a  class="mdl-navigation__link" href="https://courses.d2l.ai">
                  <i class="fas fa-user-graduate"></i>
                  Courses
              </a>
          
              <a  class="mdl-navigation__link" href="https://github.com/d2l-ai/d2l-en">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
          
              <a  class="mdl-navigation__link" href="https://zh.d2l.ai">
                  <i class="fas fa-external-link-alt"></i>
                  中文版
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  Dive into Deep Learning
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index.html">Notation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index.html">2. Preliminaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/ndarray.html">2.1. Data Manipulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/pandas.html">2.2. Data Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/linear-algebra.html">2.3. Linear Algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/calculus.html">2.4. Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/autograd.html">2.5. Automatic Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/probability.html">2.6. Probability and Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/lookup-api.html">2.7. Documentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-regression/index.html">3. Linear Neural Networks for Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression.html">3.1. Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/oo-design.html">3.2. Object-Oriented Design for Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/synthetic-regression-data.html">3.3. Synthetic Regression Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-scratch.html">3.4. Linear Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-concise.html">3.5. Concise Implementation of Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/generalization.html">3.6. Generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/weight-decay.html">3.7. Weight Decay</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-classification/index.html">4. Linear Neural Networks for Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression.html">4.1. Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/classification.html">4.2. The Base Classification Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression-scratch.html">4.3. Softmax Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression-concise.html">4.4. Concise Implementation of Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/generalization-classification.html">4.5. Generalization in Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/environment-and-distribution-shift.html">4.6. Environment and Distribution Shift</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multilayer-perceptrons/index.html">5. Multilayer Perceptrons</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp.html">5.1. Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-implementation.html">5.2. Implementation of Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/backprop.html">5.3. Forward Propagation, Backward Propagation, and Computational Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html">5.4. Numerical Stability and Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/generalization-deep.html">5.5. Generalization in Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/dropout.html">5.6. Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/kaggle-house-price.html">5.7. Predicting House Prices on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_builders-guide/index.html">6. Builders’ Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/model-construction.html">6.1. Layers and Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/parameters.html">6.2. Parameter Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/init-param.html">6.3. Parameter Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/custom-layer.html">6.4. Custom Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/read-write.html">6.5. File I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/use-gpu.html">6.6. GPUs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-neural-networks/index.html">7. Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/why-conv.html">7.1. From Fully Connected Layers to Convolutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/conv-layer.html">7.2. Convolutions for Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/padding-and-strides.html">7.3. Padding and Stride</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/channels.html">7.4. Multiple Input and Multiple Output Channels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/pooling.html">7.5. Pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/lenet.html">7.6. Convolutional Neural Networks (LeNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-modern/index.html">8. Modern Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/alexnet.html">8.1. Deep Convolutional Neural Networks (AlexNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/googlenet.html">8.2. Multi-Branch Networks (GoogLeNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/batch-norm.html">8.3. Batch Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/resnet.html">8.4. Residual Networks (ResNet) and ResNeXt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/densenet.html">8.5. Densely Connected Networks (DenseNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-neural-networks/index.html">9. Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/sequence.html">9.1. Working with Sequences</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/text-sequence.html">9.2. Converting Raw Text into Sequence Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/language-model.html">9.3. Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn.html">9.4. Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-scratch.html">9.5. Recurrent Neural Network Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-concise.html">9.6. Concise Implementation of Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/bptt.html">9.7. Backpropagation Through Time</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-modern/index.html">10. Modern Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/lstm.html">10.1. Long Short-Term Memory (LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/gru.html">10.2. Gated Recurrent Units (GRU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/deep-rnn.html">10.3. Deep Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/machine-translation-and-dataset.html">10.4. Machine Translation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/encoder-decoder.html">10.5. The Encoder–Decoder Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/seq2seq.html">10.6. Sequence-to-Sequence Learning for Machine Translation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/beam-search.html">10.7. Beam Search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/index.html">11. Attention Mechanisms and Transformers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html">11.1. Queries, Keys, and Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html">11.2. Attention Pooling by Similarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html">11.3. Attention Scoring Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html">11.4. The Bahdanau Attention Mechanism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html">11.5. Multi-Head Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html">11.6. Self-Attention and Positional Encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/transformer.html">11.7. The Transformer Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html">11.8. Transformers for Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html">11.9. Large-Scale Pretraining with Transformers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_optimization/index.html">12. Optimization Algorithms</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro.html">12.1. Optimization and Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/convexity.html">12.2. Convexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/gd.html">12.3. Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/sgd.html">12.4. Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/minibatch-sgd.html">12.5. Minibatch Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/momentum.html">12.6. Momentum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adagrad.html">12.7. Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/rmsprop.html">12.8. RMSProp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adadelta.html">12.9. Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adam.html">12.10. Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/lr-scheduler.html">12.11. Learning Rate Scheduling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computer-vision/index.html">13. Computer Vision</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/image-augmentation.html">13.1. Image Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fine-tuning.html">13.2. Fine-Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/bounding-box.html">13.3. Object Detection and Bounding Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/anchor.html">13.4. Anchor Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/multiscale-object-detection.html">13.5. Multiscale Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/object-detection-dataset.html">13.6. The Object Detection Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/ssd.html">13.7. Single Shot Multibox Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/rcnn.html">13.8. Region-based CNNs (R-CNNs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/semantic-segmentation-and-dataset.html">13.9. Semantic Segmentation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/transposed-conv.html">13.10. Transposed Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fcn.html">13.11. Fully Convolutional Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/neural-style.html">13.12. Neural Style Transfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-cifar10.html">13.13. Image Classification (CIFAR-10) on Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-dog.html">13.14. Dog Breed Identification (ImageNet Dogs) on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/index.html">14. Natural Language Processing: Pretraining</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec.html">14.1. Word Embedding (word2vec)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/approx-training.html">14.2. Approximate Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html">14.3. The Dataset for Pretraining Word Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html">14.4. Pretraining word2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/glove.html">14.5. Word Embedding with Global Vectors (GloVe)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/subword-embedding.html">14.6. Subword Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/similarity-analogy.html">14.7. Word Similarity and Analogy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert.html">14.8. Bidirectional Encoder Representations from Transformers (BERT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-dataset.html">14.9. The Dataset for Pretraining BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-pretraining.html">14.10. Pretraining BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-applications/index.html">15. Natural Language Processing: Applications</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html">15.1. Sentiment Analysis and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html">15.2. Sentiment Analysis: Using Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html">15.3. Natural Language Inference and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html">15.4. Natural Language Inference: Using Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/finetuning-bert.html">15.5. Fine-Tuning BERT for Sequence-Level and Token-Level Applications</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement-learning/index.html">16. Reinforcement Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/mdp.html">16.1. Markov Decision Process (MDP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/value-iter.html">16.2. Value Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/qlearning.html">16.3. Q-Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_gaussian-processes/index.html">17. Gaussian Processes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-intro.html">17.1. Introduction to Gaussian Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-priors.html">17.2. Gaussian Process Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-inference.html">17.3. Gaussian Process Inference</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">18. Hyperparameter Optimization</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="hyperopt-intro.html">18.1. What Is Hyperparameter Optimization?</a></li>
<li class="toctree-l2"><a class="reference internal" href="hyperopt-api.html">18.2. Hyperparameter Optimization API</a></li>
<li class="toctree-l2"><a class="reference internal" href="rs-async.html">18.3. Asynchronous Random Search</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">18.4. Multi-Fidelity Hyperparameter Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="sh-async.html">18.5. Asynchronous Successive Halving</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/index.html">19. Appendix: Tools for Deep Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/utils.html">19.1. Utility Functions and Classes</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  Dive into Deep Learning
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index.html">Notation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index.html">2. Preliminaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/ndarray.html">2.1. Data Manipulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/pandas.html">2.2. Data Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/linear-algebra.html">2.3. Linear Algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/calculus.html">2.4. Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/autograd.html">2.5. Automatic Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/probability.html">2.6. Probability and Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/lookup-api.html">2.7. Documentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-regression/index.html">3. Linear Neural Networks for Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression.html">3.1. Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/oo-design.html">3.2. Object-Oriented Design for Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/synthetic-regression-data.html">3.3. Synthetic Regression Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-scratch.html">3.4. Linear Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-concise.html">3.5. Concise Implementation of Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/generalization.html">3.6. Generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/weight-decay.html">3.7. Weight Decay</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-classification/index.html">4. Linear Neural Networks for Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression.html">4.1. Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/classification.html">4.2. The Base Classification Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression-scratch.html">4.3. Softmax Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression-concise.html">4.4. Concise Implementation of Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/generalization-classification.html">4.5. Generalization in Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/environment-and-distribution-shift.html">4.6. Environment and Distribution Shift</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multilayer-perceptrons/index.html">5. Multilayer Perceptrons</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp.html">5.1. Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-implementation.html">5.2. Implementation of Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/backprop.html">5.3. Forward Propagation, Backward Propagation, and Computational Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html">5.4. Numerical Stability and Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/generalization-deep.html">5.5. Generalization in Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/dropout.html">5.6. Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/kaggle-house-price.html">5.7. Predicting House Prices on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_builders-guide/index.html">6. Builders’ Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/model-construction.html">6.1. Layers and Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/parameters.html">6.2. Parameter Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/init-param.html">6.3. Parameter Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/custom-layer.html">6.4. Custom Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/read-write.html">6.5. File I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/use-gpu.html">6.6. GPUs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-neural-networks/index.html">7. Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/why-conv.html">7.1. From Fully Connected Layers to Convolutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/conv-layer.html">7.2. Convolutions for Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/padding-and-strides.html">7.3. Padding and Stride</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/channels.html">7.4. Multiple Input and Multiple Output Channels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/pooling.html">7.5. Pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/lenet.html">7.6. Convolutional Neural Networks (LeNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-modern/index.html">8. Modern Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/alexnet.html">8.1. Deep Convolutional Neural Networks (AlexNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/googlenet.html">8.2. Multi-Branch Networks (GoogLeNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/batch-norm.html">8.3. Batch Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/resnet.html">8.4. Residual Networks (ResNet) and ResNeXt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/densenet.html">8.5. Densely Connected Networks (DenseNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-neural-networks/index.html">9. Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/sequence.html">9.1. Working with Sequences</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/text-sequence.html">9.2. Converting Raw Text into Sequence Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/language-model.html">9.3. Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn.html">9.4. Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-scratch.html">9.5. Recurrent Neural Network Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-concise.html">9.6. Concise Implementation of Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/bptt.html">9.7. Backpropagation Through Time</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-modern/index.html">10. Modern Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/lstm.html">10.1. Long Short-Term Memory (LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/gru.html">10.2. Gated Recurrent Units (GRU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/deep-rnn.html">10.3. Deep Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/machine-translation-and-dataset.html">10.4. Machine Translation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/encoder-decoder.html">10.5. The Encoder–Decoder Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/seq2seq.html">10.6. Sequence-to-Sequence Learning for Machine Translation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/beam-search.html">10.7. Beam Search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/index.html">11. Attention Mechanisms and Transformers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html">11.1. Queries, Keys, and Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html">11.2. Attention Pooling by Similarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html">11.3. Attention Scoring Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html">11.4. The Bahdanau Attention Mechanism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html">11.5. Multi-Head Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html">11.6. Self-Attention and Positional Encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/transformer.html">11.7. The Transformer Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html">11.8. Transformers for Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html">11.9. Large-Scale Pretraining with Transformers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_optimization/index.html">12. Optimization Algorithms</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro.html">12.1. Optimization and Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/convexity.html">12.2. Convexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/gd.html">12.3. Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/sgd.html">12.4. Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/minibatch-sgd.html">12.5. Minibatch Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/momentum.html">12.6. Momentum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adagrad.html">12.7. Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/rmsprop.html">12.8. RMSProp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adadelta.html">12.9. Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adam.html">12.10. Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/lr-scheduler.html">12.11. Learning Rate Scheduling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computer-vision/index.html">13. Computer Vision</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/image-augmentation.html">13.1. Image Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fine-tuning.html">13.2. Fine-Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/bounding-box.html">13.3. Object Detection and Bounding Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/anchor.html">13.4. Anchor Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/multiscale-object-detection.html">13.5. Multiscale Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/object-detection-dataset.html">13.6. The Object Detection Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/ssd.html">13.7. Single Shot Multibox Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/rcnn.html">13.8. Region-based CNNs (R-CNNs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/semantic-segmentation-and-dataset.html">13.9. Semantic Segmentation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/transposed-conv.html">13.10. Transposed Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fcn.html">13.11. Fully Convolutional Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/neural-style.html">13.12. Neural Style Transfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-cifar10.html">13.13. Image Classification (CIFAR-10) on Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-dog.html">13.14. Dog Breed Identification (ImageNet Dogs) on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/index.html">14. Natural Language Processing: Pretraining</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec.html">14.1. Word Embedding (word2vec)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/approx-training.html">14.2. Approximate Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html">14.3. The Dataset for Pretraining Word Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html">14.4. Pretraining word2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/glove.html">14.5. Word Embedding with Global Vectors (GloVe)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/subword-embedding.html">14.6. Subword Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/similarity-analogy.html">14.7. Word Similarity and Analogy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert.html">14.8. Bidirectional Encoder Representations from Transformers (BERT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-dataset.html">14.9. The Dataset for Pretraining BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-pretraining.html">14.10. Pretraining BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-applications/index.html">15. Natural Language Processing: Applications</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html">15.1. Sentiment Analysis and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html">15.2. Sentiment Analysis: Using Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html">15.3. Natural Language Inference and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html">15.4. Natural Language Inference: Using Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/finetuning-bert.html">15.5. Fine-Tuning BERT for Sequence-Level and Token-Level Applications</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement-learning/index.html">16. Reinforcement Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/mdp.html">16.1. Markov Decision Process (MDP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/value-iter.html">16.2. Value Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/qlearning.html">16.3. Q-Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_gaussian-processes/index.html">17. Gaussian Processes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-intro.html">17.1. Introduction to Gaussian Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-priors.html">17.2. Gaussian Process Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-inference.html">17.3. Gaussian Process Inference</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">18. Hyperparameter Optimization</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="hyperopt-intro.html">18.1. What Is Hyperparameter Optimization?</a></li>
<li class="toctree-l2"><a class="reference internal" href="hyperopt-api.html">18.2. Hyperparameter Optimization API</a></li>
<li class="toctree-l2"><a class="reference internal" href="rs-async.html">18.3. Asynchronous Random Search</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">18.4. Multi-Fidelity Hyperparameter Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="sh-async.html">18.5. Asynchronous Successive Halving</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/index.html">19. Appendix: Tools for Deep Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/utils.html">19.1. Utility Functions and Classes</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <section id="multi-fidelity-hyperparameter-optimization">
<span id="sec-mf-hpo"></span><h1><span class="section-number">18.4. </span>Multi-Fidelity Hyperparameter Optimization<a class="headerlink" href="#multi-fidelity-hyperparameter-optimization" title="Link to this heading">¶</a></h1>
<p>Training neural networks can be expensive even on moderate size
datasets. Depending on the configuration space
(<a class="reference internal" href="hyperopt-intro.html#sec-intro-config-spaces"><span class="std std-numref">18.1.1.2section</span></a>), hyperparameter optimization
requires tens to hundreds of function evaluations to find a
well-performing hyperparameter configuration. As we have seen in
<a class="reference internal" href="rs-async.html#sec-rs-async"><span class="std std-numref">18.3section</span></a>, we can significantly speed up the overall
wall-clock time of HPO by exploiting parallel resources, but this does
not reduce the total amount of compute required.</p>
<p>In this section, we will show how the evaluation of hyperparameter
configurations can be sped up. Methods such as random search allocate
the same amount of resources (e.g., number of epochs, training data
points) to each hyperparameter evaluation. <a class="reference internal" href="#img-samples-lc"><span class="std std-numref">figure18.4.1</span></a>
depicts learning curves of a set of neural networks trained with
different hyperparameter configurations. After a few epochs we are
already able to visually distinguish between well-performing and
suboptimal configurations. However, the learning curves are noisy, and
we might still require the full amount of 100 epochs to identify the
best performing one.</p>
<figure class="align-default" id="id2">
<span id="img-samples-lc"></span><img alt="../_images/samples_lc.svg" src="../_images/samples_lc.svg" />
<figcaption>
<p><span class="caption-number">figure18.4.1 </span><span class="caption-text">Learning curves of random hyperparameter configurations</span><a class="headerlink" href="#id2" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p>Multi-fidelity hyperparameter optimization allocates more resources to
promising configurations and stop evaluations of poorly performing ones
early. This speeds up the optimization process, since we can try a
larger number of configurations for the same total amount of resources.</p>
<p>More formally, we expand our definition in
<a class="reference internal" href="hyperopt-intro.html#sec-definition-hpo"><span class="std std-numref">18.1.1section</span></a>, such that our objective function
<span class="math notranslate nohighlight">\(f(\mathbf{x}, r)\)</span> gets an additional input
<span class="math notranslate nohighlight">\(r \in [r_{\mathrm{min}}, r_{max}]\)</span>, specifying the amount of
resources that we are willing to spend for the evaluation of
configuration <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. We assume that the error
<span class="math notranslate nohighlight">\(f(\mathbf{x}, r)\)</span> decreases with <span class="math notranslate nohighlight">\(r\)</span>, whereas the
computational cost <span class="math notranslate nohighlight">\(c(\mathbf{x}, r)\)</span> increases. Typically,
<span class="math notranslate nohighlight">\(r\)</span> represents the number of epochs for training the neural
network, but it could also be the training subset size or the number of
cross-validation folds.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">d2l</span><span class="w"> </span><span class="kn">import</span> <span class="n">mlx</span> <span class="k">as</span> <span class="n">d2l</span>

<span class="n">d2l</span><span class="o">.</span><span class="n">set_figsize</span><span class="p">()</span>
</pre></div>
</div>
<section id="successive-halving">
<span id="sec-mf-hpo-sh"></span><h2><span class="section-number">18.4.1. </span>Successive Halving<a class="headerlink" href="#successive-halving" title="Link to this heading">¶</a></h2>
<p>One of the simplest ways to adapt random search to the multi-fidelity
setting is <em>successive halving</em>
<span id="id1">()</span>. The basic idea is to start
with <span class="math notranslate nohighlight">\(N\)</span> configurations, for example randomly sampled from the
configuration space, and to train each of them for
<span class="math notranslate nohighlight">\(r_{\mathrm{min}}\)</span> epochs only. We then discard a fraction of the
worst performing trials and train the remaining ones for longer.
Iterating this process, fewer trials run for longer, until at least one
trial reaches <span class="math notranslate nohighlight">\(r_{max}\)</span> epochs.</p>
<p>More formally, consider a minimum budget <span class="math notranslate nohighlight">\(r_{\mathrm{min}}\)</span> (for
example 1 epoch), a maximum budget <span class="math notranslate nohighlight">\(r_{max}\)</span>, for example
<code class="docutils literal notranslate"><span class="pre">max_epochs</span></code> in our previous example, and a halving constant
<span class="math notranslate nohighlight">\(\eta\in\{2, 3, \dots\}\)</span>. For simplicity, assume that
<span class="math notranslate nohighlight">\(r_{max} = r_{\mathrm{min}} \eta^K\)</span>, with <span class="math notranslate nohighlight">\(K \in \mathbb{I}\)</span>
. The number of initial configurations is then <span class="math notranslate nohighlight">\(N = \eta^K\)</span>. Let
us define the set of rungs
<span class="math notranslate nohighlight">\(\mathcal{R} = \{ r_{\mathrm{min}}, r_{\mathrm{min}}\eta, r_{\mathrm{min}}\eta^2, \dots, r_{max} \}\)</span>.</p>
<p>One round of successive halving proceeds as follows. We start with
running <span class="math notranslate nohighlight">\(N\)</span> trials until the first rung <span class="math notranslate nohighlight">\(r_{\mathrm{min}}\)</span>.
Sorting the validation errors, we keep the top <span class="math notranslate nohighlight">\(1 / \eta\)</span> fraction
(which amounts to <span class="math notranslate nohighlight">\(\eta^{K-1}\)</span> configurations) and discard all the
rest. The surviving trials are trained for the next rung
(<span class="math notranslate nohighlight">\(r_{\mathrm{min}}\eta\)</span> epochs), and the process is repeated. At
each rung, a <span class="math notranslate nohighlight">\(1 / \eta\)</span> fraction of trials survives and their
training continues with a <span class="math notranslate nohighlight">\(\eta\)</span> times larger budget. With this
particular choice of <span class="math notranslate nohighlight">\(N\)</span>, only a single trial will be trained to
the full budget <span class="math notranslate nohighlight">\(r_{max}\)</span>. Once such a round of successive halving
is done, we start the next one with a new set of initial configurations,
iterating until the total budget is spent.</p>
<figure class="align-default" id="id3">
<img alt="../_images/sh.svg" src="../_images/sh.svg" />
<figcaption>
<p><span class="caption-number">figure18.4.2 </span><span class="caption-text">Learning curves of random hyperparameter configurations.</span><a class="headerlink" href="#id3" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p>We subclass the <code class="docutils literal notranslate"><span class="pre">HPOScheduler</span></code> base class from <a class="reference internal" href="hyperopt-api.html#sec-api-hpo"><span class="std std-numref">18.2section</span></a>
in order to implement successive halving, allowing for a generic
<code class="docutils literal notranslate"><span class="pre">HPOSearcher</span></code> object to sample configurations (which, in our example
below, will be a <code class="docutils literal notranslate"><span class="pre">RandomSearcher</span></code>). Additionally, the user has to pass
the minimum resource <span class="math notranslate nohighlight">\(r_{\mathrm{min}}\)</span>, the maximum resource
<span class="math notranslate nohighlight">\(r_{max}\)</span> and <span class="math notranslate nohighlight">\(\eta\)</span> as input. Inside our scheduler, we
maintain a queue of configurations that still need to be evaluated for
the current rung <span class="math notranslate nohighlight">\(r_i\)</span>. We update the queue every time we jump to
the next rung.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SuccessiveHalvingScheduler</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">HPOScheduler</span><span class="p">):</span>  <span class="c1">#@save</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">searcher</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">r_min</span><span class="p">,</span> <span class="n">r_max</span><span class="p">,</span> <span class="n">prefact</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="c1"># Compute K, which is later used to determine the number of configurations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">r_max</span> <span class="o">/</span> <span class="n">r_min</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">eta</span><span class="p">))</span>
        <span class="c1"># Define the rungs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rung_levels</span> <span class="o">=</span> <span class="p">[</span><span class="n">r_min</span> <span class="o">*</span> <span class="n">eta</span> <span class="o">**</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">r_max</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rung_levels</span><span class="p">:</span>
            <span class="c1"># The final rung should be r_max</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rung_levels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r_max</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># Bookkeeping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observed_error_at_rungs</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_observed_error_at_rungs</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="c1"># Our processing queue</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>
</div>
<p>In the beginning our queue is empty, and we fill it with
<span class="math notranslate nohighlight">\(n = \textrm{prefact} \cdot \eta^{K}\)</span> configurations, which are
first evaluated on the smallest rung <span class="math notranslate nohighlight">\(r_{\mathrm{min}}\)</span>. Here,
<span class="math notranslate nohighlight">\(\textrm{prefact}\)</span> allows us to reuse our code in a different
context. For the purpose of this section, we fix
<span class="math notranslate nohighlight">\(\textrm{prefact} = 1\)</span>. Every time resources become available and
the <code class="docutils literal notranslate"><span class="pre">HPOTuner</span></code> object queries the <code class="docutils literal notranslate"><span class="pre">suggest</span></code> function, we return an
element from the queue. Once we finish one round of successive halving,
which means that we evaluated all surviving configurations on the
highest resource level <span class="math notranslate nohighlight">\(r_{max}\)</span> and our queue is empty, we start
the entire process again with a new, randomly sampled set of
configurations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">SuccessiveHalvingScheduler</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">suggest</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Start a new round of successive halving</span>
        <span class="c1"># Number of configurations for the first rung:</span>
        <span class="n">n0</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prefact</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n0</span><span class="p">):</span>
            <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">searcher</span><span class="o">.</span><span class="n">sample_configuration</span><span class="p">()</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">r_min</span>  <span class="c1"># Set r = r_min</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="c1"># Return an element from the queue</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
</pre></div>
</div>
<p>When we collected a new data point, we first update the searcher module.
Afterwards we check if we already collect all data points on the current
rung. If so, we sort all configurations and push the top
<span class="math notranslate nohighlight">\(\frac{1}{\eta}\)</span> configurations into the queue.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">SuccessiveHalvingScheduler</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">error</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">ri</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;max_epochs&quot;</span><span class="p">])</span>  <span class="c1"># Rung r_i</span>
    <span class="c1"># Update our searcher, e.g if we use Bayesian optimization later</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">searcher</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">additional_info</span><span class="o">=</span><span class="n">info</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">all_observed_error_at_rungs</span><span class="p">[</span><span class="n">ri</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">config</span><span class="p">,</span> <span class="n">error</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">ri</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">r_max</span><span class="p">:</span>
        <span class="c1"># Bookkeeping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observed_error_at_rungs</span><span class="p">[</span><span class="n">ri</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">config</span><span class="p">,</span> <span class="n">error</span><span class="p">))</span>
        <span class="c1"># Determine how many configurations should be evaluated on this rung</span>
        <span class="n">ki</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">rung_levels</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">ri</span><span class="p">)</span>
        <span class="n">ni</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prefact</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">**</span> <span class="n">ki</span><span class="p">)</span>
        <span class="c1"># If we observed all configuration on this rung r_i, we estimate the</span>
        <span class="c1"># top 1 / eta configuration, add them to queue and promote them for</span>
        <span class="c1"># the next rung r_{i+1}</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observed_error_at_rungs</span><span class="p">[</span><span class="n">ri</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="n">ni</span><span class="p">:</span>
            <span class="n">kiplus1</span> <span class="o">=</span> <span class="n">ki</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">niplus1</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prefact</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">**</span> <span class="n">kiplus1</span><span class="p">)</span>
            <span class="n">best_performing_configurations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_top_n_configurations</span><span class="p">(</span>
                <span class="n">rung_level</span><span class="o">=</span><span class="n">ri</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">niplus1</span>
            <span class="p">)</span>
            <span class="n">riplus1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rung_levels</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">-</span> <span class="n">kiplus1</span><span class="p">]</span>  <span class="c1"># r_{i+1}</span>
            <span class="c1"># Queue may not be empty: insert new entries at the beginning</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">queue</span> <span class="o">=</span> <span class="p">[</span>
                <span class="nb">dict</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="n">riplus1</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">config</span> <span class="ow">in</span> <span class="n">best_performing_configurations</span>
            <span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">observed_error_at_rungs</span><span class="p">[</span><span class="n">ri</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Reset</span>
</pre></div>
</div>
<p>Configurations are sorted based on their observed performance on the
current rung.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">SuccessiveHalvingScheduler</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_top_n_configurations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rung_level</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="n">rung</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observed_error_at_rungs</span><span class="p">[</span><span class="n">rung_level</span><span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">rung</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>
    <span class="n">sorted_rung</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">rung</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sorted_rung</span><span class="p">[:</span><span class="n">n</span><span class="p">]]</span>
</pre></div>
</div>
<p>Let us see how successive halving is doing on our neural network
example. We will use <span class="math notranslate nohighlight">\(r_{\mathrm{min}} = 2\)</span>, <span class="math notranslate nohighlight">\(\eta = 2\)</span>,
<span class="math notranslate nohighlight">\(r_{max} = 10\)</span>, so that rung levels are <span class="math notranslate nohighlight">\(2, 4, 8, 10\)</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">min_number_of_epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">max_number_of_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">eta</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span>

<span class="n">config_space</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">stats</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">stats</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
<span class="p">}</span>
<span class="n">initial_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>We just replace the scheduler with our new
<code class="docutils literal notranslate"><span class="pre">SuccessiveHalvingScheduler</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">searcher</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RandomSearcher</span><span class="p">(</span><span class="n">config_space</span><span class="p">,</span> <span class="n">initial_config</span><span class="o">=</span><span class="n">initial_config</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">SuccessiveHalvingScheduler</span><span class="p">(</span>
    <span class="n">searcher</span><span class="o">=</span><span class="n">searcher</span><span class="p">,</span>
    <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
    <span class="n">r_min</span><span class="o">=</span><span class="n">min_number_of_epochs</span><span class="p">,</span>
    <span class="n">r_max</span><span class="o">=</span><span class="n">max_number_of_epochs</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">tuner</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">HPOTuner</span><span class="p">(</span>
    <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
    <span class="n">objective</span><span class="o">=</span><span class="n">d2l</span><span class="o">.</span><span class="n">hpo_objective_lenet</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">number_of_trials</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="n">error</span> <span class="o">=</span> <span class="mf">0.1574882117184726</span><span class="p">,</span> <span class="n">runtime</span> <span class="o">=</span> <span class="mf">25.07677412033081</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_1.svg" src="../_images/output_sh-intro_737282_13_1.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_2.svg" src="../_images/output_sh-intro_737282_13_2.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_3.svg" src="../_images/output_sh-intro_737282_13_3.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_4.svg" src="../_images/output_sh-intro_737282_13_4.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_5.svg" src="../_images/output_sh-intro_737282_13_5.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_6.svg" src="../_images/output_sh-intro_737282_13_6.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_7.svg" src="../_images/output_sh-intro_737282_13_7.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_8.svg" src="../_images/output_sh-intro_737282_13_8.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_9.svg" src="../_images/output_sh-intro_737282_13_9.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_10.svg" src="../_images/output_sh-intro_737282_13_10.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_11.svg" src="../_images/output_sh-intro_737282_13_11.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_12.svg" src="../_images/output_sh-intro_737282_13_12.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_13.svg" src="../_images/output_sh-intro_737282_13_13.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_14.svg" src="../_images/output_sh-intro_737282_13_14.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_15.svg" src="../_images/output_sh-intro_737282_13_15.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_16.svg" src="../_images/output_sh-intro_737282_13_16.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_17.svg" src="../_images/output_sh-intro_737282_13_17.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_18.svg" src="../_images/output_sh-intro_737282_13_18.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_19.svg" src="../_images/output_sh-intro_737282_13_19.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_20.svg" src="../_images/output_sh-intro_737282_13_20.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_21.svg" src="../_images/output_sh-intro_737282_13_21.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_22.svg" src="../_images/output_sh-intro_737282_13_22.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_23.svg" src="../_images/output_sh-intro_737282_13_23.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_24.svg" src="../_images/output_sh-intro_737282_13_24.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_25.svg" src="../_images/output_sh-intro_737282_13_25.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_26.svg" src="../_images/output_sh-intro_737282_13_26.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_27.svg" src="../_images/output_sh-intro_737282_13_27.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_28.svg" src="../_images/output_sh-intro_737282_13_28.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_29.svg" src="../_images/output_sh-intro_737282_13_29.svg" />
</figure>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_13_30.svg" src="../_images/output_sh-intro_737282_13_30.svg" />
</figure>
<p>We can visualize the learning curves of all configurations that we
evaluated. Most of the configurations are stopped early and only the
better performing configurations survive until <span class="math notranslate nohighlight">\(r_{max}\)</span>. Compare
this to vanilla random search, which would allocate <span class="math notranslate nohighlight">\(r_{max}\)</span> to
every configuration.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">rung_index</span><span class="p">,</span> <span class="n">rung</span> <span class="ow">in</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">all_observed_error_at_rungs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="p">[</span><span class="n">xi</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">xi</span> <span class="ow">in</span> <span class="n">rung</span><span class="p">]</span>
    <span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="n">rung_index</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">errors</span><span class="p">),</span> <span class="n">errors</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">min_number_of_epochs</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">max_number_of_epochs</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">min_number_of_epochs</span><span class="p">,</span> <span class="n">max_number_of_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">min_number_of_epochs</span><span class="p">,</span> <span class="n">max_number_of_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;validation error&quot;</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;epochs&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;epochs&#39;</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="../_images/output_sh-intro_737282_15_1.svg" src="../_images/output_sh-intro_737282_15_1.svg" />
</figure>
<p>Finally, note some slight complexity in our implementation of
<code class="docutils literal notranslate"><span class="pre">SuccessiveHalvingScheduler</span></code>. Say that a worker is free to run a job,
and <code class="docutils literal notranslate"><span class="pre">suggest</span></code> is called when the current rung has almost been
completely filled, but another worker is still busy with an evaluation.
Since we lack the metric value from this worker, we cannot determine the
top <span class="math notranslate nohighlight">\(1 / \eta\)</span> fraction to open up the next rung. On the other
hand, we want to assign a job to our free worker, so it does not remain
idle. Our solution is to start a new round of successive halving and
assign our worker to the first trial there. However, once a rung is
completed in <code class="docutils literal notranslate"><span class="pre">update</span></code>, we make sure to insert new configurations at
the beginning of the queue, so they take precedence over configurations
from the next round.</p>
</section>
<section id="summary">
<h2><span class="section-number">18.4.2. </span>Summary<a class="headerlink" href="#summary" title="Link to this heading">¶</a></h2>
<p>In this section, we introduced the concept of multi-fidelity
hyperparameter optimization, where we assume to have access to
cheap-to-evaluate approximations of the objective function, such as
validation error after a certain number of epochs of training as proxy
to validation error after the full number of epochs. Multi-fidelity
hyperparameter optimization allows to reduce the overall computation of
the HPO instead of just reducing the wall-clock time.</p>
<p>We implemented and evaluated successive halving, a simple yet efficient
multi-fidelity HPO algorithm.</p>
</section>
</section>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">18.4. Multi-Fidelity Hyperparameter Optimization</a><ul>
<li><a class="reference internal" href="#successive-halving">18.4.1. Successive Halving</a></li>
<li><a class="reference internal" href="#summary">18.4.2. Summary</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="rs-async.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>18.3. Asynchronous Random Search</div>
         </div>
     </a>
     <a id="button-next" href="sh-async.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>18.5. Asynchronous Successive Halving</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>