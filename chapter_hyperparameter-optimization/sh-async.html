<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>18.5. Asynchronous Successive Halving &#8212; Dive into Deep Learning 1.0.3 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d75fae25" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=fb9458d3" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css?v=6319a5cd" />
    <script src="../_static/documentation_options.js?v=baaebd52"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/d2l.js?v=e720e058"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="19. Appendix: Tools for Deep Learning" href="../chapter_appendix-tools-for-deep-learning/index.html" />
    <link rel="prev" title="18.4. Multi-Fidelity Hyperparameter Optimization" href="sh-intro.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index.html"><span class="section-number">18. </span>Hyperparameter Optimization</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">18.5. </span>Asynchronous Successive Halving</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_hyperparameter-optimization/sh-async.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="###_ALTERNATE_VERSION_BASE_LINK_###">
                  <i class="fas fa-book"></i>
                  ###_ALTERNATE_VERSION_###
              </a>
          
              <a  class="mdl-navigation__link" href="###_CURRENT_VERSION_BASE_LINK_###/d2l-en.pdf">
                  <i class="fas fa-file-pdf"></i>
                  PyTorch
              </a>
          
              <a  class="mdl-navigation__link" href="###_CURRENT_VERSION_BASE_LINK_###/d2l-en-mxnet.pdf">
                  <i class="fas fa-file-pdf"></i>
                  MXNet
              </a>
          
              <a  class="mdl-navigation__link" href="https://d2l.ai/d2l-en.zip">
                  <i class="fab fa-python"></i>
                  Notebooks
              </a>
          
              <a  class="mdl-navigation__link" href="https://courses.d2l.ai">
                  <i class="fas fa-user-graduate"></i>
                  Courses
              </a>
          
              <a  class="mdl-navigation__link" href="https://github.com/d2l-ai/d2l-en">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
          
              <a  class="mdl-navigation__link" href="https://zh.d2l.ai">
                  <i class="fas fa-external-link-alt"></i>
                  中文版
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  Dive into Deep Learning
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index.html">Notation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index.html">2. Preliminaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/ndarray.html">2.1. Data Manipulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/pandas.html">2.2. Data Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/linear-algebra.html">2.3. Linear Algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/calculus.html">2.4. Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/autograd.html">2.5. Automatic Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/probability.html">2.6. Probability and Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/lookup-api.html">2.7. Documentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-regression/index.html">3. Linear Neural Networks for Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression.html">3.1. Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/oo-design.html">3.2. Object-Oriented Design for Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/synthetic-regression-data.html">3.3. Synthetic Regression Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-scratch.html">3.4. Linear Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-concise.html">3.5. Concise Implementation of Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/generalization.html">3.6. Generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/weight-decay.html">3.7. Weight Decay</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-classification/index.html">4. Linear Neural Networks for Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression.html">4.1. Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/classification.html">4.2. The Base Classification Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression-scratch.html">4.3. Softmax Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression-concise.html">4.4. Concise Implementation of Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/generalization-classification.html">4.5. Generalization in Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/environment-and-distribution-shift.html">4.6. Environment and Distribution Shift</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multilayer-perceptrons/index.html">5. Multilayer Perceptrons</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp.html">5.1. Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-implementation.html">5.2. Implementation of Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/backprop.html">5.3. Forward Propagation, Backward Propagation, and Computational Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html">5.4. Numerical Stability and Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/generalization-deep.html">5.5. Generalization in Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/dropout.html">5.6. Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/kaggle-house-price.html">5.7. Predicting House Prices on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_builders-guide/index.html">6. Builders’ Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/model-construction.html">6.1. Layers and Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/parameters.html">6.2. Parameter Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/init-param.html">6.3. Parameter Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/custom-layer.html">6.4. Custom Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/read-write.html">6.5. File I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/use-gpu.html">6.6. GPUs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-neural-networks/index.html">7. Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/why-conv.html">7.1. From Fully Connected Layers to Convolutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/conv-layer.html">7.2. Convolutions for Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/padding-and-strides.html">7.3. Padding and Stride</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/channels.html">7.4. Multiple Input and Multiple Output Channels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/pooling.html">7.5. Pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/lenet.html">7.6. Convolutional Neural Networks (LeNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-modern/index.html">8. Modern Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/alexnet.html">8.1. Deep Convolutional Neural Networks (AlexNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/googlenet.html">8.2. Multi-Branch Networks (GoogLeNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/batch-norm.html">8.3. Batch Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/resnet.html">8.4. Residual Networks (ResNet) and ResNeXt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/densenet.html">8.5. Densely Connected Networks (DenseNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-neural-networks/index.html">9. Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/sequence.html">9.1. Working with Sequences</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/text-sequence.html">9.2. Converting Raw Text into Sequence Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/language-model.html">9.3. Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn.html">9.4. Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-scratch.html">9.5. Recurrent Neural Network Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-concise.html">9.6. Concise Implementation of Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/bptt.html">9.7. Backpropagation Through Time</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-modern/index.html">10. Modern Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/lstm.html">10.1. Long Short-Term Memory (LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/gru.html">10.2. Gated Recurrent Units (GRU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/deep-rnn.html">10.3. Deep Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/machine-translation-and-dataset.html">10.4. Machine Translation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/encoder-decoder.html">10.5. The Encoder–Decoder Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/seq2seq.html">10.6. Sequence-to-Sequence Learning for Machine Translation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/beam-search.html">10.7. Beam Search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/index.html">11. Attention Mechanisms and Transformers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html">11.1. Queries, Keys, and Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html">11.2. Attention Pooling by Similarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html">11.3. Attention Scoring Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html">11.4. The Bahdanau Attention Mechanism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html">11.5. Multi-Head Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html">11.6. Self-Attention and Positional Encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/transformer.html">11.7. The Transformer Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html">11.8. Transformers for Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html">11.9. Large-Scale Pretraining with Transformers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_optimization/index.html">12. Optimization Algorithms</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro.html">12.1. Optimization and Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/convexity.html">12.2. Convexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/gd.html">12.3. Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/sgd.html">12.4. Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/minibatch-sgd.html">12.5. Minibatch Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/momentum.html">12.6. Momentum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adagrad.html">12.7. Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/rmsprop.html">12.8. RMSProp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adadelta.html">12.9. Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adam.html">12.10. Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/lr-scheduler.html">12.11. Learning Rate Scheduling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computer-vision/index.html">13. Computer Vision</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/image-augmentation.html">13.1. Image Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fine-tuning.html">13.2. Fine-Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/bounding-box.html">13.3. Object Detection and Bounding Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/anchor.html">13.4. Anchor Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/multiscale-object-detection.html">13.5. Multiscale Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/object-detection-dataset.html">13.6. The Object Detection Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/ssd.html">13.7. Single Shot Multibox Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/rcnn.html">13.8. Region-based CNNs (R-CNNs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/semantic-segmentation-and-dataset.html">13.9. Semantic Segmentation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/transposed-conv.html">13.10. Transposed Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fcn.html">13.11. Fully Convolutional Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/neural-style.html">13.12. Neural Style Transfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-cifar10.html">13.13. Image Classification (CIFAR-10) on Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-dog.html">13.14. Dog Breed Identification (ImageNet Dogs) on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/index.html">14. Natural Language Processing: Pretraining</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec.html">14.1. Word Embedding (word2vec)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/approx-training.html">14.2. Approximate Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html">14.3. The Dataset for Pretraining Word Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html">14.4. Pretraining word2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/glove.html">14.5. Word Embedding with Global Vectors (GloVe)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/subword-embedding.html">14.6. Subword Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/similarity-analogy.html">14.7. Word Similarity and Analogy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert.html">14.8. Bidirectional Encoder Representations from Transformers (BERT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-dataset.html">14.9. The Dataset for Pretraining BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-pretraining.html">14.10. Pretraining BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-applications/index.html">15. Natural Language Processing: Applications</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html">15.1. Sentiment Analysis and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html">15.2. Sentiment Analysis: Using Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html">15.3. Natural Language Inference and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html">15.4. Natural Language Inference: Using Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/finetuning-bert.html">15.5. Fine-Tuning BERT for Sequence-Level and Token-Level Applications</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement-learning/index.html">16. Reinforcement Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/mdp.html">16.1. Markov Decision Process (MDP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/value-iter.html">16.2. Value Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/qlearning.html">16.3. Q-Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_gaussian-processes/index.html">17. Gaussian Processes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-intro.html">17.1. Introduction to Gaussian Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-priors.html">17.2. Gaussian Process Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-inference.html">17.3. Gaussian Process Inference</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">18. Hyperparameter Optimization</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="hyperopt-intro.html">18.1. What Is Hyperparameter Optimization?</a></li>
<li class="toctree-l2"><a class="reference internal" href="hyperopt-api.html">18.2. Hyperparameter Optimization API</a></li>
<li class="toctree-l2"><a class="reference internal" href="rs-async.html">18.3. Asynchronous Random Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="sh-intro.html">18.4. Multi-Fidelity Hyperparameter Optimization</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">18.5. Asynchronous Successive Halving</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/index.html">19. Appendix: Tools for Deep Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/utils.html">19.1. Utility Functions and Classes</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  Dive into Deep Learning
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index.html">Notation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index.html">2. Preliminaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/ndarray.html">2.1. Data Manipulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/pandas.html">2.2. Data Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/linear-algebra.html">2.3. Linear Algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/calculus.html">2.4. Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/autograd.html">2.5. Automatic Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/probability.html">2.6. Probability and Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/lookup-api.html">2.7. Documentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-regression/index.html">3. Linear Neural Networks for Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression.html">3.1. Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/oo-design.html">3.2. Object-Oriented Design for Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/synthetic-regression-data.html">3.3. Synthetic Regression Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-scratch.html">3.4. Linear Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-concise.html">3.5. Concise Implementation of Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/generalization.html">3.6. Generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/weight-decay.html">3.7. Weight Decay</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-classification/index.html">4. Linear Neural Networks for Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression.html">4.1. Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/classification.html">4.2. The Base Classification Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression-scratch.html">4.3. Softmax Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression-concise.html">4.4. Concise Implementation of Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/generalization-classification.html">4.5. Generalization in Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/environment-and-distribution-shift.html">4.6. Environment and Distribution Shift</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multilayer-perceptrons/index.html">5. Multilayer Perceptrons</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp.html">5.1. Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-implementation.html">5.2. Implementation of Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/backprop.html">5.3. Forward Propagation, Backward Propagation, and Computational Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html">5.4. Numerical Stability and Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/generalization-deep.html">5.5. Generalization in Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/dropout.html">5.6. Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/kaggle-house-price.html">5.7. Predicting House Prices on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_builders-guide/index.html">6. Builders’ Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/model-construction.html">6.1. Layers and Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/parameters.html">6.2. Parameter Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/init-param.html">6.3. Parameter Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/custom-layer.html">6.4. Custom Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/read-write.html">6.5. File I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/use-gpu.html">6.6. GPUs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-neural-networks/index.html">7. Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/why-conv.html">7.1. From Fully Connected Layers to Convolutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/conv-layer.html">7.2. Convolutions for Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/padding-and-strides.html">7.3. Padding and Stride</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/channels.html">7.4. Multiple Input and Multiple Output Channels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/pooling.html">7.5. Pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/lenet.html">7.6. Convolutional Neural Networks (LeNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-modern/index.html">8. Modern Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/alexnet.html">8.1. Deep Convolutional Neural Networks (AlexNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/googlenet.html">8.2. Multi-Branch Networks (GoogLeNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/batch-norm.html">8.3. Batch Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/resnet.html">8.4. Residual Networks (ResNet) and ResNeXt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/densenet.html">8.5. Densely Connected Networks (DenseNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-neural-networks/index.html">9. Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/sequence.html">9.1. Working with Sequences</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/text-sequence.html">9.2. Converting Raw Text into Sequence Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/language-model.html">9.3. Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn.html">9.4. Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-scratch.html">9.5. Recurrent Neural Network Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-concise.html">9.6. Concise Implementation of Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/bptt.html">9.7. Backpropagation Through Time</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-modern/index.html">10. Modern Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/lstm.html">10.1. Long Short-Term Memory (LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/gru.html">10.2. Gated Recurrent Units (GRU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/deep-rnn.html">10.3. Deep Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/machine-translation-and-dataset.html">10.4. Machine Translation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/encoder-decoder.html">10.5. The Encoder–Decoder Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/seq2seq.html">10.6. Sequence-to-Sequence Learning for Machine Translation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/beam-search.html">10.7. Beam Search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/index.html">11. Attention Mechanisms and Transformers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html">11.1. Queries, Keys, and Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html">11.2. Attention Pooling by Similarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html">11.3. Attention Scoring Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html">11.4. The Bahdanau Attention Mechanism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html">11.5. Multi-Head Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html">11.6. Self-Attention and Positional Encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/transformer.html">11.7. The Transformer Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html">11.8. Transformers for Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html">11.9. Large-Scale Pretraining with Transformers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_optimization/index.html">12. Optimization Algorithms</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro.html">12.1. Optimization and Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/convexity.html">12.2. Convexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/gd.html">12.3. Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/sgd.html">12.4. Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/minibatch-sgd.html">12.5. Minibatch Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/momentum.html">12.6. Momentum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adagrad.html">12.7. Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/rmsprop.html">12.8. RMSProp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adadelta.html">12.9. Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adam.html">12.10. Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/lr-scheduler.html">12.11. Learning Rate Scheduling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computer-vision/index.html">13. Computer Vision</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/image-augmentation.html">13.1. Image Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fine-tuning.html">13.2. Fine-Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/bounding-box.html">13.3. Object Detection and Bounding Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/anchor.html">13.4. Anchor Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/multiscale-object-detection.html">13.5. Multiscale Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/object-detection-dataset.html">13.6. The Object Detection Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/ssd.html">13.7. Single Shot Multibox Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/rcnn.html">13.8. Region-based CNNs (R-CNNs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/semantic-segmentation-and-dataset.html">13.9. Semantic Segmentation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/transposed-conv.html">13.10. Transposed Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fcn.html">13.11. Fully Convolutional Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/neural-style.html">13.12. Neural Style Transfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-cifar10.html">13.13. Image Classification (CIFAR-10) on Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-dog.html">13.14. Dog Breed Identification (ImageNet Dogs) on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/index.html">14. Natural Language Processing: Pretraining</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec.html">14.1. Word Embedding (word2vec)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/approx-training.html">14.2. Approximate Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html">14.3. The Dataset for Pretraining Word Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html">14.4. Pretraining word2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/glove.html">14.5. Word Embedding with Global Vectors (GloVe)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/subword-embedding.html">14.6. Subword Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/similarity-analogy.html">14.7. Word Similarity and Analogy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert.html">14.8. Bidirectional Encoder Representations from Transformers (BERT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-dataset.html">14.9. The Dataset for Pretraining BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-pretraining.html">14.10. Pretraining BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-applications/index.html">15. Natural Language Processing: Applications</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html">15.1. Sentiment Analysis and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html">15.2. Sentiment Analysis: Using Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html">15.3. Natural Language Inference and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html">15.4. Natural Language Inference: Using Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/finetuning-bert.html">15.5. Fine-Tuning BERT for Sequence-Level and Token-Level Applications</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement-learning/index.html">16. Reinforcement Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/mdp.html">16.1. Markov Decision Process (MDP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/value-iter.html">16.2. Value Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/qlearning.html">16.3. Q-Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_gaussian-processes/index.html">17. Gaussian Processes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-intro.html">17.1. Introduction to Gaussian Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-priors.html">17.2. Gaussian Process Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-inference.html">17.3. Gaussian Process Inference</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">18. Hyperparameter Optimization</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="hyperopt-intro.html">18.1. What Is Hyperparameter Optimization?</a></li>
<li class="toctree-l2"><a class="reference internal" href="hyperopt-api.html">18.2. Hyperparameter Optimization API</a></li>
<li class="toctree-l2"><a class="reference internal" href="rs-async.html">18.3. Asynchronous Random Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="sh-intro.html">18.4. Multi-Fidelity Hyperparameter Optimization</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">18.5. Asynchronous Successive Halving</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/index.html">19. Appendix: Tools for Deep Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/utils.html">19.1. Utility Functions and Classes</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <section id="asynchronous-successive-halving">
<span id="sec-sh-async"></span><h1><span class="section-number">18.5. </span>Asynchronous Successive Halving<a class="headerlink" href="#asynchronous-successive-halving" title="Link to this heading">¶</a></h1>
<p>As we have seen in <a class="reference internal" href="rs-async.html#sec-rs-async"><span class="std std-numref">18.3section</span></a>, we can accelerate HPO by
distributing the evaluation of hyperparameter configurations across
either multiple instances or multiples CPUs / GPUs on a single instance.
However, compared to random search, it is not straightforward to run
successive halving (SH) asynchronously in a distributed setting. Before
we can decide which configuration to run next, we first have to collect
all observations at the current rung level. This requires to synchronize
workers at each rung level. For example, for the lowest rung level
<span class="math notranslate nohighlight">\(r_{\mathrm{min}}\)</span>, we first have to evaluate all
<span class="math notranslate nohighlight">\(N = \eta^K\)</span> configurations, before we can promote the
<span class="math notranslate nohighlight">\(\frac{1}{\eta}\)</span> of them to the next rung level.</p>
<p>In any distributed system, synchronization typically implies idle time
for workers. First, we often observe high variations in training time
across hyperparameter configurations. For example, assuming the number
of filters per layer is a hyperparameter, then networks with less
filters finish training faster than networks with more filters, which
implies idle worker time due to stragglers. Moreover, the number of
slots in a rung level is not always a multiple of the number of workers,
in which case some workers may even sit idle for a full batch.</p>
<p>Figure <a class="reference internal" href="#synchronous-sh"><span class="std std-numref">figure18.5.1</span></a> shows the scheduling of synchronous SH
with <span class="math notranslate nohighlight">\(\eta=2\)</span> for four different trials with two workers. We start
with evaluating Trial-0 and Trial-1 for one epoch and immediately
continue with the next two trials once they are finished. We first have
to wait until Trial-2 finishes, which takes substantially more time than
the other trials, before we can promote the best two trials, i.e.,
Trial-0 and Trial-3 to the next rung level. This causes idle time for
Worker-1. Then, we continue with Rung 1. Also, here Trial-3 takes longer
than Trial-0, which leads to an additional ideling time of Worker-0.
Once, we reach Rung-2, only the best trial, Trial-0, remains which
occupies only one worker. To avoid that Worker-1 idles during that time,
most implementaitons of SH continue already with the next round, and
start evaluating new trials (e.g Trial-4) on the first rung.</p>
<figure class="align-default" id="id2">
<span id="synchronous-sh"></span><img alt="../_images/sync_sh.svg" src="../_images/sync_sh.svg" />
<figcaption>
<p><span class="caption-number">figure18.5.1 </span><span class="caption-text">Synchronous successive halving with two workers.</span><a class="headerlink" href="#id2" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p>Asynchronous successive halving (ASHA) <span id="id1">()</span> adapts SH to
the asynchronous parallel scenario. The main idea of ASHA is to promote
configurations to the next rung level as soon as we collected at least
<span class="math notranslate nohighlight">\(\eta\)</span> observations on the current rung level. This decision rule
may lead to suboptimal promotions: configurations can be promoted to the
next rung level, which in hindsight do not compare favourably against
most others at the same rung level. On the other hand, we get rid of all
synchronization points this way. In practice, such suboptimal initial
promotions have only a modest impact on performance, not only because
the ranking of hyperparameter configurations is often fairly consistent
across rung levels, but also because rungs grow over time and reflect
the distribution of metric values at this level better and better. If a
worker is free, but no configuration can be promoted, we start a new
configuration with <span class="math notranslate nohighlight">\(r = r_{\mathrm{min}}\)</span>, i.e the first rung
level.</p>
<p><a class="reference internal" href="#asha"><span class="std std-numref">figure18.5.2</span></a> shows the scheduling of the same configurations for
ASHA. Once Trial-1 finishes, we collect the results of two trials (i.e
Trial-0 and Trial-1) and immediately promote the better of them
(Trial-0) to the next rung level. After Trial-0 finishes on rung 1,
there are too few trials there in order to support a further promotion.
Hence, we continue with rung 0 and evaluate Trial-3. Once Trial-3
finishes, Trial-2 is still pending. At this point we have 3 trials
evaluated on rung 0 and one trial evaluated already on rung 1. Since
Trial-3 performs worse than Trial-0 at rung 0, and <span class="math notranslate nohighlight">\(\eta=2\)</span>, we
cannot promote any new trial yet, and Worker-1 starts Trial-4 from
scratch instead. However, once Trial-2 finishes and scores worse than
Trial-3, the latter is promoted towards rung 1. Afterwards, we collected
2 evaluations on rung 1, which means we can now promote Trial-0 towards
rung 2. At the same time, Worker-1 continues with evaluating new trials
(i.e., Trial-5) on rung 0.</p>
<figure class="align-default" id="id3">
<span id="asha"></span><img alt="../_images/asha.svg" src="../_images/asha.svg" />
<figcaption>
<p><span class="caption-number">figure18.5.2 </span><span class="caption-text">Asynchronous successive halving (ASHA) with two workers.</span><a class="headerlink" href="#id3" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">d2l</span><span class="w"> </span><span class="kn">import</span> <span class="n">mlx</span> <span class="k">as</span> <span class="n">d2l</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">syne_tune</span><span class="w"> </span><span class="kn">import</span> <span class="n">StoppingCriterion</span><span class="p">,</span> <span class="n">Tuner</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">syne_tune.backend</span><span class="w"> </span><span class="kn">import</span> <span class="n">PythonBackend</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">syne_tune.config_space</span><span class="w"> </span><span class="kn">import</span> <span class="n">loguniform</span><span class="p">,</span> <span class="n">randint</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">syne_tune.experiments</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_experiment</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">syne_tune.optimizer.baselines</span><span class="w"> </span><span class="kn">import</span> <span class="n">ASHA</span>
</pre></div>
</div>
<section id="objective-function">
<h2><span class="section-number">18.5.1. </span>Objective Function<a class="headerlink" href="#objective-function" title="Link to this heading">¶</a></h2>
<p>We will use <em>Syne Tune</em> with the same objective function as in
<a class="reference internal" href="rs-async.html#sec-rs-async"><span class="std std-numref">18.3section</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">hpo_objective_lenet_synetune</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">):</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">syne_tune</span><span class="w"> </span><span class="kn">import</span> <span class="n">Reporter</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">d2l</span><span class="w"> </span><span class="kn">import</span> <span class="n">mlx</span> <span class="k">as</span> <span class="n">d2l</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">LeNet</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">HPOTrainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">report</span> <span class="o">=</span> <span class="n">Reporter</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Initialize the state of Trainer</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">fit_epoch</span><span class="p">()</span>

        <span class="n">validation_error</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">validation_error</span><span class="p">()</span>
        <span class="n">report</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">validation_error</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">validation_error</span><span class="p">))</span>
</pre></div>
</div>
<p>We will also use the same configuration space as before:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">min_number_of_epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">max_number_of_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">eta</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">config_space</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">loguniform</span><span class="p">(</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">randint</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
    <span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="n">max_number_of_epochs</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">initial_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="asynchronous-scheduler">
<h2><span class="section-number">18.5.2. </span>Asynchronous Scheduler<a class="headerlink" href="#asynchronous-scheduler" title="Link to this heading">¶</a></h2>
<p>First, we define the number of workers that evaluate trials
concurrently. We also need to specify how long we want to run random
search, by defining an upper limit on the total wall-clock time.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">n_workers</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Needs to be &lt;= the number of available GPUs</span>
<span class="n">max_wallclock_time</span> <span class="o">=</span> <span class="mi">12</span> <span class="o">*</span> <span class="mi">60</span>  <span class="c1"># 12 minutes</span>
</pre></div>
</div>
<p>The code for running ASHA is a simple variation of what we did for
asynchronous random search.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mode = &quot;min&quot;</span>
<span class="c1"># metric = &quot;validation_error&quot;</span>
<span class="c1"># resource_attr = &quot;epoch&quot;</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">ASHA</span><span class="p">(</span>
    <span class="n">config_space</span><span class="p">,</span>
    <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;validation_error&quot;</span><span class="p">,</span>
    <span class="n">time_attr</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="n">max_t</span><span class="o">=</span><span class="n">max_number_of_epochs</span><span class="p">,</span>
    <span class="n">do_minimize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">points_to_evaluate</span><span class="o">=</span><span class="p">[</span><span class="n">initial_config</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">metric</span></code> and <code class="docutils literal notranslate"><span class="pre">resource_attr</span></code> specify the key names used with
the <code class="docutils literal notranslate"><span class="pre">report</span></code> callback, and <code class="docutils literal notranslate"><span class="pre">max_resource_attr</span></code> denotes which input
to the objective function corresponds to <span class="math notranslate nohighlight">\(r_{\mathrm{max}}\)</span>.
Moreover, <code class="docutils literal notranslate"><span class="pre">grace_period</span></code> provides <span class="math notranslate nohighlight">\(r_{\mathrm{min}}\)</span>, and
<code class="docutils literal notranslate"><span class="pre">reduction_factor</span></code> is <span class="math notranslate nohighlight">\(\eta\)</span>. We can run Syne Tune as before
(this will take about 12 minutes):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trial_backend</span> <span class="o">=</span> <span class="n">PythonBackend</span><span class="p">(</span>
    <span class="n">tune_function</span><span class="o">=</span><span class="n">hpo_objective_lenet_synetune</span><span class="p">,</span>
    <span class="n">config_space</span><span class="o">=</span><span class="n">config_space</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">stop_criterion</span> <span class="o">=</span> <span class="n">StoppingCriterion</span><span class="p">(</span><span class="n">max_wallclock_time</span><span class="o">=</span><span class="n">max_wallclock_time</span><span class="p">)</span>
<span class="n">tuner</span> <span class="o">=</span> <span class="n">Tuner</span><span class="p">(</span>
    <span class="n">trial_backend</span><span class="o">=</span><span class="n">trial_backend</span><span class="p">,</span>
    <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
    <span class="n">stop_criterion</span><span class="o">=</span><span class="n">stop_criterion</span><span class="p">,</span>
    <span class="n">n_workers</span><span class="o">=</span><span class="n">n_workers</span><span class="p">,</span>
    <span class="n">print_update_interval</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">max_wallclock_time</span> <span class="o">*</span> <span class="mf">0.6</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">results</span> <span class="n">of</span> <span class="n">trials</span> <span class="n">will</span> <span class="n">be</span> <span class="n">saved</span> <span class="n">on</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">Error</span> <span class="n">launching</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">nvidia</span><span class="o">-</span><span class="n">smi</span><span class="p">,</span> <span class="n">no</span> <span class="n">GPU</span> <span class="n">could</span> <span class="n">be</span> <span class="n">detected</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">Detected</span> <span class="mi">0</span> <span class="n">GPUs</span>
<span class="n">WARNING</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">num_gpus_per_trial</span> <span class="o">=</span> <span class="mi">1</span> <span class="ow">is</span> <span class="n">too</span> <span class="n">large</span><span class="p">,</span> <span class="n">reducing</span> <span class="n">to</span> <span class="mi">0</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.3890338391272654</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">248</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">0</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.3890338391272654</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">248</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.011335521846740686</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">162</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">1</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.011335521846740686</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">162</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.3472413436671253</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">213</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">2</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.3472413436671253</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">213</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">0</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.016820573610021133</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">115</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">3</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">3</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.016820573610021133</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">115</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.028005751626881802</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">64</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">4</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">4</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.028005751626881802</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.04981619915828577</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">34</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">5</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.04981619915828577</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">34</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.212063712661875</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">103</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">6</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">6</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.212063712661875</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">103</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">5</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">5</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">6</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.38809559103096963</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">88</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">7</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">7</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.38809559103096963</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">88</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">7</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">7</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">5</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.010988948291006459</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">235</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">8</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">8</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.010988948291006459</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">235</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.05600839449203463</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">166</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">9</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">9</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.05600839449203463</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">166</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">9</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">9</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">7</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.01176482331903498</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">159</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">10</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">10</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.01176482331903498</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">159</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.016564846045842005</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">212</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">11</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">11</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.016564846045842005</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">212</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">10</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">10</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.28001134495568514</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">118</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">12</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">12</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.28001134495568514</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">118</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.3011893656031137</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">159</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">13</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">13</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.3011893656031137</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">159</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">12</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">12</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.08928561211360032</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">102</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">14</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">14</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.08928561211360032</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">102</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">14</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">14</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">12</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.2583974707015322</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">216</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">15</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">15</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.2583974707015322</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">216</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.02994522036707356</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">248</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">16</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">16</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.02994522036707356</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">248</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">15</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">15</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">tuning</span> <span class="n">status</span> <span class="p">(</span><span class="n">last</span> <span class="n">metric</span> <span class="ow">is</span> <span class="n">reported</span><span class="p">)</span>
 <span class="n">trial_id</span>     <span class="n">status</span>  <span class="nb">iter</span>  <span class="n">learning_rate</span>  <span class="n">batch_size</span>  <span class="n">max_epochs</span>  <span class="n">epoch</span>  <span class="n">validation_error</span>  <span class="n">worker</span><span class="o">-</span><span class="n">time</span>
        <span class="mi">0</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.389034</span>         <span class="mi">248</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.174823</span>    <span class="mf">46.390648</span>
        <span class="mi">1</span>    <span class="n">Stopped</span>     <span class="mi">2</span>       <span class="mf">0.011336</span>         <span class="mi">162</span>          <span class="mi">10</span>    <span class="mf">2.0</span>          <span class="mf">0.899918</span>    <span class="mf">28.746251</span>
        <span class="mi">2</span>    <span class="n">Stopped</span>     <span class="mi">4</span>       <span class="mf">0.347241</span>         <span class="mi">213</span>          <span class="mi">10</span>    <span class="mf">4.0</span>          <span class="mf">0.199671</span>    <span class="mf">33.409475</span>
        <span class="mi">3</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.016821</span>         <span class="mi">115</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.810999</span>    <span class="mf">32.634836</span>
        <span class="mi">4</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.028006</span>          <span class="mi">64</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.329817</span>    <span class="mf">44.935998</span>
        <span class="mi">5</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.049816</span>          <span class="mi">34</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.172483</span>   <span class="mf">128.607070</span>
        <span class="mi">6</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.212064</span>         <span class="mi">103</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.157916</span>    <span class="mf">80.433653</span>
        <span class="mi">7</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.388096</span>          <span class="mi">88</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.131109</span>    <span class="mf">72.157970</span>
        <span class="mi">8</span>    <span class="n">Stopped</span>     <span class="mi">2</span>       <span class="mf">0.010989</span>         <span class="mi">235</span>          <span class="mi">10</span>    <span class="mf">2.0</span>          <span class="mf">0.900160</span>    <span class="mf">29.473000</span>
        <span class="mi">9</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.056008</span>         <span class="mi">166</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.473938</span>    <span class="mf">29.698198</span>
       <span class="mi">10</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.011765</span>         <span class="mi">159</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.900002</span>    <span class="mf">27.082558</span>
       <span class="mi">11</span>    <span class="n">Stopped</span>     <span class="mi">2</span>       <span class="mf">0.016565</span>         <span class="mi">212</span>          <span class="mi">10</span>    <span class="mf">2.0</span>          <span class="mf">0.898847</span>    <span class="mf">27.910791</span>
       <span class="mi">12</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.280011</span>         <span class="mi">118</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.170069</span>    <span class="mf">63.088011</span>
       <span class="mi">13</span>    <span class="n">Stopped</span>     <span class="mi">3</span>       <span class="mf">0.301189</span>         <span class="mi">159</span>          <span class="mi">10</span>    <span class="mf">3.0</span>          <span class="mf">0.216004</span>    <span class="mf">34.259483</span>
       <span class="mi">14</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.089286</span>         <span class="mi">102</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.261735</span>    <span class="mf">33.068030</span>
       <span class="mi">15</span> <span class="n">InProgress</span>     <span class="mi">0</span>       <span class="mf">0.258397</span>         <span class="mi">216</span>          <span class="mi">10</span>      <span class="o">-</span>                 <span class="o">-</span>            <span class="o">-</span>
       <span class="mi">16</span> <span class="n">InProgress</span>     <span class="mi">0</span>       <span class="mf">0.029945</span>         <span class="mi">248</span>          <span class="mi">10</span>      <span class="o">-</span>                 <span class="o">-</span>            <span class="o">-</span>
<span class="mi">2</span> <span class="n">trials</span> <span class="n">running</span><span class="p">,</span> <span class="mi">15</span> <span class="n">finished</span> <span class="p">(</span><span class="mi">5</span> <span class="n">until</span> <span class="n">the</span> <span class="n">end</span><span class="p">),</span> <span class="mf">435.89</span><span class="n">s</span> <span class="n">wallclock</span><span class="o">-</span><span class="n">time</span>

<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.014524661982273063</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">175</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">17</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">17</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.014524661982273063</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">175</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">16</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">16</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.09615916813911475</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">83</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">18</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">18</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.09615916813911475</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">83</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">17</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">17</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.06691128419125478</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">197</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">19</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">19</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.06691128419125478</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">197</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">18</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">18</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.20248813907299865</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">129</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">20</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">20</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.20248813907299865</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">129</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">19</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">19</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.011114022771092129</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">226</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">21</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">21</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.011114022771092129</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">226</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">20</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">20</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.1846580541163797</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">128</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">22</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">22</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.1846580541163797</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">21</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">21</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.08169016239095044</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">63</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">23</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">23</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.08169016239095044</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">63</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">22</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">22</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.04385133919593825</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">84</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">24</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">24</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.04385133919593825</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">84</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">23</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">23</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.038617876339801765</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">209</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">25</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">25</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.038617876339801765</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">209</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">24</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">24</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.41776684604758285</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">177</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">26</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">26</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.41776684604758285</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">177</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">25</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">25</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.016830288384432443</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">205</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">27</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">27</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.016830288384432443</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">205</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">26</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">26</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">26</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.12345124308220282</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">101</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">28</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">28</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.12345124308220282</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">101</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.03716318260525985</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">96</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">29</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">29</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.03716318260525985</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">96</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">28</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">28</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.08300129677257653</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">97</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">30</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">30</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.08300129677257653</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">97</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">29</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">29</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.34819874766327785</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">249</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">8</span><span class="n">d938717fd641d43907cdb9888ac1aaa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">31</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.34819874766327785</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">249</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">start</span><span class="p">:</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">30</span> <span class="n">observations</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">fit</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">30</span> <span class="n">observations</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">secs</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">stopping_criterion</span><span class="p">:</span><span class="n">reaching</span> <span class="nb">max</span> <span class="n">wallclock</span> <span class="n">time</span> <span class="p">(</span><span class="mi">720</span><span class="p">),</span> <span class="n">stopping</span> <span class="n">there</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Stopping</span> <span class="n">trials</span> <span class="n">that</span> <span class="n">may</span> <span class="n">still</span> <span class="n">be</span> <span class="n">running</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Tuning</span> <span class="n">finished</span><span class="p">,</span> <span class="n">results</span> <span class="n">of</span> <span class="n">trials</span> <span class="n">can</span> <span class="n">be</span> <span class="n">found</span> <span class="n">on</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="mi">190</span>
<span class="o">--------------------</span>
<span class="n">Resource</span> <span class="n">summary</span> <span class="p">(</span><span class="n">last</span> <span class="n">result</span> <span class="ow">is</span> <span class="n">reported</span><span class="p">):</span>
 <span class="n">trial_id</span>     <span class="n">status</span>  <span class="nb">iter</span>  <span class="n">learning_rate</span>  <span class="n">batch_size</span>  <span class="n">max_epochs</span>  <span class="n">epoch</span>  <span class="n">validation_error</span>  <span class="n">worker</span><span class="o">-</span><span class="n">time</span>
        <span class="mi">0</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.389034</span>         <span class="mi">248</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.174823</span>    <span class="mf">46.390648</span>
        <span class="mi">1</span>    <span class="n">Stopped</span>     <span class="mi">2</span>       <span class="mf">0.011336</span>         <span class="mi">162</span>          <span class="mi">10</span>    <span class="mf">2.0</span>          <span class="mf">0.899918</span>    <span class="mf">28.746251</span>
        <span class="mi">2</span>    <span class="n">Stopped</span>     <span class="mi">4</span>       <span class="mf">0.347241</span>         <span class="mi">213</span>          <span class="mi">10</span>    <span class="mf">4.0</span>          <span class="mf">0.199671</span>    <span class="mf">33.409475</span>
        <span class="mi">3</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.016821</span>         <span class="mi">115</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.810999</span>    <span class="mf">32.634836</span>
        <span class="mi">4</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.028006</span>          <span class="mi">64</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.329817</span>    <span class="mf">44.935998</span>
        <span class="mi">5</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.049816</span>          <span class="mi">34</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.172483</span>   <span class="mf">128.607070</span>
        <span class="mi">6</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.212064</span>         <span class="mi">103</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.157916</span>    <span class="mf">80.433653</span>
        <span class="mi">7</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.388096</span>          <span class="mi">88</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.131109</span>    <span class="mf">72.157970</span>
        <span class="mi">8</span>    <span class="n">Stopped</span>     <span class="mi">2</span>       <span class="mf">0.010989</span>         <span class="mi">235</span>          <span class="mi">10</span>    <span class="mf">2.0</span>          <span class="mf">0.900160</span>    <span class="mf">29.473000</span>
        <span class="mi">9</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.056008</span>         <span class="mi">166</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.473938</span>    <span class="mf">29.698198</span>
       <span class="mi">10</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.011765</span>         <span class="mi">159</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.900002</span>    <span class="mf">27.082558</span>
       <span class="mi">11</span>    <span class="n">Stopped</span>     <span class="mi">2</span>       <span class="mf">0.016565</span>         <span class="mi">212</span>          <span class="mi">10</span>    <span class="mf">2.0</span>          <span class="mf">0.898847</span>    <span class="mf">27.910791</span>
       <span class="mi">12</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.280011</span>         <span class="mi">118</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.170069</span>    <span class="mf">63.088011</span>
       <span class="mi">13</span>    <span class="n">Stopped</span>     <span class="mi">3</span>       <span class="mf">0.301189</span>         <span class="mi">159</span>          <span class="mi">10</span>    <span class="mf">3.0</span>          <span class="mf">0.216004</span>    <span class="mf">34.259483</span>
       <span class="mi">14</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.089286</span>         <span class="mi">102</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.261735</span>    <span class="mf">33.068030</span>
       <span class="mi">15</span>    <span class="n">Stopped</span>     <span class="mi">2</span>       <span class="mf">0.258397</span>         <span class="mi">216</span>          <span class="mi">10</span>    <span class="mf">2.0</span>          <span class="mf">0.268789</span>    <span class="mf">26.619754</span>
       <span class="mi">16</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.029945</span>         <span class="mi">248</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.899793</span>    <span class="mf">23.221629</span>
       <span class="mi">17</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.014525</span>         <span class="mi">175</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.899113</span>    <span class="mf">29.563362</span>
       <span class="mi">18</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.096159</span>          <span class="mi">83</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.234850</span>    <span class="mf">37.190157</span>
       <span class="mi">19</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.066911</span>         <span class="mi">197</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.466594</span>    <span class="mf">27.127466</span>
       <span class="mi">20</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.202488</span>         <span class="mi">129</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.237821</span>    <span class="mf">29.175115</span>
       <span class="mi">21</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.011114</span>         <span class="mi">226</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.900478</span>    <span class="mf">26.078950</span>
       <span class="mi">22</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.184658</span>         <span class="mi">128</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.238133</span>    <span class="mf">32.205698</span>
       <span class="mi">23</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.081690</span>          <span class="mi">63</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.247822</span>    <span class="mf">43.514397</span>
       <span class="mi">24</span>    <span class="n">Stopped</span>     <span class="mi">2</span>       <span class="mf">0.043851</span>          <span class="mi">84</span>          <span class="mi">10</span>    <span class="mf">2.0</span>          <span class="mf">0.278472</span>    <span class="mf">39.559851</span>
       <span class="mi">25</span>    <span class="n">Stopped</span>     <span class="mi">2</span>       <span class="mf">0.038618</span>         <span class="mi">209</span>          <span class="mi">10</span>    <span class="mf">2.0</span>          <span class="mf">0.899923</span>    <span class="mf">28.638117</span>
       <span class="mi">26</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.417767</span>         <span class="mi">177</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.155831</span>    <span class="mf">52.305785</span>
       <span class="mi">27</span>    <span class="n">Stopped</span>     <span class="mi">2</span>       <span class="mf">0.016830</span>         <span class="mi">205</span>          <span class="mi">10</span>    <span class="mf">2.0</span>          <span class="mf">0.899888</span>    <span class="mf">28.042010</span>
       <span class="mi">28</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.123451</span>         <span class="mi">101</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.262178</span>    <span class="mf">34.001491</span>
       <span class="mi">29</span>    <span class="n">Stopped</span>     <span class="mi">1</span>       <span class="mf">0.037163</span>          <span class="mi">96</span>          <span class="mi">10</span>    <span class="mf">1.0</span>          <span class="mf">0.414087</span>    <span class="mf">35.973114</span>
       <span class="mi">30</span> <span class="n">InProgress</span>     <span class="mi">0</span>       <span class="mf">0.083001</span>          <span class="mi">97</span>          <span class="mi">10</span>      <span class="o">-</span>                 <span class="o">-</span>            <span class="o">-</span>
       <span class="mi">31</span> <span class="n">InProgress</span>     <span class="mi">0</span>       <span class="mf">0.348199</span>         <span class="mi">249</span>          <span class="mi">10</span>      <span class="o">-</span>                 <span class="o">-</span>            <span class="o">-</span>
<span class="mi">2</span> <span class="n">trials</span> <span class="n">running</span><span class="p">,</span> <span class="mi">30</span> <span class="n">finished</span> <span class="p">(</span><span class="mi">6</span> <span class="n">until</span> <span class="n">the</span> <span class="n">end</span><span class="p">),</span> <span class="mf">721.60</span><span class="n">s</span> <span class="n">wallclock</span><span class="o">-</span><span class="n">time</span>

<span class="n">validation_error</span><span class="p">:</span> <span class="n">best</span> <span class="mf">0.13110899872947157</span> <span class="k">for</span> <span class="n">trial</span><span class="o">-</span><span class="nb">id</span> <span class="mi">7</span>
<span class="o">--------------------</span>
</pre></div>
</div>
<p>Note that we are running a variant of ASHA where underperforming trials
are stopped early. This is different to our implementation in
<a class="reference internal" href="sh-intro.html#sec-mf-hpo-sh"><span class="std std-numref">18.4.1section</span></a>, where each training job is started with a
fixed <code class="docutils literal notranslate"><span class="pre">max_epochs</span></code>. In the latter case, a well-performing trial which
reaches the full 10 epochs, first needs to train 1, then 2, then 4, then
8 epochs, each time starting from scratch. This type of pause-and-resume
scheduling can be implemented efficiently by checkpointing the training
state after each epoch, but we avoid this extra complexity here. After
the experiment has finished, we can retrieve and plot results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">d2l</span><span class="o">.</span><span class="n">set_figsize</span><span class="p">()</span>
<span class="n">e</span> <span class="o">=</span> <span class="n">load_experiment</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="n">e</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="../_images/output_sh-async_950d48_13_0.svg" src="../_images/output_sh-async_950d48_13_0.svg" />
</figure>
</section>
<section id="visualize-the-optimization-process">
<h2><span class="section-number">18.5.3. </span>Visualize the Optimization Process<a class="headerlink" href="#visualize-the-optimization-process" title="Link to this heading">¶</a></h2>
<p>Once more, we visualize the learning curves of every trial (each color
in the plot represents a trial). Compare this to asynchronous random
search in <a class="reference internal" href="rs-async.html#sec-rs-async"><span class="std std-numref">18.3section</span></a>. As we have seen for successive
halving in <a class="reference internal" href="sh-intro.html#sec-mf-hpo"><span class="std std-numref">18.4section</span></a>, most of the trials are stopped at 1
or 2 epochs (<span class="math notranslate nohighlight">\(r_{\mathrm{min}}\)</span> or
<span class="math notranslate nohighlight">\(\eta * r_{\mathrm{min}}\)</span>). However, trials do not stop at the
same point, because they require different amount of time per epoch. If
we ran standard successive halving instead of ASHA, we would need to
synchronize our workers, before we can promote configurations to the
next rung level.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">d2l</span><span class="o">.</span><span class="n">set_figsize</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">])</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">results</span>
<span class="k">for</span> <span class="n">trial_id</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">trial_id</span><span class="o">.</span><span class="n">unique</span><span class="p">():</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;trial_id&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">trial_id</span><span class="p">]</span>
    <span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;st_tuner_time&quot;</span><span class="p">],</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;validation_error&quot;</span><span class="p">],</span>
        <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span>
    <span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;wall-clock time&quot;</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;objective function&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;objective function&#39;</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="../_images/output_sh-async_950d48_15_1.svg" src="../_images/output_sh-async_950d48_15_1.svg" />
</figure>
</section>
<section id="summary">
<h2><span class="section-number">18.5.4. </span>Summary<a class="headerlink" href="#summary" title="Link to this heading">¶</a></h2>
<p>Compared to random search, successive halving is not quite as trivial to
run in an asynchronous distributed setting. To avoid synchronisation
points, we promote configurations as quickly as possible to the next
rung level, even if this means promoting some wrong ones. In practice,
this usually does not hurt much, and the gains of asynchronous versus
synchronous scheduling are usually much higher than the loss of the
suboptimal decision making.</p>
</section>
</section>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">18.5. Asynchronous Successive Halving</a><ul>
<li><a class="reference internal" href="#objective-function">18.5.1. Objective Function</a></li>
<li><a class="reference internal" href="#asynchronous-scheduler">18.5.2. Asynchronous Scheduler</a></li>
<li><a class="reference internal" href="#visualize-the-optimization-process">18.5.3. Visualize the Optimization Process</a></li>
<li><a class="reference internal" href="#summary">18.5.4. Summary</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="sh-intro.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>18.4. Multi-Fidelity Hyperparameter Optimization</div>
         </div>
     </a>
     <a id="button-next" href="../chapter_appendix-tools-for-deep-learning/index.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>19. Appendix: Tools for Deep Learning</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>