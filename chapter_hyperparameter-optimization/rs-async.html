<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>18.3. Asynchronous Random Search &#8212; Dive into Deep Learning 1.0.3 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="18.4. Multi-Fidelity Hyperparameter Optimization" href="sh-intro.html" />
    <link rel="prev" title="18.2. Hyperparameter Optimization API" href="hyperopt-api.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index.html"><span class="section-number">18. </span>Hyperparameter Optimization</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">18.3. </span>Asynchronous Random Search</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_hyperparameter-optimization/rs-async.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="###_ALTERNATE_VERSION_BASE_LINK_###">
                  <i class="fas fa-book"></i>
                  ###_ALTERNATE_VERSION_###
              </a>
          
              <a  class="mdl-navigation__link" href="###_CURRENT_VERSION_BASE_LINK_###/d2l-en.pdf">
                  <i class="fas fa-file-pdf"></i>
                  PyTorch
              </a>
          
              <a  class="mdl-navigation__link" href="###_CURRENT_VERSION_BASE_LINK_###/d2l-en-mxnet.pdf">
                  <i class="fas fa-file-pdf"></i>
                  MXNet
              </a>
          
              <a  class="mdl-navigation__link" href="https://d2l.ai/d2l-en.zip">
                  <i class="fab fa-python"></i>
                  Notebooks
              </a>
          
              <a  class="mdl-navigation__link" href="https://courses.d2l.ai">
                  <i class="fas fa-user-graduate"></i>
                  Courses
              </a>
          
              <a  class="mdl-navigation__link" href="https://github.com/d2l-ai/d2l-en">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
          
              <a  class="mdl-navigation__link" href="https://zh.d2l.ai">
                  <i class="fas fa-external-link-alt"></i>
                  中文版
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="Dive into Deep Learning"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index.html">Notation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index.html">2. Preliminaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/ndarray.html">2.1. Data Manipulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/pandas.html">2.2. Data Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/linear-algebra.html">2.3. Linear Algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/calculus.html">2.4. Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/autograd.html">2.5. Automatic Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/probability.html">2.6. Probability and Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/lookup-api.html">2.7. Documentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-regression/index.html">3. Linear Neural Networks for Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression.html">3.1. Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/oo-design.html">3.2. Object-Oriented Design for Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/synthetic-regression-data.html">3.3. Synthetic Regression Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-scratch.html">3.4. Linear Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-concise.html">3.5. Concise Implementation of Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/generalization.html">3.6. Generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/weight-decay.html">3.7. Weight Decay</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-classification/index.html">4. Linear Neural Networks for Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression.html">4.1. Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/image-classification-dataset.html">4.2. The Image Classification Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/classification.html">4.3. The Base Classification Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression-scratch.html">4.4. Softmax Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression-concise.html">4.5. Concise Implementation of Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/generalization-classification.html">4.6. Generalization in Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/environment-and-distribution-shift.html">4.7. Environment and Distribution Shift</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multilayer-perceptrons/index.html">5. Multilayer Perceptrons</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp.html">5.1. Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-implementation.html">5.2. Implementation of Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/backprop.html">5.3. Forward Propagation, Backward Propagation, and Computational Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html">5.4. Numerical Stability and Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/generalization-deep.html">5.5. Generalization in Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/dropout.html">5.6. Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/kaggle-house-price.html">5.7. Predicting House Prices on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_builders-guide/index.html">6. Builders’ Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/model-construction.html">6.1. Layers and Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/parameters.html">6.2. Parameter Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/init-param.html">6.3. Parameter Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/custom-layer.html">6.4. Custom Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/read-write.html">6.5. File I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/use-gpu.html">6.6. GPUs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-neural-networks/index.html">7. Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/why-conv.html">7.1. From Fully Connected Layers to Convolutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/conv-layer.html">7.2. Convolutions for Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/padding-and-strides.html">7.3. Padding and Stride</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/channels.html">7.4. Multiple Input and Multiple Output Channels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/pooling.html">7.5. Pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/lenet.html">7.6. Convolutional Neural Networks (LeNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-modern/index.html">8. Modern Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/alexnet.html">8.1. Deep Convolutional Neural Networks (AlexNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/googlenet.html">8.2. Multi-Branch Networks (GoogLeNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/batch-norm.html">8.3. Batch Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/resnet.html">8.4. Residual Networks (ResNet) and ResNeXt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/densenet.html">8.5. Densely Connected Networks (DenseNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-neural-networks/index.html">9. Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/sequence.html">9.1. Working with Sequences</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/text-sequence.html">9.2. Converting Raw Text into Sequence Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/language-model.html">9.3. Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn.html">9.4. Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-scratch.html">9.5. Recurrent Neural Network Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-concise.html">9.6. Concise Implementation of Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/bptt.html">9.7. Backpropagation Through Time</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-modern/index.html">10. Modern Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/lstm.html">10.1. Long Short-Term Memory (LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/gru.html">10.2. Gated Recurrent Units (GRU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/deep-rnn.html">10.3. Deep Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/machine-translation-and-dataset.html">10.4. Machine Translation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/encoder-decoder.html">10.5. The Encoder–Decoder Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/seq2seq.html">10.6. Sequence-to-Sequence Learning for Machine Translation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/beam-search.html">10.7. Beam Search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/index.html">11. Attention Mechanisms and Transformers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html">11.1. Queries, Keys, and Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html">11.2. Attention Pooling by Similarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html">11.3. Attention Scoring Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html">11.4. The Bahdanau Attention Mechanism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html">11.5. Multi-Head Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html">11.6. Self-Attention and Positional Encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/transformer.html">11.7. The Transformer Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html">11.8. Transformers for Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html">11.9. Large-Scale Pretraining with Transformers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_optimization/index.html">12. Optimization Algorithms</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro.html">12.1. Optimization and Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/convexity.html">12.2. Convexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/gd.html">12.3. Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/sgd.html">12.4. Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/minibatch-sgd.html">12.5. Minibatch Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/momentum.html">12.6. Momentum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adagrad.html">12.7. Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/rmsprop.html">12.8. RMSProp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adadelta.html">12.9. Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adam.html">12.10. Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/lr-scheduler.html">12.11. Learning Rate Scheduling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computer-vision/index.html">13. Computer Vision</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/image-augmentation.html">13.1. Image Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fine-tuning.html">13.2. Fine-Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/bounding-box.html">13.3. Object Detection and Bounding Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/anchor.html">13.4. Anchor Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/multiscale-object-detection.html">13.5. Multiscale Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/object-detection-dataset.html">13.6. The Object Detection Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/ssd.html">13.7. Single Shot Multibox Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/rcnn.html">13.8. Region-based CNNs (R-CNNs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/semantic-segmentation-and-dataset.html">13.9. Semantic Segmentation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/transposed-conv.html">13.10. Transposed Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fcn.html">13.11. Fully Convolutional Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/neural-style.html">13.12. Neural Style Transfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-cifar10.html">13.13. Image Classification (CIFAR-10) on Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-dog.html">13.14. Dog Breed Identification (ImageNet Dogs) on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/index.html">14. Natural Language Processing: Pretraining</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec.html">14.1. Word Embedding (word2vec)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/approx-training.html">14.2. Approximate Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html">14.3. The Dataset for Pretraining Word Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html">14.4. Pretraining word2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/glove.html">14.5. Word Embedding with Global Vectors (GloVe)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/subword-embedding.html">14.6. Subword Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/similarity-analogy.html">14.7. Word Similarity and Analogy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert.html">14.8. Bidirectional Encoder Representations from Transformers (BERT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-dataset.html">14.9. The Dataset for Pretraining BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-pretraining.html">14.10. Pretraining BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-applications/index.html">15. Natural Language Processing: Applications</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html">15.1. Sentiment Analysis and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html">15.2. Sentiment Analysis: Using Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html">15.3. Natural Language Inference and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html">15.4. Natural Language Inference: Using Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/finetuning-bert.html">15.5. Fine-Tuning BERT for Sequence-Level and Token-Level Applications</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement-learning/index.html">16. Reinforcement Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/mdp.html">16.1. Markov Decision Process (MDP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/value-iter.html">16.2. Value Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/qlearning.html">16.3. Q-Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_gaussian-processes/index.html">17. Gaussian Processes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-intro.html">17.1. Introduction to Gaussian Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-priors.html">17.2. Gaussian Process Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-inference.html">17.3. Gaussian Process Inference</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">18. Hyperparameter Optimization</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="hyperopt-intro.html">18.1. What Is Hyperparameter Optimization?</a></li>
<li class="toctree-l2"><a class="reference internal" href="hyperopt-api.html">18.2. Hyperparameter Optimization API</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">18.3. Asynchronous Random Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="sh-intro.html">18.4. Multi-Fidelity Hyperparameter Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="sh-async.html">18.5. Asynchronous Successive Halving</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/index.html">19. Appendix: Tools for Deep Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/utils.html">19.1. Utility Functions and Classes</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="Dive into Deep Learning"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index.html">Notation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index.html">2. Preliminaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/ndarray.html">2.1. Data Manipulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/pandas.html">2.2. Data Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/linear-algebra.html">2.3. Linear Algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/calculus.html">2.4. Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/autograd.html">2.5. Automatic Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/probability.html">2.6. Probability and Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/lookup-api.html">2.7. Documentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-regression/index.html">3. Linear Neural Networks for Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression.html">3.1. Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/oo-design.html">3.2. Object-Oriented Design for Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/synthetic-regression-data.html">3.3. Synthetic Regression Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-scratch.html">3.4. Linear Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-concise.html">3.5. Concise Implementation of Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/generalization.html">3.6. Generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/weight-decay.html">3.7. Weight Decay</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-classification/index.html">4. Linear Neural Networks for Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression.html">4.1. Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/image-classification-dataset.html">4.2. The Image Classification Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/classification.html">4.3. The Base Classification Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression-scratch.html">4.4. Softmax Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/softmax-regression-concise.html">4.5. Concise Implementation of Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/generalization-classification.html">4.6. Generalization in Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-classification/environment-and-distribution-shift.html">4.7. Environment and Distribution Shift</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multilayer-perceptrons/index.html">5. Multilayer Perceptrons</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp.html">5.1. Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-implementation.html">5.2. Implementation of Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/backprop.html">5.3. Forward Propagation, Backward Propagation, and Computational Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html">5.4. Numerical Stability and Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/generalization-deep.html">5.5. Generalization in Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/dropout.html">5.6. Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/kaggle-house-price.html">5.7. Predicting House Prices on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_builders-guide/index.html">6. Builders’ Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/model-construction.html">6.1. Layers and Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/parameters.html">6.2. Parameter Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/init-param.html">6.3. Parameter Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/custom-layer.html">6.4. Custom Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/read-write.html">6.5. File I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/use-gpu.html">6.6. GPUs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-neural-networks/index.html">7. Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/why-conv.html">7.1. From Fully Connected Layers to Convolutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/conv-layer.html">7.2. Convolutions for Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/padding-and-strides.html">7.3. Padding and Stride</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/channels.html">7.4. Multiple Input and Multiple Output Channels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/pooling.html">7.5. Pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/lenet.html">7.6. Convolutional Neural Networks (LeNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-modern/index.html">8. Modern Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/alexnet.html">8.1. Deep Convolutional Neural Networks (AlexNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/googlenet.html">8.2. Multi-Branch Networks (GoogLeNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/batch-norm.html">8.3. Batch Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/resnet.html">8.4. Residual Networks (ResNet) and ResNeXt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/densenet.html">8.5. Densely Connected Networks (DenseNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-neural-networks/index.html">9. Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/sequence.html">9.1. Working with Sequences</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/text-sequence.html">9.2. Converting Raw Text into Sequence Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/language-model.html">9.3. Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn.html">9.4. Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-scratch.html">9.5. Recurrent Neural Network Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-concise.html">9.6. Concise Implementation of Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/bptt.html">9.7. Backpropagation Through Time</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-modern/index.html">10. Modern Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/lstm.html">10.1. Long Short-Term Memory (LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/gru.html">10.2. Gated Recurrent Units (GRU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/deep-rnn.html">10.3. Deep Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/machine-translation-and-dataset.html">10.4. Machine Translation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/encoder-decoder.html">10.5. The Encoder–Decoder Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/seq2seq.html">10.6. Sequence-to-Sequence Learning for Machine Translation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/beam-search.html">10.7. Beam Search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/index.html">11. Attention Mechanisms and Transformers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html">11.1. Queries, Keys, and Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html">11.2. Attention Pooling by Similarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html">11.3. Attention Scoring Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html">11.4. The Bahdanau Attention Mechanism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html">11.5. Multi-Head Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html">11.6. Self-Attention and Positional Encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/transformer.html">11.7. The Transformer Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html">11.8. Transformers for Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html">11.9. Large-Scale Pretraining with Transformers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_optimization/index.html">12. Optimization Algorithms</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro.html">12.1. Optimization and Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/convexity.html">12.2. Convexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/gd.html">12.3. Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/sgd.html">12.4. Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/minibatch-sgd.html">12.5. Minibatch Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/momentum.html">12.6. Momentum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adagrad.html">12.7. Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/rmsprop.html">12.8. RMSProp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adadelta.html">12.9. Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adam.html">12.10. Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/lr-scheduler.html">12.11. Learning Rate Scheduling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computer-vision/index.html">13. Computer Vision</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/image-augmentation.html">13.1. Image Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fine-tuning.html">13.2. Fine-Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/bounding-box.html">13.3. Object Detection and Bounding Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/anchor.html">13.4. Anchor Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/multiscale-object-detection.html">13.5. Multiscale Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/object-detection-dataset.html">13.6. The Object Detection Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/ssd.html">13.7. Single Shot Multibox Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/rcnn.html">13.8. Region-based CNNs (R-CNNs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/semantic-segmentation-and-dataset.html">13.9. Semantic Segmentation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/transposed-conv.html">13.10. Transposed Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fcn.html">13.11. Fully Convolutional Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/neural-style.html">13.12. Neural Style Transfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-cifar10.html">13.13. Image Classification (CIFAR-10) on Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-dog.html">13.14. Dog Breed Identification (ImageNet Dogs) on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/index.html">14. Natural Language Processing: Pretraining</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec.html">14.1. Word Embedding (word2vec)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/approx-training.html">14.2. Approximate Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html">14.3. The Dataset for Pretraining Word Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html">14.4. Pretraining word2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/glove.html">14.5. Word Embedding with Global Vectors (GloVe)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/subword-embedding.html">14.6. Subword Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/similarity-analogy.html">14.7. Word Similarity and Analogy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert.html">14.8. Bidirectional Encoder Representations from Transformers (BERT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-dataset.html">14.9. The Dataset for Pretraining BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-pretraining.html">14.10. Pretraining BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-applications/index.html">15. Natural Language Processing: Applications</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html">15.1. Sentiment Analysis and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html">15.2. Sentiment Analysis: Using Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html">15.3. Natural Language Inference and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html">15.4. Natural Language Inference: Using Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/finetuning-bert.html">15.5. Fine-Tuning BERT for Sequence-Level and Token-Level Applications</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement-learning/index.html">16. Reinforcement Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/mdp.html">16.1. Markov Decision Process (MDP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/value-iter.html">16.2. Value Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/qlearning.html">16.3. Q-Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_gaussian-processes/index.html">17. Gaussian Processes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-intro.html">17.1. Introduction to Gaussian Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-priors.html">17.2. Gaussian Process Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-inference.html">17.3. Gaussian Process Inference</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">18. Hyperparameter Optimization</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="hyperopt-intro.html">18.1. What Is Hyperparameter Optimization?</a></li>
<li class="toctree-l2"><a class="reference internal" href="hyperopt-api.html">18.2. Hyperparameter Optimization API</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">18.3. Asynchronous Random Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="sh-intro.html">18.4. Multi-Fidelity Hyperparameter Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="sh-async.html">18.5. Asynchronous Successive Halving</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/index.html">19. Appendix: Tools for Deep Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/utils.html">19.1. Utility Functions and Classes</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <section id="asynchronous-random-search">
<span id="sec-rs-async"></span><h1><span class="section-number">18.3. </span>Asynchronous Random Search<a class="headerlink" href="#asynchronous-random-search" title="Permalink to this heading">¶</a></h1>
<p>As we have seen in the previous <a class="reference internal" href="hyperopt-api.html#sec-api-hpo"><span class="std std-numref">Section 18.2</span></a>, we might have
to wait hours or even days before random search returns a good
hyperparameter configuration, because of the expensive evaluation of
hyperparameter configurations. In practice, we have often access to a
pool of resources such as multiple GPUs on the same machine or multiple
machines with a single GPU. This begs the question: <em>How do we
efficiently distribute random search?</em></p>
<p>In general, we distinguish between synchronous and asynchronous parallel
hyperparameter optimization (see <a class="reference internal" href="#distributed-scheduling"><span class="std std-numref">Fig. 18.3.1</span></a>). In
the synchronous setting, we wait for all concurrently running trials to
finish, before we start the next batch. Consider configuration spaces
that contain hyperparameters such as the number of filters or number of
layers of a deep neural network. Hyperparameter configurations that
contain a larger number of layers of filters will naturally take more
time to finish, and all other trials in the same batch will have to wait
at synchronisation points (grey area in
<a class="reference internal" href="#distributed-scheduling"><span class="std std-numref">Fig. 18.3.1</span></a>) before we can continue the
optimization process.</p>
<p>In the asynchronous setting we immediately schedule a new trial as soon
as resources become available. This will optimally exploit our
resources, since we can avoid any synchronisation overhead. For random
search, each new hyperparameter configuration is chosen independently of
all others, and in particular without exploiting observations from any
prior evaluation. This means we can trivially parallelize random search
asynchronously. This is not straight-forward with more sophisticated
methods that make decision based on previous observations (see
<a class="reference internal" href="sh-async.html#sec-sh-async"><span class="std std-numref">Section 18.5</span></a>). While we need access to more resources than
in the sequential setting, asynchronous random search exhibits a linear
speed-up, in that a certain performance is reached <span class="math notranslate nohighlight">\(K\)</span> times
faster if <span class="math notranslate nohighlight">\(K\)</span> trials can be run in parallel.</p>
<figure class="align-default" id="id2">
<span id="distributed-scheduling"></span><img alt="img/distributed_scheduling.svg" src="img/distributed_scheduling.svg" /><figcaption>
<p><span class="caption-number">Fig. 18.3.1 </span><span class="caption-text">Distributing the hyperparameter optimization process either
synchronously or asynchronously. Compared to the sequential setting,
we can reduce the overall wall-clock time while keep the total
compute constant. Synchronous scheduling might lead to idling workers
in the case of stragglers.</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>In this notebook, we will look at asynchronous random search that, where
trials are executed in multiple python processes on the same machine.
Distributed job scheduling and execution is difficult to implement from
scratch. We will use <em>Syne Tune</em> <span id="id1">()</span>, which
provides us with a simple interface for asynchronous HPO. Syne Tune is
designed to be run with different execution back-ends, and the
interested reader is invited to study its simple APIs in order to learn
more about distributed HPO.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">d2l</span><span class="w"> </span><span class="kn">import</span> <span class="n">mlx</span> <span class="k">as</span> <span class="n">d2l</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">syne_tune</span><span class="w"> </span><span class="kn">import</span> <span class="n">StoppingCriterion</span><span class="p">,</span> <span class="n">Tuner</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">syne_tune.backend</span><span class="w"> </span><span class="kn">import</span> <span class="n">PythonBackend</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">syne_tune.config_space</span><span class="w"> </span><span class="kn">import</span> <span class="n">loguniform</span><span class="p">,</span> <span class="n">randint</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">syne_tune.experiments</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_experiment</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">syne_tune.optimizer.baselines</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomSearch</span>
</pre></div>
</div>
<section id="objective-function">
<h2><span class="section-number">18.3.1. </span>Objective Function<a class="headerlink" href="#objective-function" title="Permalink to this heading">¶</a></h2>
<p>First, we have to define a new objective function such that it now
returns the performance back to Syne Tune via the <code class="docutils literal notranslate"><span class="pre">report</span></code> callback.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">hpo_objective_lenet_synetune</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">):</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">syne_tune</span><span class="w"> </span><span class="kn">import</span> <span class="n">Reporter</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">d2l</span><span class="w"> </span><span class="kn">import</span> <span class="n">mlx</span> <span class="k">as</span> <span class="n">d2l</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">LeNet</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">HPOTrainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
    <span class="n">report</span> <span class="o">=</span> <span class="n">Reporter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">fit_epoch</span><span class="p">()</span>
        <span class="n">val_err</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">validation_error</span><span class="p">()</span>
        <span class="n">report</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">validation_error</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">val_err</span><span class="p">))</span>
</pre></div>
</div>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">PythonBackend</span></code> of Syne Tune requires dependencies to be
imported inside the function definition.</p>
</section>
<section id="asynchronous-scheduler">
<h2><span class="section-number">18.3.2. </span>Asynchronous Scheduler<a class="headerlink" href="#asynchronous-scheduler" title="Permalink to this heading">¶</a></h2>
<p>First, we define the number of workers that evaluate trials
concurrently. We also need to specify how long we want to run random
search, by defining an upper limit on the total wall-clock time.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">n_workers</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Needs to be &lt;= the number of available GPUs</span>

<span class="n">max_wallclock_time</span> <span class="o">=</span> <span class="mi">12</span> <span class="o">*</span> <span class="mi">60</span>  <span class="c1"># 12 minutes</span>
</pre></div>
</div>
<p>Next, we state which metric we want to optimize and whether we want to
minimize or maximize this metric. Namely, <code class="docutils literal notranslate"><span class="pre">metric</span></code> needs to correspond
to the argument name passed to the <code class="docutils literal notranslate"><span class="pre">report</span></code> callback.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mode = &quot;min&quot;</span>
<span class="n">metric</span> <span class="o">=</span> <span class="s2">&quot;validation_error&quot;</span>
</pre></div>
</div>
<p>We use the configuration space from our previous example. In Syne Tune,
this dictionary can also be used to pass constant attributes to the
training script. We make use of this feature in order to pass
<code class="docutils literal notranslate"><span class="pre">max_epochs</span></code>. Moreover, we specify the first configuration to be
evaluated in <code class="docutils literal notranslate"><span class="pre">initial_config</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">config_space</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">loguniform</span><span class="p">(</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">randint</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
    <span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">initial_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Next, we need to specify the back-end for job executions. Here we just
consider the distribution on a local machine where parallel jobs are
executed as sub-processes. However, for large scale HPO, we could run
this also on a cluster or cloud environment, where each trial consumes a
full instance.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trial_backend</span> <span class="o">=</span> <span class="n">PythonBackend</span><span class="p">(</span>
    <span class="n">tune_function</span><span class="o">=</span><span class="n">hpo_objective_lenet_synetune</span><span class="p">,</span>
    <span class="n">config_space</span><span class="o">=</span><span class="n">config_space</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>We can now create the scheduler for asynchronous random search, which is
similar in behaviour to our <code class="docutils literal notranslate"><span class="pre">BasicScheduler</span></code> from
<a class="reference internal" href="hyperopt-api.html#sec-api-hpo"><span class="std std-numref">Section 18.2</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">RandomSearch</span><span class="p">(</span>
    <span class="n">config_space</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;validation_error&quot;</span><span class="p">],</span>
    <span class="n">do_minimize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">points_to_evaluate</span><span class="o">=</span><span class="p">[</span><span class="n">initial_config</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Syne Tune also features a <code class="docutils literal notranslate"><span class="pre">Tuner</span></code>, where the main experiment loop and
bookkeeping is centralized, and interactions between scheduler and
back-end are mediated.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">stop_criterion</span> <span class="o">=</span> <span class="n">StoppingCriterion</span><span class="p">(</span><span class="n">max_wallclock_time</span><span class="o">=</span><span class="n">max_wallclock_time</span><span class="p">)</span>

<span class="n">tuner</span> <span class="o">=</span> <span class="n">Tuner</span><span class="p">(</span>
    <span class="n">trial_backend</span><span class="o">=</span><span class="n">trial_backend</span><span class="p">,</span>
    <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
    <span class="n">stop_criterion</span><span class="o">=</span><span class="n">stop_criterion</span><span class="p">,</span>
    <span class="n">n_workers</span><span class="o">=</span><span class="n">n_workers</span><span class="p">,</span>
    <span class="n">print_update_interval</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">max_wallclock_time</span> <span class="o">*</span> <span class="mf">0.6</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Let us run our distributed HPO experiment. According to our stopping
criterion, it will run for about 12 minutes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tuner</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">results</span> <span class="n">of</span> <span class="n">trials</span> <span class="n">will</span> <span class="n">be</span> <span class="n">saved</span> <span class="n">on</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">Error</span> <span class="n">launching</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">nvidia</span><span class="o">-</span><span class="n">smi</span><span class="p">,</span> <span class="n">no</span> <span class="n">GPU</span> <span class="n">could</span> <span class="n">be</span> <span class="n">detected</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">Detected</span> <span class="mi">0</span> <span class="n">GPUs</span>
<span class="n">WARNING</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">num_gpus_per_trial</span> <span class="o">=</span> <span class="mi">1</span> <span class="ow">is</span> <span class="n">too</span> <span class="n">large</span><span class="p">,</span> <span class="n">reducing</span> <span class="n">to</span> <span class="mi">0</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.1</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">128</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">0</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.785419139652293</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">253</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">1</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.785419139652293</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">253</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">1</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.015451559930309012</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">55</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">2</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.015451559930309012</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">55</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">0</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.314703831688577</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">132</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">3</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">3</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.314703831688577</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">132</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">3</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.02832486312228176</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">86</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">4</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">4</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.02832486312228176</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">86</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">2</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.3114746598543795</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">220</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">5</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.3114746598543795</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">220</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">4</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">5</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.14734507957489268</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">220</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">6</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">6</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.14734507957489268</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">220</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.37475164983438675</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">159</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">7</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">7</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.37475164983438675</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">159</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">6</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.4994060435597754</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">87</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">8</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">8</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.4994060435597754</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">87</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">7</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.06238492357004281</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">54</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">9</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">9</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.06238492357004281</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">54</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">8</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.14754101174871392</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">153</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">10</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">10</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.14754101174871392</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">153</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">9</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.42188880580044036</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">88</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">11</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">11</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.42188880580044036</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">88</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">10</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.2993200275939439</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">86</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">12</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">12</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.2993200275939439</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">86</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">11</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.19147449863618432</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">91</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">13</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">13</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.19147449863618432</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">91</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">12</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.26059001016457334</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">72</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">14</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">14</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.26059001016457334</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">72</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">13</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.964713800900415</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">47</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">15</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">15</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.964713800900415</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">47</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">14</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.10696632399613491</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">248</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">16</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">16</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.10696632399613491</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">248</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">15</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.5917570853739808</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">65</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">17</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">17</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.5917570853739808</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">65</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">16</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.04447784402047958</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">80</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">18</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">18</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.04447784402047958</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">80</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">17</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.20403568510229048</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">108</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">19</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">19</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.20403568510229048</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">108</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">tuning</span> <span class="n">status</span> <span class="p">(</span><span class="n">last</span> <span class="n">metric</span> <span class="ow">is</span> <span class="n">reported</span><span class="p">)</span>
 <span class="n">trial_id</span>     <span class="n">status</span>  <span class="nb">iter</span>  <span class="n">learning_rate</span>  <span class="n">batch_size</span>  <span class="n">max_epochs</span>  <span class="n">epoch</span>  <span class="n">validation_error</span>  <span class="n">worker</span><span class="o">-</span><span class="n">time</span>
        <span class="mi">0</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.100000</span>         <span class="mi">128</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.269680</span>    <span class="mf">29.100968</span>
        <span class="mi">1</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.785419</span>         <span class="mi">253</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.211973</span>    <span class="mf">24.808257</span>
        <span class="mi">2</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.015452</span>          <span class="mi">55</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.746909</span>    <span class="mf">43.373880</span>
        <span class="mi">3</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.314704</span>         <span class="mi">132</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.198006</span>    <span class="mf">31.834912</span>
        <span class="mi">4</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.028325</span>          <span class="mi">86</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.469100</span>    <span class="mf">34.693813</span>
        <span class="mi">5</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.311475</span>         <span class="mi">220</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.238202</span>    <span class="mf">26.783766</span>
        <span class="mi">6</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.147345</span>         <span class="mi">220</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.287549</span>    <span class="mf">25.384183</span>
        <span class="mi">7</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.374752</span>         <span class="mi">159</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.233063</span>    <span class="mf">27.162082</span>
        <span class="mi">8</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.499406</span>          <span class="mi">87</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.155126</span>    <span class="mf">37.493749</span>
        <span class="mi">9</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.062385</span>          <span class="mi">54</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.278216</span>    <span class="mf">43.484688</span>
       <span class="mi">10</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.147541</span>         <span class="mi">153</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.262952</span>    <span class="mf">27.690224</span>
       <span class="mi">11</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.421889</span>          <span class="mi">88</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.152469</span>    <span class="mf">32.553498</span>
       <span class="mi">12</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.299320</span>          <span class="mi">86</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.178825</span>    <span class="mf">33.563370</span>
       <span class="mi">13</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.191474</span>          <span class="mi">91</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.226708</span>    <span class="mf">33.486506</span>
       <span class="mi">14</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.260590</span>          <span class="mi">72</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.189823</span>    <span class="mf">39.855617</span>
       <span class="mi">15</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.964714</span>          <span class="mi">47</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.121458</span>    <span class="mf">46.087984</span>
       <span class="mi">16</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.106966</span>         <span class="mi">248</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.350325</span>    <span class="mf">23.626774</span>
       <span class="mi">17</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.591757</span>          <span class="mi">65</span>          <span class="mi">10</span>   <span class="mf">10.0</span>          <span class="mf">0.262156</span>    <span class="mf">41.274113</span>
       <span class="mi">18</span> <span class="n">InProgress</span>     <span class="mi">9</span>       <span class="mf">0.044478</span>          <span class="mi">80</span>          <span class="mi">10</span>    <span class="mf">9.0</span>          <span class="mf">0.335800</span>    <span class="mf">33.564189</span>
       <span class="mi">19</span> <span class="n">InProgress</span>     <span class="mi">0</span>       <span class="mf">0.204036</span>         <span class="mi">108</span>          <span class="mi">10</span>      <span class="o">-</span>                 <span class="o">-</span>            <span class="o">-</span>
<span class="mi">2</span> <span class="n">trials</span> <span class="n">running</span><span class="p">,</span> <span class="mi">18</span> <span class="n">finished</span> <span class="p">(</span><span class="mi">18</span> <span class="n">until</span> <span class="n">the</span> <span class="n">end</span><span class="p">),</span> <span class="mf">436.03</span><span class="n">s</span> <span class="n">wallclock</span><span class="o">-</span><span class="n">time</span>

<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">18</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.7649756579068647</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">212</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">20</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">20</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.7649756579068647</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">212</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">19</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">20</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.0988395141460621</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">251</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">21</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">21</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.0988395141460621</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">251</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.701409313060209</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">90</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">22</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">22</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.701409313060209</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">90</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">21</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.7311914189829157</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">224</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">23</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">23</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.7311914189829157</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">22</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.014936836616036158</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">240</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">24</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">24</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.014936836616036158</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">240</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">23</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.13976762587971506</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">96</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">25</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">25</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.13976762587971506</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">96</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">24</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.6377240017626923</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">165</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">26</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">26</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.6377240017626923</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">165</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">25</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">26</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.01286225998599121</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">108</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">27</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">27</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.01286225998599121</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">108</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.02014490729340573</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">124</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">28</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">28</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.02014490729340573</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">124</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">27</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">28</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.1333083293327977</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">68</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">29</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">29</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.1333083293327977</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">68</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.2879408868000836</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">102</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">30</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">30</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.2879408868000836</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">102</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">30</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.011605333152295885</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">68</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">31</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.011605333152295885</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">68</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Trial</span> <span class="n">trial_id</span> <span class="mi">29</span> <span class="n">completed</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">local_backend</span><span class="p">:</span><span class="n">running</span> <span class="n">subprocess</span> <span class="k">with</span> <span class="n">command</span><span class="p">:</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">d2lbook</span><span class="o">-</span><span class="n">en</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">syne_tune</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">python_backend</span><span class="o">/</span><span class="n">python_entrypoint</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">0.01484052260681797</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">163</span> <span class="o">--</span><span class="n">max_epochs</span> <span class="mi">10</span> <span class="o">--</span><span class="n">tune_function_root</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="n">tune_function</span> <span class="o">--</span><span class="n">tune_function_hash</span> <span class="mi">2403</span><span class="n">b5305c7599b48033ce9ca0bc5baa</span> <span class="o">--</span><span class="n">st_checkpoint_dir</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span><span class="o">/</span><span class="mi">32</span><span class="o">/</span><span class="n">checkpoints</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:(</span><span class="n">trial</span> <span class="mi">32</span><span class="p">)</span> <span class="o">-</span> <span class="n">scheduled</span> <span class="n">config</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.01484052260681797</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">163</span><span class="p">,</span> <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">stopping_criterion</span><span class="p">:</span><span class="n">reaching</span> <span class="nb">max</span> <span class="n">wallclock</span> <span class="n">time</span> <span class="p">(</span><span class="mi">720</span><span class="p">),</span> <span class="n">stopping</span> <span class="n">there</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Stopping</span> <span class="n">trials</span> <span class="n">that</span> <span class="n">may</span> <span class="n">still</span> <span class="n">be</span> <span class="n">running</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">syne_tune</span><span class="o">.</span><span class="n">tuner</span><span class="p">:</span><span class="n">Tuning</span> <span class="n">finished</span><span class="p">,</span> <span class="n">results</span> <span class="n">of</span> <span class="n">trials</span> <span class="n">can</span> <span class="n">be</span> <span class="n">found</span> <span class="n">on</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">fangkeqiu</span><span class="o">/</span><span class="n">syne</span><span class="o">-</span><span class="n">tune</span><span class="o">/</span><span class="n">python</span><span class="o">-</span><span class="n">entrypoint</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">47</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">677</span>
<span class="o">--------------------</span>
<span class="n">Resource</span> <span class="n">summary</span> <span class="p">(</span><span class="n">last</span> <span class="n">result</span> <span class="ow">is</span> <span class="n">reported</span><span class="p">):</span>
 <span class="n">trial_id</span>     <span class="n">status</span>  <span class="nb">iter</span>  <span class="n">learning_rate</span>  <span class="n">batch_size</span>  <span class="n">max_epochs</span>  <span class="n">epoch</span>  <span class="n">validation_error</span>  <span class="n">worker</span><span class="o">-</span><span class="n">time</span>
        <span class="mi">0</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.100000</span>         <span class="mi">128</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.269680</span>    <span class="mf">29.100968</span>
        <span class="mi">1</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.785419</span>         <span class="mi">253</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.211973</span>    <span class="mf">24.808257</span>
        <span class="mi">2</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.015452</span>          <span class="mi">55</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.746909</span>    <span class="mf">43.373880</span>
        <span class="mi">3</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.314704</span>         <span class="mi">132</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.198006</span>    <span class="mf">31.834912</span>
        <span class="mi">4</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.028325</span>          <span class="mi">86</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.469100</span>    <span class="mf">34.693813</span>
        <span class="mi">5</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.311475</span>         <span class="mi">220</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.238202</span>    <span class="mf">26.783766</span>
        <span class="mi">6</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.147345</span>         <span class="mi">220</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.287549</span>    <span class="mf">25.384183</span>
        <span class="mi">7</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.374752</span>         <span class="mi">159</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.233063</span>    <span class="mf">27.162082</span>
        <span class="mi">8</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.499406</span>          <span class="mi">87</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.155126</span>    <span class="mf">37.493749</span>
        <span class="mi">9</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.062385</span>          <span class="mi">54</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.278216</span>    <span class="mf">43.484688</span>
       <span class="mi">10</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.147541</span>         <span class="mi">153</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.262952</span>    <span class="mf">27.690224</span>
       <span class="mi">11</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.421889</span>          <span class="mi">88</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.152469</span>    <span class="mf">32.553498</span>
       <span class="mi">12</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.299320</span>          <span class="mi">86</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.178825</span>    <span class="mf">33.563370</span>
       <span class="mi">13</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.191474</span>          <span class="mi">91</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.226708</span>    <span class="mf">33.486506</span>
       <span class="mi">14</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.260590</span>          <span class="mi">72</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.189823</span>    <span class="mf">39.855617</span>
       <span class="mi">15</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.964714</span>          <span class="mi">47</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.121458</span>    <span class="mf">46.087984</span>
       <span class="mi">16</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.106966</span>         <span class="mi">248</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.350325</span>    <span class="mf">23.626774</span>
       <span class="mi">17</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.591757</span>          <span class="mi">65</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.262156</span>    <span class="mf">41.274113</span>
       <span class="mi">18</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.044478</span>          <span class="mi">80</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.330900</span>    <span class="mf">36.690488</span>
       <span class="mi">19</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.204036</span>         <span class="mi">108</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.207319</span>    <span class="mf">32.098498</span>
       <span class="mi">20</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.764976</span>         <span class="mi">212</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.331466</span>    <span class="mf">26.470002</span>
       <span class="mi">21</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.098840</span>         <span class="mi">251</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.358084</span>    <span class="mf">25.490762</span>
       <span class="mi">22</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.701409</span>          <span class="mi">90</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.145933</span>    <span class="mf">34.306699</span>
       <span class="mi">23</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.731191</span>         <span class="mi">224</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.170778</span>    <span class="mf">24.191342</span>
       <span class="mi">24</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.014937</span>         <span class="mi">240</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.900000</span>    <span class="mf">23.009057</span>
       <span class="mi">25</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.139768</span>          <span class="mi">96</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.223214</span>    <span class="mf">31.841101</span>
       <span class="mi">26</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.637724</span>         <span class="mi">165</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.171714</span>    <span class="mf">25.903314</span>
       <span class="mi">27</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.012862</span>         <span class="mi">108</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.899822</span>    <span class="mf">33.627085</span>
       <span class="mi">28</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.020145</span>         <span class="mi">124</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.899781</span>    <span class="mf">32.135524</span>
       <span class="mi">29</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.133308</span>          <span class="mi">68</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.214130</span>    <span class="mf">41.098702</span>
       <span class="mi">30</span>  <span class="n">Completed</span>    <span class="mi">10</span>       <span class="mf">0.287941</span>         <span class="mi">102</span>          <span class="mi">10</span>     <span class="mi">10</span>          <span class="mf">0.205189</span>    <span class="mf">35.413799</span>
       <span class="mi">31</span> <span class="n">InProgress</span>     <span class="mi">7</span>       <span class="mf">0.011605</span>          <span class="mi">68</span>          <span class="mi">10</span>      <span class="mi">7</span>          <span class="mf">0.900636</span>    <span class="mf">26.102841</span>
       <span class="mi">32</span> <span class="n">InProgress</span>     <span class="mi">5</span>       <span class="mf">0.014841</span>         <span class="mi">163</span>          <span class="mi">10</span>      <span class="mi">5</span>          <span class="mf">0.899761</span>    <span class="mf">13.691636</span>
<span class="mi">2</span> <span class="n">trials</span> <span class="n">running</span><span class="p">,</span> <span class="mi">31</span> <span class="n">finished</span> <span class="p">(</span><span class="mi">31</span> <span class="n">until</span> <span class="n">the</span> <span class="n">end</span><span class="p">),</span> <span class="mf">721.94</span><span class="n">s</span> <span class="n">wallclock</span><span class="o">-</span><span class="n">time</span>

<span class="n">validation_error</span><span class="p">:</span> <span class="n">best</span> <span class="mf">0.12145810759683173</span> <span class="k">for</span> <span class="n">trial</span><span class="o">-</span><span class="nb">id</span> <span class="mi">15</span>
<span class="o">--------------------</span>
</pre></div>
</div>
<p>The logs of all evaluated hyperparameter configurations are stored for
further analysis. At any time during the tuning job, we can easily get
the results obtained so far and plot the incumbent trajectory.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">d2l</span><span class="o">.</span><span class="n">set_figsize</span><span class="p">()</span>
<span class="n">tuning_experiment</span> <span class="o">=</span> <span class="n">load_experiment</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="n">tuning_experiment</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="../_images/output_rs-async_cdba80_19_0.svg" src="../_images/output_rs-async_cdba80_19_0.svg" /></figure>
</section>
<section id="visualize-the-asynchronous-optimization-process">
<h2><span class="section-number">18.3.3. </span>Visualize the Asynchronous Optimization Process<a class="headerlink" href="#visualize-the-asynchronous-optimization-process" title="Permalink to this heading">¶</a></h2>
<p>Below we visualize how the learning curves of every trial (each color in
the plot represents a trial) evolve during the asynchronous optimization
process. At any point in time, there are as many trials running
concurrently as we have workers. Once a trial finishes, we immediately
start the next trial, without waiting for the other trials to finish.
Idle time of workers is reduced to a minimum with asynchronous
scheduling.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">d2l</span><span class="o">.</span><span class="n">set_figsize</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">])</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">tuning_experiment</span><span class="o">.</span><span class="n">results</span>

<span class="k">for</span> <span class="n">trial_id</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">trial_id</span><span class="o">.</span><span class="n">unique</span><span class="p">():</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;trial_id&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">trial_id</span><span class="p">]</span>
    <span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;st_tuner_time&quot;</span><span class="p">],</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;validation_error&quot;</span><span class="p">],</span>
        <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span>
    <span class="p">)</span>

<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;wall-clock time&quot;</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;objective function&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;objective function&#39;</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="../_images/output_rs-async_cdba80_21_1.svg" src="../_images/output_rs-async_cdba80_21_1.svg" /></figure>
</section>
<section id="summary">
<h2><span class="section-number">18.3.4. </span>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">¶</a></h2>
<p>We can reduce the waiting time for random search substantially by
distribution trials across parallel resources. In general, we
distinguish between synchronous scheduling and asynchronous scheduling.
Synchronous scheduling means that we sample a new batch of
hyperparameter configurations once the previous batch finished. If we
have a stragglers - trials that takes more time to finish than other
trials - our workers need to wait at synchronization points.
Asynchronous scheduling evaluates a new hyperparameter configurations as
soon as resources become available, and, hence, ensures that all workers
are busy at any point in time. While random search is easy to distribute
asynchronously and does not require any change of the actual algorithm,
other methods require some additional modifications.</p>
</section>
<section id="exercises">
<h2><span class="section-number">18.3.5. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p>Consider the <code class="docutils literal notranslate"><span class="pre">DropoutMLP</span></code> model implemented in
<a class="reference internal" href="../chapter_multilayer-perceptrons/dropout.html#sec-dropout"><span class="std std-numref">Section 5.6</span></a>, and used in Exercise 1 of
<a class="reference internal" href="hyperopt-api.html#sec-api-hpo"><span class="std std-numref">Section 18.2</span></a>.</p>
<ol class="arabic simple">
<li><p>Implement an objective function
<code class="docutils literal notranslate"><span class="pre">hpo_objective_dropoutmlp_synetune</span></code> to be used with Syne Tune.
Make sure that your function reports the validation error after
every epoch.</p></li>
<li><p>Using the setup of Exercise 1 in <a class="reference internal" href="hyperopt-api.html#sec-api-hpo"><span class="std std-numref">Section 18.2</span></a>, compare
random search to Bayesian optimization. If you use SageMaker, feel
free to use Syne Tune’s benchmarking facilities in order to run
experiments in parallel. Hint: Bayesian optimization is provided
as <code class="docutils literal notranslate"><span class="pre">syne_tune.optimizer.baselines.BayesianOptimization</span></code>.</p></li>
<li><p>For this exercise, you need to run on an instance with at least 4
CPU cores. For one of the methods used above (random search,
Bayesian optimization), run experiments with <code class="docutils literal notranslate"><span class="pre">n_workers=1</span></code>,
<code class="docutils literal notranslate"><span class="pre">n_workers=2</span></code>, <code class="docutils literal notranslate"><span class="pre">n_workers=4</span></code>, and compare results (incumbent
trajectories). At least for random search, you should observe
linear scaling with respect to the number of workers. Hint: For
robust results, you may have to average over several repetitions
each.</p></li>
</ol>
</li>
<li><p><em>Advanced</em>. The goal of this exercise is to implement a new scheduler
in Syne Tune.</p>
<ol class="arabic simple">
<li><p>Create a virtual environment containing both the
<a class="reference external" href="https://github.com/d2l-ai/d2l-en/blob/master/INFO.md#installation-for-developers">d2lbook</a>
and
<a class="reference external" href="https://syne-tune.readthedocs.io/en/latest/getting_started.html">syne-tune</a>
sources.</p></li>
<li><p>Implement the <code class="docutils literal notranslate"><span class="pre">LocalSearcher</span></code> from Exercise 2 in
<a class="reference internal" href="hyperopt-api.html#sec-api-hpo"><span class="std std-numref">Section 18.2</span></a> as a new searcher in Syne Tune. Hint: Read
<a class="reference external" href="https://syne-tune.readthedocs.io/en/latest/tutorials/developer/README.html">this
tutorial</a>.
Alternatively, you may follow this
<a class="reference external" href="https://syne-tune.readthedocs.io/en/latest/examples.html#launch-hpo-experiment-with-home-made-scheduler">example</a>.</p></li>
<li><p>Compare your new <code class="docutils literal notranslate"><span class="pre">LocalSearcher</span></code> with <code class="docutils literal notranslate"><span class="pre">RandomSearch</span></code> on the
<code class="docutils literal notranslate"><span class="pre">DropoutMLP</span></code> benchmark.</p></li>
</ol>
</li>
</ol>
</section>
</section>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">18.3. Asynchronous Random Search</a><ul>
<li><a class="reference internal" href="#objective-function">18.3.1. Objective Function</a></li>
<li><a class="reference internal" href="#asynchronous-scheduler">18.3.2. Asynchronous Scheduler</a></li>
<li><a class="reference internal" href="#visualize-the-asynchronous-optimization-process">18.3.3. Visualize the Asynchronous Optimization Process</a></li>
<li><a class="reference internal" href="#summary">18.3.4. Summary</a></li>
<li><a class="reference internal" href="#exercises">18.3.5. Exercises</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="hyperopt-api.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>18.2. Hyperparameter Optimization API</div>
         </div>
     </a>
     <a id="button-next" href="sh-intro.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>18.4. Multi-Fidelity Hyperparameter Optimization</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>