Search.setIndex({"alltitles": {"1\\times 1 Convolutional Layer": [[40, "times-1-convolutional-layer"]], "A Custom Module": [[15, "a-custom-module"]], "A More Formal Treatment": [[121, "a-more-formal-treatment"]], "A Motivating Example": [[58, "a-motivating-example"]], "A Simple Example: Tossing Coins": [[121, "a-simple-example-tossing-coins"]], "A Simple Function": [[114, "a-simple-function"]], "A Simple Gaussian Process": [[49, "a-simple-gaussian-process"]], "A Taxonomy of Learning Problems": [[60, "a-taxonomy-of-learning-problems"]], "About This Book": [[113, "about-this-book"]], "Absolute Positional Information": [[9, "absolute-positional-information"]], "Accessing and Reading the Dataset": [[79, "accessing-and-reading-the-dataset"]], "Accuracy": [[59, "accuracy"]], "Acknowledgments": [[113, "acknowledgments"]], "Action-Value Function": [[141, "action-value-function"]], "Activation Functions": [[34, "activation-functions"], [80, "activation-functions"]], "Adadelta": [[101, null]], "Adagrad": [[102, null]], "Adam": [[103, null]], "Adapting Attention Pooling": [[2, "adapting-attention-pooling"]], "Adaptive Methods": [[105, "adaptive-methods"]], "Additive Attention": [[3, "additive-attention"]], "Aggregating": [[86, "aggregating"]], "AlexNet": [[34, "alexnet"]], "All Parameters at Once": [[16, "all-parameters-at-once"]], "An Example": [[19, "an-example"], [121, "an-example"]], "An Ill-conditioned Problem": [[109, "an-ill-conditioned-problem"]], "An Optimization Problem Underlying Q-Learning": [[140, "an-optimization-problem-underlying-q-learning"]], "Analysis of Gradients in RNNs": [[130, "analysis-of-gradients-in-rnns"]], "Analytic Solution": [[69, "analytic-solution"]], "Anchor Boxes": [[19, null]], "Appendix: Tools for Deep Learning": [[0, null]], "Applying Pretrained Word Vectors": [[95, "applying-pretrained-word-vectors"]], "Applying Word Embeddings": [[99, "applying-word-embeddings"]], "Approximate Training": [[89, null]], "Architecture": [[34, "architecture"]], "Assigning Ground-Truth Bounding Boxes to Anchor Boxes": [[19, "assigning-ground-truth-bounding-boxes-to-anchor-boxes"]], "Asynchronous Random Search": [[54, null]], "Asynchronous Scheduler": [[54, "asynchronous-scheduler"], [55, "asynchronous-scheduler"]], "Asynchronous Successive Halving": [[55, null]], "Attending": [[86, "attending"]], "Attention Mechanisms and Transformers": [[5, null]], "Attention Pooling by Similarity": [[2, null]], "Attention Pooling via Nadaraya\u2013Watson Regression": [[2, "attention-pooling-via-nadarayawatson-regression"]], "Attention Scoring Functions": [[3, null]], "Automatic Differentiation": [[114, null]], "Autoregressive Models": [[136, "autoregressive-models"]], "BERT: Combining the Best of Both Worlds": [[90, "bert-combining-the-best-of-both-worlds"]], "Backpropagation": [[75, "backpropagation"]], "Backpropagation Through Time": [[130, null]], "Backpropagation Through Time in Detail": [[130, "backpropagation-through-time-in-detail"]], "Backward for Non-Scalar Variables": [[114, "backward-for-non-scalar-variables"]], "Bandits": [[60, "bandits"]], "Base Network Block": [[32, "base-network-block"]], "Basic Operation": [[33, "basic-operation"]], "Basic Properties of Tensor Arithmetic": [[117, "basic-properties-of-tensor-arithmetic"]], "Basics": [[69, "basics"], [109, "basics"]], "Batch Learning": [[60, "batch-learning"]], "Batch Matrix Multiplication": [[3, "batch-matrix-multiplication"]], "Batch Normalization": [[35, null]], "Batch Normalization During Prediction": [[35, "batch-normalization-during-prediction"]], "Batch Normalization Layers": [[35, "batch-normalization-layers"]], "Beam Search": [[122, null], [122, "id1"]], "Below Sets of Convex Functions Are Convex": [[104, "below-sets-of-convex-functions-are-convex"]], "Beyond": [[82, "beyond"]], "Bidirectional Encoder Representations from Transformers (BERT)": [[90, null]], "Binary Cross-Entropy Loss": [[99, "binary-cross-entropy-loss"]], "Biology": [[69, "biology"]], "Bookkeeping the Performance of HPO Algorithms": [[51, "bookkeeping-the-performance-of-hpo-algorithms"]], "Bounding Box Prediction Layer": [[32, "bounding-box-prediction-layer"]], "Bounding Boxes": [[20, "bounding-boxes"]], "Breaking the Symmetry": [[82, "breaking-the-symmetry"]], "Broadcasting": [[119, "broadcasting"]], "Builders\u2019 Guide": [[13, null]], "Built-in Initialization": [[14, "built-in-initialization"]], "Byte Pair Encoding": [[96, "byte-pair-encoding"]], "Calculus": [[100, "calculus"], [115, null]], "Candidate Hidden State": [[125, "candidate-hidden-state"]], "Capacity Control and Preprocessing": [[34, "capacity-control-and-preprocessing"]], "Chain Rule": [[115, "chain-rule"]], "Changing Colors": [[23, "changing-colors"]], "Channels": [[46, "channels"]], "Class Prediction Layer": [[32, "class-prediction-layer"]], "Classical Regularization Methods for Deep Networks": [[77, "classical-regularization-methods-for-deep-networks"]], "Classification": [[58, "classification"], [64, "classification"]], "Classifying the Testing Set and Submitting Results on Kaggle": [[25, "classifying-the-testing-set-and-submitting-results-on-kaggle"], [26, "classifying-the-testing-set-and-submitting-results-on-kaggle"]], "Code": [[113, "code"]], "Combining Multiple Image Augmentation Methods": [[23, "combining-multiple-image-augmentation-methods"]], "Common Image Augmentation Methods": [[23, "common-image-augmentation-methods"]], "Comparing": [[86, "comparing"]], "Comparing CNNs, RNNs, and Self-Attention": [[9, "comparing-cnns-rnns-and-self-attention"]], "Comparing HPO Algorithms": [[51, "comparing-hpo-algorithms"]], "Comparing Strategies": [[130, "comparing-strategies"]], "Computational Graph of Forward Propagation": [[75, "computational-graph-of-forward-propagation"]], "Computer Vision": [[24, null]], "Computing Devices": [[18, "computing-devices"]], "Concatenating Predictions for Multiple Scales": [[32, "concatenating-predictions-for-multiple-scales"]], "Concept Shift": [[60, "concept-shift"]], "Concept Shift Correction": [[60, "concept-shift-correction"]], "Concise Implementation": [[35, "concise-implementation"], [74, "concise-implementation"], [76, "concise-implementation"], [81, "concise-implementation"], [102, "concise-implementation"], [108, "concise-implementation"], [109, "concise-implementation"], [111, "concise-implementation"], [123, "concise-implementation"], [125, "concise-implementation"], [127, "concise-implementation"]], "Concise Implementation of Linear Regression": [[70, null]], "Concise Implementation of Recurrent Neural Networks": [[134, null]], "Concise Implementation of Softmax Regression": [[65, null]], "Concise Implementation of the Data Loader": [[73, "concise-implementation-of-the-data-loader"]], "Connection to Matrix Transposition": [[33, "connection-to-matrix-transposition"]], "Considering the Environment": [[60, "considering-the-environment"]], "Constraining the MLP": [[46, "constraining-the-mlp"]], "Constraints": [[104, "constraints"]], "Content Loss": [[28, "content-loss"]], "Content and Structure": [[113, "content-and-structure"]], "Control": [[60, "control"]], "Convenience Functions": [[3, "convenience-functions"]], "Convergence Analysis": [[105, "convergence-analysis"]], "Convergence Analysis for Convex Objectives": [[112, "convergence-analysis-for-convex-objectives"]], "Conversion to Other Python Objects": [[119, "conversion-to-other-python-objects"]], "Conversion to the Tensor Format": [[120, "conversion-to-the-tensor-format"]], "Converting Raw Text into Sequence Data": [[137, null]], "Convex Functions": [[104, "convex-functions"]], "Convex Sets": [[104, "convex-sets"]], "Convexity": [[104, null]], "Convexity and Second Derivatives": [[104, "convexity-and-second-derivatives"]], "Convolutional Layers": [[35, "convolutional-layers"], [41, "convolutional-layers"]], "Convolutional Neural Networks": [[42, null]], "Convolutional Neural Networks (LeNet)": [[43, null]], "Convolutions": [[46, "convolutions"]], "Convolutions for Images": [[41, null]], "Copying": [[18, "copying"]], "Correction of Distribution Shift": [[60, "correction-of-distribution-shift"]], "Cosine Scheduler": [[107, "cosine-scheduler"]], "Covariate Shift": [[60, "covariate-shift"]], "Covariate Shift Correction": [[60, "covariate-shift-correction"]], "Creating Data Iterators": [[87, "creating-data-iterators"]], "Creating the Model": [[86, "creating-the-model"]], "Cross-Correlation and Convolution": [[41, "cross-correlation-and-convolution"]], "Cross-Entropy Revisited": [[64, "cross-entropy-revisited"]], "Cross-Validation": [[67, "cross-validation"]], "Custom Initialization": [[14, "custom-initialization"]], "Custom Layers": [[12, null]], "Custom Semantic Segmentation Dataset Class": [[31, "custom-semantic-segmentation-dataset-class"]], "Data": [[58, "data"], [72, "data"]], "Data Manipulation": [[119, null]], "Data Preparation": [[120, "data-preparation"]], "Data Preprocessing": [[31, "data-preprocessing"], [79, "data-preprocessing"], [120, null]], "Dataset Size": [[67, "dataset-size"]], "Decoder": [[10, "decoder"], [124, "decoder"], [129, "decoder"]], "Decoder-Only": [[6, "decoder-only"]], "Decoding": [[135, "decoding"]], "Deep Convolutional Neural Networks (AlexNet)": [[34, null]], "Deep Recurrent Neural Networks": [[123, null]], "Default Initialization": [[82, "default-initialization"]], "Defining Helper Functions for Pretraining Tasks": [[91, "defining-helper-functions-for-pretraining-tasks"]], "Defining Loss and Evaluation Functions": [[32, "defining-loss-and-evaluation-functions"]], "Defining \\ell_2 Norm Penalty": [[74, "defining-ell-2-norm-penalty"]], "Defining a Class for Loading the Dataset": [[85, "defining-a-class-for-loading-the-dataset"]], "Defining and Initializing the Model": [[22, "defining-and-initializing-the-model"]], "Defining the Decoder with Attention": [[4, "defining-the-decoder-with-attention"]], "Defining the Forward Propagation": [[99, "defining-the-forward-propagation"]], "Defining the Loss Function": [[28, "defining-the-loss-function"], [70, "defining-the-loss-function"], [71, "defining-the-loss-function"]], "Defining the Model": [[25, "defining-the-model"], [65, "defining-the-model"], [70, "defining-the-model"], [71, "defining-the-model"], [74, "defining-the-model"], [76, "defining-the-model"], [88, "defining-the-model"], [125, "defining-the-model"], [134, "defining-the-model"]], "Defining the Optimization Algorithm": [[70, "defining-the-optimization-algorithm"], [71, "defining-the-optimization-algorithm"]], "Defining the Training Function": [[25, "defining-the-training-function"], [26, "defining-the-training-function"]], "Defining the Training Loop": [[99, "defining-the-training-loop"]], "Definition": [[49, "definition"]], "Definition of an MDP": [[139, "definition-of-an-mdp"]], "Definitions": [[104, "definitions"]], "Demonstration": [[29, "demonstration"]], "Dense Blocks": [[36, "dense-blocks"]], "DenseNet Model": [[36, "densenet-model"]], "Densely Connected Networks (DenseNet)": [[36, null]], "Derivatives and Differentiation": [[115, "derivatives-and-differentiation"]], "Detaching Computation": [[114, "detaching-computation"]], "Discussion": [[34, "discussion"], [35, "discussion"], [37, "discussion"], [40, "discussion"], [114, "discussion"], [115, "discussion"], [117, "discussion"], [120, "discussion"], [121, "discussion"]], "Discussion of the Markov Assumption": [[139, "discussion-of-the-markov-assumption"]], "Dive into Deep Learning": [[142, null]], "Documentation": [[118, null]], "Dog Breed Identification (ImageNet Dogs) on Kaggle": [[26, null]], "Dot Product Attention": [[3, "dot-product-attention"]], "Dot Products": [[117, "dot-products"]], "Downloading Data": [[79, "downloading-data"]], "Downloading and Preprocessing the Dataset": [[128, "downloading-and-preprocessing-the-dataset"]], "Downloading and Running the Code": [[57, "downloading-and-running-the-code"]], "Downloading the Dataset": [[25, "downloading-the-dataset"], [26, "downloading-the-dataset"], [29, "downloading-the-dataset"]], "Downsampling Block": [[32, "downsampling-block"]], "Dropout": [[76, null]], "Dropout in Practice": [[76, "dropout-in-practice"]], "Dynamic Learning Rate": [[112, "dynamic-learning-rate"]], "Early Stopping": [[77, "early-stopping"]], "Effective Sample Weight": [[109, "effective-sample-weight"]], "Embedding Layer": [[99, "embedding-layer"]], "Empirical Risk and Risk": [[60, "empirical-risk-and-risk"]], "Encoder": [[10, "encoder"], [124, "encoder"], [129, "encoder"]], "Encoder-Only": [[6, "encoder-only"]], "Encoder\u2013Decoder": [[6, "encoderdecoder"]], "Encoder\u2013Decoder for Sequence-to-Sequence Learning": [[129, "encoderdecoder-for-sequence-to-sequence-learning"]], "Entropy": [[64, "entropy"]], "Environment and Distribution Shift": [[60, null]], "Equations for Making Predictions and Learning Kernel Hyperparameters in GP Regression": [[47, "equations-for-making-predictions-and-learning-kernel-hyperparameters-in-gp-regression"]], "Error Measure": [[79, "error-measure"]], "Evaluation of Predicted Sequences": [[129, "evaluation-of-predicted-sequences"]], "Example: Optimizing the Hyperparameters of a Convolutional Neural Network": [[51, "example-optimizing-the-hyperparameters-of-a-convolutional-neural-network"]], "Examples of Distribution Shift": [[60, "examples-of-distribution-shift"]], "Executing Code in the Forward Propagation Method": [[15, "executing-code-in-the-forward-propagation-method"]], "Exercises": [[2, "exercises"], [3, "exercises"], [4, "exercises"], [6, "exercises"], [7, "exercises"], [8, "exercises"], [9, "exercises"], [10, "exercises"], [11, "exercises"], [12, "exercises"], [14, "exercises"], [15, "exercises"], [16, "exercises"], [17, "exercises"], [18, "exercises"], [19, "exercises"], [20, "exercises"], [21, "exercises"], [22, "exercises"], [23, "exercises"], [25, "exercises"], [26, "exercises"], [27, "exercises"], [28, "exercises"], [29, "exercises"], [30, "exercises"], [31, "exercises"], [32, "exercises"], [33, "exercises"], [34, "exercises"], [35, "exercises"], [36, "exercises"], [37, "exercises"], [39, "exercises"], [40, "exercises"], [41, "exercises"], [43, "exercises"], [44, "exercises"], [45, "exercises"], [46, "exercises"], [47, "exercises"], [48, "exercises"], [49, "exercises"], [51, "exercises"], [52, "exercises"], [54, "exercises"], [58, "exercises"], [59, "exercises"], [60, "exercises"], [61, "exercises"], [62, "exercises"], [64, "exercises"], [65, "exercises"], [66, "exercises"], [67, "exercises"], [69, "exercises"], [70, "exercises"], [71, "exercises"], [72, "exercises"], [73, "exercises"], [74, "exercises"], [75, "exercises"], [76, "exercises"], [77, "exercises"], [79, "exercises"], [80, "exercises"], [81, "exercises"], [82, "exercises"], [83, "exercises"], [85, "exercises"], [86, "exercises"], [87, "exercises"], [88, "exercises"], [89, "exercises"], [90, "exercises"], [91, "exercises"], [92, "exercises"], [93, "exercises"], [95, "exercises"], [96, "exercises"], [97, "exercises"], [98, "exercises"], [99, "exercises"], [101, "exercises"], [102, "exercises"], [103, "exercises"], [104, "exercises"], [105, "exercises"], [107, "exercises"], [108, "exercises"], [109, "exercises"], [110, "exercises"], [111, "exercises"], [112, "exercises"], [113, "exercises"], [114, "exercises"], [115, "exercises"], [117, "exercises"], [119, "exercises"], [120, "exercises"], [121, "exercises"], [122, "exercises"], [123, "exercises"], [124, "exercises"], [125, "exercises"], [127, "exercises"], [128, "exercises"], [129, "exercises"], [130, "exercises"], [132, "exercises"], [133, "exercises"], [134, "exercises"], [135, "exercises"], [136, "exercises"], [137, "exercises"], [139, "exercises"], [140, "exercises"], [141, "exercises"]], "Exhaustive Search": [[122, "exhaustive-search"]], "Expectations": [[121, "expectations"]], "Exploding Gradients": [[82, "exploding-gradients"]], "Exploration in Q-Learning": [[140, "exploration-in-q-learning"]], "Exploratory Language Statistics": [[137, "exploratory-language-statistics"]], "Extracting Center Words and Context Words": [[97, "extracting-center-words-and-context-words"]], "Extracting Features": [[28, "extracting-features"]], "Factor Scheduler": [[107, "factor-scheduler"]], "Fairness, Accountability, and Transparency in Machine Learning": [[60, "fairness-accountability-and-transparency-in-machine-learning"]], "Fast R-CNN": [[30, "fast-r-cnn"]], "Faster R-CNN": [[30, "faster-r-cnn"]], "Feature Map and Receptive Field": [[41, "feature-map-and-receptive-field"]], "File I/O": [[17, null]], "Fine-Tuning": [[22, null]], "Fine-Tuning BERT": [[6, "fine-tuning-bert"]], "Fine-Tuning BERT for Sequence-Level and Token-Level Applications": [[83, null]], "Fine-Tuning T5": [[6, "fine-tuning-t5"]], "Fine-Tuning a Pretrained Model": [[26, "fine-tuning-a-pretrained-model"]], "Fine-Tuning the Model": [[22, "fine-tuning-the-model"]], "Flipping and Cropping": [[23, "flipping-and-cropping"]], "Forward Propagation": [[75, "forward-propagation"]], "Forward Propagation, Backward Propagation, and Computational Graphs": [[75, null]], "From Context-Independent to Context-Sensitive": [[90, "from-context-independent-to-context-sensitive"]], "From Fully Connected Layers to Convolutions": [[46, null]], "From Linear to Nonlinear": [[80, "from-linear-to-nonlinear"]], "From ResNet to DenseNet": [[36, "from-resnet-to-densenet"]], "From Task-Specific to Task-Agnostic": [[90, "from-task-specific-to-task-agnostic"]], "From Weight Space to Function Space": [[49, "from-weight-space-to-function-space"]], "Full Computation": [[130, "full-computation"]], "Fully Connected Layers": [[35, "fully-connected-layers"]], "Fully Convolutional Networks": [[21, null]], "Function Classes": [[39, "function-classes"]], "Functions and Classes in a Module": [[118, "functions-and-classes-in-a-module"]], "Functions and Operators": [[100, "functions-and-operators"]], "GPT and GPT-2": [[6, "gpt-and-gpt-2"]], "GPT-3 and Beyond": [[6, "gpt-3-and-beyond"]], "GPUs": [[18, null]], "Gated Hidden State": [[127, "gated-hidden-state"]], "Gated Memory Cell": [[127, "gated-memory-cell"]], "Gated Recurrent Units (GRU)": [[125, null]], "Gaussian Process Inference": [[47, null]], "Gaussian Process Priors": [[49, null]], "Gaussian Processes": [[50, null]], "Generalization": [[67, null]], "Generalization in Classification": [[61, null]], "Generalization in Deep Learning": [[77, null]], "Generating Multiple Anchor Boxes": [[19, "generating-multiple-anchor-boxes"]], "Generating the Dataset": [[73, "generating-the-dataset"]], "Generating the Masked Language Modeling Task": [[91, "generating-the-masked-language-modeling-task"]], "Generating the Next Sentence Prediction Task": [[91, "generating-the-next-sentence-prediction-task"]], "Getting Started": [[119, "getting-started"]], "Goal of Optimization": [[110, "goal-of-optimization"]], "GoogLeNet Model": [[37, "googlenet-model"]], "Gradient Clipping": [[135, "gradient-clipping"]], "Gradient Descent": [[105, null]], "Gradient Descent with Line Search": [[105, "gradient-descent-with-line-search"]], "Gradients and Python Control Flow": [[114, "gradients-and-python-control-flow"]], "Greedy Search": [[122, "greedy-search"]], "Hidden Layers": [[80, "hidden-layers"]], "Hidden State": [[125, "hidden-state"], [127, "hidden-state"]], "Hierarchical Softmax": [[89, "hierarchical-softmax"]], "High-Dimensional Linear Regression": [[74, "high-dimensional-linear-regression"]], "Hot Dog Recognition": [[22, "hot-dog-recognition"]], "Hyperparameter Optimization": [[53, null]], "Hyperparameter Optimization API": [[51, null]], "Image Augmentation": [[23, null], [25, "image-augmentation"], [26, "image-augmentation"]], "Image Classification (CIFAR-10) on Kaggle": [[25, null]], "Image Segmentation and Instance Segmentation": [[31, "image-segmentation-and-instance-segmentation"]], "Implementation": [[7, "implementation"], [101, "implementation"], [103, "implementation"]], "Implementation from Scratch": [[35, "implementation-from-scratch"], [74, "implementation-from-scratch"], [76, "implementation-from-scratch"], [81, "implementation-from-scratch"], [102, "implementation-from-scratch"], [108, "implementation-from-scratch"], [109, "implementation-from-scratch"], [111, "implementation-from-scratch"], [123, "implementation-from-scratch"], [125, "implementation-from-scratch"], [127, "implementation-from-scratch"]], "Implementation of Multilayer Perceptrons": [[81, null]], "Implementation of Q-Learning": [[140, "implementation-of-q-learning"]], "Implementation of Value Iteration": [[141, "implementation-of-value-iteration"]], "Inception Blocks": [[37, "inception-blocks"]], "Incorporating Hidden Layers": [[80, "incorporating-hidden-layers"]], "Indexing and Slicing": [[119, "indexing-and-slicing"]], "Information Theory Basics": [[64, "information-theory-basics"]], "Initializing Model Parameters": [[81, "initializing-model-parameters"], [99, "initializing-model-parameters"], [125, "initializing-model-parameters"], [127, "initializing-model-parameters"]], "Initializing Transposed Convolutional Layers": [[21, "initializing-transposed-convolutional-layers"]], "Initializing the Synthesized Image": [[28, "initializing-the-synthesized-image"]], "Input Gate, Forget Gate, and Output Gate": [[127, "input-gate-forget-gate-and-output-gate"]], "Input Node": [[127, "input-node"]], "Input Representation": [[90, "input-representation"]], "Inspiration from Nonparametrics": [[77, "inspiration-from-nonparametrics"]], "Installation": [[57, null]], "Installing Miniconda": [[57, "installing-miniconda"]], "Installing the Deep Learning Framework and the d2l Package": [[57, "installing-the-deep-learning-framework-and-the-d2l-package"]], "Interacting with an Environment": [[58, "interacting-with-an-environment"]], "Interpreting Equations for Learning and Predictions": [[47, "interpreting-equations-for-learning-and-predictions"]], "Interpreting GloVe from the Ratio of Co-occurrence Probabilities": [[93, "interpreting-glove-from-the-ratio-of-co-occurrence-probabilities"]], "Intersection over Union (IoU)": [[19, "intersection-over-union-iou"]], "Introduction": [[58, null]], "Introduction to Gaussian Processes": [[48, null]], "Invariance": [[46, "invariance"]], "Jensen\u2019s Inequality": [[104, "jensens-inequality"]], "K-Fold Cross-Validation": [[79, "k-fold-cross-validation"]], "Kaggle": [[79, "kaggle"]], "Kernels and Data": [[2, "kernels-and-data"]], "Key Components": [[58, "key-components"]], "Kinds of Machine Learning Problems": [[58, "kinds-of-machine-learning-problems"]], "Label Shift": [[60, "label-shift"]], "Label Shift Correction": [[60, "label-shift-correction"]], "Labeling Anchor Boxes in Training Data": [[19, "labeling-anchor-boxes-in-training-data"]], "Labeling Classes and Offsets": [[19, "labeling-classes-and-offsets"]], "Lagrangian": [[104, "lagrangian"]], "Language Models": [[132, null]], "Laplace Smoothing": [[132, "laplace-smoothing"]], "Large Language Models": [[6, "large-language-models"]], "Large-Scale Pretraining with Transformers": [[6, null]], "Layer Normalization": [[35, "layer-normalization"]], "Layers and Modules": [[15, null]], "Layers with Parameters": [[12, "layers-with-parameters"]], "Layers without Parameters": [[12, "layers-without-parameters"]], "LeNet": [[43, "lenet"]], "LeNet with Batch Normalization": [[35, "lenet-with-batch-normalization"]], "Leaky Averages": [[109, "leaky-averages"]], "Learning Language Models": [[132, "learning-language-models"]], "Learning Rate": [[105, "learning-rate"]], "Learning Rate Scheduling": [[107, null]], "Learning a Kernel": [[41, "learning-a-kernel"]], "Learning by Doing": [[113, "learning-by-doing"]], "Limitations of Linear Models": [[80, "limitations-of-linear-models"]], "Linear Algebra": [[117, null]], "Linear Model": [[64, "linear-model"]], "Linear Neural Networks for Classification": [[63, null]], "Linear Neural Networks for Regression": [[68, null]], "Linear Regression": [[69, null]], "Linear Regression Implementation from Scratch": [[71, null]], "Linear Regression as a Neural Network": [[69, "linear-regression-as-a-neural-network"]], "Loading Pretrained Word Vectors": [[88, "loading-pretrained-word-vectors"], [95, "loading-pretrained-word-vectors"]], "Loading Sequences of Fixed Length": [[128, "loading-sequences-of-fixed-length"]], "Loading Training Examples in Minibatches": [[97, "loading-training-examples-in-minibatches"]], "Loading and Saving Model Parameters": [[17, "loading-and-saving-model-parameters"]], "Loading and Saving Tensors": [[17, "loading-and-saving-tensors"]], "Loading the Dataset": [[62, "loading-the-dataset"]], "Local Minima": [[105, "local-minima"], [110, "local-minima"]], "Local Minima Are Global Minima": [[104, "local-minima-are-global-minima"]], "Locality": [[46, "locality"]], "Log-Likelihood": [[64, "log-likelihood"]], "Long Short-Term Memory (LSTM)": [[127, null]], "Loss Function": [[28, "loss-function"], [64, "loss-function"], [69, "loss-function"]], "Loss Function with Masking": [[129, "loss-function-with-masking"]], "Machine Translation and the Dataset": [[128, null]], "Making Life Easy with GPyTorch": [[47, "making-life-easy-with-gpytorch"]], "Markov Decision Process (MDP)": [[139, null]], "Markov Models": [[136, "markov-models"]], "Markov Models and n-grams": [[132, "markov-models-and-n-grams"]], "Mask R-CNN": [[30, "mask-r-cnn"]], "Masked Language Modeling": [[90, "masked-language-modeling"]], "Masked Softmax Operation": [[3, "masked-softmax-operation"]], "Matrices": [[117, "matrices"]], "Matrix\u2013Matrix Multiplication": [[117, "matrixmatrix-multiplication"]], "Matrix\u2013Vector Products": [[117, "matrixvector-products"]], "Max-Over-Time Pooling": [[88, "max-over-time-pooling"]], "Maximum Pooling and Average Pooling": [[45, "maximum-pooling-and-average-pooling"]], "Medical Diagnostics": [[60, "medical-diagnostics"]], "Memory Cell Internal State": [[127, "memory-cell-internal-state"]], "Method": [[28, "method"]], "Minibatch Stochastic Gradient Descent": [[69, "minibatch-stochastic-gradient-descent"], [108, null]], "Minibatches": [[108, "minibatches"]], "Missing Ingredient: Data": [[34, "missing-ingredient-data"]], "Missing Ingredient: Hardware": [[34, "missing-ingredient-hardware"]], "Model": [[4, "model"], [7, "model"], [10, "model"], [11, "model"], [32, "model"], [69, "model"], [81, "model"], [81, "id1"]], "Model Complexity": [[67, "model-complexity"]], "Model Selection": [[67, "model-selection"], [79, "model-selection"]], "Models": [[58, "models"], [72, "models"]], "Modern Convolutional Neural Networks": [[38, null]], "Modern Recurrent Neural Networks": [[126, null]], "Momentum": [[109, null]], "More Anecdotes": [[60, "more-anecdotes"]], "Multi Factor Scheduler": [[107, "multi-factor-scheduler"]], "Multi-Branch Networks (GoogLeNet)": [[37, null]], "Multi-Fidelity Hyperparameter Optimization": [[56, null]], "Multi-GPU Training": [[23, "multi-gpu-training"]], "Multi-Head Attention": [[7, null]], "Multilayer Perceptrons": [[78, null], [80, null]], "Multiple Channels": [[45, "multiple-channels"]], "Multiple Input Channels": [[40, "multiple-input-channels"]], "Multiple Input and Multiple Output Channels": [[40, null]], "Multiple Output Channels": [[40, "multiple-output-channels"]], "Multiple Random Variables": [[121, "multiple-random-variables"]], "Multiscale Anchor Boxes": [[27, "multiscale-anchor-boxes"]], "Multiscale Detection": [[27, "multiscale-detection"]], "Multiscale Object Detection": [[27, null]], "Multivariate Gradient Descent": [[105, "multivariate-gradient-descent"]], "Natural Language Inference": [[85, "natural-language-inference"]], "Natural Language Inference and the Dataset": [[85, null]], "Natural Language Inference: Using Attention": [[86, null]], "Natural Language Processing: Applications": [[84, null]], "Natural Language Processing: Pretraining": [[94, null]], "Negative Sampling": [[89, "negative-sampling"], [97, "negative-sampling"]], "Neural Networks and GPUs": [[18, "neural-networks-and-gpus"]], "Neural Networks without Hidden States": [[133, "neural-networks-without-hidden-states"]], "Neural Style Transfer": [[28, null]], "Newton\u2019s Method": [[105, "newtons-method"]], "Next Sentence Prediction": [[90, "next-sentence-prediction"]], "Non-Reduction Sum": [[117, "non-reduction-sum"]], "Nonstationary Distributions": [[60, "nonstationary-distributions"]], "Norms": [[117, "norms"]], "Norms and Weight Decay": [[74, "norms-and-weight-decay"]], "Notation": [[100, null]], "Notebooks, Website, GitHub, and Forum": [[113, "notebooks-website-github-and-forum"]], "Numerical Objects": [[100, "numerical-objects"]], "Numerical Stability and Initialization": [[82, null]], "Object Detection and Bounding Boxes": [[20, null]], "Object Edge Detection in Images": [[41, "object-edge-detection-in-images"]], "Object-Oriented Design for Implementation": [[72, null]], "Objective Function": [[54, "objective-function"], [55, "objective-function"]], "Objective Functions": [[58, "objective-functions"]], "Obtaining and Organizing the Dataset": [[25, "obtaining-and-organizing-the-dataset"], [26, "obtaining-and-organizing-the-dataset"]], "One Medium Combining Code, Math, and HTML": [[113, "one-medium-combining-code-math-and-html"]], "One-Dimensional Convolutions": [[88, "one-dimensional-convolutions"]], "One-Dimensional Gradient Descent": [[105, "one-dimensional-gradient-descent"]], "One-Hot Encoding": [[135, "one-hot-encoding"]], "One-Hot Vectors Are a Bad Choice": [[98, "one-hot-vectors-are-a-bad-choice"]], "Online Learning": [[60, "online-learning"]], "Operations": [[119, "operations"]], "Optimal Stochastic Policy": [[141, "optimal-stochastic-policy"]], "Optimization Algorithms": [[58, "optimization-algorithms"], [106, null]], "Optimization Challenges in Deep Learning": [[110, "optimization-challenges-in-deep-learning"]], "Optimization and Deep Learning": [[110, null]], "Organizing the Dataset": [[25, "organizing-the-dataset"], [26, "organizing-the-dataset"]], "Padding": [[44, "padding"]], "Padding and Stride": [[44, null], [45, "padding-and-stride"]], "Padding, Strides, and Multiple Channels": [[33, "padding-strides-and-multiple-channels"]], "Parameter Access": [[16, "parameter-access"]], "Parameter Initialization": [[14, null], [82, "parameter-initialization"]], "Parameter Management": [[16, null]], "Partial Derivatives and Gradients": [[115, "partial-derivatives-and-gradients"]], "Partitioning Sequences": [[132, "partitioning-sequences"]], "Patch Embedding": [[11, "patch-embedding"]], "Penalties": [[104, "penalties"]], "Perplexity": [[132, "perplexity"]], "Policies": [[107, "policies"]], "Policy Evaluation": [[141, "policy-evaluation"]], "Polynomial Curve Fitting": [[67, "polynomial-curve-fitting"]], "Pooling": [[45, null]], "Positional Encoding": [[9, "positional-encoding"]], "Positionwise Feed-Forward Networks": [[10, "positionwise-feed-forward-networks"]], "Posterior Inference for Regression": [[47, "posterior-inference-for-regression"]], "Practical Experiments": [[109, "practical-experiments"]], "Preconditioning": [[102, "preconditioning"], [105, "preconditioning"]], "Predicting Bounding Boxes with Non-Maximum Suppression": [[19, "predicting-bounding-boxes-with-non-maximum-suppression"]], "Predicting House Prices on Kaggle": [[79, null]], "Prediction": [[21, "prediction"], [32, "prediction"], [66, "prediction"], [129, "prediction"], [136, "prediction"]], "Predictions": [[69, "predictions"]], "Preface": [[113, null]], "Preliminaries": [[116, null]], "Preprocessing and Postprocessing": [[28, "preprocessing-and-postprocessing"]], "Preprocessing the Dataset": [[87, "preprocessing-the-dataset"]], "Pretraining BERT": [[6, "pretraining-bert"], [92, null], [92, "id1"]], "Pretraining T5": [[6, "pretraining-t5"]], "Pretraining Tasks": [[90, "pretraining-tasks"]], "Pretraining word2vec": [[99, null]], "Principle of Dynamic Programming": [[141, "principle-of-dynamic-programming"]], "Probability and Information Theory": [[100, "probability-and-information-theory"]], "Probability and Statistics": [[121, null]], "Projections": [[104, "projections"]], "Properties": [[104, "properties"]], "Putting It All Together": [[11, "putting-it-all-together"], [31, "putting-it-all-together"], [85, "putting-it-all-together"], [86, "putting-it-all-together"], [87, "putting-it-all-together"], [90, "putting-it-all-together"], [97, "putting-it-all-together"], [137, "putting-it-all-together"]], "Putting the Encoder and Decoder Together": [[124, "putting-the-encoder-and-decoder-together"]], "Q-Learning": [[140, null]], "Quadratic Convex Functions": [[109, "quadratic-convex-functions"]], "Queries, Keys, and Values": [[8, null]], "Question Answering": [[83, "question-answering"]], "R-CNNs": [[30, "r-cnns"]], "RMSProp": [[111, null]], "RNN Model": [[135, "rnn-model"]], "RNN-Based Character-Level Language Models": [[133, "rnn-based-character-level-language-models"]], "RNN-Based Language Model": [[135, "rnn-based-language-model"]], "Random Search": [[52, "random-search"]], "Random Variables": [[121, "random-variables"]], "Randomized Truncation": [[130, "randomized-truncation"]], "ReLU Function": [[80, "relu-function"]], "Reading a Minibatch": [[62, "reading-a-minibatch"]], "Reading the Content and Style Images": [[28, "reading-the-content-and-style-images"]], "Reading the Dataset": [[21, "reading-the-dataset"], [22, "reading-the-dataset"], [25, "reading-the-dataset"], [26, "reading-the-dataset"], [29, "reading-the-dataset"], [31, "reading-the-dataset"], [73, "reading-the-dataset"], [85, "reading-the-dataset"], [87, "reading-the-dataset"], [97, "reading-the-dataset"], [108, "reading-the-dataset"], [120, "reading-the-dataset"], [128, "reading-the-dataset"], [137, "reading-the-dataset"]], "Reading the Dataset and Initializing the Model": [[32, "reading-the-dataset-and-initializing-the-model"]], "Reading the dataset": [[86, "reading-the-dataset"]], "Recommender Systems": [[58, "recommender-systems"]], "Recurrent Neural Network Implementation from Scratch": [[135, null]], "Recurrent Neural Networks": [[131, null], [133, null]], "Recurrent Neural Networks with Hidden States": [[133, "recurrent-neural-networks-with-hidden-states"]], "Reduction": [[117, "reduction"]], "Region-based CNNs (R-CNNs)": [[30, null]], "Regression": [[58, "regression"]], "Reinforcement Learning": [[58, "reinforcement-learning"], [60, "reinforcement-learning"], [138, null]], "Relative Positional Information": [[9, "relative-positional-information"]], "Representation Learning": [[34, "representation-learning"]], "Representing Text with BERT": [[92, "representing-text-with-bert"]], "ResNeXt": [[39, "resnext"]], "ResNet Model": [[39, "resnet-model"]], "Reset Gate and Update Gate": [[125, "reset-gate-and-update-gate"]], "Residual Blocks": [[39, "residual-blocks"]], "Residual Connection and Layer Normalization": [[10, "residual-connection-and-layer-normalization"]], "Residual Networks (ResNet) and ResNeXt": [[39, null]], "Return and Discount Factor": [[139, "return-and-discount-factor"]], "Revisiting Overfitting and Regularization": [[77, "revisiting-overfitting-and-regularization"]], "Roots": [[58, "roots"]], "Saddle Points": [[110, "saddle-points"]], "Saving Memory": [[119, "saving-memory"]], "Scalability": [[6, "scalability"]], "Scalar Functions": [[109, "scalar-functions"]], "Scalars": [[117, "scalars"]], "Scaled Dot Product Attention": [[3, "scaled-dot-product-attention"]], "Scheduler": [[51, "scheduler"]], "Schedulers": [[107, "schedulers"]], "Search": [[58, "search"]], "Searcher": [[51, "searcher"]], "Self-Attention": [[9, "self-attention"]], "Self-Attention and Positional Encoding": [[9, null]], "Self-Driving Cars": [[60, "self-driving-cars"]], "Self-Supervised word2vec": [[98, "self-supervised-word2vec"]], "Semantic Segmentation and the Dataset": [[31, null]], "Sentiment Analysis and the Dataset": [[87, null]], "Sentiment Analysis: Using Convolutional Neural Networks": [[88, null]], "Sequence Learning": [[58, "sequence-learning"]], "Sequence Models": [[136, "sequence-models"]], "Sequence-to-Sequence Learning for Machine Translation": [[129, null]], "Set Theory": [[100, "set-theory"]], "Side Notes": [[18, "side-notes"]], "Sigmoid Function": [[80, "sigmoid-function"]], "Single Shot Multibox Detection": [[32, null]], "Single Text Classification": [[83, "single-text-classification"]], "Skip-Gram with Global Corpus Statistics": [[93, "skip-gram-with-global-corpus-statistics"]], "Softmax Regression": [[64, null]], "Softmax Regression Implementation from Scratch": [[66, null]], "Softmax Revisited": [[65, "softmax-revisited"]], "Softmax and Cross-Entropy Loss": [[64, "softmax-and-cross-entropy-loss"]], "Sparse Features and Learning Rates": [[102, "sparse-features-and-learning-rates"]], "Specific Functions and Classes": [[118, "specific-functions-and-classes"]], "Statistical Learning Theory": [[61, "statistical-learning-theory"]], "Steps": [[22, "steps"]], "Stochastic Gradient Descent": [[112, null]], "Stochastic Gradient Updates": [[112, "stochastic-gradient-updates"]], "Stochastic Gradients and Finite Samples": [[112, "stochastic-gradients-and-finite-samples"]], "Stochastic Policy": [[141, "stochastic-policy"]], "Storage on the GPU": [[18, "storage-on-the-gpu"]], "Stride": [[44, "stride"]], "Style Loss": [[28, "style-loss"]], "Submitting Predictions on Kaggle": [[79, "submitting-predictions-on-kaggle"]], "Subsampling": [[97, "subsampling"]], "Subword Embedding": [[96, null]], "Success Stories": [[58, "success-stories"]], "Successive Halving": [[56, "successive-halving"]], "Summary": [[2, "summary"], [3, "summary"], [4, "summary"], [7, "summary"], [8, "summary"], [9, "summary"], [10, "summary"], [12, "summary"], [14, "summary"], [15, "summary"], [16, "summary"], [17, "summary"], [18, "summary"], [19, "summary"], [20, "summary"], [21, "summary"], [22, "summary"], [23, "summary"], [25, "summary"], [26, "summary"], [27, "summary"], [28, "summary"], [29, "summary"], [30, "summary"], [31, "summary"], [32, "summary"], [33, "summary"], [41, "summary"], [43, "summary"], [45, "summary"], [47, "summary"], [48, "summary"], [49, "summary"], [51, "summary"], [52, "summary"], [54, "summary"], [55, "summary"], [56, "summary"], [58, "summary"], [59, "summary"], [60, "summary"], [61, "summary"], [62, "summary"], [65, "summary"], [66, "summary"], [67, "summary"], [69, "summary"], [70, "summary"], [71, "summary"], [72, "summary"], [73, "summary"], [74, "summary"], [75, "summary"], [76, "summary"], [77, "summary"], [81, "summary"], [82, "summary"], [83, "summary"], [85, "summary"], [86, "summary"], [87, "summary"], [88, "summary"], [89, "summary"], [90, "summary"], [91, "summary"], [92, "summary"], [93, "summary"], [95, "summary"], [96, "summary"], [97, "summary"], [98, "summary"], [99, "summary"], [101, "summary"], [102, "summary"], [103, "summary"], [104, "summary"], [105, "summary"], [107, "summary"], [108, "summary"], [109, "summary"], [110, "summary"], [111, "summary"], [112, "summary"], [113, "summary"], [119, "summary"], [122, "summary"], [123, "summary"], [124, "summary"], [125, "summary"], [127, "summary"], [128, "summary"], [129, "summary"], [130, "summary"], [133, "summary"], [134, "summary"], [135, "summary"], [136, "summary"], [137, "summary"], [139, "summary"], [140, "summary"], [141, "summary"]], "Summary and Discussion": [[6, "summary-and-discussion"], [11, "summary-and-discussion"], [36, "summary-and-discussion"], [39, "summary-and-discussion"], [44, "summary-and-discussion"], [46, "summary-and-discussion"], [64, "summary-and-discussion"], [79, "summary-and-discussion"], [80, "summary-and-discussion"], [132, "summary-and-discussion"]], "Supervised Learning": [[58, "supervised-learning"]], "Surprisal": [[64, "surprisal"]], "Synthetic Regression Data": [[73, null]], "Tagging": [[58, "tagging"]], "Tanh Function": [[80, "tanh-function"]], "Target Audience": [[113, "target-audience"]], "Targeted Parameters": [[16, "targeted-parameters"]], "Teacher Forcing": [[129, "teacher-forcing"]], "Tensors": [[117, "tensors"]], "Tensors and GPUs": [[18, "tensors-and-gpus"]], "Test Set Reuse": [[61, "test-set-reuse"]], "Text Pair Classification or Regression": [[83, "text-pair-classification-or-regression"]], "Text Tagging": [[83, "text-tagging"]], "The Algorithm": [[101, "the-algorithm"], [102, "the-algorithm"], [103, "the-algorithm"], [111, "the-algorithm"]], "The Bahdanau Attention Mechanism": [[4, null]], "The Base Classification Model": [[59, null]], "The Classifier Class": [[59, "the-classifier-class"]], "The Complete Model": [[32, "the-complete-model"]], "The Configuration Space": [[52, "the-configuration-space"]], "The Continuous Bag of Words (CBOW) Model": [[98, "the-continuous-bag-of-words-cbow-model"]], "The Cross-Correlation Operation": [[41, "the-cross-correlation-operation"]], "The Cross-Entropy Loss": [[66, "the-cross-entropy-loss"]], "The Dataset for Pretraining BERT": [[91, null]], "The Dataset for Pretraining Word Embeddings": [[97, null]], "The Encoder\u2013Decoder Architecture": [[124, null]], "The Essence of Deep Learning": [[58, "the-essence-of-deep-learning"]], "The GloVe Model": [[93, "the-glove-model"]], "The Image Classification Dataset": [[62, null]], "The Model": [[21, "the-model"], [66, "the-model"], [86, "the-model"]], "The Momentum Method": [[109, "the-momentum-method"]], "The Neural Network Kernel": [[49, "the-neural-network-kernel"]], "The Normal Distribution and Squared Loss": [[69, "the-normal-distribution-and-squared-loss"]], "The Object Detection Dataset": [[29, null]], "The Objective Function": [[52, "the-objective-function"]], "The Optimization Problem": [[52, "the-optimization-problem"]], "The Order of Decoding": [[136, "the-order-of-decoding"]], "The Pascal VOC2012 Semantic Segmentation Dataset": [[31, "the-pascal-voc2012-semantic-segmentation-dataset"]], "The Q-Learning Algorithm": [[140, "the-q-learning-algorithm"]], "The Radial Basis Function (RBF) Kernel": [[49, "the-radial-basis-function-rbf-kernel"]], "The Road to Deep Learning": [[58, "the-road-to-deep-learning"]], "The Sequential Module": [[15, "the-sequential-module"]], "The Skip-Gram Model": [[98, "the-skip-gram-model"], [99, "the-skip-gram-model"]], "The Softmax": [[64, "the-softmax"], [66, "the-softmax"]], "The Stanford Natural Language Inference (SNLI) Dataset": [[85, "the-stanford-natural-language-inference-snli-dataset"]], "The Test Set": [[61, "the-test-set"]], "The Transformer Architecture": [[10, null]], "The fastText Model": [[96, "the-fasttext-model"]], "The textCNN Model": [[88, "the-textcnn-model"]], "The \u201cSelf-correcting\u201d Property of Q-Learning": [[140, "the-self-correcting-property-of-q-learning"]], "Theoretical Analysis": [[109, "theoretical-analysis"]], "Tied Parameters": [[16, "tied-parameters"]], "Tokenization": [[128, "tokenization"], [137, "tokenization"]], "Total Variation Loss": [[28, "total-variation-loss"]], "Toy Problem": [[107, "toy-problem"]], "Training": [[4, "training"], [10, "training"], [11, "training"], [21, "training"], [28, "training"], [32, "training"], [34, "training"], [36, "training"], [37, "training"], [39, "training"], [43, "training"], [65, "training"], [66, "training"], [70, "training"], [71, "training"], [72, "training"], [76, "training"], [81, "training"], [81, "id2"], [98, "training"], [98, "id3"], [99, "training"], [125, "training"], [129, "training"], [135, "training"], [136, "training"]], "Training Deep Networks": [[35, "training-deep-networks"]], "Training Error and Generalization Error": [[67, "training-error-and-generalization-error"]], "Training Neural Networks": [[75, "training-neural-networks"]], "Training and Evaluating the Model": [[86, "training-and-evaluating-the-model"], [86, "id2"], [88, "training-and-evaluating-the-model"]], "Training and Predicting": [[134, "training-and-predicting"]], "Training and Prediction": [[127, "training-and-prediction"]], "Training and Validating the Model": [[25, "training-and-validating-the-model"], [26, "training-and-validating-the-model"]], "Training the Model": [[32, "training-the-model"]], "Training with Image Augmentation": [[23, "training-with-image-augmentation"]], "Training without Regularization": [[74, "training-without-regularization"]], "Transformers for Vision": [[11, null]], "Transforming RNN Outputs": [[135, "transforming-rnn-outputs"]], "Transforming Text into the Pretraining Dataset": [[91, "transforming-text-into-the-pretraining-dataset"]], "Transition Layers": [[36, "transition-layers"]], "Translation Invariance": [[46, "translation-invariance"]], "Transposed Convolution": [[33, null]], "Truncating Time Steps": [[130, "truncating-time-steps"]], "Tuner": [[51, "tuner"]], "Types of Distribution Shift": [[60, "types-of-distribution-shift"]], "Underfitting or Overfitting?": [[67, "underfitting-or-overfitting"]], "Universal Approximators": [[80, "universal-approximators"]], "Unsupervised and Self-Supervised Learning": [[58, "unsupervised-and-self-supervised-learning"]], "Using Weight Decay": [[74, "using-weight-decay"]], "Using the Model": [[86, "using-the-model"]], "Utilities": [[72, "utilities"]], "Utility Functions and Classes": [[1, null]], "Value Function": [[141, "value-function"]], "Value Iteration": [[141, null], [141, "id2"]], "Vanishing Gradients": [[82, "vanishing-gradients"], [110, "vanishing-gradients"]], "Vanishing and Exploding Gradients": [[82, "vanishing-and-exploding-gradients"]], "Vectorization": [[64, "vectorization"]], "Vectorization and Caches": [[108, "vectorization-and-caches"]], "Vectorization for Speed": [[69, "vectorization-for-speed"]], "Vectors": [[117, "vectors"]], "Vision Transformer Encoder": [[11, "vision-transformer-encoder"]], "Visualization": [[8, "visualization"], [62, "visualization"]], "Visualization Utilities": [[115, "visualization-utilities"]], "Visualize the Asynchronous Optimization Process": [[54, "visualize-the-asynchronous-optimization-process"]], "Visualize the Optimization Process": [[55, "visualize-the-optimization-process"]], "Vocabulary": [[137, "vocabulary"]], "Warmup": [[107, "warmup"]], "Weight Decay": [[74, null]], "What Is Hyperparameter Optimization?": [[52, null]], "Word Analogy": [[95, "word-analogy"]], "Word Embedding (word2vec)": [[98, null]], "Word Embedding with Global Vectors (GloVe)": [[93, null]], "Word Frequency": [[132, "word-frequency"]], "Word Similarity": [[95, "word-similarity"]], "Word Similarity and Analogy": [[95, null]], "Worked Example from Scratch": [[47, "worked-example-from-scratch"]], "Working with Sequences": [[136, null]], "Xavier Initialization": [[82, "xavier-initialization"]], "Yogi": [[103, "yogi"]], "label:tab_example_configspace": [[52, "id11"]], "label:tab_glove": [[93, "id4"]], "label:tab_intro_decade": [[58, "id59"]]}, "docnames": ["chapter_appendix-tools-for-deep-learning/index", "chapter_appendix-tools-for-deep-learning/utils", "chapter_attention-mechanisms-and-transformers/attention-pooling", "chapter_attention-mechanisms-and-transformers/attention-scoring-functions", "chapter_attention-mechanisms-and-transformers/bahdanau-attention", "chapter_attention-mechanisms-and-transformers/index", "chapter_attention-mechanisms-and-transformers/large-pretraining-transformers", "chapter_attention-mechanisms-and-transformers/multihead-attention", "chapter_attention-mechanisms-and-transformers/queries-keys-values", "chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding", "chapter_attention-mechanisms-and-transformers/transformer", "chapter_attention-mechanisms-and-transformers/vision-transformer", "chapter_builders-guide/custom-layer", "chapter_builders-guide/index", "chapter_builders-guide/init-param", "chapter_builders-guide/model-construction", "chapter_builders-guide/parameters", "chapter_builders-guide/read-write", "chapter_builders-guide/use-gpu", "chapter_computer-vision/anchor", "chapter_computer-vision/bounding-box", "chapter_computer-vision/fcn", "chapter_computer-vision/fine-tuning", "chapter_computer-vision/image-augmentation", "chapter_computer-vision/index", "chapter_computer-vision/kaggle-cifar10", "chapter_computer-vision/kaggle-dog", "chapter_computer-vision/multiscale-object-detection", "chapter_computer-vision/neural-style", "chapter_computer-vision/object-detection-dataset", "chapter_computer-vision/rcnn", "chapter_computer-vision/semantic-segmentation-and-dataset", "chapter_computer-vision/ssd", "chapter_computer-vision/transposed-conv", "chapter_convolutional-modern/alexnet", "chapter_convolutional-modern/batch-norm", "chapter_convolutional-modern/densenet", "chapter_convolutional-modern/googlenet", "chapter_convolutional-modern/index", "chapter_convolutional-modern/resnet", "chapter_convolutional-neural-networks/channels", "chapter_convolutional-neural-networks/conv-layer", "chapter_convolutional-neural-networks/index", "chapter_convolutional-neural-networks/lenet", "chapter_convolutional-neural-networks/padding-and-strides", "chapter_convolutional-neural-networks/pooling", "chapter_convolutional-neural-networks/why-conv", "chapter_gaussian-processes/gp-inference", "chapter_gaussian-processes/gp-intro", "chapter_gaussian-processes/gp-priors", "chapter_gaussian-processes/index", "chapter_hyperparameter-optimization/hyperopt-api", "chapter_hyperparameter-optimization/hyperopt-intro", "chapter_hyperparameter-optimization/index", "chapter_hyperparameter-optimization/rs-async", "chapter_hyperparameter-optimization/sh-async", "chapter_hyperparameter-optimization/sh-intro", "chapter_installation/index", "chapter_introduction/index", "chapter_linear-classification/classification", "chapter_linear-classification/environment-and-distribution-shift", "chapter_linear-classification/generalization-classification", "chapter_linear-classification/image-classification-dataset", "chapter_linear-classification/index", "chapter_linear-classification/softmax-regression", "chapter_linear-classification/softmax-regression-concise", "chapter_linear-classification/softmax-regression-scratch", "chapter_linear-regression/generalization", "chapter_linear-regression/index", "chapter_linear-regression/linear-regression", "chapter_linear-regression/linear-regression-concise", "chapter_linear-regression/linear-regression-scratch", "chapter_linear-regression/oo-design", "chapter_linear-regression/synthetic-regression-data", "chapter_linear-regression/weight-decay", "chapter_multilayer-perceptrons/backprop", "chapter_multilayer-perceptrons/dropout", "chapter_multilayer-perceptrons/generalization-deep", "chapter_multilayer-perceptrons/index", "chapter_multilayer-perceptrons/kaggle-house-price", "chapter_multilayer-perceptrons/mlp", "chapter_multilayer-perceptrons/mlp-implementation", "chapter_multilayer-perceptrons/numerical-stability-and-init", "chapter_natural-language-processing-applications/finetuning-bert", "chapter_natural-language-processing-applications/index", "chapter_natural-language-processing-applications/natural-language-inference-and-dataset", "chapter_natural-language-processing-applications/natural-language-inference-attention", "chapter_natural-language-processing-applications/sentiment-analysis-and-dataset", "chapter_natural-language-processing-applications/sentiment-analysis-cnn", "chapter_natural-language-processing-pretraining/approx-training", "chapter_natural-language-processing-pretraining/bert", "chapter_natural-language-processing-pretraining/bert-dataset", "chapter_natural-language-processing-pretraining/bert-pretraining", "chapter_natural-language-processing-pretraining/glove", "chapter_natural-language-processing-pretraining/index", "chapter_natural-language-processing-pretraining/similarity-analogy", "chapter_natural-language-processing-pretraining/subword-embedding", "chapter_natural-language-processing-pretraining/word-embedding-dataset", "chapter_natural-language-processing-pretraining/word2vec", "chapter_natural-language-processing-pretraining/word2vec-pretraining", "chapter_notation/index", "chapter_optimization/adadelta", "chapter_optimization/adagrad", "chapter_optimization/adam", "chapter_optimization/convexity", "chapter_optimization/gd", "chapter_optimization/index", "chapter_optimization/lr-scheduler", "chapter_optimization/minibatch-sgd", "chapter_optimization/momentum", "chapter_optimization/optimization-intro", "chapter_optimization/rmsprop", "chapter_optimization/sgd", "chapter_preface/index", "chapter_preliminaries/autograd", "chapter_preliminaries/calculus", "chapter_preliminaries/index", "chapter_preliminaries/linear-algebra", "chapter_preliminaries/lookup-api", "chapter_preliminaries/ndarray", "chapter_preliminaries/pandas", "chapter_preliminaries/probability", "chapter_recurrent-modern/beam-search", "chapter_recurrent-modern/deep-rnn", "chapter_recurrent-modern/encoder-decoder", "chapter_recurrent-modern/gru", "chapter_recurrent-modern/index", "chapter_recurrent-modern/lstm", "chapter_recurrent-modern/machine-translation-and-dataset", "chapter_recurrent-modern/seq2seq", "chapter_recurrent-neural-networks/bptt", "chapter_recurrent-neural-networks/index", "chapter_recurrent-neural-networks/language-model", "chapter_recurrent-neural-networks/rnn", "chapter_recurrent-neural-networks/rnn-concise", "chapter_recurrent-neural-networks/rnn-scratch", "chapter_recurrent-neural-networks/sequence", "chapter_recurrent-neural-networks/text-sequence", "chapter_reinforcement-learning/index", "chapter_reinforcement-learning/mdp", "chapter_reinforcement-learning/qlearning", "chapter_reinforcement-learning/value-iter", "index"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["chapter_appendix-tools-for-deep-learning/index.rst", "chapter_appendix-tools-for-deep-learning/utils.rst", "chapter_attention-mechanisms-and-transformers/attention-pooling.rst", "chapter_attention-mechanisms-and-transformers/attention-scoring-functions.rst", "chapter_attention-mechanisms-and-transformers/bahdanau-attention.rst", "chapter_attention-mechanisms-and-transformers/index.rst", "chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.rst", "chapter_attention-mechanisms-and-transformers/multihead-attention.rst", "chapter_attention-mechanisms-and-transformers/queries-keys-values.rst", "chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.rst", "chapter_attention-mechanisms-and-transformers/transformer.rst", "chapter_attention-mechanisms-and-transformers/vision-transformer.rst", "chapter_builders-guide/custom-layer.rst", "chapter_builders-guide/index.rst", "chapter_builders-guide/init-param.rst", "chapter_builders-guide/model-construction.rst", "chapter_builders-guide/parameters.rst", "chapter_builders-guide/read-write.rst", "chapter_builders-guide/use-gpu.rst", "chapter_computer-vision/anchor.rst", "chapter_computer-vision/bounding-box.rst", "chapter_computer-vision/fcn.rst", "chapter_computer-vision/fine-tuning.rst", "chapter_computer-vision/image-augmentation.rst", "chapter_computer-vision/index.rst", "chapter_computer-vision/kaggle-cifar10.rst", "chapter_computer-vision/kaggle-dog.rst", "chapter_computer-vision/multiscale-object-detection.rst", "chapter_computer-vision/neural-style.rst", "chapter_computer-vision/object-detection-dataset.rst", "chapter_computer-vision/rcnn.rst", "chapter_computer-vision/semantic-segmentation-and-dataset.rst", "chapter_computer-vision/ssd.rst", "chapter_computer-vision/transposed-conv.rst", "chapter_convolutional-modern/alexnet.rst", "chapter_convolutional-modern/batch-norm.rst", "chapter_convolutional-modern/densenet.rst", "chapter_convolutional-modern/googlenet.rst", "chapter_convolutional-modern/index.rst", "chapter_convolutional-modern/resnet.rst", "chapter_convolutional-neural-networks/channels.rst", "chapter_convolutional-neural-networks/conv-layer.rst", "chapter_convolutional-neural-networks/index.rst", "chapter_convolutional-neural-networks/lenet.rst", "chapter_convolutional-neural-networks/padding-and-strides.rst", "chapter_convolutional-neural-networks/pooling.rst", "chapter_convolutional-neural-networks/why-conv.rst", "chapter_gaussian-processes/gp-inference.rst", "chapter_gaussian-processes/gp-intro.rst", "chapter_gaussian-processes/gp-priors.rst", "chapter_gaussian-processes/index.rst", "chapter_hyperparameter-optimization/hyperopt-api.rst", "chapter_hyperparameter-optimization/hyperopt-intro.rst", "chapter_hyperparameter-optimization/index.rst", "chapter_hyperparameter-optimization/rs-async.rst", "chapter_hyperparameter-optimization/sh-async.rst", "chapter_hyperparameter-optimization/sh-intro.rst", "chapter_installation/index.rst", "chapter_introduction/index.rst", "chapter_linear-classification/classification.rst", "chapter_linear-classification/environment-and-distribution-shift.rst", "chapter_linear-classification/generalization-classification.rst", "chapter_linear-classification/image-classification-dataset.rst", "chapter_linear-classification/index.rst", "chapter_linear-classification/softmax-regression.rst", "chapter_linear-classification/softmax-regression-concise.rst", "chapter_linear-classification/softmax-regression-scratch.rst", "chapter_linear-regression/generalization.rst", "chapter_linear-regression/index.rst", "chapter_linear-regression/linear-regression.rst", "chapter_linear-regression/linear-regression-concise.rst", "chapter_linear-regression/linear-regression-scratch.rst", "chapter_linear-regression/oo-design.rst", "chapter_linear-regression/synthetic-regression-data.rst", "chapter_linear-regression/weight-decay.rst", "chapter_multilayer-perceptrons/backprop.rst", "chapter_multilayer-perceptrons/dropout.rst", "chapter_multilayer-perceptrons/generalization-deep.rst", "chapter_multilayer-perceptrons/index.rst", "chapter_multilayer-perceptrons/kaggle-house-price.rst", "chapter_multilayer-perceptrons/mlp.rst", "chapter_multilayer-perceptrons/mlp-implementation.rst", "chapter_multilayer-perceptrons/numerical-stability-and-init.rst", "chapter_natural-language-processing-applications/finetuning-bert.rst", "chapter_natural-language-processing-applications/index.rst", "chapter_natural-language-processing-applications/natural-language-inference-and-dataset.rst", "chapter_natural-language-processing-applications/natural-language-inference-attention.rst", "chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.rst", "chapter_natural-language-processing-applications/sentiment-analysis-cnn.rst", "chapter_natural-language-processing-pretraining/approx-training.rst", "chapter_natural-language-processing-pretraining/bert.rst", "chapter_natural-language-processing-pretraining/bert-dataset.rst", "chapter_natural-language-processing-pretraining/bert-pretraining.rst", "chapter_natural-language-processing-pretraining/glove.rst", "chapter_natural-language-processing-pretraining/index.rst", "chapter_natural-language-processing-pretraining/similarity-analogy.rst", "chapter_natural-language-processing-pretraining/subword-embedding.rst", "chapter_natural-language-processing-pretraining/word-embedding-dataset.rst", "chapter_natural-language-processing-pretraining/word2vec.rst", "chapter_natural-language-processing-pretraining/word2vec-pretraining.rst", "chapter_notation/index.rst", "chapter_optimization/adadelta.rst", "chapter_optimization/adagrad.rst", "chapter_optimization/adam.rst", "chapter_optimization/convexity.rst", "chapter_optimization/gd.rst", "chapter_optimization/index.rst", "chapter_optimization/lr-scheduler.rst", "chapter_optimization/minibatch-sgd.rst", "chapter_optimization/momentum.rst", "chapter_optimization/optimization-intro.rst", "chapter_optimization/rmsprop.rst", "chapter_optimization/sgd.rst", "chapter_preface/index.rst", "chapter_preliminaries/autograd.rst", "chapter_preliminaries/calculus.rst", "chapter_preliminaries/index.rst", "chapter_preliminaries/linear-algebra.rst", "chapter_preliminaries/lookup-api.rst", "chapter_preliminaries/ndarray.rst", "chapter_preliminaries/pandas.rst", "chapter_preliminaries/probability.rst", "chapter_recurrent-modern/beam-search.rst", "chapter_recurrent-modern/deep-rnn.rst", "chapter_recurrent-modern/encoder-decoder.rst", "chapter_recurrent-modern/gru.rst", "chapter_recurrent-modern/index.rst", "chapter_recurrent-modern/lstm.rst", "chapter_recurrent-modern/machine-translation-and-dataset.rst", "chapter_recurrent-modern/seq2seq.rst", "chapter_recurrent-neural-networks/bptt.rst", "chapter_recurrent-neural-networks/index.rst", "chapter_recurrent-neural-networks/language-model.rst", "chapter_recurrent-neural-networks/rnn.rst", "chapter_recurrent-neural-networks/rnn-concise.rst", "chapter_recurrent-neural-networks/rnn-scratch.rst", "chapter_recurrent-neural-networks/sequence.rst", "chapter_recurrent-neural-networks/text-sequence.rst", "chapter_reinforcement-learning/index.rst", "chapter_reinforcement-learning/mdp.rst", "chapter_reinforcement-learning/qlearning.rst", "chapter_reinforcement-learning/value-iter.rst", "index.rst"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 54, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "0": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "00": 19, "000": [4, 9, 10, 34, 47, 58, 61, 62, 69, 70, 79, 80, 82, 83, 121, 129, 132, 137], "00000": [91, 92], "000000": [102, 111], "0000000e": 19, "0000001e": 19, "00001": [91, 92, 115], "000017": 93, "000018": 93, "00002": 69, "000022": 93, "00003": 115, "000066": 93, "000073": [105, 109], "0001": [55, 61], "00010": 115, "00019": 93, "000244141": 21, "0003": [10, 121], "00030": 115, "000732422": 21, "00078": 93, "0008111000061035156": 108, "001": [4, 9, 21, 22, 23, 86, 88, 129], "00100": 115, "0012009039055556059": 74, "0012207": 21, "0013": 110, "00131906": 14, "001491": 55, "0015": 121, "00168506": 35, "00176955": 121, "002": [99, 108], "00219727": 21, "0022": 93, "00220588": 21, "002295": 102, "002553": 109, "003": 93, "00300": 115, "00366156": 14, "00366211": 21, "00405765": 70, "004499880970120725": 52, "005": [108, 109], "00550299": 14, "00610352": 21, "006795": 44, "00708594": 14, "007188": 109, "00831387": 44, "00873405858874321": 74, "009": [108, 109], "009057": 54, "0094018": 70, "009999999": 19, "01": [1, 14, 19, 22, 26, 32, 34, 36, 37, 39, 47, 61, 66, 69, 70, 71, 73, 74, 79, 81, 92, 103, 104, 105, 107, 108, 109, 110, 111, 121, 123, 125, 127, 135, 136], "010": [9, 102, 109], "01000": 115, "0103469": 70, "010599": 111, "0108574": 35, "010988948291006459": 55, "010989": 55, "011": [9, 102, 103, 111], "011114": 55, "011114022771092129": 55, "011335521846740686": 55, "011336": 55, "011485": 121, "011605": 54, "011605333152295885": 54, "01176482331903498": 55, "011765": 55, "012": [101, 108, 111], "01255": 12, "0127203": 99, "012862": 54, "01286225998599121": 54, "013": [101, 103], "0134493": 44, "014524661982273063": 55, "014525": 55, "01484052260681797": 54, "014841": 54, "014936836616036158": 54, "014937": 54, "015451559930309012": 54, "015452": 54, "0154659": 35, "016564846045842005": 55, "016565": 55, "016820573610021133": 55, "016821": 55, "016830": 55, "016830288384432443": 55, "01737": 35, "0181194": 22, "01948e": 105, "0196834": 18, "01ada507287d82875905620988597833ad4e0903": 87, "02": [109, 121], "02014490729340573": 54, "020145": 54, "02252": 82, "0230466": 16, "024": 58, "0244": 35, "0253824": 35, "028005751626881802": 55, "028006": 55, "0280585": 99, "02832486312228176": 54, "028325": 54, "0288679": 35, "029945": 55, "02994522036707356": 55, "03": [32, 54, 70, 71, 108, 121], "03000": 115, "0301728": 35, "0303096": 35, "03262e": 82, "03332": 41, "03371e": 82, "0353719": 44, "0356934": 35, "0360559": 35, "037163": 55, "03716318260525985": 55, "038617876339801765": 55, "038618": 55, "03883": 35, "03b": 9, "04084": 35, "0411104": 10, "0418726": 35, "042010": 55, "042019": 15, "0438392": 35, "043851": 55, "04385133919593825": 55, "04447784402047958": 54, "044478": 54, "048": 122, "048605": 112, "049816": 55, "04981619915828577": 55, "05": [19, 21, 32, 74, 80, 105, 108, 110], "0521719": 44, "052413": 112, "054": [88, 122], "0541353": 22, "0551168": 19, "056008": 55, "05600839449203463": 55, "056797": 44, "057646": 105, "0596657": 44, "06": [19, 55, 121], "060466": 105, "0622285": 35, "06238492357004281": 54, "062385": 54, "06249": 12, "06351": 92, "0640211": 22, "0650986": 35, "0660146": 22, "066911": 55, "06691128419125478": 55, "068030": 55, "06858": 119, "0691823": 22, "07": 54, "0715241": 19, "074": 108, "07677412033081": 56, "0769677": 35, "0777335": 44, "078950": 55, "08": [19, 26, 48, 54, 55, 119], "081690": 55, "08169016239095044": 55, "0818383": 44, "082": 92, "082558": 55, "083001": 55, "08300129677257653": 55, "085": 93, "08622": 92, "0876096": 16, "087984": 54, "088011": 55, "08928561211360032": 55, "089286": 55, "09": 12, "0906907": 22, "090b5e7e70c295757f55df93cb0a180b9691891a": 137, "09278e": 82, "09346": 35, "094441": 44, "0959341": 22, "09613e": 82, "096159": 55, "09615916813911475": 55, "0963696": 22, "098498": 54, "098702": 54, "0988395141460621": 54, "098840": 54, "09969": 119, "0_test": 85, "0_train": 85, "0b8703943ccdb6eb788e6f091b8946e82231bc4d": 95, "0cb91d09b814ecdc07b50f31f8dcad3e81d6a86d": 26, "0kib": 107, "0th": [40, 88], "0\u65f6": 117, "1": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141], "10": [1, 3, 4, 5, 6, 8, 9, 10, 11, 14, 15, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 41, 43, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 61, 62, 65, 66, 69, 70, 72, 74, 76, 79, 80, 81, 82, 87, 88, 90, 91, 92, 94, 96, 97, 98, 99, 101, 102, 103, 105, 107, 108, 109, 110, 111, 112, 115, 117, 119, 121, 122, 123, 124, 125, 129, 132, 137, 141, 142], "100": [6, 7, 9, 10, 11, 16, 18, 22, 23, 25, 34, 35, 39, 40, 56, 58, 62, 66, 67, 74, 79, 82, 86, 88, 93, 95, 99, 108, 114, 117, 121, 123, 132, 134, 135, 136], "1000": [1, 6, 9, 18, 21, 22, 25, 26, 29, 34, 46, 47, 51, 60, 62, 70, 71, 73, 87, 90, 112, 114, 121, 123, 130, 136, 139], "10000": [9, 25, 52, 62, 69, 71, 85, 90, 97, 115, 121, 122, 132], "100000": 54, "1000000": 121, "100968": 54, "100d": [86, 88, 95], "100k": 121, "101": [9, 55, 110], "10138": 22, "102": [54, 55, 137], "10222": 26, "1024": [32, 37, 46, 51, 52, 81, 90, 92, 123, 125, 127, 134, 135], "1025": 81, "1026": 81, "1028": 81, "102841": 54, "103": 55, "1032": 81, "10357": 26, "10369": 22, "104": 40, "1048576": 1, "105": [31, 128], "105315": 22, "105919": 35, "106000": 120, "106966": 54, "10696632399613491": 54, "107239": 44, "10743": 22, "1078": [21, 31], "108": 54, "108251": 44, "108913": 44, "109": 137, "10section": [21, 83, 84, 102, 113, 131], "10th": 136, "11": [2, 3, 4, 6, 7, 8, 9, 10, 11, 21, 30, 34, 37, 41, 45, 54, 55, 58, 64, 74, 75, 77, 88, 90, 99, 112, 117, 119, 130, 132], "110": [9, 83, 92], "111": [9, 110, 128], "1114": [21, 31], "111812": 21, "112": [20, 32, 37, 137], "1122": 21, "112784": 18, "11369": 133, "113741": 44, "114575": 82, "115": [31, 55], "115258": 14, "1155": 137, "116": 107, "116763": 66, "117833": 133, "118": 55, "118367": 71, "119619": 112, "11b": 6, "11section": [38, 74, 84, 113, 128, 129, 131], "12": [2, 6, 28, 30, 33, 34, 37, 39, 45, 46, 54, 55, 57, 64, 76, 92, 101, 102, 103, 105, 107, 108, 109, 111, 112, 113, 114, 117, 119], "120": [26, 35, 40, 43, 107], "120000": 58, "121458": 54, "12145810759683173": 54, "123451": 55, "12345124308220282": 55, "124": 54, "1245": 137, "125": 79, "12587": 99, "126": 62, "126340": 109, "1267": 137, "126733": 16, "12681": 35, "127466": 55, "127500": 120, "128": [1, 4, 10, 11, 12, 22, 25, 26, 31, 32, 34, 35, 36, 37, 39, 40, 43, 51, 54, 55, 56, 85, 92, 108, 128, 129], "128638": 66, "129": 55, "12section": 52, "13": [19, 21, 23, 25, 26, 27, 30, 31, 32, 33, 45, 54, 55, 64, 76, 80, 92, 112, 113, 117, 121, 130, 132, 137], "130": [31, 137], "1306": 121, "130971": 99, "13110899872947157": 55, "131109": 55, "132": 54, "133308": 54, "1333083293327977": 54, "13479": 69, "134918": 82, "135524": 54, "13654": 44, "137718": 133, "137964": 99, "139319": 66, "13976762587971506": 54, "139768": 54, "13section": 26, "14": [26, 30, 43, 45, 48, 54, 55, 64, 76, 83, 84, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 113, 117, 120, 128, 129, 130, 132, 137], "140": 31, "1400": 22, "140000": [79, 120], "141182": 66, "14128": 133, "144": 37, "14518": 12, "1456": 21, "1459": 79, "145933": 54, "146": [22, 107], "1460": [58, 79], "14624": 133, "147345": 54, "14734507957489268": 54, "147541": 54, "14754101174871392": 54, "147898": 99, "148": [40, 128], "14811": 71, "14section": 84, "15": [1, 19, 21, 27, 30, 45, 54, 55, 61, 66, 70, 76, 85, 86, 89, 90, 91, 96, 105, 107, 113, 117, 130, 132, 137], "150": 23, "1500": 108, "1500529": 97, "151705": 44, "152": [15, 39], "152469": 54, "153": 54, "1533": 58, "155126": 54, "155831": 55, "1563": 12, "156726": 18, "15719": 35, "1574882117184726": 56, "157916": 55, "157970": 55, "158591": 102, "159": [54, 55], "15section": [90, 92, 94, 95], "16": [4, 11, 15, 21, 27, 30, 32, 33, 34, 35, 37, 39, 43, 45, 51, 52, 54, 55, 58, 76, 92, 107, 108, 113, 117, 119, 129, 132, 135, 136, 137, 141], "160": 37, "16009": 35, "160262": 44, "161859": 12, "162": [23, 55], "162082": 54, "163": 54, "163435": 99, "164": 34, "164617": 66, "165": 54, "165136": 44, "1655": 58, "166": 55, "166621": 99, "1673": 109, "168": 128, "168673": 44, "169": 137, "169669": 44, "16khz": 58, "17": [47, 48, 49, 54, 55, 80, 88, 117, 119], "170069": 55, "1705": 58, "170778": 54, "171714": 54, "172": 40, "17206": 86, "1723233e": 19, "172483": 55, "173428": 137, "174823": 55, "175": 55, "175115": 55, "1754241e": 19, "177": 55, "17722380250692366": 79, "1777": 58, "178032": 16, "178100": 120, "178825": 54, "18": [1, 21, 22, 23, 36, 39, 51, 52, 54, 55, 56, 76, 117], "181500": 79, "182764": 85, "182909": 99, "183187": 85, "183416": 85, "18379": 12, "184658": 55, "1846580541163797": 55, "1855": 58, "185595": 12, "186632": 109, "18678": 85, "187": 22, "1873": 58, "1879": 120, "1890": 58, "1898": 137, "189823": 54, "18e": 32, "19": [28, 41, 54, 55, 72, 109, 117, 121, 132], "190": [55, 128], "190157": 55, "19016": 119, "1904": 58, "191": 41, "1912": 58, "191342": 54, "191474": 54, "19147449863618432": 54, "1916": 58, "192": [31, 37, 40, 128], "1922": 97, "1936": 58, "19399": 18, "1950": 141, "1954": 58, "1960": 66, "1962": 58, "1963": 61, "197": 55, "1970": [58, 66], "1978": 79, "19781": 35, "198": 22, "1980": [43, 58, 81, 114], "198006": 54, "1985": 58, "198504": 66, "1990": [34, 43, 58, 62, 80, 113], "1991": 127, "199337": 99, "1994": [25, 34, 49], "1995": [34, 58, 62], "1996": 49, "199671": 55, "1997": 127, "1999": 34, "1999989e": 19, "19th": 69, "1d": [1, 3], "1e": [1, 19, 21, 26, 35, 40, 51, 52, 54, 55, 56, 92, 95, 97, 99, 101, 102, 103, 107, 108, 111], "1e3": 28, "1e6": 3, "1f": [1, 23, 25, 26, 32, 92, 99], "1f77b4": 105, "1gb": 34, "1ghz": 34, "1k": 117, "1m": 117, "1n": 117, "1section": [5, 11, 12, 15, 16, 20, 23, 25, 27, 31, 41, 51, 55, 56, 60, 64, 66, 67, 71, 72, 73, 74, 79, 80, 82, 83, 85, 89, 91, 92, 93, 97, 99, 105, 110, 113, 120, 125, 127, 129, 130, 132, 133, 134, 135, 136], "1x1\u5377\u79ef\u5c42\u540e\u63a53x3\u5377\u79ef\u5c42": 37, "1x1\u5377\u79ef\u5c42\u540e\u63a55x5\u5377\u79ef\u5c42": 37, "1x_1": 111, "2": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 60, 61, 62, 64, 66, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 125, 127, 128, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "20": [1, 3, 15, 17, 25, 30, 32, 33, 34, 47, 49, 51, 54, 55, 58, 61, 70, 74, 76, 79, 88, 90, 97, 99, 102, 105, 107, 109, 111, 117, 123, 125, 127, 128, 134, 135], "200": [10, 22, 23, 31, 44, 58, 74, 86, 108, 117], "2000": [6, 18, 22, 30, 34, 43, 58, 70, 127], "20002": 3, "2001": [25, 58], "2005": 58, "2006": 79, "2007": 13, "2009": [34, 58], "200k": 121, "2010": [5, 25, 38, 58, 79, 97, 125, 131], "2011": 127, "2012": [31, 34], "2014": [37, 58], "2015": [15, 39, 58, 112], "2017": [35, 58, 62, 127], "2018": [5, 90], "201815": 44, "2020": 58, "2021": 113, "2023": 25, "202488": 55, "20248813907299865": 55, "2025": [54, 55], "202501": 66, "20256": 91, "203396": 82, "20403568510229048": 54, "204036": 54, "2042040": 19, "2048": 11, "205": 55, "205189": 54, "2056": 123, "205698": 55, "205997": 112, "2065": 25, "2068874e4b9a9f0fb07ebe0ad2b29754449ccacd": 25, "207319": 54, "208": 37, "208500": 79, "209": 55, "20b": 6, "21": [21, 54, 55, 64, 117, 132, 137, 140, 141], "210023": 15, "21129e": 82, "211973": 54, "212": [54, 55], "212063712661875": 55, "212064": 55, "212274": 44, "213": 55, "213216": 14, "214130": 54, "214373": 44, "214382": 119, "2146": 52, "21545": 12, "216": 55, "216004": 55, "216009": 99, "2164": 88, "217464": 71, "21776": 32, "21e": 32, "22": [54, 55, 64, 82, 108, 117], "220": 54, "22026": 119, "22097": 82, "221213": 12, "221629": 55, "222": 22, "223214": 54, "223500": 79, "223754": 44, "224": [8, 21, 22, 26, 28, 31, 34, 36, 37, 40, 54], "225": [21, 22, 26, 28, 31], "226": 55, "2261": 137, "226452": 112, "226628": 44, "226708": 54, "229": [21, 22, 26, 28, 31], "229808": 10, "23": [19, 36, 54, 55, 64, 82, 117], "233063": 54, "233703": 44, "234850": 55, "235": 55, "235121": 99, "237821": 55, "238133": 55, "238202": 54, "239171": 10, "23945": 82, "24": [10, 11, 37, 39, 47, 54, 55, 58, 64, 82, 92, 117, 136, 137], "240": [44, 54], "2403b5305c7599b48033ce9ca0bc5baa": 54, "240856": 3, "242": [101, 102, 111], "243": [101, 103, 108, 109], "244": 103, "244533": 10, "245147": 35, "246": 109, "2465": 108, "247822": 55, "248": [54, 55], "249": [55, 108], "25": [1, 19, 28, 41, 47, 48, 49, 54, 55, 56, 58, 61, 80, 82, 107, 109, 110, 117], "250": [6, 19, 58, 140], "2500": 61, "25000": 87, "251": [41, 54], "25294": 12, "253": 54, "25300": 32, "254": 108, "254271": 44, "25461": 82, "255": [1, 21, 23, 25, 28, 29, 31, 65], "25507": 35, "256": [1, 4, 10, 15, 17, 21, 22, 23, 26, 29, 31, 32, 34, 35, 37, 39, 40, 51, 52, 54, 55, 56, 65, 66, 69, 76, 81, 86, 92, 107, 108, 129, 137, 140], "257939": 35, "258015": 99, "2582040e": 19, "258397": 55, "2583974707015322": 55, "259483": 55, "26": [34, 54, 55, 88, 105], "260590": 54, "26059001016457334": 54, "261735": 55, "262156": 54, "262178": 55, "262952": 54, "26585e": 82, "268789": 55, "269680": 54, "26986": 105, "27": [33, 54, 55, 97], "270": 6, "270000": 120, "271": 107, "271574": 3, "272": 32, "27212": 73, "273626": 119, "274113": 54, "276235": 16, "278216": 54, "278472": 55, "28": [28, 34, 37, 43, 47, 54, 55, 58, 62, 66, 81, 105, 114, 128, 131, 137], "280": 6, "280011": 55, "28001134495568514": 55, "281054": 3, "282096": 99, "283": 47, "284035": 3, "285598": 16, "287549": 54, "28755": 3, "2879408868000836": 54, "287941": 54, "288": 37, "288431": 66, "29": [54, 55, 62], "290000": 25, "290871": 66, "295838": 18, "297738": 3, "299": 47, "299320": 54, "2993200275939439": 54, "2_": 82, "2_j": 82, "2_x": 100, "2d": [1, 3, 9, 35, 41, 105, 109, 137, 140, 141], "2e": [25, 32], "2f": [32, 62, 104, 105, 107, 109, 111], "2g": 49, "2ghz": 108, "2i": [47, 117], "2j": 9, "2k": 117, "2m": [98, 117], "2mib": 107, "2mnp": 108, "2n": [61, 117], "2section": [3, 10, 11, 20, 26, 27, 31, 33, 34, 39, 43, 45, 51, 52, 54, 56, 60, 66, 71, 77, 79, 81, 88, 91, 93, 97, 99, 110, 113, 123, 130, 132, 133, 135], "2x": [80, 105, 115], "2x_1": 105, "2x_2": [105, 111], "2xx": 49, "3": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 44, 45, 46, 47, 48, 50, 52, 54, 55, 56, 57, 58, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99, 103, 104, 105, 107, 108, 110, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 125, 127, 128, 129, 130, 132, 133, 135, 136, 141], "30": [4, 5, 10, 30, 43, 44, 54, 55, 56, 58, 90, 105, 107, 121, 129, 136, 137], "300": [6, 11, 28, 31, 34, 95], "3000": 58, "30000": [91, 115], "300000": 25, "3001": 82, "300d": 95, "301189": 55, "3011893656031137": 55, "303517": 44, "305785": 55, "306699": 54, "308797": 44, "309": 137, "309312": 44, "31": [54, 55, 64], "311101": 99, "3114746598543795": 54, "311475": 54, "313": 22, "314703831688577": 54, "314704": 54, "31702": 82, "319d85e578af0cdc590547f26231e4e31cdf1e42": 97, "32": [9, 15, 21, 23, 25, 26, 29, 32, 34, 36, 37, 39, 43, 51, 52, 54, 55, 56, 58, 62, 64, 69, 73, 88, 107, 108, 117, 123, 125, 127, 134, 135], "320": [21, 31, 37, 108], "3219": 85, "322396": 3, "3228": 97, "3237": 85, "32831": 35, "329175": 66, "329817": 55, "33": [32, 54, 55, 64], "330": 79, "33087": 16, "330900": 54, "331": 79, "331466": 54, "333": 21, "333075": 12, "33314": 12, "333333": 117, "3341822624206543": 108, "335": 21, "335800": 54, "3367": 95, "3368": 85, "34": [26, 54, 55, 64], "340": [83, 92], "34086e": 82, "342522": 3, "342722": 3, "345029": 3, "345343": 73, "347241": 55, "3472413436671253": 55, "34819874766327785": 55, "348199": 55, "35": [51, 54, 55], "350": [6, 58], "350325": 54, "350m": 6, "35254": 133, "355678": 44, "356": 22, "356574": 99, "357395": 3, "35802": 35, "358084": 54, "35857": 3, "36": [54, 93, 121], "362": 25, "363": 26, "36314": 108, "365109": 109, "366": 21, "37": [32, 33, 41, 54, 55, 80, 112], "37369": 35, "373880": 54, "37475164983438675": 54, "374752": 54, "375": 21, "376224": 3, "378": 20, "378752": 10, "37976": 35, "379866": 3, "38": [65, 140, 141], "382": 99, "382563": 102, "38278": 133, "384": [34, 37, 51, 108], "384183": 54, "385643": 35, "38626": 35, "38707": 99, "387814": 109, "38809559103096963": 55, "388096": 55, "3890338391272654": 55, "389034": 55, "38906": 119, "39": [54, 55], "39026": 35, "390648": 55, "391": [26, 87], "391895": 119, "3922": 97, "396722": 99, "39698e": 12, "3999999e": 19, "3am": 61, "3b": 6, "3c914d17d80b1459be871a5039ac23e752a53cb": 91, "3d": [1, 3, 110], "3e": 41, "3f": [1, 4, 10, 23, 25, 26, 41, 92, 95, 99, 107, 108, 129], "3gb": 34, "3mib": 23, "3section": [6, 7, 10, 19, 21, 31, 32, 33, 37, 43, 52, 55, 56, 64, 66, 69, 71, 73, 77, 79, 80, 86, 90, 91, 93, 94, 95, 99, 105, 108, 109, 112, 113, 119, 128, 129, 130, 131, 132, 133, 135], "3x": 115, "3x3\u6700\u5927\u6c47\u805a\u5c42\u540e\u63a51x1\u5377\u79ef\u5c42": 37, "3x_1": 115, "4": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 14, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 56, 58, 60, 64, 65, 66, 69, 70, 71, 72, 73, 79, 80, 81, 82, 83, 86, 88, 89, 90, 92, 93, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 110, 111, 112, 114, 115, 117, 118, 119, 120, 121, 122, 125, 127, 128, 129, 130, 132, 133, 135, 136, 140, 141], "40": [2, 6, 25, 30, 34, 47, 96, 108, 109, 111, 121, 122], "400": [20, 23, 43, 86], "400000": 95, "400001": 95, "40436e": 82, "406": [21, 22, 26, 28, 31], "4060": 97, "409475": 55, "4096": [1, 32, 34], "41": [54, 121], "412": 107, "412968": 12, "413799": 54, "414087": 55, "41537": 12, "416667": 117, "41776684604758285": 55, "417767": 55, "417826": 99, "42": [6, 14, 81], "42069": 97, "42188880580044036": 54, "421889": 54, "421943": 10, "42661": 14, "426747": 44, "42b": [81, 95], "43": [41, 54, 55, 81, 121], "432": 107, "433653": 55, "435": 55, "436": 54, "436326": 99, "439": 18, "43999": 35, "44": [55, 58, 64], "440": 137, "44081": 35, "442": 41, "443": 137, "443679": 119, "445965": 44, "4465": 25, "447": 32, "45": [19, 20, 48, 97, 102, 105, 135], "450": 28, "45000": 25, "4507520512": 119, "451126": 99, "452218": 3, "454": 107, "455": 26, "456": [21, 22, 23, 26, 28, 31], "4576": 35, "459932": 99, "46": [54, 55, 121, 135], "460184": 119, "466594": 55, "469100": 54, "47": [54, 121], "470002": 54, "473000": 55, "473938": 55, "4743": 97, "48": [10, 11, 37], "480": [21, 31, 34, 37, 41], "48148e": 82, "4822": 25, "484": 26, "484688": 54, "485": [21, 22, 26, 28, 31], "485261": 99, "486506": 54, "486784": 105, "490762": 54, "4914": 25, "4915": 121, "492": 23, "493": 20, "49346": 88, "493749": 54, "495389": 133, "49573": 35, "496": 26, "496423": 18, "49787": 66, "49847": 35, "499139": 44, "499406": 54, "4994060435597754": 54, "4e443f8a2eca6b1dac8a6c57641b67dd40621a49": 31, "4f": 99, "4mib": 23, "4section": [3, 10, 11, 14, 19, 23, 27, 32, 35, 36, 37, 39, 40, 41, 43, 52, 55, 64, 65, 66, 69, 70, 71, 74, 77, 80, 81, 87, 90, 92, 94, 95, 103, 107, 108, 109, 114, 124, 127, 129, 131, 133, 135], "4x": [47, 115], "4x_2": 105, "5": [1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 14, 15, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 47, 48, 49, 51, 52, 54, 55, 56, 58, 60, 61, 62, 66, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 85, 87, 88, 89, 90, 91, 93, 96, 97, 99, 101, 104, 105, 107, 108, 109, 110, 112, 113, 115, 117, 119, 120, 121, 122, 124, 125, 127, 128, 129, 130, 132, 133, 135, 136, 137, 140, 141], "50": [23, 25, 28, 35, 47, 49, 51, 58, 70, 80, 85, 86, 87, 92, 95, 107, 112, 121, 125, 127], "500": [21, 23, 28, 47, 87, 108], "5000": [25, 132], "50000": 25, "500000": 85, "500px": 60, "5066198515892029": 51, "50770": 97, "5085": 121, "50d": 95, "51": 54, "512": [1, 11, 21, 22, 37, 39, 91, 92, 97, 99, 108, 128], "514397": 55, "515": 25, "516": 20, "52": [19, 48, 55, 110], "521": 86, "528": [25, 37], "528166": 105, "529": 41, "53": [40, 121], "530": 6, "530845": 18, "531": 99, "532": 99, "53246": 86, "54": [19, 32, 34, 54, 121], "540": 6, "541": 137, "5444": 32, "545724": 133, "547782": 3, "549062": 18, "549367": [85, 86], "55": [19, 32, 54, 105], "550000": 85, "550684": 12, "552": 137, "552186": 12, "553498": 54, "55914": 73, "559851": 55, "56": [19, 40], "5600": 92, "561": [19, 21, 27], "562286": 44, "563362": 55, "563370": 54, "564189": 54, "5654519e": 19, "57": [19, 33, 121, 128], "57311": 82, "57469": 82, "578": 108, "578095": 44, "580": 34, "58351": 82, "585e9cc93e70b39160e7921475f9bcd7d31219c": 79, "58963": 35, "59": 137, "591757": 54, "5917570853739808": 54, "5939715e": 19, "59847": 119, "59874": 119, "5998": 23, "5b": 34, "5de26c8fce5ccdea9f91267273464dc968d20d72": 29, "5e": [22, 25, 26, 32, 115], "5f": [69, 115], "5mib": 107, "5section": [6, 10, 15, 23, 30, 32, 33, 54, 61, 64, 65, 82, 91, 98, 99, 102, 103, 104, 107, 113, 121, 122, 123, 125, 127, 129, 130, 131, 132, 133, 134], "6": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 16, 18, 19, 22, 30, 32, 33, 35, 37, 39, 40, 41, 43, 44, 45, 46, 47, 52, 54, 55, 58, 66, 67, 72, 74, 76, 77, 79, 80, 81, 82, 88, 90, 91, 92, 96, 97, 99, 102, 103, 107, 108, 109, 110, 111, 114, 115, 117, 119, 121, 122, 128, 129, 132, 136, 137, 141], "60": [9, 20, 34, 54, 55, 58, 62, 79, 87, 97, 137], "600": [1, 58, 136], "6000": 62, "60000": [22, 52, 62], "601": 136, "601254": 133, "6013": 133, "602": 136, "603": 136, "604": 136, "605": 136, "606": 136, "607": 136, "607070": 55, "608": 136, "609": 136, "61": 105, "61295e": 82, "619": 32, "619754": 55, "62": 19, "62279": 35, "624": 99, "626774": 54, "627085": 54, "63": [19, 55, 112], "63307": 19, "634836": 55, "637724": 54, "6377240017626923": 54, "638117": 55, "64": [1, 10, 12, 15, 21, 25, 31, 32, 34, 36, 37, 39, 48, 55, 58, 62, 79, 87, 88, 91, 92, 108, 119, 123, 136], "6400": 34, "641095": 12, "64mb": 62, "65": [54, 79], "654971": 3, "655": 20, "657478": 3, "658": 10, "65959": 82, "66": [19, 119, 140, 141], "666667": 117, "668324": 92, "67": 33, "670142": 14, "6719": 97, "677": 54, "67893": 119, "68": [54, 79], "6823640e": 19, "68279": 14, "6881757e": 19, "68987": 12, "690224": 54, "690488": 54, "6912": 34, "691636": 54, "69262": 119, "693813": 54, "695": 137, "698198": 55, "6b": [86, 88, 95], "6mib": 23, "6section": [4, 6, 8, 10, 11, 32, 34, 35, 51, 52, 54, 61, 66, 76, 77, 99, 102, 103, 107, 110, 111, 113, 122], "6x": 115, "7": [1, 2, 3, 4, 6, 9, 10, 11, 19, 21, 23, 27, 28, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 44, 45, 46, 51, 54, 55, 58, 60, 64, 66, 69, 76, 79, 88, 89, 90, 92, 93, 96, 97, 102, 105, 107, 108, 111, 117, 119, 121, 122, 130, 132, 137], "70": [6, 79], "700": 92, "701409": 54, "701409313060209": 54, "705484": 92, "706855": 18, "71": [19, 32], "710": 97, "713": 22, "7142800e": 19, "716": 23, "71828": 119, "72": [40, 54, 55, 117], "720": [54, 55], "721": [54, 55], "728": [19, 21, 27], "729": 21, "73": 137, "731191": 54, "7311914189829157": 54, "731557": 99, "732056": 92, "74202e": 82, "746251": 55, "74634e": 82, "746909": 54, "749": 95, "75": [19, 47, 93, 97, 122, 128], "750546": 92, "750m": 6, "759199": 82, "76": 40, "760812": 82, "7649756579068647": 54, "764976": 54, "7679648399353": 51, "768": [90, 92], "76e5be1548fd8222e5074cf0faae75edff8cf93f": 108, "77": 110, "77749": 35, "78": 137, "780": 6, "783766": 54, "784": [43, 52, 65, 66, 76, 81], "785419": 54, "785419139652293": 54, "787": 108, "79": [32, 79, 121], "792": 95, "793": 86, "797": 22, "7kib": 107, "7mib": 107, "7section": [5, 6, 19, 24, 25, 26, 27, 30, 35, 36, 52, 66, 76, 77, 88, 90, 101, 103, 104, 107, 111, 113, 120, 129, 131], "7z": 25, "8": [1, 3, 4, 6, 9, 10, 11, 12, 14, 16, 19, 20, 22, 23, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 48, 51, 52, 54, 55, 56, 58, 62, 64, 69, 76, 80, 82, 87, 88, 89, 90, 91, 92, 93, 96, 97, 98, 105, 107, 108, 110, 111, 112, 114, 117, 119, 121, 123, 128, 129, 140, 141], "80": [34, 54, 55, 58, 79, 90, 91, 121, 128], "800": [22, 90, 95], "801392782910287192": 121, "80186": 58, "80486": 58, "8080": 58, "808257": 54, "81": [34, 47, 79, 121, 128], "8103": 119, "810999": 55, "816": 137, "820": 86, "821524": 19, "823": 107, "83": [48, 55], "830": [23, 95], "8307": 121, "832": 37, "834": 107, "8341": 105, "834912": 54, "835": 25, "838213": 82, "839": 95, "84": [35, 43, 55, 107], "841101": 54, "844": 107, "8462": 99, "84621": 99, "847": 25, "848": 22, "85": 137, "850": [88, 107], "855617": 54, "856": 95, "858": 107, "86": 54, "862": 107, "87": 54, "874176": 112, "87474e": 82, "876": 21, "88": [19, 32, 54, 55], "885": 107, "88754": 35, "887637": 35, "8888": 57, "89": 55, "893": 95, "8937": 86, "898847": 55, "899113": 55, "899761": 54, "899781": 54, "899793": 55, "899822": 54, "899888": 55, "899918": 55, "899923": 55, "8d938717fd641d43907cdb9888ac1aaa": 55, "8khz": 58, "8section": [6, 11, 24, 31, 83, 84, 91, 92, 101, 103, 113], "9": [6, 9, 19, 21, 25, 26, 30, 31, 32, 33, 35, 37, 40, 45, 46, 48, 54, 55, 57, 58, 61, 66, 76, 82, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 101, 103, 104, 107, 108, 109, 111, 112, 117, 119, 122, 123, 125, 127, 128, 129, 130, 132, 133, 134, 135, 137, 140], "90": [54, 58, 65, 67], "900000": 54, "900002": 55, "900160": 55, "900478": 55, "900636": 54, "90324": 86, "903314": 54, "90823e": 82, "91": [19, 54], "910791": 55, "917": 22, "917364": 105, "92": 19, "921": 95, "924": 22, "92416": 12, "931088": 35, "934": 22, "9352": 99, "93521": 99, "935998": 55, "94": 54, "943467": 109, "943922": 41, "94646ad1522d915e7b0f9296181140edcf86a4f5": [1, 128], "95": [19, 25, 47, 48, 51, 61, 62, 109, 110, 111, 140, 141], "95319e": 82, "959": 99, "96": [11, 34, 36, 37, 39, 40, 54, 55, 93], "961": 32, "964713800900415": 54, "964714": 54, "97": [55, 121], "97283": 14, "973114": 55, "976": 107, "97949": 35, "98": [19, 80, 121], "9824": [85, 86], "983": 88, "985": 108, "98607": 14, "98983": 119, "98ee727e59fcc34fddaadae93e15b1f8ed5561a4": 91, "99": [52, 61, 121, 137, 139], "99174e": 82, "992138": 35, "99709": 133, "99846": 12, "999": 103, "999702": 35, "99998": 10, "9999990e": 19, "9fcde07509c7e87ec61c640c1b2753d9041758e4": 85, "9section": [21, 84, 92, 113, 126, 132], "A": [1, 2, 6, 8, 11, 13, 18, 19, 21, 22, 23, 25, 26, 28, 29, 30, 31, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 57, 61, 62, 63, 64, 65, 67, 69, 72, 76, 77, 80, 82, 83, 85, 86, 87, 90, 98, 100, 102, 103, 104, 105, 107, 108, 110, 112, 115, 116, 117, 119, 120, 122, 126, 127, 129, 131, 132, 133, 135, 136, 137, 139, 140, 141, 142], "AT": [43, 62], "And": [34, 45, 46, 58, 60, 61, 64, 67, 77, 79, 80, 113, 117, 121, 127, 138], "As": [2, 3, 6, 7, 8, 9, 10, 12, 18, 19, 21, 22, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 39, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 59, 60, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 94, 96, 97, 98, 99, 100, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 139, 140, 141], "At": [2, 4, 5, 9, 10, 19, 24, 27, 32, 34, 36, 37, 39, 40, 41, 43, 44, 45, 48, 53, 54, 55, 56, 57, 58, 60, 62, 66, 67, 69, 70, 71, 72, 76, 77, 78, 86, 87, 108, 112, 113, 114, 115, 117, 122, 123, 129, 132, 133, 135, 136, 139, 141], "BY": 60, "But": [1, 18, 46, 47, 58, 60, 61, 65, 67, 70, 74, 77, 79, 80, 102, 117, 129, 131, 134, 135, 136, 137, 140], "By": [6, 8, 14, 15, 18, 27, 28, 29, 31, 34, 35, 39, 40, 41, 43, 44, 45, 46, 47, 49, 58, 59, 61, 62, 65, 66, 67, 70, 74, 75, 76, 85, 86, 91, 104, 105, 109, 110, 113, 117, 118, 119, 121, 125, 130, 135], "For": [1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141], "If": [1, 3, 5, 8, 18, 19, 21, 22, 25, 26, 27, 28, 33, 34, 35, 39, 40, 41, 43, 44, 47, 48, 49, 54, 55, 56, 57, 58, 60, 61, 64, 65, 67, 69, 71, 72, 79, 80, 82, 93, 102, 104, 105, 106, 107, 108, 109, 110, 112, 113, 117, 118, 119, 121, 122, 127, 128, 129, 130, 131, 132, 133, 136, 137, 139, 140, 141], "In": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141], "It": [1, 2, 4, 5, 8, 16, 18, 19, 20, 21, 22, 23, 24, 28, 30, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 48, 49, 51, 52, 58, 59, 60, 61, 62, 64, 65, 66, 69, 70, 71, 72, 73, 75, 79, 80, 83, 84, 88, 93, 94, 98, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 121, 122, 130, 131, 132, 133, 135, 139, 140, 141], "Its": [6, 22, 27, 30, 39, 51, 91, 97, 110, 125, 127], "No": [1, 6, 61, 72, 113, 121], "Not": [60, 65, 69, 79, 115], "Of": [29, 38, 45, 59, 61, 89, 108, 121, 141], "On": [3, 7, 19, 31, 34, 35, 39, 48, 51, 52, 55, 56, 57, 58, 60, 61, 67, 75, 77, 79, 82, 83, 90, 91, 93, 102, 106, 108, 112, 113, 121, 122, 131, 135], "One": [2, 3, 4, 8, 12, 15, 19, 22, 28, 30, 31, 34, 35, 36, 39, 40, 43, 44, 47, 56, 58, 60, 61, 62, 64, 67, 69, 72, 73, 74, 75, 76, 79, 80, 82, 84, 94, 103, 104, 106, 107, 109, 111, 114, 117, 121, 127, 129, 130, 131, 132, 136, 137], "Or": [121, 137], "Such": [31, 58, 69, 77, 82, 83, 84, 85, 86, 108, 136, 137, 138, 140], "That": [2, 3, 19, 34, 35, 36, 39, 41, 45, 46, 58, 59, 60, 64, 66, 69, 70, 74, 77, 80, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 115, 119, 121, 130, 136], "The": [1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 60, 63, 65, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 89, 90, 92, 94, 95, 100, 104, 105, 106, 107, 108, 110, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 141, 142], "Their": [38, 72, 76, 103, 113], "Then": [3, 4, 5, 7, 8, 11, 15, 18, 19, 21, 22, 23, 24, 26, 28, 29, 30, 32, 33, 36, 39, 47, 49, 55, 57, 58, 59, 60, 64, 67, 69, 71, 76, 77, 78, 79, 85, 86, 88, 90, 91, 95, 96, 98, 99, 104, 107, 112, 113, 115, 122, 125, 129, 130], "There": [2, 3, 8, 16, 18, 19, 26, 29, 31, 32, 34, 39, 44, 46, 47, 50, 52, 58, 64, 69, 72, 74, 80, 82, 86, 97, 104, 107, 108, 109, 110, 112, 115, 117, 119, 121, 123, 131, 132, 133, 136, 138, 140], "These": [3, 5, 6, 9, 10, 13, 15, 19, 22, 28, 30, 32, 34, 35, 37, 39, 42, 43, 45, 47, 48, 50, 52, 58, 60, 70, 75, 79, 80, 83, 88, 90, 91, 99, 108, 109, 113, 117, 119, 120, 121, 123, 127, 131, 133, 134, 136, 137, 138], "To": [0, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 46, 47, 48, 51, 52, 55, 57, 58, 60, 61, 62, 64, 66, 67, 69, 70, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 128, 129, 130, 132, 133, 135, 136, 137, 140, 141], "Will": 48, "With": [6, 10, 31, 39, 46, 48, 51, 56, 58, 61, 66, 76, 77, 79, 80, 81, 82, 86, 87, 90, 92, 108, 113, 115, 119, 126, 128, 133, 136], "_": [1, 4, 8, 10, 11, 19, 23, 28, 29, 31, 32, 35, 39, 46, 47, 52, 56, 61, 66, 69, 75, 82, 86, 89, 92, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 108, 109, 111, 112, 115, 117, 118, 121, 122, 123, 125, 127, 128, 129, 130, 133, 135, 136, 139, 140, 141], "_0": [102, 103, 109], "_1": [3, 8, 9, 28, 39, 60, 64, 86, 102, 112, 117, 121, 129, 130, 136], "_2": [3, 89, 102, 104, 115, 117, 121, 130], "_3": [39, 130, 133], "_5": 9, "_6": 39, "__": 118, "__call__": [1, 3, 4, 7, 9, 10, 11, 12, 15, 17, 26, 28, 32, 35, 36, 37, 39, 41, 65, 66, 70, 71, 72, 76, 81, 86, 88, 90, 107, 123, 124, 125, 127, 129, 134, 135], "__class__": 43, "__doc__": 118, "__getitem__": [1, 29, 31, 72, 85, 91, 95, 97, 137], "__init__": [1, 3, 4, 7, 9, 10, 11, 12, 15, 17, 18, 26, 28, 29, 31, 32, 34, 35, 36, 37, 39, 41, 43, 51, 56, 62, 65, 66, 70, 71, 72, 73, 74, 76, 79, 81, 85, 86, 88, 90, 91, 95, 97, 99, 107, 108, 123, 124, 125, 127, 128, 129, 132, 134, 135, 136, 137], "__iter__": [72, 85, 91], "__len__": [1, 29, 31, 72, 73, 85, 91, 95, 97, 115, 137], "__loader__": 118, "__module__": 107, "__name__": [43, 72, 107, 113, 118], "__next__": 72, "__package__": 118, "__spec__": 118, "_a": [86, 90], "_attention_weight": [3, 4, 10], "_b": [86, 90, 104], "_build_arrai": 128, "_c": [28, 89, 98], "_d": 102, "_dataset": 21, "_device_nam": 107, "_download": [128, 132, 137], "_f": [39, 60], "_g": 96, "_get_batch_loss_bert": 92, "_get_mlm_data_from_token": 91, "_get_next_sent": 91, "_get_nsp_data_from_paragraph": 91, "_i": [2, 3, 7, 8, 9, 28, 60, 64, 66, 77, 79, 86, 93, 98, 100, 102, 104, 109, 112, 121, 130, 131], "_initialize_weight": 1, "_j": [2, 3, 8, 28, 64, 65, 86, 93, 98, 117, 121], "_k": 93, "_load_embed": 95, "_m": [8, 60, 86, 117], "_make_list": 19, "_make_tupl": 11, "_n": [3, 9, 60, 86], "_o": [89, 98], "_p": [100, 104, 117], "_pad": 85, "_pad_bert_input": 91, "_preprocess": [128, 137], "_read_wiki": 91, "_replace_mlm_token": 91, "_sequence_mask": 3, "_t": [60, 69, 101, 102, 103, 108, 109, 111, 112, 123, 125, 127, 129, 130, 133, 136, 139], "_token": [128, 137], "_w": 96, "_wikitextdataset": 91, "a0": 1, "a1": 1, "a100": 34, "a_": [19, 47, 96, 117, 130], "a_0": [19, 139, 141], "a_1": [19, 61, 139, 141], "a_2": [19, 139], "a_3": 19, "a_4": 19, "a_5": 19, "a_6": 19, "a_7": 19, "a_8": 19, "a_9": 19, "a_i": 19, "a_n": 61, "a_t": [130, 139, 140, 141], "aaron": 53, "aarush": 113, "ab": [2, 14, 15, 21, 28, 32, 40, 71, 105, 113, 117, 122], "abalon": 120, "abbrevi": [20, 80], "abc": 131, "abd": 122, "abhinav": 113, "abhinavsp0730": 113, "abhishek": 113, "abil": [6, 13, 22, 23, 35, 39, 40, 49, 58, 64, 67, 71, 114, 116, 121, 123, 136, 140], "abl": [3, 16, 34, 35, 43, 46, 51, 53, 56, 57, 58, 64, 67, 72, 73, 75, 77, 82, 85, 90, 104, 105, 108, 110, 113, 121, 126, 127, 132, 136, 138], "ablat": 6, "abnorm": 20, "abnorml": 79, "aboobakuru": 60, "abound": 60, "about": [1, 3, 4, 6, 9, 13, 15, 17, 18, 19, 31, 34, 35, 38, 44, 45, 47, 48, 49, 50, 52, 54, 55, 58, 59, 60, 61, 64, 67, 68, 69, 70, 72, 73, 75, 76, 77, 79, 80, 82, 83, 85, 96, 102, 112, 117, 120, 121, 127, 130, 131, 132, 135, 136, 137], "abov": [2, 6, 7, 8, 9, 10, 15, 19, 22, 23, 25, 26, 31, 32, 33, 34, 35, 40, 41, 44, 46, 47, 48, 49, 52, 54, 58, 60, 61, 62, 64, 66, 67, 72, 73, 75, 76, 78, 80, 82, 83, 87, 88, 93, 97, 98, 99, 102, 104, 105, 109, 110, 112, 121, 125, 127, 128, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "absent": [60, 61, 67, 76, 77, 136], "absolut": [32, 71, 79, 105, 117, 121], "absorb": 49, "abstract": [8, 13, 15, 27, 49, 58, 73, 81, 104, 139], "absurd": [61, 67, 80], "absurdli": 80, "abund": [6, 34, 58, 67, 90], "abus": [80, 121], "academ": [34, 58, 75, 113], "academia": [22, 24], "acc": [1, 21, 22, 23, 25, 26, 59, 86, 88, 107], "acceler": [11, 22, 25, 26, 29, 31, 34, 35, 37, 39, 45, 55, 64, 69, 79, 82, 86, 87, 88, 95, 99, 103, 109, 119, 132, 139], "accept": [35, 41, 58, 72, 83], "access": [12, 13, 14, 15, 19, 31, 32, 43, 54, 56, 57, 58, 60, 61, 65, 67, 69, 70, 72, 73, 78, 85, 91, 102, 108, 113, 114, 117, 119, 121, 129, 140], "accid": 60, "accomplish": [34, 39, 43, 44, 45, 58, 64, 73, 75, 86, 105, 107, 109, 110, 113, 132], "accord": [2, 8, 9, 14, 15, 19, 21, 25, 26, 27, 30, 37, 45, 46, 54, 58, 60, 61, 64, 67, 69, 75, 76, 77, 79, 82, 83, 91, 97, 98, 99, 104, 117, 119, 130, 136], "accordingli": [42, 46, 60, 102, 104, 117], "account": [25, 26, 58, 61, 63, 69, 77, 79, 80, 113, 127, 132], "accru": [58, 127], "accumul": [1, 23, 25, 26, 32, 58, 92, 99, 102, 107, 108, 109, 111, 136], "accur": [19, 20, 30, 34, 39, 41, 42, 58, 60, 65, 67, 69, 71, 77, 79, 98, 102, 121, 130, 132, 136], "accuraci": [1, 6, 11, 19, 21, 22, 23, 25, 30, 32, 34, 35, 37, 38, 39, 43, 45, 52, 58, 60, 61, 62, 63, 64, 65, 66, 67, 73, 74, 80, 81, 86, 88, 102, 107, 115, 122, 123, 132, 136], "accuracy_sum": 52, "achiev": [1, 4, 6, 13, 21, 25, 26, 30, 33, 34, 36, 37, 39, 42, 43, 45, 46, 49, 58, 60, 61, 62, 64, 67, 77, 86, 102, 107, 108, 113, 121, 125, 130, 134, 139, 141], "achil": 34, "achin": 133, "aclimdb": 87, "aclimdb_v1": [87, 88], "acquaint": 49, "acquir": [48, 58, 119], "acquisit": [47, 121], "across": [3, 6, 8, 10, 16, 19, 29, 34, 35, 37, 38, 39, 40, 41, 42, 45, 49, 51, 52, 54, 55, 58, 60, 67, 69, 74, 76, 77, 80, 82, 83, 88, 90, 113, 120, 126, 127, 130, 131, 132], "act": [6, 15, 35, 58, 60, 80, 121, 124, 136, 140], "action": [1, 2, 3, 43, 58, 60, 66, 72, 121, 125, 127, 138, 139, 140], "action2dxdi": 1, "action_spac": [1, 140], "activ": [3, 5, 6, 11, 12, 15, 26, 35, 36, 37, 39, 43, 46, 49, 50, 52, 57, 58, 60, 62, 64, 69, 71, 75, 76, 78, 81, 82, 89, 90, 99, 104, 107, 110, 123, 125, 127, 130, 131, 133, 135], "actual": [3, 8, 16, 19, 34, 35, 36, 37, 40, 41, 46, 47, 48, 49, 54, 58, 60, 61, 64, 66, 70, 77, 79, 80, 102, 105, 107, 108, 109, 113, 121, 130, 132, 136, 137, 140], "actuat": [58, 69], "ad": [6, 9, 10, 15, 20, 34, 35, 36, 37, 38, 39, 40, 44, 46, 47, 59, 60, 64, 69, 71, 72, 73, 76, 77, 79, 80, 81, 90, 101, 103, 104, 112, 117, 119, 127, 133], "adadelta": [106, 142], "adag": 80, "adagrad": [35, 101, 105, 106, 111, 142], "adagrad_2d": 102, "adam": [23, 28, 35, 47, 86, 88, 92, 99, 106, 113, 129, 142], "adapativemaxpool2d": 32, "adapt": [1, 5, 6, 11, 35, 42, 43, 46, 47, 52, 55, 56, 58, 60, 61, 63, 64, 72, 76, 82, 93, 94, 101, 104, 106, 111, 113, 131], "adaptiveavgpool1d": [1, 88], "adaptiveavgpool2d": [1, 21], "adaptivemaxpool2d": 32, "add": [1, 6, 10, 11, 18, 19, 21, 22, 23, 25, 26, 28, 32, 34, 35, 36, 37, 39, 40, 41, 44, 46, 47, 51, 56, 58, 64, 65, 69, 71, 73, 74, 75, 76, 80, 81, 88, 89, 92, 93, 95, 96, 99, 104, 107, 108, 109, 112, 121, 124, 132, 133], "add_modul": 21, "add_norm": 10, "add_patch": [19, 20], "add_subplot": 110, "add_to_class": [1, 7, 18, 36, 37, 39, 43, 51, 56, 59, 62, 65, 66, 70, 71, 72, 73, 79, 81, 123, 125, 127, 128, 129, 132, 135, 136, 137], "addit": [2, 4, 5, 6, 7, 9, 10, 18, 21, 22, 23, 27, 30, 31, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 49, 52, 54, 55, 56, 58, 60, 62, 65, 67, 69, 72, 73, 74, 76, 80, 82, 83, 90, 93, 102, 103, 107, 108, 109, 110, 112, 117, 118, 119, 121, 123, 124, 132, 135, 136, 141], "addition": [16, 17, 30, 35, 48, 56, 60, 76, 121, 127], "additional_info": [51, 56], "additiveattent": [3, 4], "addnorm": 10, "addnorm1": 10, "addnorm2": 10, "addnorm3": 10, "address": [3, 8, 11, 15, 17, 21, 22, 25, 26, 35, 45, 46, 58, 60, 61, 64, 66, 67, 74, 79, 80, 81, 82, 84, 86, 96, 98, 102, 103, 104, 107, 109, 113, 115, 119, 120, 121, 127, 130, 135, 136], "adequ": [60, 102], "adher": [100, 113, 121], "adilov": 113, "adjac": [40, 41, 42, 45, 88, 131, 132, 133, 136], "adject": [83, 95], "adjust": [2, 3, 12, 19, 21, 22, 23, 28, 35, 36, 37, 39, 40, 43, 45, 52, 58, 60, 66, 71, 74, 79, 81, 101, 102, 103, 104, 105, 107, 111, 112, 116, 125, 127, 129, 132, 135], "administ": [60, 67, 121], "admit": 69, "adolesc": 64, "adopt": [6, 19, 32, 35, 39, 58, 70, 74, 77, 131, 135], "adpat": 1, "adriaan": 113, "adtygan": 113, "adult": [58, 64], "adursun": 113, "advanc": [3, 6, 13, 24, 38, 43, 47, 50, 52, 53, 54, 58, 61, 62, 64, 79, 105, 107, 112, 113, 114, 117, 120, 121, 128, 131, 135, 138], "advantag": [34, 35, 36, 41, 44, 45, 47, 49, 58, 60, 62, 70, 71, 75, 80, 113, 125, 135], "advent": [34, 58], "adversari": [58, 60], "advertis": [58, 60, 102], "advis": [103, 108], "aerial": 60, "aeronaut": 69, "aeroplan": 31, "affair": 34, "affect": [2, 10, 11, 19, 27, 28, 34, 37, 41, 48, 49, 58, 60, 62, 81, 82, 85, 97, 106, 107, 121, 122, 126, 128, 130, 138, 141], "affin": [21, 35, 64, 69, 80], "afford": [41, 67, 70, 103], "aforement": [34, 39, 75, 82, 89, 90, 91, 92, 96, 110, 114, 129], "after": [1, 2, 3, 4, 6, 7, 10, 11, 16, 17, 19, 20, 22, 23, 25, 26, 31, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 54, 55, 56, 58, 60, 61, 65, 67, 69, 72, 73, 75, 76, 77, 79, 80, 82, 85, 87, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 112, 113, 114, 117, 119, 121, 122, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141], "afteral": 140, "afterthought": 34, "afterward": [51, 55, 56], "ag": [58, 60, 69, 121], "again": [26, 34, 36, 39, 47, 48, 56, 58, 60, 61, 64, 65, 69, 79, 80, 81, 104, 107, 112, 114, 121, 127, 140, 141], "against": [39, 51, 55, 62, 66, 71, 73, 79, 83], "agarw": 113, "agent": [58, 113, 121], "aggreg": [3, 4, 6, 8, 35, 39, 42, 45, 46, 58, 69, 70, 102, 103, 109, 111, 121], "aggress": [35, 46, 61, 102, 112], "agnost": 94, "ago": [60, 64, 113], "agre": [46, 61, 69, 76], "agricultur": 46, "ahead": [58, 117, 136], "ahmaurya": 113, "ahuja": 113, "ai": [4, 5, 6, 10, 57, 58, 113, 129, 140, 141], "aid": 113, "ailment": 67, "aim": [35, 46, 52, 60, 61, 76, 78, 85, 121, 125, 133], "air": [83, 138], "aircraft": 108, "airfoil": 108, "airfoil_self_nois": 108, "airplan": [25, 31, 34, 69, 85], "aka": 47, "akash5474": 113, "akin": [6, 8, 45, 103], "ala": [60, 80, 102, 105, 108], "alan": [58, 60], "alarm": 121, "albeit": [39, 44, 58, 65, 82, 102, 105, 108, 109, 112, 137], "albert": [6, 120], "albument": [21, 22, 23, 25, 26, 28, 31], "alchemi": 35, "alcohol": 60, "aleator": [47, 121], "alert": 58, "alessandro": 113, "alex": [8, 34, 58], "alexa": 58, "alexand": 58, "alexei": 61, "alexnet": [23, 37, 38, 39, 113, 142], "alexsau": 113, "algebra": [3, 34, 47, 69, 70, 113, 115, 116, 119, 142], "algorithm": [4, 6, 19, 21, 23, 25, 26, 32, 34, 35, 37, 40, 46, 50, 52, 53, 54, 56, 60, 62, 64, 65, 67, 68, 69, 72, 73, 74, 75, 77, 78, 80, 81, 82, 83, 91, 96, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 117, 120, 132, 136, 138, 139, 141, 142], "ali": [35, 113], "align": [2, 4, 6, 9, 14, 30, 45, 46, 47, 58, 60, 61, 64, 69, 74, 76, 80, 81, 82, 86, 89, 98, 101, 102, 103, 104, 108, 109, 111, 112, 115, 121, 122, 125, 127, 130, 132, 135, 136, 140], "align_corn": 21, "alik": [2, 46], "alipai": 58, "all": [2, 3, 4, 5, 6, 8, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 88, 89, 92, 93, 94, 96, 98, 99, 100, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 139, 140, 141], "all_cent": 97, "all_context": 97, "all_hypothesis_token": 85, "all_id_sort": 19, "all_idx": 19, "all_imag": 23, "all_mlm_label": 91, "all_mlm_weight": 91, "all_neg": 97, "all_observed_error_at_rung": 56, "all_pred_posit": 91, "all_premise_token": 85, "all_seg": 91, "all_token_id": 91, "allahyar": 113, "allevi": [108, 127, 128, 130], "alloc": [16, 18, 35, 37, 44, 51, 56, 60, 70, 75, 81, 119], "allow": [3, 6, 7, 8, 9, 10, 12, 14, 15, 16, 18, 23, 28, 29, 34, 35, 36, 37, 39, 40, 44, 46, 51, 52, 56, 58, 60, 61, 62, 64, 65, 66, 67, 69, 70, 72, 73, 74, 79, 80, 88, 93, 96, 102, 103, 104, 105, 106, 109, 112, 113, 115, 117, 121, 125, 126, 127, 129, 132, 135, 136, 138, 140], "allud": 35, "almost": [18, 24, 34, 45, 47, 56, 60, 67, 69, 71, 91, 98, 106, 107, 118, 130, 132, 136], "alon": [6, 45, 52, 58, 67, 69, 74, 113], "along": [5, 6, 9, 30, 32, 35, 37, 41, 52, 58, 61, 66, 69, 75, 77, 80, 88, 104, 117, 119, 126, 133, 135, 138, 139], "alongsid": [13, 48, 70], "alor": 128, "alpha": [2, 3, 4, 8, 32, 35, 47, 49, 61, 64, 80, 86, 93, 104, 105, 107, 111, 112, 117, 121, 122, 135, 137, 140], "alpha_1": 104, "alpha_i": [104, 112, 121], "alpha_n": 104, "alphago": 58, "alreadi": [4, 5, 8, 10, 16, 21, 39, 45, 47, 48, 49, 50, 52, 55, 56, 57, 58, 60, 61, 67, 71, 74, 79, 80, 84, 102, 105, 106, 108, 109, 113, 114, 115, 117, 119, 121, 122, 123, 129, 130, 131, 135, 136, 137], "also": [2, 5, 6, 8, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 64, 65, 67, 69, 71, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 88, 90, 92, 93, 95, 96, 97, 98, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 129, 130, 131, 133, 135, 136, 137, 138, 139, 140, 141], "alter": [32, 46, 81, 119], "altern": [5, 6, 9, 23, 33, 35, 36, 39, 40, 44, 47, 49, 52, 54, 57, 58, 61, 69, 75, 89, 103, 104, 105, 107, 108, 111, 112, 120, 122, 127, 129, 130, 135], "although": [5, 6, 10, 19, 22, 29, 30, 32, 34, 36, 39, 47, 58, 59, 69, 74, 78, 80, 90, 98, 105, 108, 110, 127, 129, 136], "alto": [79, 117], "altogeth": [5, 60, 61, 65, 69, 79, 121], "alu": 34, "alwai": [2, 5, 6, 10, 20, 34, 39, 40, 45, 46, 55, 58, 59, 61, 64, 66, 67, 74, 77, 79, 80, 81, 90, 105, 117, 119, 127, 132, 133, 135, 136], "alxnorden": 113, "am": [79, 86], "amarazov": 113, "amari": 34, "amateur": 58, "amazon": [34, 50, 52, 53, 58, 87, 113, 138], "amazonaw": [22, 25, 26, 29, 31, 79, 86, 88, 91, 95, 99, 107, 132], "ambient": 60, "ambigu": [67, 115, 131, 132], "ambiti": 61, "amd": 34, "amen": [43, 58, 80], "amend": [39, 103], "amin": 113, "ammunit": 113, "among": [5, 12, 19, 26, 28, 30, 32, 37, 40, 43, 46, 58, 59, 60, 61, 64, 67, 69, 71, 74, 77, 79, 80, 81, 82, 83, 88, 90, 93, 94, 95, 96, 97, 98, 108, 113, 114, 119, 121, 122, 126, 128, 130, 132, 137], "amount": [2, 6, 8, 22, 32, 34, 35, 37, 39, 40, 43, 46, 47, 48, 49, 52, 55, 56, 58, 60, 61, 64, 67, 69, 70, 73, 74, 77, 79, 94, 97, 101, 103, 104, 105, 107, 108, 109, 110, 113, 114, 115, 121, 123, 126, 132, 136, 139, 140], "amper": 34, "amplitud": [47, 48, 49, 58], "amsalem": 113, "an": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 141], "anachronist": 69, "anaconda3": [54, 55], "analog": [4, 39, 58, 61, 64, 117, 121, 133, 141], "analogi": [34, 76, 94, 98, 142], "analys": [61, 132], "analysi": [6, 40, 42, 54, 58, 61, 69, 74, 77, 80, 83, 84, 85, 90, 96, 102, 104, 106, 113, 131, 142], "analyt": [34, 61, 77, 82, 110, 135], "analyz": [19, 34, 35, 58, 82, 84, 94, 102, 103, 104, 105, 107, 109, 114, 117, 121, 125, 127, 130, 140, 141], "anatomi": 69, "anc": 19, "anc_i": 19, "anc_i_np": 19, "anc_idx": 19, "ancestor": 114, "anchor": [24, 30, 32, 142], "anchor_manipul": 19, "anchors_bbox_map": 19, "ancient": 115, "andrei": 113, "andrew": [34, 50, 113], "angeschaut": 58, "angl": [22, 98, 117], "ani": [1, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 19, 21, 27, 28, 29, 30, 31, 32, 34, 35, 39, 41, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 57, 58, 60, 61, 64, 66, 67, 69, 70, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 96, 97, 98, 99, 104, 105, 107, 108, 109, 110, 112, 113, 115, 117, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 135, 136, 137, 139, 140, 141], "anim": [1, 23, 25, 26, 28, 32, 34, 41, 58, 60, 72, 92, 99, 107, 108, 109], "anirudh": 113, "ankl": [1, 62], "annot": [46, 58, 60, 110], "anomal": [58, 69, 121], "anoth": [3, 6, 7, 9, 16, 19, 20, 22, 23, 28, 33, 34, 35, 39, 44, 45, 46, 48, 52, 56, 58, 60, 64, 67, 69, 76, 77, 80, 81, 82, 83, 85, 93, 96, 101, 102, 105, 107, 110, 118, 120, 121, 122, 124, 127, 128, 130, 131, 135, 137, 139, 141], "answer": [2, 6, 8, 47, 58, 64, 67, 74, 76, 80, 84, 85, 90, 113, 116, 117, 128], "anteced": 5, "anthoni": 113, "anticip": [46, 58, 136], "anticlimact": 103, "anyon": [58, 80, 89, 106], "anyth": [3, 16, 35, 37, 58, 60, 67, 69, 102, 113, 119, 121, 136], "anywai": 74, "anywher": 46, "apach": 58, "apart": [49, 51, 52, 61, 117], "api": [13, 25, 26, 31, 33, 35, 53, 54, 58, 62, 64, 65, 70, 71, 72, 73, 76, 80, 81, 101, 113, 123, 125, 127, 134, 142], "apocalyps": 58, "app": [58, 94], "appar": [34, 80], "apparel": 62, "appeal": [10, 61, 64, 82, 104, 130], "appear": [5, 23, 27, 35, 46, 48, 58, 60, 61, 77, 87, 90, 91, 93, 97, 127, 128, 129, 130, 136, 137], "append": [1, 4, 10, 11, 15, 19, 25, 26, 28, 29, 30, 31, 32, 36, 39, 51, 52, 56, 69, 79, 82, 85, 86, 87, 88, 90, 91, 92, 95, 96, 97, 105, 108, 125, 127, 128, 129, 135, 136], "appendix": [113, 142], "appetit": [58, 64], "appl": [34, 58, 64, 69], "appli": [1, 3, 4, 5, 8, 10, 11, 14, 15, 19, 20, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 52, 53, 58, 61, 63, 64, 65, 66, 67, 69, 71, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 88, 90, 94, 96, 102, 104, 105, 107, 108, 111, 113, 114, 115, 116, 117, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 136, 139], "applic": [3, 5, 6, 8, 10, 11, 15, 22, 23, 24, 30, 31, 32, 35, 41, 46, 47, 48, 49, 50, 58, 59, 60, 66, 67, 69, 70, 80, 85, 86, 87, 88, 90, 91, 92, 94, 98, 99, 104, 113, 117, 120, 122, 123, 124, 126, 129, 130, 131, 133, 135, 137, 138, 142], "apply_init": 51, "apply_init_cnn": [34, 35, 36, 37, 39], "appoint": 58, "appreci": 49, "approach": [2, 5, 8, 9, 26, 30, 35, 42, 43, 46, 47, 49, 50, 52, 53, 58, 60, 61, 64, 77, 79, 80, 82, 90, 96, 104, 105, 108, 110, 112, 113, 115, 124, 125, 128, 129, 132, 136], "appropri": [9, 18, 37, 43, 46, 57, 58, 60, 61, 67, 69, 70, 75, 80, 101, 102, 107, 108, 111, 117, 121, 129, 130, 137, 138], "approx": [35, 47, 64, 93, 112, 129, 133], "approxim": [8, 30, 35, 41, 47, 49, 52, 56, 58, 60, 61, 64, 65, 69, 77, 94, 97, 102, 104, 105, 108, 110, 130, 132, 133, 136, 139, 140, 142], "apricot": 58, "apt": 57, "aptitud": 116, "aptli": 67, "ar": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "arab": 136, "arang": [1, 2, 3, 9, 10, 17, 19, 21, 30, 32, 33, 45, 56, 69, 72, 76, 80, 82, 85, 90, 91, 104, 105, 107, 109, 110, 111, 114, 115, 117, 119, 135, 136], "arbitrag": 60, "arbitrari": [4, 6, 12, 15, 17, 35, 37, 45, 47, 49, 58, 60, 61, 67, 75, 77, 96, 114, 117, 119, 120, 136, 141], "arbitrarili": [8, 31, 58, 67, 77, 85, 91, 121, 136, 140], "arc": 115, "arch": [36, 39], "archambeau": 53, "archimed": 115, "architectur": [3, 4, 5, 6, 9, 11, 12, 13, 15, 16, 17, 37, 38, 39, 40, 41, 42, 43, 46, 51, 52, 57, 58, 61, 67, 68, 70, 76, 77, 80, 81, 82, 83, 84, 86, 88, 90, 94, 113, 122, 123, 125, 126, 127, 129, 130, 131, 135, 136, 142], "archiv": 58, "area": [3, 10, 19, 21, 22, 23, 25, 26, 31, 34, 39, 41, 44, 45, 54, 58, 60, 64, 69, 82, 102, 113, 115, 131], "areas1": 19, "areas2": 19, "arg": [1, 15, 118, 124, 129], "argmax": [1, 19, 21, 23, 25, 26, 32, 59, 64, 66, 86, 122, 129, 135, 140, 141], "argmin": [39, 52, 69, 104], "argsort": [19, 95, 99], "argu": [76, 80, 112], "arguabl": [4, 5, 37, 47, 58, 66, 67, 70, 103], "argument": [1, 2, 3, 7, 12, 15, 18, 19, 20, 23, 25, 30, 32, 34, 35, 37, 39, 41, 46, 51, 54, 64, 65, 66, 71, 72, 73, 75, 76, 80, 85, 86, 91, 96, 97, 100, 105, 107, 115, 121, 124, 128, 132, 135, 136, 137], "aris": [8, 35, 36, 40, 53, 58, 60, 66, 67, 69, 71, 103, 106, 108, 120, 122, 130, 131, 140, 141], "arithmet": [3, 15, 34, 116, 119], "arm": [34, 58, 60, 103, 133], "armi": 60, "armin": 113, "arnav": 113, "arno": 113, "around": [10, 32, 34, 39, 41, 44, 46, 52, 58, 60, 107, 119, 136], "arrai": [1, 2, 3, 7, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 40, 41, 43, 44, 45, 47, 58, 62, 65, 66, 70, 71, 72, 73, 76, 79, 81, 82, 85, 86, 87, 88, 90, 91, 92, 95, 97, 99, 104, 105, 106, 107, 108, 114, 117, 118, 119, 120, 121, 128, 129, 132, 133, 135, 136, 140, 141], "arrang": [5, 15, 37, 43, 58, 117, 131], "arraydataset": 97, "arriv": [3, 9, 36, 37, 39, 60, 69, 74, 102, 104, 105, 108, 112, 117, 120, 121, 127, 130, 136, 138, 140], "arrow": [1, 28, 75, 130, 141], "arrowprop": 110, "arrowstyl": 110, "arsen": 77, "art": [5, 6, 11, 47, 49, 50, 52, 53, 58, 62, 66, 81, 83, 90, 128, 132], "articl": [2, 6, 35, 58, 64, 83, 94, 97, 100, 108, 109, 137], "articul": 127, "artifact": [15, 44, 121], "artifici": [13, 29, 34, 58, 69, 73, 80, 82, 90, 97], "arun": 113, "as_in_ctx": [21, 26, 99, 107], "asadi": 138, "asarrai": 21, "ascend": 5, "ascii": [25, 29, 31, 137], "asha": 55, "asid": [35, 43, 47, 61, 64, 74, 105, 113, 122], "asimov": 58, "ask": [6, 35, 45, 58, 60, 70, 74, 79, 80, 113, 117, 121, 132], "asnumpi": [19, 20, 21, 23, 26, 27, 99, 105, 110], "aspect": [19, 22, 23, 27, 28, 30, 32, 34, 35, 46, 58, 60, 64, 65, 66, 69, 71, 90, 107, 109, 121, 141], "aspir": [60, 70], "assembl": [10, 15, 37, 43, 58, 113], "assembli": 43, "assert": [1, 35, 40, 72, 76, 97, 100, 135], "assess": [46, 58, 59, 61, 64, 67, 69, 80, 121, 131], "asset": 121, "assign": [2, 4, 5, 9, 15, 21, 32, 33, 37, 46, 52, 56, 58, 61, 64, 66, 67, 69, 74, 77, 79, 83, 90, 93, 100, 101, 102, 103, 108, 109, 111, 114, 117, 119, 121, 129, 132, 136, 137], "assign_anchor_to_bbox": 19, "assigned_bb": 19, "assist": [58, 70, 94, 135], "associ": [8, 9, 15, 34, 41, 47, 48, 49, 58, 60, 61, 62, 64, 69, 75, 80, 82, 86, 100, 102, 110, 112, 113, 115, 117, 121, 133, 137, 141], "assum": [1, 2, 3, 15, 17, 18, 19, 20, 21, 22, 27, 28, 35, 39, 40, 41, 44, 45, 46, 47, 48, 52, 55, 56, 58, 59, 60, 61, 64, 66, 67, 69, 71, 73, 74, 75, 79, 80, 82, 89, 98, 104, 105, 107, 110, 112, 113, 114, 121, 125, 130, 131, 132, 133, 135, 136, 140, 141], "assumpt": [35, 38, 46, 47, 48, 49, 58, 60, 61, 67, 69, 77, 80, 82, 121, 138, 141], "ast": 104, "aston": [8, 58, 64], "astronomi": 58, "astrophys": 113, "astut": [2, 74, 121, 136], "astyp": [1, 2, 3, 19, 21, 23, 25, 28, 29, 31, 32, 59, 66, 76, 79, 99, 121, 128, 129, 135], "asymmetr": 93, "asymptot": [61, 104], "asynchron": [53, 142], "atari": [6, 58, 139], "aterzi": 113, "atgctg": 113, "ati": [34, 113], "atishai": 113, "atm": 43, "atom": 137, "atop": 80, "attach": 114, "attack": [58, 77, 117, 121], "attain": [51, 61, 104], "attempt": [6, 35, 58, 60, 61, 67, 107, 110, 113, 121, 132], "attend": [2, 4, 5, 6, 7, 9, 10, 11], "attent": [1, 6, 8, 10, 11, 43, 45, 47, 58, 61, 80, 83, 84, 90, 92, 110, 113, 120, 121, 127, 129, 136, 142], "attention1": 10, "attention2": 10, "attention_w": 2, "attention_weight": [3, 4, 8, 10, 129], "attentiondecod": [4, 10], "attn": 10, "attribut": [1, 5, 23, 54, 58, 72, 79, 117, 118, 119, 121, 131], "atwood": 113, "au": 5, "auc": 115, "audienc": [35, 65], "audio": [42, 44, 46, 58, 79, 120], "aug": 23, "augment": [24, 29, 31, 34, 38, 90, 142], "austinmw": 113, "author": [35, 39, 58, 60, 76, 82, 101, 103, 113, 123, 135], "authorit": 58, "auto": [15, 50, 58, 136], "autocomplet": 135, "autocorrel": 47, "autoencod": [6, 58], "autograd": [23, 26, 81, 92, 99, 107, 113, 114], "autom": [6, 39, 52, 58, 60, 62, 70, 71, 113], "automat": [15, 18, 22, 28, 34, 35, 36, 37, 38, 41, 47, 48, 52, 57, 58, 60, 64, 69, 70, 71, 75, 78, 79, 102, 105, 107, 113, 115, 116, 119, 128, 133, 141, 142], "automl": 52, "autonom": [31, 60], "autonomi": [58, 113], "autopilot": 58, "autoregress": [6, 10, 50, 90, 127, 131, 134], "autumn": 28, "auxiliari": [23, 102, 109, 114], "avail": [1, 2, 5, 6, 8, 12, 18, 23, 34, 37, 43, 51, 54, 55, 56, 58, 60, 61, 62, 67, 70, 77, 95, 109, 111, 112, 113, 121, 123, 131, 132, 136, 138], "avenu": [58, 77, 117], "averag": [1, 3, 6, 7, 8, 11, 21, 22, 35, 36, 37, 39, 42, 43, 48, 51, 54, 58, 59, 60, 61, 65, 67, 69, 70, 71, 72, 79, 86, 98, 99, 101, 103, 107, 108, 110, 111, 112, 117, 121, 129, 132, 141], "averagepool": 107, "avg": [45, 108], "avgpool": [1, 21], "avgpool1d": 1, "avgpool2d": [1, 35, 36, 37, 39, 43, 107], "avinashingit": 113, "avoid": [7, 13, 28, 31, 39, 44, 52, 54, 55, 60, 62, 64, 65, 66, 69, 71, 75, 76, 79, 90, 105, 113, 117, 126, 128, 130, 134, 139], "avx": 108, "aw": [18, 58], "awai": [16, 39, 46, 47, 48, 49, 58, 67, 80, 98, 109, 112, 113, 121, 136], "awaken": 58, "awar": [51, 58, 129], "award": 35, "awesom": 58, "awkward": 64, "ax": [1, 2, 8, 19, 20, 27, 28, 29, 32, 46, 72, 104, 108, 110, 114, 115, 117, 119], "axhlin": 121, "axi": [1, 3, 4, 6, 7, 10, 19, 20, 21, 22, 23, 25, 26, 27, 30, 32, 35, 36, 37, 40, 41, 59, 61, 66, 69, 77, 86, 88, 92, 95, 99, 102, 108, 115, 117, 119, 121, 123, 133, 134, 135], "axiom": 121, "axon": 69, "azimjonn": 113, "b": [1, 3, 19, 23, 35, 39, 40, 45, 46, 48, 49, 51, 57, 58, 59, 64, 66, 69, 70, 71, 72, 73, 74, 80, 86, 90, 95, 96, 100, 102, 104, 105, 108, 109, 114, 115, 117, 119, 121, 122, 123, 125, 127, 129, 133, 137], "b1": [1, 36, 37, 39, 81], "b2": [1, 37, 81], "b3": [1, 37], "b4": [1, 37], "b5": [1, 37], "b5116e234e9eb9076672cfeabf5469f3eec904fa": 95, "b_": [19, 117, 130], "b_1": [19, 64], "b_2": [19, 64], "b_3": [19, 64], "b_4": 19, "b_c": 127, "b_f": 127, "b_h": [125, 135], "b_i": [93, 127], "b_j": 19, "b_o": 127, "b_q": 135, "b_r": 125, "b_t": 130, "b_z": 125, "babi": [58, 64, 95, 137], "back": [1, 13, 17, 18, 21, 31, 34, 35, 39, 46, 54, 58, 60, 61, 62, 64, 69, 80, 104, 105, 114, 115, 121, 135, 136, 137], "backbon": [6, 11, 42, 58, 113, 121], "backend": [54, 55], "backend_inlin": [113, 115], "backgammon": [58, 60], "background": [2, 5, 19, 25, 29, 30, 31, 32, 34, 58, 113, 131], "backpropag": [15, 28, 33, 34, 40, 43, 58, 65, 76, 78, 82, 105, 114, 115, 127, 131, 133, 135, 142], "backpropg": 130, "backward": [15, 23, 26, 28, 40, 78, 92, 99, 107, 115, 116, 121, 130, 135, 142], "backyard": 58, "bad": [34, 58, 60, 67, 77, 81, 86, 88, 94, 95, 122, 135, 140], "badli": [58, 61, 67, 74, 104], "bag": [1, 34, 62, 77, 89, 94, 96, 137], "bahdanau": [5, 10, 142], "baidu": 113, "bail": 58, "bain": 58, "bake": [12, 73], "balaji": 113, "balanc": [28, 32, 85, 104, 110], "ball": [58, 104, 109, 110, 135], "ballpark": 61, "balmi": 117, "banach": 74, "banana": [29, 32, 132], "bananas_train": 29, "bananas_v": 29, "bananasdataset": 29, "bandit": 58, "bandwidth": [3, 34, 37, 108], "bang": 122, "bank": [58, 90, 94, 97, 121], "bapat": 113, "bar": [1, 47, 48, 60, 65, 98, 102, 112, 136], "baratov": 113, "barbaro": 113, "barber": 58, "bare": [58, 65, 82, 109, 136], "barkan": 113, "baromet": 38, "barrier": 58, "bart": 6, "base": [3, 4, 5, 6, 7, 9, 10, 11, 12, 14, 15, 19, 20, 21, 22, 23, 24, 27, 28, 34, 35, 36, 38, 41, 42, 43, 46, 47, 48, 51, 52, 54, 56, 57, 58, 60, 61, 63, 64, 66, 67, 69, 70, 72, 74, 77, 80, 82, 83, 84, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 108, 110, 113, 115, 117, 118, 119, 120, 121, 122, 123, 124, 129, 130, 131, 132, 134, 136, 137, 140, 141, 142], "base_dir": 1, "base_lr": 107, "base_lr_orig": 107, "base_net": 32, "basebal": 64, "baselin": [52, 54, 55, 64, 68, 79, 121, 132], "basement": 79, "bash": 57, "basi": [2, 19, 35, 46, 48, 50, 67, 69, 76, 77, 80, 94, 102, 103, 104, 109, 111, 124, 132, 138], "basic": [5, 12, 13, 15, 20, 21, 24, 37, 38, 39, 42, 43, 47, 51, 53, 56, 61, 63, 68, 70, 74, 75, 79, 80, 81, 84, 94, 98, 105, 106, 107, 112, 113, 114, 116, 119, 125, 131, 132, 136, 137], "basicblock": 21, "basicconfig": [54, 55], "basicschedul": [51, 54], "batch": [1, 5, 9, 10, 11, 18, 19, 22, 23, 25, 26, 29, 31, 32, 34, 36, 37, 38, 39, 41, 43, 44, 45, 47, 51, 52, 54, 55, 58, 59, 62, 66, 69, 71, 72, 73, 75, 80, 85, 86, 87, 88, 90, 91, 92, 97, 99, 103, 108, 109, 114, 127, 129, 133, 135, 140, 142], "batch_class_label": 19, "batch_data": [85, 91, 97], "batch_dot": 99, "batch_i": 85, "batch_idx": [30, 90], "batch_indic": [72, 73, 85, 91, 97], "batch_item": 91, "batch_mask": 19, "batch_norm": 35, "batch_offset": 19, "batch_siz": [1, 3, 4, 7, 9, 10, 11, 19, 21, 22, 23, 25, 26, 29, 31, 32, 34, 35, 36, 37, 39, 43, 51, 52, 54, 55, 56, 62, 65, 66, 72, 73, 74, 76, 79, 81, 85, 86, 87, 88, 90, 91, 92, 97, 99, 101, 102, 103, 107, 108, 109, 111, 123, 125, 127, 128, 129, 132, 134, 135, 136], "batch_x": 85, "batch_x0": 85, "batch_x1": 85, "batchifi": 97, "batchify_fn": 97, "batchnorm": [1, 10, 21, 32, 35, 36, 39], "bathroom": 58, "bay": 121, "bayesian": [35, 47, 48, 49, 50, 51, 54, 56, 64, 69, 74, 121], "bayesianoptim": 54, "bb_idx": 19, "bbox": [19, 20, 32], "bbox_": 32, "bbox_ev": 32, "bbox_label": 32, "bbox_loss": 32, "bbox_ma": 32, "bbox_mask": [19, 32], "bbox_offset": 19, "bbox_pr": 32, "bbox_predictor": 32, "bbox_scal": [19, 27], "bbox_to_rect": [19, 20], "bc": 108, "beach": 132, "beam": [126, 129, 142], "bear": [34, 42, 60, 67, 87, 88], "beat": [38, 58, 67, 113, 132], "beauti": [34, 58, 95, 109], "becam": [5, 58, 127], "becaus": [3, 6, 9, 10, 11, 12, 18, 19, 21, 22, 23, 26, 30, 32, 34, 35, 40, 41, 42, 43, 44, 46, 47, 48, 52, 54, 55, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77, 79, 80, 82, 85, 93, 99, 108, 112, 113, 115, 117, 119, 121, 122, 127, 130, 131, 133, 136, 137, 139, 140, 141], "becom": [6, 8, 11, 18, 28, 34, 35, 36, 39, 40, 46, 47, 48, 49, 51, 52, 54, 56, 58, 60, 61, 67, 69, 74, 76, 77, 80, 85, 90, 94, 98, 103, 105, 109, 110, 113, 114, 117, 118, 120, 121, 126, 129, 135, 136], "bed": 120, "bedrock": 61, "bedroom": [58, 64], "been": [2, 5, 6, 8, 10, 19, 20, 22, 23, 24, 25, 27, 28, 32, 34, 35, 36, 38, 39, 43, 47, 48, 52, 56, 58, 60, 61, 64, 67, 69, 72, 73, 75, 77, 80, 83, 85, 87, 90, 94, 96, 104, 107, 108, 109, 114, 115, 119, 120, 121, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 140], "befor": [1, 4, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 22, 23, 25, 26, 28, 30, 32, 35, 37, 39, 40, 42, 45, 46, 47, 49, 51, 52, 54, 55, 57, 58, 60, 61, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 85, 88, 91, 92, 97, 99, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 119, 120, 121, 123, 127, 128, 129, 130, 132, 133, 134, 136, 138, 140], "beg": [34, 54], "began": [5, 60, 69, 125, 137], "begin": [2, 4, 6, 7, 9, 10, 14, 15, 18, 20, 24, 32, 33, 37, 38, 39, 41, 46, 47, 48, 49, 52, 56, 58, 60, 61, 64, 66, 67, 69, 70, 71, 74, 76, 80, 81, 82, 85, 86, 89, 90, 91, 94, 96, 97, 98, 101, 102, 103, 104, 105, 107, 109, 111, 112, 115, 117, 119, 121, 122, 125, 127, 128, 129, 130, 132, 133, 134, 135, 136, 140, 141], "beginn": [110, 113], "begun": [34, 38, 61], "behalf": 108, "behav": [11, 12, 35, 58, 64, 69, 72, 73, 77, 80, 82, 102, 105, 109, 110, 112, 117, 121, 129, 137, 138], "behavior": [3, 6, 7, 13, 35, 39, 58, 60, 61, 64, 69, 71, 73, 74, 77, 101, 102, 107, 108, 109, 111, 121], "behaviour": 54, "behind": [5, 12, 15, 50, 58, 107, 108, 113, 114, 126, 140, 141], "beij": 95, "being": [8, 10, 19, 33, 38, 39, 47, 49, 51, 58, 60, 61, 64, 69, 73, 79, 80, 82, 83, 89, 90, 93, 96, 97, 98, 107, 108, 109, 119, 121, 125, 127, 130, 138], "belief": [47, 121], "believ": [34, 35, 46, 47, 48, 60, 66, 67, 69, 113, 117, 121, 136], "bell": [34, 43, 62, 71], "bellman": 141, "belong": [19, 31, 34, 58, 64, 73, 83, 100, 117], "below": [2, 7, 9, 10, 11, 14, 15, 16, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 44, 45, 47, 48, 49, 51, 52, 54, 56, 58, 60, 62, 64, 66, 69, 70, 71, 73, 74, 76, 78, 80, 85, 86, 88, 95, 99, 105, 107, 109, 110, 114, 115, 117, 119, 120, 123, 127, 128, 129, 135, 137], "below_min_idx": 19, "ben": 113, "bench": 6, "benchmark": [6, 24, 34, 51, 54, 58, 59, 60, 61, 62, 67, 69, 83, 85, 108], "bend": 58, "benefici": [7, 35, 82, 107, 109, 110], "benefit": [3, 6, 8, 10, 12, 13, 15, 17, 34, 35, 37, 39, 43, 44, 58, 65, 69, 73, 74, 77, 80, 84, 99, 102, 108, 109, 114, 136], "bengio": [34, 127], "benign": 132, "berkov": 113, "bernoulli": [58, 61, 76, 118], "bert": [5, 23, 84, 94, 142], "bertencod": 90, "bertmodel": [90, 92], "besid": [9, 20, 22, 30, 31, 32, 48, 60, 74, 75, 82, 83, 88, 93, 95, 96, 107, 110, 124, 130], "best": [17, 34, 35, 37, 39, 40, 43, 46, 51, 52, 54, 55, 56, 58, 61, 67, 69, 71, 79, 81, 86, 94, 102, 104, 107, 108, 110, 113, 121, 125, 132, 139, 141], "best_idx": 52, "best_performing_configur": 56, "bestow": 135, "bet": 39, "beta": [35, 80, 86, 103, 104, 109, 112], "beta1": 103, "beta2": 103, "beta_1": 103, "beta_2": 103, "beta_i": 60, "better": [2, 5, 6, 11, 18, 22, 26, 34, 39, 43, 45, 47, 51, 52, 55, 56, 58, 60, 61, 64, 65, 66, 67, 69, 77, 79, 80, 82, 86, 96, 98, 102, 103, 105, 107, 108, 109, 112, 113, 118, 121, 125, 130, 132, 135, 136, 137], "between": [1, 2, 3, 4, 5, 6, 8, 9, 10, 18, 19, 20, 22, 23, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 45, 46, 48, 51, 52, 54, 56, 58, 60, 61, 62, 64, 67, 69, 72, 74, 76, 77, 79, 80, 81, 85, 86, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 102, 103, 104, 107, 108, 109, 110, 112, 115, 117, 121, 122, 123, 127, 128, 129, 130, 132, 133, 136, 138, 140], "bewar": 105, "beyond": [3, 5, 11, 34, 36, 38, 45, 46, 47, 51, 52, 58, 73, 75, 76, 77, 102, 103, 107, 108, 109, 113, 118, 120, 121, 122, 132, 136, 137, 140], "bfg": 47, "bfloat16": [34, 65], "bia": [3, 7, 12, 14, 16, 17, 21, 22, 23, 33, 35, 39, 40, 41, 46, 49, 52, 58, 60, 61, 64, 67, 69, 70, 71, 74, 75, 77, 80, 81, 93, 103, 108, 123, 125, 127, 130, 133, 135], "biagiom": 113, "bias": [16, 39, 46, 64, 66, 67, 69, 74, 77, 80, 90, 125, 127, 130], "bias_fn": [14, 70, 108], "bicycl": 31, "bidirect": [6, 88, 94, 126, 129, 142], "bidirection": 90, "biel": 113, "biesialska": 113, "big": [6, 18, 58, 61, 65, 67, 77, 94, 95, 113, 117, 140, 141], "bigcup_": 121, "bigg": 105, "bigger": [32, 34, 69, 77, 80], "biggest": [47, 95, 120, 135], "bigram": [132, 137], "bigram_freq": 137, "bigram_token": 137, "bigram_vocab": 137, "bij": 99, "bik": 99, "bilinear": [21, 30], "bilinear_kernel": 21, "bilingu": [128, 129], "bill": [58, 131], "billion": [6, 34, 40, 46, 90, 97, 108], "bin": [54, 55, 57, 87], "binari": [2, 9, 30, 58, 60, 61, 62, 64, 76, 80, 88, 89, 90, 91, 105, 119, 121], "binary_cross_entropi": 99, "binary_cross_entropy_with_logit": 99, "bioasq": 58, "biolog": [58, 69, 80, 82], "biologi": [41, 42, 58], "biologist": 121, "biomed": 113, "biomedicin": 113, "bird": [25, 31, 69], "birdsong": 58, "bishop": [47, 76], "biswajit": 113, "bit": [2, 3, 9, 18, 19, 23, 34, 39, 40, 43, 62, 64, 65, 69, 80, 82, 104, 105, 107, 108, 112, 114, 130, 132], "bite": 132, "bizarr": 87, "bkj": 99, "black": [31, 41, 45, 47, 49, 58, 60, 62, 69, 71, 104, 106, 121], "blade": 34, "blame": 58, "blank": [3, 58], "blazingli": 62, "bleak": 61, "bless": 65, "bleu": [4, 10, 129], "blissfulli": 46, "blister": [62, 77], "blitzstein": 113, "blk": [1, 10, 11, 32, 36, 39, 90], "blk_": 32, "blk_dropout": 11, "blk_forward": 32, "blk_i": 32, "block": [10, 11, 13, 14, 15, 18, 28, 35, 38, 40, 43, 47, 57, 61, 72, 92, 108, 113, 115], "blog": [58, 70, 87, 113], "blood": 60, "bloom": 6, "blow": [74, 82, 103, 130], "blue": [9, 19, 20, 22, 40, 46, 47, 48, 58, 62, 113, 117], "blume": 113, "blunt": [74, 126], "blur": [41, 64], "bmatrix": [7, 9, 47, 48, 109, 117], "bmm": [3, 99], "bn": [10, 35], "bn1": [1, 21, 39], "bn2": [1, 21, 39], "bn3": 39, "bn4": 39, "bnlenet": 35, "bnlenetscratch": 35, "bo": [1, 6, 128, 129], "board": [18, 51, 58, 72, 74, 77, 79, 113], "boast": [79, 82], "boat": [25, 31], "bodi": [11, 31, 37, 58, 71, 77, 80, 104], "boi": [95, 96], "boiler": 60, "boilerpl": [15, 35, 71], "bokeh": 120, "bold": [1, 89, 113, 117], "boldsymbol": [35, 64, 73, 86, 102, 105, 109, 112, 121], "boltzmann": [64, 71], "bomb": 20, "bone": [1, 65, 121], "book": [0, 1, 4, 6, 10, 24, 35, 51, 57, 58, 59, 62, 64, 65, 67, 69, 70, 71, 72, 74, 79, 80, 84, 91, 94, 100, 106, 108, 112, 115, 116, 117, 118, 121, 123, 131, 135, 136, 137], "bookcorpu": [90, 91], "bookeep": 51, "bookkeep": [35, 53, 54, 56], "bool": [1, 16, 17, 20, 33, 114, 117, 119], "boolean": 100, "boom": [5, 34], "boost": [6, 43], "booster": 114, "boot": [1, 62], "bootcamp": 1, "border": [31, 44], "bore": 64, "borrow": 122, "boss": [58, 75], "boston": [58, 79], "bot_channel": 39, "bot_mul": 39, "both": [1, 3, 4, 6, 9, 10, 11, 15, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 58, 60, 61, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 92, 93, 94, 96, 98, 102, 103, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 119, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 133, 134, 137, 140, 141], "bother": 136, "bottl": [31, 58], "bottleneck": [6, 30, 34, 39, 47, 62, 120], "bottom": [1, 41, 44, 45, 58, 79, 113, 130], "bottou": 43, "bounc": 107, "bound": [3, 24, 27, 29, 30, 31, 35, 39, 47, 49, 52, 61, 64, 67, 77, 82, 104, 105, 107, 111, 112, 121, 132, 135, 142], "boundari": [19, 41, 44, 46, 58, 62, 67, 80, 96, 104, 128], "bowen": 113, "bowen0701": 113, "box": [24, 29, 30, 31, 39, 79, 104, 106, 123, 130, 138, 142], "box_area": 19, "box_center_to_corn": [19, 20], "box_corner_to_cent": [19, 20], "box_idx": 19, "box_iou": 19, "box_j": 19, "box_j_np": 19, "boxcar": 2, "boxes1": 19, "boxes2": 19, "boxes_per_pixel": 19, "boyfriend": 96, "bpe": 96, "bradlei": 64, "brain": [41, 58, 80, 131], "branch": [34, 38, 39, 74, 142], "brand": 87, "breadth": 113, "break": [1, 4, 10, 14, 19, 31, 34, 39, 60, 69, 71, 76, 85, 87, 91, 92, 96, 97, 101, 108, 128, 129, 130, 132, 141], "breakthrough": [5, 34, 58, 128, 131], "breath": 121, "breathless": 5, "breed": [24, 142], "breez": 119, "bremen": 58, "brent": 8, "brettkoonc": 113, "breviti": 98, "brian": 113, "brianhende": 113, "brief": [58, 107, 108, 126], "briefli": [15, 31, 38, 46, 58, 76, 80, 83, 115], "bright": [23, 26, 28, 58, 77, 80, 135], "brilliant": [61, 77], "bring": [46, 60, 105, 113, 130], "brittl": 64, "britton": 113, "broad": [35, 58, 67, 77, 90], "broadcast": [3, 33, 66, 69, 71, 116, 117, 127, 129, 133], "broadcast_to": 11, "broader": [35, 41, 63, 113, 121], "broadli": [50, 61, 64, 69, 110, 121, 128, 131], "broken": [40, 82, 85, 108, 121, 140], "brought": 42, "brown": 75, "brows": 58, "browser": [57, 58, 118], "broyd": 113, "brush": 28, "bruss": 113, "brute": [37, 38], "bsharmi": 113, "bu": [31, 81], "buck": 122, "bucket": 128, "buddareddygari": 113, "budget": [6, 34, 52, 56, 58], "buffer_from_vector": [1, 25, 29, 31], "bug": [79, 120], "bui": [64, 136], "build": [4, 9, 10, 12, 15, 17, 31, 34, 39, 41, 42, 49, 58, 60, 61, 65, 73, 77, 79, 80, 97, 107, 113, 114, 115, 117, 121, 123, 128, 129, 132, 133, 135, 136, 137, 138], "build_array_nmt": 1, "builder": 142, "built": [12, 13, 17, 38, 41, 45, 58, 62, 65, 66, 69, 70, 71, 72, 73, 77, 81, 90, 107, 109, 117, 119, 127], "bulk": 8, "bunch": [1, 38], "burden": 52, "burgl": 121, "burn": 61, "burst": [46, 108], "buse": 34, "busi": [15, 52, 54, 56, 58, 61, 64, 67, 121], "butterfli": 130, "button": [6, 25, 26, 58, 79], "bygon": 58, "bypass": 39, "byte": [91, 94, 108], "b\u00e1lint": 113, "b\u00f6ther": 113, "c": [1, 3, 4, 11, 15, 19, 21, 23, 25, 26, 27, 28, 30, 32, 35, 39, 40, 43, 45, 46, 47, 49, 56, 58, 60, 61, 62, 69, 71, 72, 79, 80, 82, 88, 90, 93, 95, 96, 97, 98, 102, 105, 108, 109, 114, 115, 117, 119, 121, 122, 127, 129, 133, 136, 137], "c0": 72, "c1": [37, 72], "c1816da3821ae9f43899be655002f6c723e91b88": 95, "c2": [37, 72], "c2050": 58, "c3": [37, 72], "c4": [6, 37], "c4\u662f\u6bcf\u6761\u8def\u5f84\u7684\u8f93\u51fa\u901a\u9053\u6570": 37, "c795ba47163d06ce5c6c89f6062abe763c9e03ea": 28, "c_": [39, 40, 49, 60, 117, 130], "c_0": 49, "c_1": [49, 104], "c_2": 104, "c_anc": 19, "c_assigned_bb": 19, "c_i": [33, 40, 49, 93, 104, 119], "c_in": 32, "c_j": [49, 93], "c_o": 40, "c_out": 32, "c_t": 130, "c_tild": 127, "cach": [1, 28, 34, 37, 69, 79, 97, 106, 130], "caff": [34, 58, 70], "caffein": 58, "calc_loss": 32, "calcul": [1, 12, 14, 15, 18, 19, 21, 26, 28, 32, 34, 35, 40, 41, 44, 45, 58, 60, 61, 63, 64, 65, 67, 69, 70, 75, 76, 78, 79, 80, 89, 90, 93, 96, 97, 98, 99, 101, 108, 109, 114, 115, 117, 121, 123, 127, 129, 130, 131, 132, 133, 135, 141], "calculu": [75, 105, 113, 116, 142], "calibr": [35, 101], "california": 79, "call": [2, 5, 6, 7, 8, 9, 10, 13, 14, 15, 19, 22, 23, 27, 28, 31, 33, 34, 37, 39, 41, 42, 45, 46, 47, 48, 51, 56, 58, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 86, 93, 96, 98, 99, 102, 103, 104, 105, 108, 109, 113, 114, 115, 117, 118, 119, 120, 121, 126, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141], "callabl": 51, "callback": [54, 55, 107], "calm": [4, 10, 129], "cambrian": [58, 70], "cambridg": 113, "came": [34, 58, 60, 75, 90, 92, 115, 121, 122, 127], "camera": [24, 45, 60], "campu": 60, "can": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141], "cancel": [69, 74, 76, 109], "cancer": [58, 60, 69, 121], "candid": [34, 40, 51, 58, 97, 122, 126, 127, 136], "candidate_pred_posit": 91, "canni": 58, "cannot": [6, 9, 17, 18, 22, 31, 34, 35, 40, 44, 45, 47, 52, 55, 56, 58, 60, 61, 64, 67, 69, 70, 71, 73, 76, 77, 79, 82, 96, 97, 98, 104, 105, 107, 108, 121, 131, 135, 136, 138], "canyon": 109, "cao": 113, "caojilin": 113, "cap": [19, 58, 100, 104, 121], "cap_": 104, "capabl": [6, 34, 37, 49, 58, 67, 73, 77, 80, 83, 108, 122, 136, 139], "capac": [37, 39, 52, 58, 74, 78, 136], "capit": [95, 117, 137], "caption": [6, 41, 58, 131, 136], "captur": [1, 5, 7, 9, 20, 34, 36, 37, 39, 43, 44, 46, 47, 58, 64, 67, 69, 77, 88, 95, 113, 117, 121, 122, 125, 130, 131, 132, 133, 136, 137], "car": [6, 25, 31, 43, 58, 83, 113], "carbon": 48, "card": [18, 58], "cardin": 100, "care": [15, 18, 19, 35, 42, 43, 46, 47, 58, 59, 60, 61, 64, 66, 67, 69, 73, 79, 82, 102, 108, 115, 119, 121, 123, 129], "career": [60, 79, 82, 113, 120, 121], "carefulli": [60, 82], "careless": 47, "carl": 58, "carlo": [47, 58], "carnegi": 58, "carri": [3, 8, 10, 12, 35, 37, 39, 46, 58, 75, 79, 93, 102, 105, 137], "cart": 58, "cartesian": 52, "cartoon": 60, "cartoonish": 69, "cartoonishli": 58, "cascad": 126, "case": [1, 2, 3, 4, 8, 9, 10, 12, 14, 18, 22, 23, 32, 34, 35, 36, 39, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 58, 59, 60, 61, 64, 65, 67, 69, 70, 71, 74, 76, 77, 78, 80, 82, 84, 85, 88, 91, 93, 96, 98, 102, 103, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 125, 127, 128, 129, 131, 132, 133, 135, 136, 139, 140, 141], "caser": 113, "cash": 90, "cast": [34, 53, 64, 66, 67, 113], "cat": [19, 20, 23, 25, 31, 43, 45, 46, 58, 60, 64, 77, 80, 96, 132], "cat1": 23, "cat_bbox": 20, "catalyst": 60, "catalyz": 113, "catastroph": 60, "catch": 60, "catdog": [19, 20, 21, 27], "catdoor": 60, "categor": [6, 52, 58, 59, 64, 79, 87, 118, 120, 135, 141], "categori": [20, 22, 25, 26, 34, 46, 58, 60, 62, 64, 69, 80, 85, 87, 88, 90, 110, 120, 133], "caught": 1, "caus": [47, 55, 58, 60, 61, 64, 66, 80, 82, 105, 110, 119, 121, 132, 135], "causal": [6, 58, 60, 136], "caution": [58, 66, 108, 117], "cautiou": [105, 109], "cavallo": 113, "caveat": 105, "cbow": 94, "cc": [60, 95], "cclauss": 113, "cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a": 95, "cdot": [15, 35, 36, 39, 40, 56, 67, 69, 71, 80, 82, 86, 89, 98, 100, 102, 104, 105, 107, 108, 110, 112, 114, 115, 117, 121, 130, 136, 139], "ce": 122, "ced": 122, "cede": 131, "cedric": 53, "ceil": [25, 72, 87, 91, 97], "celebr": [35, 58, 69], "cell": [1, 60, 123, 125, 126, 140, 141], "celsiu": 117, "censor": 58, "center": [1, 5, 19, 20, 21, 26, 27, 30, 32, 34, 35, 44, 46, 58, 61, 79, 89, 93, 94, 96, 98, 99, 121], "center_h": 19, "center_w": 19, "centercrop": [22, 26], "centeredlay": 12, "centers_batch": 97, "centr": 49, "central": [19, 22, 49, 54, 59, 61, 64, 67, 85, 107, 121, 140], "centuri": [2, 58, 69, 80, 114], "ceo": 58, "certain": [14, 18, 19, 23, 27, 28, 41, 46, 48, 54, 56, 58, 65, 77, 88, 105, 107, 109, 113, 117, 119, 121, 132, 135, 137], "certainli": [69, 76, 122], "certainti": [64, 121], "certifi": [61, 67, 113], "cfg": 1, "ch": 47, "chain": [6, 15, 33, 36, 43, 58, 75, 114, 116, 121, 125, 130, 135, 136], "chainer": 58, "chair": [22, 31], "chaitanya": 113, "challeng": [10, 34, 37, 38, 39, 43, 51, 52, 58, 60, 61, 62, 64, 69, 72, 76, 77, 80, 81, 106, 113, 131, 136], "champaign": 58, "champion": 58, "chanc": [47, 79, 82, 121], "chang": [1, 3, 5, 8, 10, 11, 15, 16, 19, 21, 22, 26, 28, 30, 32, 33, 34, 35, 36, 37, 39, 41, 43, 45, 47, 48, 49, 54, 57, 58, 60, 64, 66, 69, 70, 72, 73, 74, 75, 76, 77, 81, 83, 84, 85, 90, 93, 97, 101, 102, 105, 107, 108, 109, 112, 113, 114, 115, 117, 119, 121, 122, 127, 130, 135, 136, 137, 139, 141], "changer": [11, 34], "channel": [1, 9, 11, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 62, 88, 107, 117, 142], "chao": 113, "chaotic": 46, "chapet": 140, "chapter": [1, 3, 4, 5, 6, 13, 15, 18, 21, 22, 23, 24, 30, 38, 42, 43, 46, 47, 50, 51, 52, 53, 57, 58, 61, 62, 66, 67, 68, 69, 71, 72, 75, 77, 78, 80, 83, 84, 87, 90, 94, 102, 106, 107, 108, 110, 112, 113, 115, 116, 126, 128, 130, 131, 132, 135, 136, 138, 140], "char": [1, 128], "charact": [1, 4, 58, 67, 96, 98, 127, 128, 130, 131, 132, 135, 137], "character": [15, 35, 36, 46, 58, 61, 69, 74, 76, 113, 121, 122, 136, 137], "characterist": [35, 46, 58, 60, 102, 115, 121], "charg": 58, "charleybel": 113, "charm": 58, "chase": [79, 113], "chat": [6, 58, 94], "chatgpt": [6, 58], "chaudhari": 138, "cheap": [5, 53, 56, 58, 67, 69, 71, 102, 107, 108, 122], "cheaper": [37, 52, 102], "cheat": [3, 25, 90, 140], "chebyshev": 121, "check": [1, 3, 8, 12, 16, 20, 40, 44, 47, 51, 56, 57, 58, 62, 64, 71, 73, 77, 79, 104, 112, 117, 120, 121, 132, 135, 136], "check_len": 135, "check_shap": [3, 4, 7, 9, 10, 11, 129, 135], "checkpoint": [17, 54, 55], "chen": 113, "chernovenki": 61, "chervonenki": 61, "chess": [58, 60], "chez": [4, 10, 129], "chicken": 64, "chihuahua": 26, "child": 89, "children": [21, 46, 99], "chimera": 15, "china": 95, "chinchilla": 6, "chines": [58, 113, 128], "chip": [34, 37, 41, 95, 97, 99], "chiplet": 108, "choi": 113, "choic": [2, 3, 11, 35, 37, 38, 39, 45, 46, 47, 51, 56, 58, 59, 60, 61, 63, 64, 69, 74, 76, 77, 79, 80, 81, 82, 88, 91, 93, 94, 97, 102, 103, 105, 107, 109, 111, 112, 113, 114, 121, 122, 132, 136, 137, 141], "choleski": 47, "cholesterol": 117, "choos": [6, 7, 19, 26, 28, 30, 40, 44, 49, 51, 53, 58, 59, 61, 64, 66, 67, 69, 74, 77, 81, 82, 84, 90, 98, 101, 102, 105, 107, 108, 109, 112, 113, 121, 122, 123, 140, 141], "chose": [48, 139], "chosen": [3, 6, 16, 37, 54, 58, 61, 64, 67, 69, 104, 137, 140, 141], "christabella": 113, "christma": 60, "chronolog": 38, "chunk": 117, "church": 58, "chw": 28, "cifar": [23, 24, 26, 34, 52, 142], "cifar10": [23, 25], "cifar10_tini": 25, "circ": 82, "circa": 80, "circl": [47, 74, 75, 102, 104, 115, 130], "circuit": [13, 58], "circumst": [58, 60, 67], "citat": [35, 113], "citi": 138, "cl": [6, 11, 32, 83, 90, 91, 92], "cla": [1, 115], "claim": [5, 35, 76], "clamp": 19, "clarifi": 113, "clariti": 121, "class": [0, 3, 4, 7, 9, 10, 11, 12, 15, 16, 17, 21, 22, 25, 26, 27, 28, 29, 30, 34, 35, 36, 37, 38, 41, 43, 46, 47, 48, 49, 50, 51, 52, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 86, 88, 90, 91, 95, 97, 99, 107, 108, 113, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129, 134, 135, 136, 137, 139, 142], "class_id": 19, "class_label": 19, "class_to_idx": 25, "classic": [2, 5, 8, 34, 52, 58, 60, 61, 67, 68, 69, 74, 76, 78], "classif": [2, 6, 11, 20, 21, 22, 24, 26, 29, 31, 32, 33, 34, 37, 41, 43, 47, 52, 60, 65, 66, 67, 68, 69, 77, 80, 81, 84, 86, 87, 88, 90, 91, 92, 113, 126, 133, 136, 142], "classifi": [1, 11, 21, 24, 30, 32, 33, 34, 35, 36, 37, 39, 43, 46, 58, 60, 61, 62, 63, 65, 66, 67, 76, 80, 81, 83, 85, 90, 121, 124, 135, 136, 137], "claud": [58, 64], "clean": [6, 34, 35, 58, 62, 113], "cleaner": [34, 48], "cleanli": 77, "clear": [1, 2, 4, 14, 35, 37, 44, 47, 58, 74, 76, 80, 103, 113, 117, 121, 135], "clear_output": 1, "clearer": 114, "clearli": [2, 5, 8, 39, 48, 58, 61, 77, 103, 104, 112, 113, 132, 136], "cleric": 44, "clever": [34, 42, 76, 80, 82, 115], "cleverli": [5, 58], "clhm": 113, "clich\u00e9": [58, 121], "click": [25, 26, 57, 58, 60, 79], "client": 136, "climat": [113, 136], "clip": [1, 6, 19, 28, 29, 34, 104, 123, 126, 127, 130, 131], "clip_grad_norm": 1, "clip_gradi": [71, 135], "clipped_grad": 1, "clipper": 1, "clock": [34, 51, 54, 55, 56, 102, 108], "clog": 79, "clone": [17, 117], "close": [2, 6, 22, 24, 27, 28, 34, 35, 39, 41, 47, 48, 49, 50, 52, 57, 58, 60, 61, 67, 69, 70, 71, 76, 77, 79, 80, 82, 93, 110, 125, 127, 135, 141], "closer": [15, 27, 28, 32, 35, 39, 46, 48, 58, 61, 67, 76, 82, 107, 130, 136], "closest": [19, 21, 28, 75, 104, 138], "closet": [58, 104], "cloth": [43, 58, 62, 80, 138], "cloud": [18, 52, 54, 58, 120], "cls_": 32, "cls_err": 32, "cls_eval": 32, "cls_label": 32, "cls_loss": 32, "cls_pred": 32, "cls_predictor": 32, "cls_prob": [19, 32], "cls_token": 11, "clueless": 113, "clunki": 121, "cluster": [54, 58, 104], "cmap": [1, 2, 8, 9], "cmd": 57, "cmp": 1, "cnn": [5, 8, 10, 11, 21, 24, 27, 28, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 83, 84, 88, 113, 123, 131, 142], "cntk": 58, "co": [9, 22, 26, 72, 76, 91, 92, 94, 95, 97, 99, 104, 105, 107, 110, 114, 136], "co_2": 47, "coars": 13, "coarser": [13, 45, 121], "coat": [1, 43, 62], "cocktail": 37, "coco": 15, "code": [3, 6, 8, 9, 10, 13, 14, 16, 17, 18, 22, 23, 25, 26, 33, 34, 35, 39, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 55, 56, 58, 59, 61, 64, 65, 66, 69, 70, 71, 72, 73, 74, 76, 79, 80, 81, 85, 90, 91, 97, 107, 108, 114, 115, 117, 118, 119, 123, 127, 128, 129, 133, 134, 135, 140, 141], "codeblock": 47, "codypenta": 113, "coeffici": [12, 35, 46, 79, 100, 111, 115, 129], "coerc": [58, 80], "coffe": [18, 58, 60], "cognit": [45, 58, 115, 131], "coher": [60, 77, 132], "cohort": 60, "coin": 116, "coincid": [5, 60, 64], "col": 9, "col_discard": 19, "cola": 83, "collabor": [79, 102], "collaps": [49, 80, 121], "collate_fn": [72, 97], "colleagu": [43, 113], "collect": [1, 8, 22, 25, 29, 34, 35, 42, 46, 47, 48, 49, 52, 55, 56, 58, 60, 61, 67, 69, 74, 77, 79, 85, 86, 96, 97, 100, 113, 117, 121, 129, 136, 137, 140], "collect_param": [21, 22, 23, 26, 92, 99, 107], "colleg": 67, "colloqui": [42, 64], "color": [1, 19, 20, 21, 22, 25, 26, 28, 29, 31, 34, 40, 42, 47, 49, 54, 55, 58, 62, 72, 105, 117, 121, 141], "color_aug": 23, "colorbar": [2, 8], "colorjitt": [23, 26], "colormap": [21, 31], "colormap2label": 31, "coloss": 6, "column": [2, 3, 8, 9, 19, 25, 27, 28, 33, 41, 42, 43, 44, 46, 58, 60, 66, 69, 79, 99, 100, 108, 114, 117, 119, 120, 121, 129, 131, 133], "com": [1, 22, 25, 26, 29, 31, 60, 79, 86, 88, 91, 95, 99, 107, 132], "combat": 67, "combin": [7, 8, 9, 15, 19, 25, 28, 36, 37, 40, 41, 45, 46, 47, 48, 50, 52, 58, 64, 65, 69, 70, 71, 72, 74, 77, 84, 86, 94, 103, 109, 121, 123, 125, 126, 132, 137], "combinatori": 52, "come": [3, 5, 8, 9, 10, 15, 19, 25, 33, 34, 35, 39, 40, 41, 46, 47, 52, 58, 60, 62, 64, 65, 69, 71, 76, 77, 80, 83, 84, 89, 96, 98, 105, 108, 109, 112, 113, 115, 121, 122, 127, 132, 136, 139], "comedi": 58, "comfort": [58, 77], "comma": [120, 121], "command": [18, 54, 55, 57, 58, 80, 108, 113, 139], "commenc": 58, "comment": [87, 115], "commerc": [58, 120], "commerci": [58, 113], "commiss": 113, "common": [1, 2, 3, 6, 8, 15, 19, 22, 24, 28, 35, 39, 47, 58, 59, 60, 64, 66, 67, 69, 70, 72, 74, 76, 77, 79, 80, 82, 83, 90, 94, 96, 102, 103, 104, 105, 106, 107, 109, 112, 113, 114, 115, 117, 119, 120, 121, 123, 129, 132, 133, 134, 135, 136, 137], "commonli": [3, 14, 20, 21, 24, 28, 32, 35, 37, 39, 42, 44, 58, 62, 64, 67, 74, 75, 80, 93, 104, 110, 113, 114, 117, 130], "commonsens": 6, "commun": [11, 34, 46, 58, 64, 94, 113, 131], "commut": 117, "comorbid": 58, "comp_conv2d": 44, "compact": [15, 34, 35, 64, 69, 101], "compactli": [69, 80], "compani": [58, 60, 67, 113, 121], "compar": [5, 6, 8, 10, 18, 20, 22, 23, 30, 31, 32, 34, 35, 36, 37, 39, 41, 42, 43, 47, 52, 53, 54, 55, 56, 58, 59, 61, 62, 64, 65, 66, 67, 69, 70, 71, 76, 77, 79, 80, 81, 83, 88, 89, 91, 96, 99, 101, 102, 108, 109, 112, 117, 121, 122, 123, 125, 127, 129, 132, 133, 134, 135, 136, 137, 140, 141], "compare_count": 97, "comparison": [22, 34, 51, 58, 67, 79, 86, 90], "compartment": 47, "compat": [1, 8, 9, 35, 67, 77, 101], "compel": [6, 49, 58], "compens": [43, 60, 102], "compensatori": 35, "compet": [6, 37, 50, 61, 67, 79, 113], "competit": [5, 6, 15, 25, 26, 34, 38, 52, 58, 79, 85, 127], "competitor": 42, "compil": [35, 60, 107, 114, 127], "complement": [113, 121], "complementari": 50, "complet": [4, 18, 21, 25, 35, 37, 47, 54, 55, 56, 58, 60, 66, 75, 90, 95, 97, 118, 122, 128, 129, 130, 132, 134, 136, 140, 141], "complex": [4, 6, 8, 9, 11, 12, 13, 15, 16, 19, 28, 32, 34, 35, 36, 37, 39, 40, 43, 46, 47, 52, 55, 56, 58, 60, 61, 69, 70, 72, 74, 77, 79, 80, 81, 86, 89, 90, 91, 96, 98, 106, 112, 113, 114, 123, 125, 126, 128, 131, 141], "complic": [19, 22, 29, 37, 40, 44, 58, 64, 67, 68, 69, 75, 77, 79, 104, 105, 110, 117, 121, 130], "compon": [2, 8, 10, 12, 13, 15, 16, 24, 31, 36, 41, 51, 60, 62, 64, 65, 66, 69, 70, 71, 72, 74, 103, 113, 114, 117, 119, 121, 124, 131, 134, 139, 142], "compos": [10, 12, 22, 23, 25, 26, 28, 34, 36, 58, 62, 69, 71, 73, 90, 108, 115, 117, 121, 136, 137], "composit": [22, 69, 77, 115, 127], "comprehens": [6, 77, 83, 84, 112, 113, 131], "compress": [5, 8, 35, 43, 64, 65, 96, 129, 132], "compris": [15, 36, 37, 40, 42, 46, 47, 58, 61, 68, 137], "compromis": [113, 122, 136], "comput": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74, 76, 77, 78, 80, 81, 82, 83, 86, 88, 89, 90, 92, 93, 94, 96, 97, 98, 99, 102, 103, 104, 105, 107, 108, 109, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 141, 142], "computation": [6, 18, 34, 37, 42, 46, 58, 65, 81, 93, 103, 108, 122, 125, 130], "compute_loss": 28, "concat": [19, 79, 86, 88, 129], "concat_pr": 32, "concaten": [3, 4, 7, 10, 11, 15, 19, 28, 29, 30, 33, 36, 37, 40, 45, 79, 81, 86, 88, 90, 91, 97, 99, 100, 115, 119, 129, 130, 133, 135], "conceiv": [13, 58, 67], "concentr": [47, 48, 74], "concept": [8, 13, 15, 35, 39, 48, 51, 56, 58, 74, 78, 105, 113, 115, 117, 119, 121, 131, 133, 138, 139], "conceptu": [34, 58, 81, 90], "concern": [5, 15, 32, 46, 58, 60, 71, 80, 81, 110, 113, 114, 115, 117, 121, 127, 137, 140], "concert": 77, "concis": [8, 19, 32, 38, 39, 59, 63, 64, 68, 71, 72, 78, 101, 103, 106, 126, 131, 142], "conclud": [6, 24, 37, 42, 60, 61, 67], "conclus": [69, 121], "concret": [19, 22, 25, 27, 28, 30, 32, 46, 49, 60, 69, 84, 88, 98, 104, 112, 129, 132, 139], "concurr": [6, 54, 55], "conda": 57, "condit": [3, 6, 15, 41, 47, 48, 58, 60, 64, 69, 76, 77, 79, 80, 82, 89, 93, 94, 98, 100, 102, 103, 104, 105, 107, 114, 119, 121, 122, 124, 129, 130, 132, 133, 135, 136, 139, 141], "condition": [100, 121, 136], "condition_mx": 19, "condition_np": 19, "conduct": [58, 61, 121, 135], "cone": [8, 35], "conf": 19, "confer": [5, 35, 45, 58], "confid": [19, 32, 41, 47, 48, 58, 61, 64, 67, 69, 76, 121], "config": [51, 52, 54, 55, 56], "config_ax": 1, "config_spac": [51, 52, 54, 55, 56], "configur": [37, 39, 51, 54, 55, 56, 71, 92, 103, 125, 127], "configure_optim": [59, 70, 71, 72, 74, 129], "confirm": [18, 34, 35, 73, 112, 118], "conflict": [112, 113], "confront": [60, 77, 120], "confus": [47, 58, 60, 69, 117], "confusingli": 60, "conjectur": 35, "conjunct": 105, "connect": [4, 5, 6, 7, 9, 11, 12, 15, 16, 21, 22, 24, 26, 30, 32, 34, 37, 38, 39, 40, 41, 42, 43, 49, 50, 64, 65, 67, 68, 69, 70, 76, 77, 78, 80, 81, 82, 83, 88, 90, 104, 107, 125, 127, 129, 131, 133, 134, 135, 142], "connoisseur": 58, "consciou": 58, "consecut": [6, 85, 90, 96, 132, 137], "consequ": [4, 8, 34, 35, 39, 42, 45, 46, 58, 60, 62, 66, 75, 76, 80, 82, 89, 102, 105, 109, 110, 121, 130, 136], "consequenti": 58, "conserv": [61, 77], "consid": [3, 6, 8, 9, 11, 19, 27, 30, 33, 34, 35, 37, 39, 41, 44, 46, 47, 48, 49, 51, 52, 54, 56, 58, 61, 62, 64, 66, 67, 69, 74, 77, 81, 82, 83, 87, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 110, 112, 114, 117, 120, 121, 122, 129, 130, 132, 133, 136, 139, 140], "consider": [35, 39, 44, 58, 60, 61, 64, 67, 69, 70, 73, 74, 77, 79, 81, 102, 105, 108, 117, 121, 123, 131, 132], "consist": [2, 5, 6, 8, 11, 15, 19, 22, 25, 26, 28, 30, 32, 34, 35, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 52, 55, 58, 59, 60, 62, 64, 65, 66, 67, 69, 73, 76, 77, 78, 79, 81, 83, 86, 87, 90, 97, 98, 105, 112, 117, 120, 121, 123, 124, 128, 129, 130, 131, 135, 136, 137], "conspicu": 58, "conspir": 58, "const": 47, "const_fn": 14, "constant": [2, 3, 14, 15, 19, 21, 23, 31, 33, 35, 46, 48, 54, 56, 58, 60, 61, 64, 66, 69, 70, 71, 74, 82, 93, 97, 102, 105, 107, 108, 111, 112, 114, 115, 117, 127, 132, 135, 136, 137], "constant_embed": 88, "constant_lr": 112, "constantli": 58, "constitu": [15, 31], "constitut": [40, 58, 66, 67, 74, 117, 121, 123, 137], "constrain": [35, 42, 48, 52, 62, 74, 77, 80, 104, 121], "constraint": [6, 11, 83, 102, 106, 108, 140, 141], "construct": [1, 8, 10, 12, 13, 15, 16, 19, 21, 22, 28, 32, 33, 34, 36, 40, 41, 44, 45, 46, 49, 50, 51, 58, 64, 65, 70, 71, 79, 80, 85, 88, 89, 98, 103, 105, 109, 114, 117, 118, 119, 121, 123, 129, 133, 136, 137, 139], "constructor": [15, 34, 37, 41, 72, 76, 85], "consult": [35, 61, 109], "consum": [18, 34, 52, 54, 58, 74, 77, 108, 114], "consumpt": [34, 36, 60], "contact": 61, "contain": [1, 8, 9, 10, 15, 16, 17, 19, 20, 21, 22, 25, 26, 27, 29, 30, 31, 33, 34, 35, 39, 40, 41, 45, 46, 47, 48, 49, 50, 54, 57, 58, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 72, 75, 76, 79, 80, 81, 85, 87, 88, 89, 91, 95, 96, 97, 98, 100, 102, 104, 113, 114, 115, 117, 119, 120, 122, 125, 127, 132, 136, 137, 138, 140, 141], "contempl": 60, "content": [1, 6, 8, 24, 34, 46, 60, 64, 106, 116, 118, 126, 132, 136], "content_img": 28, "content_lay": 28, "content_loss": 28, "content_weight": 28, "content_x": 28, "contents_i": 28, "contents_l": 28, "contents_y_hat": 28, "context": [4, 5, 6, 12, 16, 17, 35, 45, 56, 58, 59, 61, 68, 74, 77, 80, 89, 92, 93, 94, 98, 99, 102, 104, 106, 107, 109, 113, 117, 120, 121, 122, 124, 129, 132, 136], "context_neg": 99, "contexts_and_neg": 99, "contexts_neg": [97, 99], "contexts_negatives_batch": 97, "contextu": 58, "contigu": 58, "continu": [1, 6, 9, 19, 23, 28, 32, 34, 35, 41, 44, 47, 49, 50, 54, 55, 56, 58, 60, 61, 62, 74, 75, 77, 79, 80, 82, 83, 86, 89, 91, 94, 96, 97, 102, 105, 106, 113, 117, 121, 122, 130, 132, 135, 136, 139], "contour": [48, 105], "contractor": 58, "contradict": [46, 85, 86, 104], "contrari": [35, 82, 85], "contrast": [6, 10, 11, 22, 23, 26, 30, 33, 34, 35, 36, 43, 48, 58, 61, 67, 70, 74, 86, 90, 97, 113, 117, 121, 125, 126, 129, 130], "contribut": [0, 3, 37, 47, 58, 61, 69, 82, 113], "contributor": [58, 113], "contriv": [109, 114], "control": [3, 5, 8, 15, 30, 32, 35, 36, 39, 44, 47, 48, 49, 50, 53, 58, 61, 67, 69, 74, 76, 79, 80, 82, 103, 109, 111, 112, 116, 125, 127, 131, 135, 138], "conv": [11, 33, 88], "conv1": [1, 21, 39], "conv1d": 88, "conv2": [1, 21, 39], "conv2d": [1, 11, 21, 23, 32, 33, 34, 35, 36, 37, 39, 41, 43, 44, 107], "conv2dtranspos": [21, 33], "conv3": [1, 39], "conv4": 39, "conv_block": 36, "conv_tran": 21, "convei": [35, 38, 58, 75, 112, 114, 121], "conveni": [2, 5, 8, 15, 17, 18, 31, 33, 35, 47, 58, 59, 62, 64, 65, 69, 70, 72, 73, 74, 79, 103, 104, 107, 108, 109, 115, 123, 130, 132, 135, 137], "convent": [1, 35, 38, 44, 47, 58, 60, 62, 65, 74, 80, 100, 110, 115, 121, 122, 131], "convention": [4, 42], "converg": [2, 34, 35, 47, 52, 61, 65, 69, 77, 82, 90, 101, 102, 103, 106, 107, 108, 109, 111, 115, 121, 123, 135, 140, 141], "convers": [5, 6, 20, 40, 58, 60, 79, 102, 104, 105, 107, 108, 109, 112, 115, 116, 121, 136], "convert": [1, 3, 6, 18, 20, 23, 32, 59, 62, 85, 91, 117, 119, 120, 124, 128, 131, 136, 142], "convex": [8, 34, 35, 47, 64, 102, 103, 105, 106, 107, 110, 111, 125, 142], "convinc": [43, 52], "convnet": [34, 42, 64], "convolut": [5, 8, 9, 10, 11, 15, 23, 24, 27, 28, 30, 32, 36, 37, 39, 44, 45, 53, 58, 65, 66, 70, 84, 86, 107, 113, 126, 130, 131, 142], "convolv": 38, "convtranspose2d": [21, 33], "cool": 107, "cooper": 60, "coordin": [2, 19, 20, 21, 27, 28, 29, 30, 38, 46, 64, 69, 80, 101, 102, 103, 105, 108, 109, 111, 112, 117, 121, 131], "cope": [60, 130], "copi": [7, 21, 22, 25, 79, 91, 108, 113, 119, 125], "copy_": 21, "copyfil": 25, "cord": 17, "core": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 49, 52, 54, 58, 59, 62, 65, 66, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 85, 86, 87, 88, 90, 91, 92, 95, 97, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 123, 124, 125, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137], "corefer": 90, "corner": [19, 20, 21, 25, 29, 30, 41, 44, 58, 65, 75], "coronaviru": 83, "corpor": 58, "corpora": [5, 6, 58, 90, 91, 94, 95, 97, 98, 137], "corpu": [6, 83, 85, 90, 91, 94, 97, 99, 132, 135, 137], "corr1d": 88, "corr1d_multi_in": 88, "corr2d": [33, 40, 41, 45], "corr2d_multi_in": 40, "corr2d_multi_in_out": 40, "corr2d_multi_in_out_1x1": 40, "correct": [1, 20, 21, 58, 59, 63, 64, 66, 69, 73, 103, 109, 117, 130, 135, 138, 141], "correctli": [58, 66], "corrector": 60, "correl": [28, 31, 40, 42, 44, 45, 46, 48, 58, 88, 100, 121, 132], "correspond": [2, 5, 8, 9, 15, 16, 19, 21, 22, 27, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 54, 55, 58, 60, 61, 62, 64, 66, 67, 69, 74, 75, 76, 79, 80, 85, 88, 89, 90, 97, 98, 102, 104, 105, 117, 119, 120, 121, 123, 128, 129, 130, 131, 132, 133, 135, 136, 137, 139, 140, 141], "correspondingli": [103, 105, 108, 127], "corrupt": [6, 58, 64, 73, 74, 136], "corston": 113, "cortex": 41, "corthorn": 113, "cosh": 105, "cosin": [9, 95, 98, 99, 104, 105, 117], "cosineschedul": 107, "cosmet": [46, 103], "cost": [3, 7, 22, 26, 32, 34, 37, 39, 40, 45, 56, 58, 60, 64, 75, 84, 89, 93, 102, 105, 108, 109, 112, 122, 127, 133], "costli": [34, 37, 39, 69, 74, 105, 127], "could": [2, 5, 6, 9, 15, 32, 34, 35, 39, 40, 42, 45, 46, 47, 48, 52, 54, 55, 56, 58, 60, 61, 62, 64, 65, 67, 69, 71, 73, 74, 80, 81, 82, 98, 101, 102, 103, 105, 107, 108, 109, 110, 112, 113, 114, 117, 119, 120, 121, 122, 123, 130, 132, 133, 135, 136, 137, 141], "couldn": 102, "count": [6, 19, 40, 69, 85, 87, 91, 92, 93, 97, 102, 108, 121, 128, 132, 136, 137], "count_corpu": [1, 97], "countabl": 121, "counter": [1, 25, 97, 102, 103, 137], "counteract": [35, 130], "counterintuit": [67, 77, 121, 131], "counterpart": [58, 70, 75, 117], "countri": [58, 95], "coupl": [34, 60, 121], "cour": 128, "courez": 128, "cours": [29, 35, 38, 45, 46, 58, 61, 89, 108, 113, 117, 120, 121, 135, 136], "court": [61, 129], "courtesi": [34, 46], "cousin": 35, "cov": [8, 47, 48, 49, 100, 121], "covari": [2, 35, 47, 48, 49, 50, 58, 69, 100, 121], "covariogram": 47, "cove": 90, "cover": [8, 16, 19, 21, 23, 24, 25, 31, 34, 35, 38, 45, 46, 47, 64, 65, 69, 71, 77, 79, 84, 94, 95, 107, 109, 113, 117, 128, 129, 131, 136], "coverag": [5, 118], "covid": 121, "covmat": 49, "cow": 31, "cp": 11, "cpu": [18, 21, 26, 34, 54, 55, 57, 69, 72, 81, 99, 108, 119], "craft": [2, 19, 34, 60, 83, 84, 90], "crane": [90, 92], "crash": [18, 113, 117, 120], "crawl": 6, "creat": [1, 9, 10, 12, 14, 15, 18, 19, 21, 22, 23, 25, 26, 28, 29, 31, 32, 33, 35, 39, 40, 41, 44, 47, 48, 54, 57, 58, 60, 61, 62, 66, 69, 72, 73, 79, 84, 88, 90, 95, 97, 98, 103, 108, 113, 114, 117, 118, 119, 120, 129, 133, 134, 136, 139], "create_banana_data_it": 29, "create_data_it": [25, 26], "create_dataset": [25, 26], "create_model": [1, 21, 22, 26, 28], "create_voc_data_it": 31, "creativ": [6, 12, 15, 46, 58, 113, 115], "creator": [58, 82], "credibl": [42, 47, 48], "credit": [58, 60], "creditworthi": 58, "crime": [58, 60], "crisper": 115, "crispli": 58, "criteria": [19, 60], "criterion": [52, 54, 67, 69, 77], "critic": [34, 35, 36, 60, 69, 113, 140], "crop": [21, 22, 25, 26, 29, 31, 58, 73, 82], "crop_rect": 21, "crop_siz": [21, 31], "cropped_featur": 31, "cropped_label": 31, "cross": [2, 5, 6, 32, 36, 40, 42, 43, 44, 45, 46, 56, 58, 61, 63, 65, 78, 88, 90, 93, 96, 129, 132, 133, 139], "cross_entropi": [1, 21, 22, 23, 25, 26, 32, 65, 66, 86, 88, 90, 92, 107], "crossentropyloss": [22, 23, 26, 92, 107], "crowdsourc": 34, "crucial": [3, 8, 47, 51, 58, 60, 61, 67, 71, 77, 82, 114, 115, 121, 131], "crude": 102, "cryptonaut": 113, "cstride": 110, "csv": [25, 26, 29, 79, 120], "csv_data": 29, "csv_fname": 29, "ctx": [19, 21, 23, 26, 92, 99, 107], "cubic": 117, "cuda": [18, 34, 35, 57], "culmin": [38, 43, 126], "culprit": 82, "cum_count": 121, "cumbersom": [47, 105, 141], "cumsum": [108, 117, 121], "cumul": [80, 102, 117], "cumulative_runtim": 51, "cuong": 113, "cup": [19, 100, 104, 121], "cur_len": 97, "cur_output": 96, "curat": 61, "curatori": 113, "curr_featur": 30, "current": [2, 4, 10, 22, 24, 27, 32, 35, 38, 46, 51, 55, 56, 57, 58, 62, 67, 69, 70, 71, 74, 75, 77, 99, 107, 108, 112, 113, 117, 123, 124, 125, 127, 129, 130, 132, 133, 135, 138, 139, 140, 141], "current_index": 72, "current_runtim": 51, "currentfram": 1, "curs": [52, 65], "curtain": 13, "curv": [6, 48, 54, 55, 56, 65, 71, 107, 115, 121], "curvatur": 105, "custom": [1, 13, 25, 26, 29, 35, 58, 60, 64, 71, 72, 85, 90, 91, 105, 107, 120, 121, 129, 136, 142], "custom_callback": 107, "cut": [40, 77, 82, 134], "cx": [20, 105], "cy": 20, "cyberneticist": 69, "cycl": [34, 58, 60, 131], "cyclic": [107, 131], "cys4": 113, "d": [3, 8, 9, 10, 30, 32, 41, 46, 47, 49, 52, 58, 60, 61, 64, 67, 69, 74, 75, 77, 80, 86, 88, 89, 95, 96, 98, 102, 104, 105, 110, 114, 115, 117, 119, 121, 122, 123, 125, 127, 129, 130, 132, 133, 136], "d1": [1, 141], "d2": [1, 141], "d2l": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 45, 47, 49, 51, 52, 54, 55, 56, 59, 62, 65, 66, 69, 70, 71, 72, 73, 74, 76, 79, 80, 81, 82, 85, 86, 87, 88, 90, 91, 92, 95, 97, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 121, 123, 124, 125, 127, 128, 129, 132, 133, 134, 135, 136, 137, 140, 141], "d2lbook": [54, 55], "d_": [100, 115], "d_1": 121, "d_2": 121, "d_grad": 114, "d_i": 115, "d_k": 7, "d_q": 7, "d_v": 7, "d_x": 115, "dachshund": 26, "dagar": 113, "dai": [6, 17, 34, 43, 46, 52, 54, 58, 59, 60, 61, 64, 69, 70, 77, 106, 117, 131, 134, 136], "daili": [58, 113, 138], "daisi": 15, "dall": [6, 58], "dam": 121, "damag": [60, 135], "danc": 83, "danger": 65, "daniel": 113, "dark": [28, 141], "dash": [28, 51, 79, 121], "dat": 108, "data": [1, 4, 5, 6, 8, 10, 11, 12, 15, 17, 18, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 80, 81, 84, 85, 86, 88, 89, 91, 92, 94, 95, 97, 98, 99, 101, 102, 103, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 121, 123, 124, 125, 127, 128, 129, 131, 132, 133, 134, 135, 136, 140, 142], "data_arrai": 1, "data_dir": [1, 22, 25, 26, 29, 85, 87, 91, 95, 97], "data_fil": 120, "data_fold": 79, "data_hub": [1, 22, 25, 26, 29, 31, 85, 87, 91, 95, 97, 108], "data_it": [1, 23, 25, 26, 29, 31, 71, 91, 97, 99, 101, 102, 103, 108, 109, 111], "data_maker1": 47, "data_url": [1, 22, 25, 26, 29, 31, 79, 87, 95, 97, 108, 128, 137], "databas": [8, 58, 113, 120], "dataclass": 113, "datafram": [10, 25, 79], "dataload": [22, 23, 26, 29, 31, 62, 71, 72, 73, 85, 91, 97], "datamodul": [62, 72, 73, 74, 79, 128, 136, 137], "dataparallel": [23, 26, 92], "datapoint": [47, 48], "dataset": [1, 6, 10, 11, 13, 19, 23, 24, 28, 30, 34, 35, 37, 39, 43, 46, 47, 48, 49, 52, 56, 58, 60, 61, 63, 64, 66, 68, 69, 70, 71, 72, 74, 76, 77, 78, 81, 83, 84, 92, 94, 95, 96, 99, 105, 106, 110, 112, 113, 116, 117, 121, 123, 125, 126, 127, 129, 131, 132, 134, 135, 136, 140, 142], "date": [39, 58, 64, 69, 113, 114, 136], "dateset": 91, "datum": 138, "daughter": 95, "daunt": 103, "david": 113, "dawn": 69, "dc": 49, "dchoi77": 113, "ddot": [48, 117], "de": 6, "deactiv": 57, "dead": 67, "deal": [3, 12, 34, 46, 58, 59, 60, 61, 64, 69, 73, 74, 79, 81, 82, 104, 107, 108, 109, 113, 119, 120, 121, 130, 131, 132, 135, 136, 137], "dealt": [64, 126], "death": [58, 136], "debat": [6, 35, 69, 76], "debia": 103, "debias": 76, "debug": [6, 16, 58, 73, 113], "dec_attention_weight": [4, 10], "dec_attention_weights_2d": 10, "dec_attention_weights_fil": 10, "dec_inter_attention_weight": 10, "dec_output": 129, "dec_self_attention_weight": 10, "dec_stat": [124, 129], "dec_valid_len": 10, "dec_x": 124, "decad": [4, 8, 18, 34, 43, 47, 58, 62, 67, 70, 80, 113, 114, 128], "decai": [34, 35, 52, 61, 67, 68, 75, 76, 77, 79, 102, 104, 107, 108, 112, 136, 137, 142], "decent": 6, "decid": [18, 46, 51, 55, 58, 60, 77, 80, 85, 102, 105, 113, 121, 132, 136], "decidedli": 60, "decis": [51, 54, 55, 58, 60, 67, 80, 87, 94, 108, 113, 121, 123, 129, 138, 140, 141, 142], "declar": [16, 41, 72], "declin": [105, 108, 136], "decod": [1, 5, 9, 43, 64, 87, 88, 90, 122, 126, 128, 131, 142], "decoder_blk": 10, "decoder_input": 72, "decompos": [36, 40, 86, 109, 117, 130, 136], "decomposableattent": 86, "decomposit": [47, 64, 86, 117, 141], "decompress": 62, "decor": 72, "decoupl": [16, 103, 111, 121], "decreas": [9, 39, 48, 56, 64, 65, 67, 74, 77, 80, 101, 102, 105, 107, 108, 109, 111, 112, 115, 116], "dedic": [34, 117, 127], "deem": 4, "deep": [1, 2, 3, 4, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 30, 32, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 52, 54, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 84, 85, 86, 90, 94, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 119, 120, 126, 131, 132, 134, 135, 136, 137, 138, 140], "deepak": 113, "deepblu": 58, "deeper": [10, 13, 26, 34, 35, 36, 37, 39, 40, 41, 45, 46, 61, 67, 69, 75, 80, 94, 106, 109], "deepli": [42, 115], "deer": 25, "def": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 47, 49, 51, 52, 54, 55, 56, 59, 60, 62, 64, 65, 66, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 114, 115, 121, 123, 124, 125, 127, 128, 129, 132, 134, 135, 136, 137, 140, 141], "default": [1, 5, 12, 14, 15, 18, 19, 39, 43, 44, 45, 51, 52, 53, 58, 59, 60, 64, 66, 70, 79, 80, 101, 107, 112, 114, 117, 118, 125, 131], "default_devic": 18, "default_valu": 19, "defaultdict": [56, 96, 113, 129], "defeat": 105, "defer": [35, 72], "defin": [1, 2, 5, 7, 8, 12, 14, 15, 16, 18, 19, 20, 23, 24, 27, 29, 31, 33, 35, 36, 37, 41, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 58, 60, 63, 64, 66, 67, 68, 69, 72, 73, 75, 80, 81, 82, 86, 89, 90, 92, 94, 95, 96, 97, 104, 105, 107, 108, 110, 112, 114, 115, 117, 121, 123, 127, 128, 129, 131, 132, 133, 135, 137, 139, 141], "definit": [3, 9, 23, 27, 37, 46, 47, 50, 54, 56, 60, 64, 66, 72, 75, 79, 80, 89, 91, 99, 100, 103, 106, 109, 111, 113, 115, 117, 121, 129, 130, 133, 138], "degener": 60, "degrad": [60, 136], "degre": [23, 35, 45, 58, 67, 72, 74, 102, 105, 110, 113, 117, 121, 132, 135], "deit": 11, "delai": [46, 138], "deleg": 51, "delet": [6, 120], "deliber": [37, 58], "delici": 58, "delightfulli": 41, "delimit": [91, 96, 108, 128], "delin": [35, 45], "deliv": [15, 58, 138], "deliveri": 138, "dell": 99, "delta": [9, 40, 46, 49, 61, 79, 101, 102], "delta_": [48, 112], "delta_b": 101, "delta_w": 101, "delv": [34, 60, 82, 109, 113], "demand": [15, 18, 52, 61, 69, 72, 113, 131], "demo": [25, 26], "democrat": [6, 43], "demograph": 58, "demonstr": [2, 6, 9, 11, 16, 22, 24, 25, 27, 30, 41, 45, 46, 47, 58, 77, 79, 82, 84, 86, 88, 90, 91, 92, 95, 113, 114, 119, 120, 121, 122, 129, 133, 137], "demot": 61, "demystifi": [58, 64], "dendrit": 69, "deni": 60, "dennismalmgren": 113, "denois": [28, 58], "denomin": [6, 65, 66, 122], "denot": [2, 8, 9, 10, 12, 19, 21, 28, 32, 35, 36, 39, 40, 41, 45, 46, 55, 58, 59, 60, 64, 69, 75, 79, 80, 86, 89, 93, 95, 96, 98, 100, 104, 105, 109, 112, 117, 119, 121, 122, 129, 130, 132, 133, 141], "dens": [4, 10, 26, 38, 39, 43, 83, 107, 129, 142], "dense1": [10, 11], "dense2": [10, 11], "denseblock": 36, "densenet": [38, 142], "densiti": [2, 47, 48, 58, 61, 67, 71, 100, 121, 136], "depart": 121, "depend": [2, 3, 6, 7, 9, 10, 23, 30, 35, 36, 45, 46, 47, 48, 51, 52, 53, 54, 56, 58, 60, 61, 64, 67, 69, 71, 74, 75, 76, 77, 79, 80, 89, 90, 96, 102, 103, 105, 108, 112, 113, 114, 115, 117, 120, 121, 123, 125, 127, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "depict": [4, 6, 11, 37, 39, 44, 46, 56, 58, 64, 69, 80, 83, 84, 86, 90, 129, 131], "deploi": [3, 17, 35, 38, 42, 58, 60], "deploy": [17, 60, 121], "deposit": [43, 58, 90, 94], "deprec": 1, "depth": [34, 36, 40, 47, 58, 64, 77, 106, 108, 109, 113, 123, 135], "derefer": 119, "deriv": [2, 6, 8, 35, 38, 39, 40, 41, 45, 46, 47, 48, 49, 60, 61, 64, 67, 69, 71, 74, 75, 80, 100, 102, 105, 109, 110, 114, 116, 121, 130], "desanti": 113, "desc": [1, 140, 141], "descend": 19, "descent": [1, 2, 34, 43, 52, 58, 59, 71, 74, 75, 77, 82, 93, 98, 102, 103, 104, 106, 109, 110, 113, 133, 135, 140, 142], "describ": [6, 7, 8, 9, 10, 15, 19, 20, 21, 22, 24, 26, 28, 30, 32, 35, 37, 38, 39, 40, 41, 44, 45, 46, 48, 58, 60, 64, 69, 70, 73, 75, 76, 77, 80, 81, 83, 84, 86, 88, 89, 91, 99, 104, 109, 110, 112, 113, 117, 121, 127, 130, 131, 133, 136, 139, 141], "descript": [4, 6, 31, 41, 58, 91, 99, 113, 118, 137], "descriptor": 34, "deserv": 117, "desiderata": 46, "desideratum": 46, "design": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 19, 21, 22, 27, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 52, 54, 58, 60, 62, 64, 65, 68, 69, 71, 73, 76, 79, 81, 82, 83, 84, 85, 86, 88, 90, 93, 96, 98, 103, 104, 105, 106, 107, 114, 117, 120, 121, 123, 124, 126, 127, 129, 132, 134, 135, 136, 137, 139, 142], "desir": [6, 8, 35, 39, 43, 45, 58, 61, 74, 86, 105, 107, 108, 109, 111, 113, 114, 117, 122, 130, 132, 135, 136], "desktop": 18, "despit": [2, 5, 10, 35, 46, 47, 48, 58, 60, 61, 69, 77, 80, 88, 113, 121, 123, 126], "destabil": 130, "destin": 69, "destroi": [35, 58, 82], "det": 47, "detach": [21, 26, 116, 130], "detail": [3, 4, 6, 13, 15, 16, 17, 28, 30, 32, 34, 35, 37, 39, 40, 42, 43, 58, 61, 62, 64, 71, 72, 75, 79, 81, 82, 86, 97, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 120, 125, 127, 129, 131, 133, 139], "detect": [5, 6, 15, 19, 21, 24, 25, 30, 31, 34, 35, 37, 38, 40, 42, 45, 46, 54, 55, 58, 60, 121, 142], "detector": [40, 41, 46, 58, 60], "determin": [1, 2, 5, 19, 20, 27, 30, 32, 41, 46, 47, 48, 56, 57, 58, 60, 61, 64, 69, 71, 73, 77, 79, 81, 82, 83, 85, 86, 102, 105, 109, 111, 115, 116, 121, 125, 126, 127, 133, 135, 137, 138], "determinist": [35, 45, 58, 60, 69, 140, 141], "dethron": 58, "detour": [2, 36], "detriment": [58, 108], "dev": 1, "develop": [15, 34, 35, 38, 43, 48, 57, 58, 60, 61, 62, 67, 68, 69, 70, 76, 77, 90, 108, 113, 114, 115, 120, 121, 123, 130, 131, 135, 136, 138, 141], "deviat": [6, 14, 21, 22, 26, 34, 35, 47, 48, 51, 61, 69, 71, 73, 74, 79, 100, 103, 108, 119, 121, 125, 127], "devic": [13, 17, 19, 21, 22, 23, 26, 34, 35, 43, 60, 67, 92, 99, 106, 107, 108, 118, 129, 135], "device_id": [23, 26, 92], "device_nam": 107, "devis": 58, "devot": [35, 58, 74, 121], "df": [25, 47, 54, 55, 91, 114, 115], "dgx": 58, "diag": [47, 102, 105], "diagnos": [58, 60, 67, 113, 121, 131], "diagnosi": [24, 66, 121], "diagnost": [2, 16, 31, 58], "diagon": [35, 39, 40, 41, 47, 48, 100, 102, 105, 109, 117, 121], "diagram": [41, 64, 69, 109, 121, 127], "dial": 61, "dialog": [58, 128, 132], "dialogu": [58, 113, 131, 132], "diamet": 58, "diamond": 104, "dib": 61, "dict": [1, 17, 19, 22, 23, 25, 29, 31, 51, 56, 96, 110, 113], "dict_kei": 22, "dictat": 127, "dictatori": 58, "dictionari": [17, 25, 54, 89, 96, 97, 98, 99, 103, 108, 122, 137], "did": [6, 15, 18, 26, 34, 35, 45, 46, 48, 51, 55, 58, 59, 60, 70, 71, 79, 95, 102, 112, 113, 121, 136, 137], "didact": 73, "die": [58, 121], "dies": 58, "diet": 60, "differ": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 60, 61, 64, 65, 67, 69, 71, 72, 73, 74, 76, 77, 79, 81, 82, 83, 84, 86, 87, 88, 90, 92, 93, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 119, 121, 122, 123, 124, 127, 128, 129, 130, 132, 133, 135, 136, 139, 140, 141], "differenti": [4, 5, 8, 15, 58, 59, 67, 69, 70, 71, 75, 77, 78, 80, 82, 98, 104, 105, 113, 116, 119, 129, 130, 133, 136, 142], "difficult": [8, 18, 27, 32, 35, 46, 52, 54, 58, 59, 60, 61, 64, 65, 67, 69, 71, 80, 81, 102, 104, 112, 113, 115, 129, 132, 136], "difficulti": [126, 136], "diffus": 58, "dig": 13, "digest": 60, "digit": [43, 58, 62, 67], "digitalvis": 60, "dilat": 21, "dilemma": [60, 82, 107], "dilig": 67, "dim": [1, 19, 21, 22, 26, 99], "dimens": [1, 3, 4, 9, 10, 14, 15, 19, 20, 21, 26, 27, 30, 32, 33, 35, 36, 37, 40, 41, 43, 44, 45, 46, 49, 58, 59, 60, 61, 66, 67, 73, 76, 77, 81, 86, 88, 95, 99, 100, 105, 110, 117, 119, 127, 129, 133, 135], "dimension": [2, 3, 4, 9, 10, 15, 20, 21, 27, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 52, 58, 60, 61, 64, 65, 68, 69, 73, 75, 77, 80, 81, 84, 86, 95, 98, 100, 104, 106, 110, 115, 116, 117, 119, 133, 135], "diminish": [58, 76, 102, 136], "diner": 85, "diningt": 31, "dinner": 58, "dinosaur": 58, "dioxid": 48, "dir": 118, "direct": [4, 6, 20, 28, 35, 40, 41, 58, 69, 71, 75, 79, 80, 104, 105, 107, 109, 114, 115, 116, 121, 123, 130, 135, 136], "directli": [2, 9, 12, 17, 25, 29, 30, 34, 35, 38, 39, 48, 49, 50, 52, 57, 58, 59, 60, 61, 64, 66, 68, 69, 70, 74, 77, 80, 81, 96, 98, 105, 106, 121, 125, 127, 129, 136], "directori": [25, 79], "dirnam": 1, "dirti": [34, 59, 117, 119], "disabl": [3, 74, 76], "disadvantag": 75, "disagre": [58, 61], "disappear": [3, 47, 48, 60, 121], "disast": 60, "disastr": 60, "discard": [19, 26, 31, 56, 58, 67, 80, 97, 120, 122, 128, 132], "discharg": 64, "disciplin": [69, 77, 113, 131], "disclos": 6, "disconnect": 58, "discount": [138, 140, 141], "discours": [35, 113], "discov": [10, 43, 49, 58, 60, 64, 67, 69, 77, 96, 117], "discoveri": [34, 61], "discrep": [79, 130], "discret": [41, 46, 50, 58, 64, 79, 83, 87, 112, 121, 132, 136], "discrimin": [58, 60], "discuss": [3, 5, 8, 9, 10, 14, 17, 18, 21, 22, 23, 26, 27, 31, 32, 38, 42, 45, 47, 51, 52, 58, 60, 61, 62, 63, 66, 67, 69, 71, 72, 75, 76, 77, 78, 81, 82, 83, 84, 85, 87, 89, 91, 92, 93, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 116, 119, 122, 127, 129, 130, 131, 133, 135, 136, 137, 138, 140, 141], "diseas": [60, 67, 113, 121], "disentangl": 60, "disincent": 65, "disjoint": [52, 104, 108, 121], "disk": [13, 16, 17, 73, 77], "dislodg": 110, "dispens": 5, "displac": [35, 38, 113], "displai": [1, 8, 27, 32, 43, 57, 58, 72, 79, 113, 115, 118], "display_anchor": 27, "dispos": 74, "disproportion": 130, "disregard": 81, "dissatisfact": 58, "dissemin": [58, 60], "dist": [2, 49], "distanc": [2, 3, 21, 39, 41, 48, 49, 58, 61, 62, 69, 74, 77, 80, 93, 97, 102, 104, 105, 109, 112, 117, 121, 125], "distance_matrix": [47, 49, 113], "distant": [46, 58], "distbelief": [34, 70], "distil": [6, 109, 113], "distilbert": 6, "distinct": [23, 34, 37, 39, 46, 48, 49, 58, 60, 64, 67, 73, 83, 117, 120, 121, 122, 123, 127, 137, 138], "distinguish": [27, 31, 34, 35, 46, 54, 56, 58, 60, 62, 77, 90, 96, 97, 110, 117, 125, 130, 140], "distort": [102, 109], "distract": [46, 68], "distribut": [2, 6, 8, 14, 19, 26, 27, 32, 35, 39, 46, 47, 48, 49, 50, 51, 52, 54, 55, 58, 59, 61, 63, 64, 67, 68, 71, 73, 74, 76, 77, 80, 82, 83, 89, 93, 97, 100, 104, 107, 110, 111, 112, 118, 119, 121, 125, 127, 129, 132, 133, 136, 137, 139, 141, 142], "distrust": 61, "disturb": 132, "disutil": 121, "ditch": 9, "dive": [0, 2, 3, 42, 51, 64, 72, 75, 78, 82, 85, 90, 113, 116], "diverg": [35, 80, 82, 100, 103, 105, 107, 109, 130, 135, 136], "divers": [5, 6, 39, 40, 58, 60, 77, 87, 90, 113, 131, 132, 140], "diversifi": 6, "divid": [15, 19, 22, 25, 26, 27, 28, 30, 31, 35, 58, 64, 71, 73, 74, 76, 102, 105, 108, 113, 117, 121, 132], "dividend": 72, "divis": [21, 35, 39, 44, 58, 66, 71, 81, 111, 117, 119], "dizzi": 58, "djliden": 113, "do": [2, 3, 9, 10, 11, 15, 16, 17, 18, 19, 22, 23, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 81, 82, 86, 89, 91, 92, 95, 96, 100, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 114, 115, 117, 118, 119, 120, 121, 124, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139], "do_minim": [54, 55], "doan": 113, "doctor": 121, "doctorcolossu": 113, "document": [14, 23, 62, 70, 80, 108, 113, 116, 120, 131, 132, 135, 136, 142], "doe": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 16, 21, 22, 23, 26, 28, 31, 34, 35, 37, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 74, 75, 77, 79, 80, 81, 82, 84, 88, 89, 90, 97, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 115, 117, 121, 122, 127, 128, 129, 130, 132, 133, 135, 136, 138, 139, 140, 141], "dog": [19, 20, 24, 25, 31, 34, 46, 58, 60, 64, 77, 80, 96, 132, 142], "dog_bbox": 20, "dog_tini": 26, "dollar": [22, 58, 64, 69, 77, 121], "domain": [15, 48, 51, 58, 60, 66, 67, 69, 77, 80, 85, 91, 110, 112, 113, 131, 137], "domin": [5, 9, 11, 34, 38, 43, 52, 58, 64, 113, 127], "domkm": 113, "don": 32, "donald": 58, "donat": 60, "done": [1, 3, 17, 43, 49, 51, 52, 56, 60, 71, 79, 80, 119, 140], "done_idx": 1, "donhaus": 113, "donkei": [58, 64], "doodler": 58, "doom": 80, "door": 41, "doorstep": 138, "dop": 113, "dormant": [58, 112], "dose": 42, "dot": [2, 4, 5, 7, 9, 10, 28, 39, 41, 47, 48, 49, 56, 69, 89, 95, 98, 99, 100, 108, 112, 116, 119, 131, 136], "dotproductattent": [3, 7], "doubl": [21, 32, 39, 40, 64, 65, 69, 77], "down": [1, 20, 37, 40, 43, 44, 47, 58, 62, 65, 67, 85, 90, 94, 102, 105, 107, 108, 109, 121, 134, 135, 136, 137, 140, 141], "down_sample_blk": 32, "download": [1, 18, 22, 23, 24, 28, 31, 62, 72, 78, 85, 86, 87, 88, 91, 92, 95, 97, 99, 107, 108, 113, 126, 132, 137], "download_extract": [1, 21, 22, 25, 26, 29, 31, 85, 87, 91, 95, 97], "download_from_hf": 1, "downsampl": [1, 21, 33, 40, 43, 44, 45], "downsid": [40, 77, 135], "downstream": [5, 6, 58, 83, 84, 86, 88, 90, 92, 94, 95], "downtown": [58, 117], "downward": 107, "downweight": 109, "dozen": [34, 47, 82], "dp": 121, "dq": 64, "dqn": 140, "draft": 113, "drain": 58, "dramat": [13, 34, 46, 69, 74, 102, 121, 136], "drastic": [40, 44, 46, 107, 135], "draw": [1, 2, 4, 19, 20, 31, 46, 48, 49, 51, 58, 64, 69, 71, 72, 75, 76, 82, 97, 102, 104, 112, 121, 125, 130, 132], "drawback": [69, 86, 108], "drawn": [2, 3, 48, 49, 51, 58, 60, 61, 64, 67, 69, 71, 73, 77, 82, 108, 110, 112, 119, 140], "dread": [18, 65], "dress": [1, 62], "drew": [76, 121], "drift": 35, "drink": [60, 77, 90], "drive": [20, 24, 52, 58, 67, 105, 108, 109, 113], "driven": [5, 113, 131, 136], "driver": [5, 18, 69, 90, 92], "drop": [3, 19, 34, 41, 71, 74, 76, 79, 80, 97, 112, 119, 121, 136, 137], "drop_last": [25, 26, 31, 72, 85, 91], "dropout": [1, 3, 4, 5, 7, 9, 10, 11, 34, 35, 51, 52, 58, 77, 78, 79, 82, 86, 88, 90, 92, 123, 125, 129, 142], "dropout1": 11, "dropout2": 11, "dropout_1": [51, 76], "dropout_2": [51, 76], "dropout_lay": [76, 125], "dropout_p": 76, "dropoutmlp": [51, 54, 76], "dropoutmlpscratch": 76, "drove": [34, 60], "dset": [1, 25], "dsweet": 113, "dt": 49, "dtype": [1, 3, 4, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 30, 31, 32, 33, 35, 40, 41, 44, 45, 59, 62, 66, 70, 71, 73, 76, 79, 82, 86, 88, 91, 92, 97, 99, 105, 108, 114, 117, 118, 119, 120, 121, 128, 132, 133, 135, 136], "du": [101, 113, 115], "dual": [34, 45], "dub": 34, "dubiou": 58, "duboi": 113, "duc": 113, "due": [9, 12, 15, 21, 22, 30, 32, 34, 35, 37, 38, 43, 45, 46, 52, 55, 58, 60, 61, 65, 69, 70, 80, 81, 86, 89, 90, 97, 102, 103, 104, 105, 107, 108, 109, 111, 112, 121, 127, 130, 134], "dui": 113, "dummi": 3, "dummy_model": 107, "dummy_na": [79, 120], "dump": [34, 58], "duplic": [75, 130], "dure": [1, 6, 10, 15, 16, 19, 22, 23, 25, 26, 28, 31, 32, 39, 41, 52, 54, 55, 58, 59, 60, 66, 69, 75, 76, 82, 83, 88, 90, 91, 92, 97, 102, 104, 105, 107, 108, 113, 125, 127, 129, 130, 133, 135, 140], "duti": 39, "dvincent1337": 113, "dx": [1, 22, 23, 25, 28, 29, 31, 80, 97, 100, 114, 115, 121], "dy": [1, 58, 60, 61, 67, 100, 104, 115], "dynam": [1, 4, 5, 12, 58, 65, 102, 106, 107, 113, 114, 131, 136, 138], "dzreyev": 113, "e": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 16, 18, 20, 21, 22, 23, 26, 28, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 55, 56, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 73, 74, 76, 77, 79, 80, 81, 82, 83, 86, 87, 88, 90, 93, 96, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141], "e_": [60, 61, 67, 86, 104, 112, 121, 141], "e_greedi": 140, "e_i": 83, "e_j": 83, "e_x": 104, "ea": 58, "each": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 15, 16, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99, 101, 102, 105, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "eager": 117, "earli": [2, 34, 43, 55, 56, 58, 60, 78, 82, 107, 127], "earlier": [3, 6, 10, 20, 21, 22, 29, 32, 34, 35, 36, 41, 43, 45, 58, 61, 69, 70, 79, 84, 112, 113, 126, 133, 136], "earliest": [2, 5, 46, 58, 80, 114], "earn": [35, 58, 121, 139], "eas": [25, 34, 43, 65, 86, 92], "easi": [15, 42, 48, 49, 50, 54, 58, 60, 61, 64, 69, 72, 74, 76, 86, 98, 102, 104, 105, 110, 113, 119, 121, 130, 136, 140], "easier": [9, 19, 23, 25, 26, 27, 28, 34, 39, 44, 47, 58, 62, 65, 70, 74, 102, 104, 117, 121, 127, 136], "easiest": [15, 80], "easili": [3, 9, 18, 19, 30, 34, 39, 47, 48, 54, 58, 61, 66, 75, 80, 82, 96, 107, 108, 123, 130, 131, 132, 137, 140], "eat": [58, 83, 121, 132], "ec2": [18, 52], "eclips": 113, "econom": 58, "economi": 67, "economist": 121, "edg": [22, 34, 40, 42, 45, 46, 58, 65, 69, 70, 126, 127, 131], "edgarroman": 113, "edge_s": 29, "edgecolor": 20, "edit": 113, "editor": [58, 113], "edu": [23, 85, 86, 95], "educ": 58, "effect": [3, 6, 8, 10, 11, 22, 23, 24, 30, 32, 34, 35, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 58, 60, 64, 66, 69, 70, 74, 76, 80, 102, 103, 105, 107, 108, 110, 111, 121, 125, 130, 133, 135, 138], "efficaci": [58, 77, 83, 109, 113, 121, 126], "effici": [1, 3, 4, 6, 9, 10, 11, 18, 29, 32, 33, 34, 36, 37, 38, 39, 41, 42, 44, 46, 51, 52, 53, 54, 55, 56, 58, 62, 64, 66, 69, 71, 73, 78, 79, 81, 88, 93, 96, 97, 99, 103, 104, 105, 106, 107, 108, 112, 113, 114, 119, 120, 122, 128, 129, 130, 132, 134, 136], "effort": [52, 58, 77, 90, 94, 104], "effortlessli": [13, 58], "eigen": 113, "eigendecomposit": 102, "eigenspac": 109, "eigensystem": 109, "eigenvalu": [82, 102, 109, 110, 130], "eigenvector": [102, 109, 110, 130], "eight": [34, 77], "einstein": [87, 120], "einsum": 99, "either": [2, 3, 9, 10, 22, 32, 33, 34, 39, 41, 44, 45, 46, 48, 52, 54, 55, 57, 58, 60, 64, 67, 69, 77, 79, 80, 82, 84, 87, 90, 102, 104, 108, 120, 121, 128, 135, 136], "elabor": [119, 127], "elast": 52, "eldarkurt": 113, "electra": [5, 6], "electron": [58, 64, 77, 95], "eleg": [34, 39, 52, 58, 65, 113], "elegantli": 16, "elem": [92, 95], "element": [3, 8, 9, 19, 28, 29, 30, 33, 34, 35, 38, 39, 40, 41, 44, 45, 56, 58, 60, 64, 66, 76, 80, 82, 88, 92, 93, 97, 98, 99, 100, 105, 108, 112, 116, 117, 118, 119, 121, 122, 135, 136, 137], "elementari": [113, 117, 121], "elementwis": [3, 19, 35, 41, 59, 69, 75, 80, 88, 100, 108, 117, 119, 121, 125, 127], "elev": 44, "eleven": 90, "elicit": 6, "elid": 71, "elif": [1, 19, 23, 32, 45, 115], "elimin": [58, 85, 102], "elit": 58, "elizabeth": 113, "ell": [47, 48, 49, 140], "ell_1": [15, 32, 74, 77, 104, 117], "ell_2": [75, 76, 77, 100, 104, 112, 117], "ell_est": 47, "ell_p": [74, 100, 117], "elli": 67, "ellips": 48, "ellipsoid": 109, "elman": 127, "elmo": 90, "els": [1, 2, 3, 10, 18, 19, 21, 22, 23, 25, 26, 29, 30, 31, 32, 35, 39, 51, 55, 59, 60, 61, 62, 65, 67, 72, 73, 74, 79, 85, 86, 87, 90, 91, 96, 105, 107, 114, 115, 123, 127, 128, 132, 135, 136, 140], "elsewher": [9, 115], "elucid": 61, "elus": 102, "email": [58, 59, 64, 94, 135, 136], "eman": 71, "emb": [86, 88, 95, 99, 129, 135], "emb_dropout": 11, "embark": 2, "embed": [4, 5, 6, 9, 10, 86, 88, 89, 90, 91, 94, 95, 129, 135, 142], "embed_s": [4, 86, 88, 99, 129], "embed_u": 99, "embed_v": 99, "embedding_dim": 99, "embedding_nam": 95, "embedding_weight": 99, "embodi": 140, "embrac": [34, 46], "embs_and_context": 129, "emerg": [5, 6, 11, 42, 60, 61, 77, 82, 113, 132], "emilyong": 113, "emin": 34, "emit": [39, 43, 58, 135], "emp": [61, 67], "emphas": [6, 47, 65, 93, 112, 118], "emphasi": [6, 58], "empir": [6, 10, 11, 35, 36, 47, 58, 59, 61, 67, 69, 84, 90, 107, 110, 121, 132], "empiric": 58, "emploi": [3, 10, 34, 35, 45, 58, 60, 61, 67, 69, 71, 114, 117, 121, 128, 131, 136], "employ": [58, 77, 117], "employe": 58, "empti": [56, 58, 120, 128], "emptyset": [104, 121], "en": [4, 10, 54, 55, 95, 129], "enabl": [13, 32, 34, 35, 43, 47, 48, 58, 69, 81, 94, 106, 115, 140, 141], "enc_all_output": [124, 129], "enc_attention_weight": 10, "enc_output": [4, 10, 129], "enc_stat": 129, "enc_valid_len": [4, 10], "enc_x": 124, "encapsul": [57, 125, 127], "encod": [1, 2, 4, 5, 25, 29, 31, 43, 44, 47, 49, 64, 66, 77, 79, 83, 88, 91, 92, 94, 98, 117, 121, 122, 126, 127, 128, 132, 139, 142], "encoded_pair": 92, "encoded_pair_cl": 92, "encoded_pair_cran": 92, "encoded_text": 92, "encoded_text_cl": 92, "encoded_text_cran": 92, "encoded_x": [90, 92], "encoder_blk": [10, 11], "encoderdecod": [124, 129], "encoding_dim": 9, "encount": [4, 21, 22, 37, 39, 40, 43, 46, 50, 58, 60, 61, 64, 67, 69, 71, 73, 82, 92, 103, 104, 108, 109, 110, 111, 112, 121, 123, 126, 127, 131, 136, 137], "encourag": [58, 69, 90, 112, 113, 118, 139], "end": [2, 3, 4, 6, 7, 9, 10, 13, 14, 24, 26, 27, 29, 30, 32, 33, 34, 36, 40, 45, 46, 47, 48, 53, 54, 55, 58, 59, 60, 64, 67, 69, 70, 71, 74, 76, 77, 78, 80, 82, 83, 84, 85, 89, 91, 96, 98, 101, 102, 103, 104, 105, 107, 109, 111, 112, 113, 115, 117, 118, 119, 121, 122, 123, 125, 127, 128, 129, 130, 132, 136, 140, 141], "end_axi": [1, 11, 65, 76, 81], "end_h": 30, "end_index": 72, "end_w": 30, "endow": 67, "endur": [58, 76], "energi": [34, 64, 71], "enforc": [1, 6, 104], "eng": [1, 4, 10, 128, 129], "engag": [58, 113, 131, 136], "engin": [8, 18, 34, 41, 43, 44, 58, 60, 64, 65, 80, 83, 108, 113, 118, 135], "english": [1, 4, 6, 10, 58, 85, 90, 91, 95, 96, 98, 113, 124, 128, 129, 132], "engulf": 67, "enhanc": [5, 58, 82], "enjoi": [6, 9, 10, 43, 58, 85, 87, 109, 121], "enlarg": 32, "enorm": [5, 35, 46, 58, 121, 122], "enough": [4, 9, 15, 17, 34, 35, 41, 57, 58, 61, 62, 64, 67, 69, 77, 79, 80, 90, 102, 104, 105, 107, 108, 109, 116, 121, 132], "enrich": 72, "ensembl": [34, 64, 66], "ensemble_pr": 79, "ensur": [1, 3, 8, 10, 17, 23, 34, 35, 40, 44, 52, 54, 58, 61, 64, 66, 74, 76, 82, 85, 91, 102, 104, 105, 107, 109, 111, 115, 123, 127, 131, 135, 138, 140, 141], "ent": 58, "entail": [85, 86], "entangl": 60, "enter": [31, 34, 58, 60, 113], "entertain": 64, "enthusiast": 28, "entir": [2, 3, 5, 6, 8, 10, 15, 16, 17, 19, 22, 25, 26, 30, 34, 35, 37, 39, 45, 46, 47, 48, 49, 52, 56, 58, 60, 61, 64, 65, 67, 69, 71, 72, 73, 74, 83, 89, 90, 92, 93, 102, 105, 107, 108, 110, 113, 117, 121, 127, 129, 132, 133, 135, 136, 138], "entireti": 105, "entiti": [58, 90, 139], "entrepreneur": 113, "entri": [1, 3, 15, 41, 47, 56, 58, 59, 64, 65, 66, 69, 71, 73, 100, 102, 105, 110, 114, 117, 119, 120, 125, 129, 132, 135], "entropi": [6, 32, 43, 58, 60, 61, 63, 65, 90, 93, 100, 129, 132, 133], "entrypoint": [54, 55], "enumer": [1, 8, 10, 15, 19, 23, 25, 26, 31, 32, 36, 39, 46, 58, 69, 79, 91, 95, 99, 107, 122, 128, 137], "env": [1, 54, 55, 140], "env_desc": [1, 140, 141], "env_info": [1, 140, 141], "enviro": [1, 141], "environ": [1, 20, 54, 57, 63, 121, 138, 140, 141, 142], "environment": [60, 69], "envis": 5, "eo": [1, 4, 6, 10, 122, 128, 129], "ep": [19, 21, 35, 101, 102, 103, 111], "epanechikov": 2, "ephemer": 127, "epicent": 140, "epidemiologi": 69, "epistem": [47, 48, 121], "epoch": [1, 22, 23, 25, 26, 28, 32, 34, 41, 43, 52, 54, 55, 56, 61, 65, 66, 70, 71, 72, 76, 77, 81, 92, 99, 101, 102, 103, 105, 107, 108, 109, 111, 112, 132, 135, 136], "epsilion": 140, "epsilon": [2, 19, 35, 41, 47, 48, 52, 61, 64, 69, 73, 74, 76, 77, 101, 102, 103, 104, 105, 111, 136, 140], "epsilon_": 61, "epsilon_1": [132, 136], "epsilon_2": [132, 136], "epsilon_3": 132, "epsilon_i": 64, "equal": [1, 5, 8, 9, 16, 19, 34, 35, 44, 52, 58, 59, 60, 64, 66, 67, 69, 74, 76, 80, 87, 89, 90, 97, 99, 100, 102, 107, 108, 111, 115, 117, 119, 121, 132, 135, 136, 140, 141], "equat": [2, 48, 49, 50, 58, 64, 73, 74, 75, 80, 103, 105, 107, 109, 111, 113, 117, 121, 125, 127, 129, 136], "equi": 52, "equip": [58, 62, 127], "equiv": 141, "equival": [2, 3, 15, 32, 40, 46, 49, 64, 69, 74, 76, 77, 80, 82, 83, 85, 88, 93, 98, 104, 107, 110, 112, 115, 117, 119, 132, 133, 135, 137, 141], "equivari": 46, "er": [60, 96], "er_": 96, "erf": 49, "err": [32, 58, 79, 113], "error": [1, 11, 32, 37, 38, 39, 41, 43, 47, 48, 51, 52, 53, 54, 55, 56, 58, 61, 62, 64, 68, 69, 70, 71, 74, 75, 77, 78, 80, 90, 92, 93, 105, 107, 108, 110, 113, 114, 120, 121, 133, 136], "ervat": 60, "escap": [65, 80], "esoter": 113, "especi": [5, 16, 31, 33, 34, 49, 52, 58, 67, 70, 74, 82, 90, 93, 109, 113, 121, 127, 130, 136], "essenc": [27, 110, 142], "essenti": [10, 21, 27, 40, 45, 47, 48, 49, 58, 77, 102, 107, 108, 111, 117, 130], "est": [4, 10, 129], "establish": [34, 35, 46, 77], "estim": [2, 8, 34, 35, 37, 47, 48, 52, 56, 58, 59, 60, 61, 64, 67, 69, 70, 71, 73, 74, 76, 77, 79, 98, 101, 103, 112, 120, 121, 130, 132, 136, 137, 140, 141], "eta": [22, 55, 56, 69, 71, 74, 102, 103, 105, 107, 109, 111, 112, 135], "eta_": 107, "eta_0": [102, 107, 112], "eta_i": [102, 112], "eta_t": [107, 108, 109, 112], "etc": [1, 35, 37, 47, 48, 49, 60, 67, 69, 72, 79, 107, 113, 117, 136, 137, 138, 139], "etern": 75, "ethic": 60, "eu": 107, "euclidean": [58, 74, 117], "eugen": 58, "evad": 58, "eval": [1, 3, 10, 11, 17, 21, 23, 32, 52, 71, 86, 107, 108], "evalu": [1, 2, 3, 23, 25, 34, 36, 37, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 65, 66, 67, 69, 71, 72, 73, 74, 77, 79, 84, 85, 90, 92, 100, 105, 106, 108, 112, 114, 115, 117, 119, 122, 126, 130, 131, 132, 135, 136, 138], "evaluate_accuraci": 1, "evaluate_accuracy_gpu": [1, 23, 25, 107], "evaluate_loss": [1, 26, 108], "even": [2, 3, 4, 6, 8, 11, 13, 15, 17, 18, 19, 28, 30, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 67, 69, 71, 72, 74, 75, 77, 79, 80, 81, 82, 91, 96, 97, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 119, 121, 127, 128, 132, 133, 135, 136, 137, 138, 139, 140], "even_split": 92, "evenli": [32, 74], "event": [58, 64, 69, 89, 93, 100, 121, 131, 135, 136, 138], "eventu": [35, 43, 46, 58, 77, 105, 117, 135, 138], "ever": [3, 37, 39, 45, 49, 58, 60, 61, 65, 67, 80, 107, 110, 113, 139], "everi": [3, 5, 9, 10, 12, 18, 19, 25, 26, 27, 32, 35, 39, 40, 45, 47, 48, 51, 52, 53, 54, 55, 56, 58, 60, 61, 64, 65, 69, 70, 71, 73, 77, 80, 81, 82, 83, 86, 90, 96, 107, 109, 113, 119, 121, 124, 128, 129, 131, 134, 136, 140], "every_n": [1, 51, 72], "everydai": [58, 94, 117], "everyon": [79, 113], "everyth": [8, 18, 45, 46, 50, 58, 61, 66, 81, 113, 137], "everywher": 49, "evgenii": 113, "evid": [41, 69, 121], "evidenc": 6, "evil": 108, "evolut": 58, "evolutionari": 34, "evolv": [13, 39, 54, 61, 76, 77, 107, 121, 136, 139, 140], "ewma": 103, "ex": 73, "exact": [8, 16, 35, 47, 48, 58, 61, 69, 102, 104, 105, 119, 121], "exactli": [8, 11, 40, 45, 47, 52, 58, 60, 67, 69, 71, 74, 77, 80, 81, 102, 112, 121, 125, 139], "exam": [58, 67], "examin": [16, 83, 113], "exampl": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 56, 57, 61, 62, 63, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 142], "exce": [18, 19, 34, 58, 61, 64, 65, 79, 80, 97, 108, 135], "exceed": [34, 58], "exceedingli": [45, 105], "excel": [34, 58, 67, 105, 112, 113, 117], "except": [1, 3, 6, 10, 18, 21, 22, 32, 33, 35, 47, 51, 65, 69, 72, 73, 76, 83, 110, 125, 135, 137], "excess": [28, 34, 36, 62, 69, 82, 105, 128, 135], "exchang": [33, 39, 58, 80, 117], "excit": [6, 8, 38, 58, 64, 69, 104, 137], "exclud": [4, 6, 39, 69, 79, 91, 95, 97, 124, 128, 129], "exclus": [4, 58, 117, 121, 126], "execut": [8, 13, 16, 34, 51, 52, 54, 57, 58, 64, 67, 71, 108, 113, 114, 137], "exemplar": 113, "exercis": [5, 13, 24, 38, 42, 50, 53, 63, 68, 78, 84, 94, 106, 116, 126, 131, 138, 142], "exert": [104, 113, 135], "exhaust": [52, 58, 73, 113, 126], "exhibit": [35, 37, 46, 54, 58, 79, 80, 82, 104, 130, 136], "exist": [1, 12, 18, 23, 34, 39, 52, 58, 60, 70, 71, 73, 79, 80, 82, 90, 94, 99, 104, 106, 110, 112, 115, 123, 125], "exist_ok": [1, 25, 120], "exit": [57, 58], "exot": 79, "exp": [2, 3, 8, 19, 47, 48, 49, 60, 61, 64, 65, 66, 69, 71, 79, 80, 82, 86, 89, 93, 98, 99, 100, 104, 105, 112, 119, 129, 132, 135], "expand": [23, 56, 109, 111, 119, 121, 130], "expand_dim": [3, 4, 9, 19, 21, 29, 49, 92], "expans": [3, 36, 69, 105, 111], "expect": [1, 2, 3, 8, 15, 18, 39, 41, 43, 45, 47, 48, 58, 59, 60, 61, 64, 67, 69, 72, 73, 74, 75, 76, 79, 80, 81, 87, 93, 97, 100, 103, 104, 107, 108, 109, 110, 112, 113, 114, 116, 119, 130, 135, 136, 140, 141], "expedi": [114, 117], "expens": [3, 34, 43, 47, 52, 54, 56, 58, 60, 67, 93, 94, 102, 105, 108, 112, 113, 114, 133], "experi": [4, 6, 7, 10, 21, 22, 23, 25, 26, 27, 28, 31, 32, 34, 35, 37, 41, 43, 45, 51, 54, 55, 58, 62, 66, 67, 70, 71, 72, 74, 76, 85, 90, 92, 97, 102, 105, 106, 107, 108, 111, 112, 115, 121, 125, 127, 129, 130, 135, 136, 137, 138, 140], "experienc": [58, 64], "experiment": [34, 37, 38, 42, 43, 44, 58, 103, 109, 111], "expert": [6, 52, 83, 113, 138], "explain": [6, 8, 9, 10, 21, 23, 24, 28, 32, 33, 41, 47, 58, 60, 61, 64, 67, 72, 77, 83, 84, 90, 93, 104, 105, 107, 112, 113, 121, 122, 124, 126, 128, 129, 130, 133], "explan": [9, 35, 47, 64, 72, 113, 126], "explicit": [1, 8, 58, 103, 125, 127], "explicitli": [37, 47, 58, 67, 69, 70, 73, 80, 90, 107, 109, 130], "explod": [52, 78, 126, 127, 130, 135], "exploit": [15, 46, 51, 53, 54, 56, 58, 60, 62, 66, 108, 110, 112, 113, 114], "explor": [35, 37, 38, 41, 44, 47, 52, 58, 62, 64, 67, 76, 80, 82, 84, 96, 106, 109, 114, 118, 126, 131, 138, 139], "exploratori": 131, "explos": [58, 70, 130], "expon": [82, 107, 137], "exponenti": [2, 3, 8, 34, 64, 65, 66, 69, 79, 100, 103, 104, 109, 112, 117, 119, 122, 132, 133], "exponential_lr": 112, "expos": 60, "exposit": [8, 75, 113, 131], "expositori": 109, "express": [7, 16, 28, 30, 35, 39, 40, 41, 45, 46, 48, 49, 58, 59, 61, 64, 67, 69, 70, 74, 77, 80, 82, 93, 98, 104, 109, 115, 117, 119, 121, 122, 123, 129, 130, 133, 140], "ext": 1, "extend": [6, 11, 25, 26, 44, 52, 58, 61, 64, 65, 68, 72, 81, 91, 96, 113, 136], "extens": [2, 6, 25, 36, 39, 44, 49, 51, 74, 94, 105, 117, 129, 132], "extent": [5, 36, 37, 58, 60, 125, 136], "extra": [1, 12, 44, 55, 83, 109, 124], "extract": [1, 11, 16, 21, 22, 24, 26, 30, 31, 32, 34, 35, 37, 73, 79, 85, 87, 88, 94, 96, 120, 128, 136], "extract_featur": 28, "extract_text": 85, "extractal": 1, "extractor": [34, 58], "extraordinari": [46, 50, 67], "extrapol": 136, "extravag": 18, "extrem": [47, 58, 60, 64, 65, 67, 69, 77, 95, 108, 121, 125, 136], "exuperi": 132, "ey": [8, 31, 34, 47], "f": [1, 2, 4, 7, 9, 10, 15, 21, 22, 23, 25, 26, 29, 31, 32, 33, 36, 39, 41, 46, 47, 48, 49, 51, 52, 56, 60, 61, 62, 67, 69, 70, 71, 74, 75, 79, 80, 85, 86, 87, 90, 91, 92, 93, 95, 96, 97, 99, 100, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 127, 128, 129, 130, 133, 135, 136, 137, 140, 141], "f_": [47, 60, 61, 115], "f_1": [36, 61, 82], "f_2": [36, 61], "f_2d": [102, 105, 109, 111], "f_2d_grad": 105, "f_3": 36, "f_a": 86, "f_b": 86, "f_back": 1, "f_grad": [105, 112], "f_hess": 105, "f_i": [112, 115], "f_k": 61, "f_l": 82, "f_line": 105, "f_t": 60, "fa": 96, "fa19780a7b011d9b009e8bff8e99922a8ee2eb90": 79, "fabric": 58, "face": [10, 52, 58, 60, 61, 65, 67, 82, 87, 102, 109, 115, 117, 120, 126, 127, 131], "facebook": [58, 60], "facecolor": 19, "facil": 54, "facilit": [10, 25, 61, 72, 79, 91, 108, 113], "fact": [2, 6, 8, 12, 19, 22, 23, 26, 32, 34, 35, 36, 37, 38, 39, 43, 45, 46, 47, 49, 58, 61, 64, 65, 67, 69, 71, 72, 73, 74, 77, 79, 80, 82, 84, 85, 89, 90, 101, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 121, 122, 130, 132, 136], "facto": [6, 73], "factoid": 58, "factor": [5, 6, 12, 18, 21, 23, 35, 39, 40, 43, 47, 58, 60, 61, 64, 69, 70, 77, 108, 113, 117, 129, 130, 136, 138, 140, 141], "factori": 15, "factorschedul": 107, "fade": 61, "fahrenheit": 117, "fail": [1, 4, 18, 35, 58, 60, 65, 67, 77, 80, 102, 103, 109, 112, 121, 135, 136], "failur": [58, 60], "fair": [58, 63, 109, 121], "fair_prob": 121, "fairi": 58, "fairli": [2, 34, 39, 55, 58, 69, 72, 79, 101, 103, 105, 107, 121, 130, 132], "faith": 34, "fake": 58, "fakoor": 138, "falcon": 6, "fall": [60, 61, 85, 110, 121], "fals": [1, 2, 3, 7, 8, 10, 11, 20, 21, 22, 23, 25, 26, 29, 31, 33, 39, 41, 59, 61, 62, 72, 79, 85, 86, 87, 90, 91, 92, 107, 119, 120, 121, 128, 129, 135, 140], "falsifi": 67, "falter": 58, "famili": [8, 42, 46, 58, 62, 64], "familiar": [12, 17, 28, 29, 49, 65, 72, 77, 117, 130, 136], "famou": [58, 77, 79, 85, 87, 121], "fan": 58, "fanci": 60, "fancier": [46, 68, 79], "fangkeqiu": [28, 54, 55], "far": [2, 6, 8, 13, 17, 25, 33, 34, 37, 39, 40, 42, 43, 44, 46, 47, 48, 51, 52, 54, 58, 60, 61, 66, 67, 69, 70, 74, 75, 77, 78, 82, 101, 105, 107, 108, 109, 112, 113, 114, 115, 117, 120, 121, 122, 130, 132, 133, 135, 136, 139], "fare": [43, 61], "farm": 58, "farmer": 58, "fascin": 77, "fashion": [1, 11, 22, 23, 29, 34, 35, 37, 39, 43, 52, 60, 62, 65, 66, 76, 77, 80, 81, 90, 93, 102, 107, 111, 114, 131, 136], "fashionmnist": [11, 34, 35, 36, 37, 39, 43, 51, 52, 54, 55, 62, 65, 66, 76, 81], "fast": [13, 18, 24, 32, 34, 40, 41, 60, 62, 69, 77, 96, 108, 112, 119], "fast_": 96, "faster": [3, 24, 34, 35, 39, 40, 54, 55, 69, 70, 74, 95, 105, 108, 125, 127, 134], "faster_": 96, "fasttext": [94, 95], "fatal": [58, 105], "father": 64, "fatter_": 96, "faulti": 120, "fauna": 58, "favor": [9, 64, 108], "favorit": 34, "favour": 55, "fba480ffa8aa7e0febbb511d181409f899b9baa5": 22, "fc": [21, 22], "fcn": 21, "fear": 58, "feasibl": [10, 34, 39, 52, 84, 105, 109], "feat": [1, 58, 113], "featur": [1, 2, 3, 4, 9, 10, 15, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 48, 54, 58, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 77, 79, 80, 81, 88, 90, 98, 99, 103, 106, 113, 119, 121, 125, 126, 129, 131, 133, 135, 136, 140], "feature_dim": [101, 102, 103, 108, 109, 111], "feature_list": 28, "features_dim": 109, "fed": [3, 5, 6, 7, 10, 11, 26, 58, 69, 72, 82, 83, 84, 90, 94, 108, 129, 133, 135], "feder": 120, "feed": [5, 6, 9, 11, 12, 33, 34, 42, 43, 51, 58, 79, 80, 86, 88, 90, 117, 119, 120, 127, 129, 133, 135], "feedback": [6, 58, 60, 113], "feedforward": [130, 131], "feel": [47, 48, 51, 54, 58, 61], "feet": [5, 58, 64, 69], "felin": 132, "femal": 95, "fetch": [57, 129], "few": [1, 3, 4, 5, 6, 10, 15, 20, 21, 26, 34, 38, 39, 44, 46, 47, 48, 49, 50, 52, 55, 56, 57, 58, 60, 62, 65, 67, 68, 69, 72, 74, 76, 80, 81, 84, 104, 105, 107, 112, 113, 115, 116, 117, 119, 129, 130, 131, 132, 136, 137, 139, 140], "fewer": [6, 27, 29, 32, 42, 43, 46, 47, 48, 56, 61, 64, 65, 67, 70, 77, 86, 90, 128, 132, 140], "fewest": 25, "ff7f0e": 105, "ffn": [10, 11], "ffn_num_hidden": [10, 90, 92], "ffn_num_input": [10, 90, 92], "ffn_num_output": 10, "fiction": 58, "fidel": [6, 53, 103, 142], "field": [9, 11, 20, 24, 27, 29, 31, 32, 34, 38, 42, 45, 52, 58, 69, 80, 87, 113, 120, 121, 128, 136], "fiet": 113, "fifth": [32, 34, 37, 61], "fig": [1, 2, 8, 19, 20, 32, 72], "fig_nlp": 88, "figsiz": [1, 2, 8, 9, 10, 28, 69, 72, 80, 82, 104, 115, 136], "figur": [1, 6, 30, 39, 41, 46, 48, 49, 55, 58, 61, 69, 72, 110, 112, 113, 115, 137], "figure1": [58, 113], "figure10": [4, 122, 123, 124, 125, 127, 128, 129], "figure11": [3, 4, 6, 7, 8, 9, 10, 11], "figure12": 104, "figure13": [19, 21, 22, 25, 26, 28, 30, 31, 32, 33], "figure14": [89, 90, 94, 98], "figure15": [83, 84, 86, 88], "figure16": 139, "figure18": [54, 55, 56], "figure2": 115, "figure3": [67, 69, 70, 77], "figure4": [60, 64, 80], "figure5": [75, 76, 79, 80], "figure6": [15, 18], "figure7": [40, 41, 43, 44, 45, 46], "figure8": [34, 36, 37, 39], "figure9": [130, 131, 132, 133, 136], "file": [1, 13, 22, 25, 26, 29, 31, 57, 58, 73, 79, 87, 95, 97, 120, 142], "file_nam": [85, 91], "filenam": [1, 25, 79], "filepath": [1, 79], "files_and_class": 25, "filevich": 113, "fill": [10, 20, 44, 48, 56, 58, 60, 87, 113, 136], "fill_between": [47, 49], "filler": 44, "fillna": [10, 79, 120], "film": 87, "filt": 21, "filter": [19, 24, 28, 31, 32, 34, 35, 37, 41, 46, 52, 54, 55, 58, 60, 73, 87, 91, 102, 107, 129, 137], "final": [3, 4, 7, 10, 11, 15, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 43, 44, 45, 47, 51, 56, 58, 60, 61, 64, 66, 67, 69, 71, 72, 74, 75, 79, 80, 81, 86, 88, 90, 92, 104, 108, 110, 112, 113, 114, 119, 120, 121, 122, 123, 125, 128, 129, 130, 131, 135, 138], "final_conv": 21, "final_lr": 107, "finamor": 113, "financ": 87, "financi": [58, 121, 136], "find": [15, 16, 18, 19, 20, 21, 25, 26, 31, 39, 41, 44, 46, 47, 48, 49, 51, 52, 56, 58, 60, 61, 62, 65, 67, 69, 71, 72, 74, 77, 79, 80, 82, 95, 99, 101, 102, 105, 107, 110, 113, 115, 116, 121, 122, 130, 132, 136, 137, 138, 139, 140, 141], "fine": [3, 5, 23, 24, 31, 48, 58, 60, 74, 84, 90, 92, 113, 115, 121, 142], "finetune_net": [22, 26], "finish": [54, 55, 56], "finit": [41, 49, 60, 61, 64, 67, 69, 70, 77, 104, 106, 110, 121], "finnish": 96, "fiocco": 113, "fire": [58, 80, 82], "firm": [58, 78], "firmli": 58, "first": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 99, 102, 103, 104, 105, 107, 108, 110, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141], "first_block": [1, 39], "first_train_sampl": 22, "fisher": 58, "fit": [4, 6, 10, 11, 19, 31, 34, 35, 36, 37, 39, 41, 42, 43, 46, 47, 48, 49, 51, 52, 54, 55, 58, 60, 61, 65, 66, 69, 70, 71, 72, 74, 76, 77, 79, 81, 91, 93, 107, 108, 113, 115, 123, 125, 127, 129, 131, 132, 134, 135, 136], "fit_epoch": [54, 55, 70, 71, 72, 135], "fittingli": 39, "five": [19, 27, 30, 31, 32, 34, 37, 58, 67, 76, 80, 91, 122, 132, 135], "fix": [4, 5, 8, 9, 10, 15, 31, 35, 40, 43, 45, 48, 49, 52, 55, 56, 58, 60, 61, 65, 66, 67, 69, 71, 76, 80, 81, 82, 87, 88, 96, 98, 102, 103, 105, 107, 111, 117, 124, 126, 127, 129, 131, 132, 136, 141], "fixed_crop": [21, 31], "fixedhiddenmlp": 15, "flag": 23, "flamingo": 6, "flat": [6, 43, 81, 109], "flat_param": 17, "flatten": [1, 11, 32, 34, 35, 36, 37, 39, 42, 43, 65, 66, 75, 76, 81, 86, 90, 107, 137], "flatten_pr": 32, "flatter": 105, "flavor": [123, 128], "flaw": [58, 105], "flax": 113, "flexibl": [12, 13, 15, 35, 39, 40, 47, 49, 51, 58, 61, 122, 127, 136], "flexibli": 130, "flickr": 67, "flight": 64, "flip": [25, 34, 41, 46, 58, 60, 110, 117, 121, 127], "float": [1, 9, 12, 19, 23, 26, 28, 29, 30, 31, 32, 34, 40, 51, 52, 54, 55, 56, 58, 64, 65, 74, 79, 92, 95, 99, 105, 107, 108, 119, 120, 121], "float32": [1, 2, 3, 9, 10, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 35, 40, 41, 44, 45, 59, 62, 66, 70, 71, 73, 76, 79, 82, 86, 88, 91, 92, 99, 105, 108, 114, 117, 118, 119, 120, 121, 129, 133, 135, 136], "floor": [1, 25], "flop": 34, "florian": 113, "flow": [15, 18, 34, 39, 43, 58, 60, 69, 75, 80, 116, 125, 127], "fluctuat": 69, "fluenci": 116, "flush": 127, "flux": 37, "fly": [46, 60, 73, 90, 92], "flygar": 113, "fmap": 27, "fmap_h": 27, "fmap_w": 27, "fmt": [1, 105, 115], "fn": 70, "fname": [1, 25, 31, 137], "focal": [32, 35], "focal_loss": 32, "focu": [5, 8, 10, 11, 15, 20, 24, 30, 32, 39, 46, 48, 50, 52, 58, 61, 62, 64, 68, 69, 70, 74, 75, 81, 84, 94, 110, 112, 113, 114, 115, 117, 128, 131, 132, 136], "focus": [5, 6, 15, 16, 31, 58, 61, 79, 80, 84, 94, 107, 113, 117, 123, 130, 131, 136], "fold": [40, 56, 67, 77, 78], "fold_siz": 79, "folder": [1, 22, 25, 26, 64, 79], "folder_nam": 87, "folk": 77, "follow": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 84, 85, 86, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 112, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141], "font": 117, "fontsiz": [1, 19, 47, 49], "fontweight": 1, "food": 22, "fool": 58, "foot": 58, "footag": 58, "footprint": [34, 40, 75, 117, 120], "footwear": 60, "forc": [37, 38, 58, 60, 103, 104, 108, 109, 125, 126, 135], "force_reinit": [99, 107], "forecast": [48, 60, 69, 136], "foreign": 58, "foremost": 104, "forese": [60, 122], "forest": 60, "forev": 127, "forget": [60, 70, 103, 115, 116], "forgo": [43, 61], "forgotten": [58, 113], "form": [1, 2, 8, 15, 25, 29, 35, 38, 39, 43, 46, 47, 48, 49, 52, 58, 60, 63, 67, 69, 71, 76, 80, 83, 85, 88, 93, 95, 96, 97, 102, 103, 104, 105, 107, 109, 113, 114, 117, 119, 121, 124, 126, 127, 130, 132, 135, 136, 137, 138, 139], "formal": [7, 46, 56, 58, 60, 67, 69, 76, 80, 90, 102, 104, 113, 115, 116, 117, 122, 123, 130, 135], "format": [1, 18, 19, 20, 21, 23, 25, 28, 31, 32, 33, 34, 41, 47, 64, 65, 91, 96, 97, 100, 115, 116, 128], "former": [6, 10, 19, 30, 35, 36, 43, 73, 90, 92, 103, 110, 115], "formid": [58, 61, 62, 69, 113], "formul": [6, 46, 49, 58, 59, 60, 69, 113, 121, 128, 139, 141], "formula": [1, 67, 69, 105, 132], "fortran": 80, "fortuit": 70, "fortun": [15, 34, 47, 48, 49, 58, 60, 61, 64, 65, 69, 71, 81, 89, 105, 110, 114, 115, 117, 119, 120, 126], "forum": [59, 79, 87], "forward": [1, 5, 11, 12, 13, 16, 21, 27, 28, 30, 32, 33, 34, 36, 39, 40, 41, 45, 51, 52, 54, 62, 65, 66, 70, 71, 72, 76, 78, 81, 82, 90, 92, 107, 114, 115, 123, 124, 125, 127, 130, 135, 136, 139, 142], "foster": 79, "fou": 135, "found": [1, 6, 34, 41, 47, 51, 54, 55, 57, 58, 67, 70, 77, 80, 107, 112, 113, 141], "foundat": [5, 50, 58, 61, 113, 121, 141], "four": [4, 8, 9, 19, 21, 22, 23, 29, 30, 32, 33, 34, 36, 37, 39, 41, 43, 45, 46, 55, 58, 61, 64, 79, 80, 108, 117, 122, 132, 135, 136, 139, 141], "fourier": [12, 49, 50, 64], "fourth": [28, 32, 37, 46], "fp": 1, "fp16": 65, "fp32": [34, 65], "fp64": 65, "fr": [4, 10, 129], "fra": [1, 4, 10, 128, 129], "frac": [2, 3, 8, 9, 14, 19, 34, 35, 36, 37, 41, 44, 47, 48, 49, 55, 56, 60, 61, 64, 65, 66, 67, 69, 70, 71, 74, 75, 76, 79, 80, 82, 86, 89, 93, 97, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 111, 112, 114, 115, 117, 121, 122, 129, 130, 132, 135, 137, 140], "fraction": [33, 45, 56, 58, 59, 60, 61, 76, 120, 121], "fragment": [72, 132], "frame": [1, 30, 52, 58, 61], "framework": [3, 8, 12, 14, 16, 17, 18, 23, 25, 26, 34, 35, 36, 37, 43, 45, 50, 51, 58, 59, 62, 64, 65, 66, 70, 71, 73, 74, 75, 80, 81, 82, 107, 108, 113, 114, 119, 123, 134, 135], "franc": 58, "francesco": 113, "francisco": [58, 132], "fraud": 58, "free": [29, 47, 48, 51, 54, 55, 56, 58, 61, 70, 77, 101, 102, 109, 111, 121], "freedom": [35, 114], "freeli": [58, 113], "freez": [26, 28, 67, 88, 90], "french": [1, 4, 5, 6, 10, 58, 96, 124, 128, 129], "freq": [96, 137], "frequenc": [1, 9, 28, 34, 61, 96, 97, 121, 136, 137], "frequent": [35, 44, 52, 57, 58, 60, 69, 72, 80, 82, 93, 96, 102, 108, 113, 132, 136, 137], "frequentist": 121, "fresh": [61, 67], "fri": 64, "friedrich": 58, "friend": 58, "frisbe": 34, "frivol": 58, "frobeniu": [18, 74, 75, 117], "frog": 25, "from": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 45, 48, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 75, 78, 79, 82, 83, 85, 86, 87, 88, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142], "from_logit": 107, "fromarrai": 28, "front": [31, 77], "frozen": [6, 90, 140, 141], "frozen_lak": 1, "frozenlak": [1, 140, 141], "frugal": 39, "fruit": 77, "frustrat": [58, 61], "ftse": 136, "fulfil": 58, "full": [9, 19, 25, 26, 35, 37, 39, 42, 47, 54, 55, 56, 58, 69, 71, 72, 105, 108, 110, 111, 112, 113, 114, 136, 138, 140], "fulli": [4, 6, 7, 10, 11, 12, 13, 15, 16, 22, 24, 26, 30, 32, 34, 36, 37, 39, 40, 41, 42, 43, 47, 58, 60, 64, 65, 69, 70, 71, 72, 76, 77, 78, 80, 81, 82, 83, 88, 90, 113, 123, 125, 127, 129, 133, 134, 135, 142], "fuma": 113, "fumag": 113, "fun": 132, "func": [47, 104], "function": [0, 2, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 53, 56, 57, 59, 60, 61, 62, 63, 65, 66, 67, 68, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 105, 106, 107, 108, 110, 111, 112, 113, 115, 116, 117, 119, 121, 123, 125, 126, 127, 130, 133, 134, 135, 136, 138, 139, 140, 142], "functiontyp": 113, "functool": 113, "fund": 22, "fundament": [47, 58, 60, 61, 64, 66, 67, 74, 79, 80, 82, 110, 113, 117, 121, 131, 135, 138, 140], "funk": 75, "further": [3, 4, 6, 11, 16, 21, 22, 25, 26, 27, 30, 32, 34, 35, 37, 39, 44, 48, 49, 54, 55, 58, 61, 64, 67, 77, 80, 81, 82, 83, 88, 90, 93, 107, 109, 114, 120, 121, 124, 129, 130, 135, 136, 137, 140], "furthermor": [5, 34, 36, 41, 52, 58, 79, 82, 103, 104, 105, 107, 109, 110, 113, 117, 121, 128, 129, 132, 137], "fuse": 108, "fuss": 49, "futur": [6, 16, 24, 35, 47, 58, 59, 60, 72, 101, 113, 121, 126, 136, 138, 139, 140], "g": [1, 3, 4, 5, 6, 7, 8, 11, 16, 18, 19, 20, 22, 23, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 52, 55, 56, 58, 60, 64, 67, 69, 71, 74, 75, 77, 79, 80, 82, 83, 86, 87, 88, 90, 93, 96, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 124, 125, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141], "g1": [102, 105, 111, 112], "g2": [102, 105, 111, 112], "g4dn": 52, "g_i": 115, "ga": [64, 93], "gab": 113, "gadget": 58, "gain": [16, 34, 37, 49, 55, 72, 77, 79, 80, 121, 125, 134, 135, 136], "galactica": 6, "gallop": 58, "game": [11, 34, 46, 58, 60, 77, 113, 139, 140], "gamma": [32, 35, 82, 107, 111, 139, 140, 141], "gamma1": 111, "gammon": 58, "gaosheng": 113, "gap": [5, 39, 61, 67, 76, 77, 107], "garbag": 58, "gardner": 113, "garg": 113, "garri": 58, "garter": 58, "gate": [39, 113, 123, 126, 142], "gather": 64, "gato": 6, "gaurav": 113, "gauss": [58, 69], "gaussian": [2, 3, 11, 14, 43, 52, 58, 66, 69, 74, 76, 80, 82, 90, 117, 119, 121, 125, 127, 142], "gaussian_with_width": 2, "gave": [58, 60], "gb": [6, 31, 58, 108], "gca": [1, 108, 110, 115, 121], "gd": [105, 108], "gd_2d": [105, 109], "gd_re": 108, "gducharm": 113, "ge": 113, "gear": 113, "geforc": 34, "gelu": [11, 80, 90], "gem": 113, "gen_img": 28, "gender": 58, "gene": 76, "gener": [1, 3, 4, 5, 6, 8, 10, 11, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 37, 38, 39, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 60, 62, 63, 64, 66, 68, 69, 70, 71, 72, 74, 76, 78, 79, 80, 83, 84, 89, 90, 92, 93, 94, 97, 98, 100, 102, 104, 107, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142], "generalist": 6, "generaliz": 67, "genet": [37, 58], "genfromtxt": 108, "geni": 108, "genom": 58, "gentl": [102, 117], "gentli": 107, "genuin": 121, "geoff": 34, "geograph": [58, 60], "geographi": 60, "geogunow": 113, "geometr": [109, 132], "geometri": [34, 58, 117], "georg": [71, 113], "geq": [8, 19, 61, 64, 104, 112, 121, 130], "geriatr": 64, "german": [58, 127], "gerschgorin": 102, "gerson": 113, "get": [0, 1, 2, 13, 16, 17, 18, 19, 23, 25, 26, 28, 30, 33, 35, 36, 39, 40, 42, 43, 45, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58, 60, 61, 64, 65, 66, 67, 68, 69, 70, 73, 75, 77, 79, 80, 81, 82, 83, 85, 86, 87, 90, 91, 93, 95, 96, 101, 102, 104, 105, 109, 110, 112, 113, 114, 116, 117, 118, 120, 121, 122, 123, 130, 131, 132, 135, 136, 137, 139, 141], "get_analogi": 95, "get_bert_encod": 92, "get_blk": 32, "get_centers_and_context": 97, "get_cont": 28, "get_data_ch11": [101, 102, 103, 108, 109, 111], "get_dataload": [51, 62, 72, 73, 74, 79, 128, 132, 136], "get_dataloader_work": [23, 31, 85, 91, 97], "get_dummi": [79, 120], "get_fashion_mnist_label": 1, "get_init": 28, "get_last_lr": 107, "get_lr": 107, "get_max_freq_pair": 96, "get_neg": 97, "get_net": [25, 26], "get_num_batch": [1, 86, 88, 107, 108], "get_param": 31, "get_similar_token": [95, 99], "get_styl": 28, "get_tensor": 79, "get_tensorload": [73, 74, 79, 128, 132, 136], "get_tokens_and_seg": [90, 91, 92], "get_top_n_configur": 56, "get_w_b": 70, "get_warmup_lr": 107, "get_xaxi": 1, "get_yaxi": 1, "getargvalu": 1, "getattr": 32, "getti": 60, "gf": 58, "ghejc": 113, "gholampoor": 113, "ghrzuzudu": 60, "gianni": 113, "giant": [13, 58, 135], "gibb": 64, "giel": 113, "gigaflop": 108, "gij": 113, "girl": [95, 96], "girlfriend": 96, "give": [4, 9, 13, 15, 16, 19, 33, 37, 41, 43, 44, 46, 47, 48, 49, 52, 58, 60, 61, 64, 65, 67, 74, 78, 79, 80, 81, 82, 88, 90, 107, 108, 112, 113, 115, 117, 119, 120, 121, 122, 127, 130, 136, 137, 140, 141], "given": [1, 2, 3, 5, 6, 7, 8, 9, 14, 19, 21, 27, 28, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 50, 51, 52, 58, 59, 60, 61, 64, 66, 67, 69, 71, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 88, 89, 90, 92, 93, 94, 95, 98, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 130, 132, 133, 134, 135, 136, 139, 140, 141], "gkutiel": 113, "glad": 70, "glanc": [9, 136], "glean": 46, "glob": 25, "global": [1, 2, 6, 11, 18, 21, 22, 28, 32, 36, 37, 39, 45, 52, 69, 88, 94, 105, 110, 112, 142], "globalp": 60, "glorot_uniform": [1, 14, 22, 23, 43, 129], "gloss": 82, "glove": [86, 88, 90, 94, 95, 96, 142], "glove_6b50d": 95, "glove_embed": [86, 88], "gluon": [19, 21, 22, 23, 26, 29, 31, 33, 58, 85, 91, 92, 97, 99, 102, 103, 107, 108, 109, 113], "gluoncv": 107, "gmail": 59, "gnaw": 61, "go": [4, 10, 15, 17, 26, 29, 34, 37, 40, 43, 44, 45, 46, 48, 58, 60, 61, 64, 66, 67, 69, 70, 72, 75, 77, 80, 81, 82, 94, 95, 99, 102, 103, 105, 107, 108, 110, 112, 113, 117, 121, 123, 128, 129, 130, 135, 136, 137, 138, 139, 141], "goal": [16, 32, 45, 46, 51, 52, 54, 58, 61, 64, 67, 69, 71, 77, 83, 105, 106, 112, 113, 115, 122, 131, 132, 136, 139, 140, 141], "god": 60, "goe": [58, 61, 107, 121, 136], "goetz": 113, "gold": 61, "goldilock": 82, "gone": 3, "good": [2, 8, 10, 16, 34, 39, 43, 46, 47, 49, 53, 54, 58, 60, 61, 62, 65, 66, 67, 69, 70, 71, 73, 76, 79, 80, 86, 93, 98, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 121, 123, 128, 132, 135, 136, 140, 141], "goodread": 58, "googl": [1, 34, 58], "googlenet": [38, 39, 142], "gopalakrishna": 113, "gopher": 6, "gordon": 50, "gorgeou": 95, "got": [1, 58, 105, 110, 128], "gotten": [82, 114, 117, 121], "govern": [12, 35, 47, 58, 69, 109, 121, 127], "gp": [48, 49, 50], "gpgpu": 34, "gpt": [5, 90, 96], "gpu": [1, 3, 5, 13, 26, 34, 36, 39, 42, 43, 46, 51, 54, 55, 57, 58, 62, 64, 71, 72, 75, 77, 81, 103, 108, 119, 142], "gpyotrch": 47, "gpytorch": 50, "grab": [5, 58, 71, 73], "grace": 58, "grace_period": 55, "gracefulli": 58, "grad": [1, 16, 23, 28, 32, 41, 71, 72, 80, 82, 92, 99, 101, 102, 103, 107, 108, 109, 111, 113, 114, 135], "grad_clip": 1, "grad_clip_v": 135, "grad_leav": 135, "grad_relu": 80, "grad_req": 22, "grad_sigmoid": [80, 82], "grad_tanh": 80, "grade": [58, 71], "gradient": [1, 2, 3, 6, 8, 15, 16, 23, 26, 34, 41, 43, 52, 58, 59, 63, 64, 70, 71, 74, 75, 76, 77, 78, 80, 81, 89, 93, 98, 100, 101, 102, 103, 104, 106, 107, 109, 111, 113, 116, 126, 127, 131, 133, 140, 142], "gradient_clip_v": [4, 10, 18, 71, 72, 123, 125, 127, 129, 134, 135], "gradual": [45, 58, 60, 98, 105], "graduat": [34, 113], "grai": 47, "grain": [3, 31, 48, 74], "gram": [9, 28, 85, 88, 89, 94, 96, 97, 129, 133, 137], "gram_i": 28, "grammat": [83, 128, 132], "grander": 67, "grandma": 132, "grant": [37, 58, 60, 71, 82, 108, 115], "graph": [5, 36, 39, 42, 52, 58, 78, 108, 110, 114, 115, 121, 130, 142], "graphic": [18, 34, 58, 115, 127], "grappl": 60, "grasp": [78, 113], "grass": 34, "gravit": 120, "graviti": 104, "graviton": 34, "grayscal": [62, 64, 81], "graytown": 113, "greadi": 140, "great": [2, 13, 18, 34, 49, 50, 58, 64, 79, 82, 87, 88, 90, 91, 104, 109, 110, 113, 127, 131, 132, 136], "greater": [1, 15, 19, 22, 28, 34, 40, 41, 43, 44, 47, 48, 58, 61, 64, 67, 69, 76, 77, 80, 82, 97, 98, 112, 113, 121, 122, 129], "greatli": [43, 47, 58, 72], "greec": 115, "greedi": [19, 96, 126, 140], "greedili": 122, "greek": 101, "green": [22, 40, 46, 58, 62, 117, 139], "greenawald": 113, "gregori": 113, "grei": 54, "grew": [5, 58], "grid": [1, 19, 30, 42, 46, 52, 58, 81, 115, 131, 140, 141], "gridwold": 139, "gridworld": 139, "gritti": [16, 42], "groceri": 69, "grossartig": 58, "grossli": [46, 61], "ground": [21, 27, 29, 30, 32, 47, 48, 58, 59, 60, 71, 73, 83, 85, 90, 117, 129, 138], "ground_truth": 19, "groundbreak": 58, "groundwork": 113, "group": [15, 17, 21, 26, 34, 35, 37, 39, 42, 58, 113, 121], "grow": [15, 16, 34, 46, 47, 48, 55, 58, 60, 61, 67, 70, 72, 74, 77, 79, 102, 104, 108, 111, 112, 113, 114, 117, 121, 129, 133, 140], "growth": [7, 18, 36, 58], "growth_rat": 36, "gru": [4, 123, 126, 127, 129, 142], "gruscratch": [123, 125], "gtx": 34, "guarante": [31, 35, 39, 47, 58, 60, 61, 64, 67, 77, 102, 105, 107, 110, 112, 121, 122], "guard": 83, "guess": [35, 47, 58, 61, 67, 79, 102, 104, 118, 121, 136], "guid": [35, 46, 52, 64, 79, 136, 142], "guidanc": [61, 77, 113, 121], "guilherm": 113, "gumbel": 118, "gunk": 58, "guowei": 113, "gupta": 113, "gurgul": 113, "gutenberg": 132, "gym": [1, 140, 141], "gymlibrari": 1, "gz": [1, 23, 87, 88, 107], "h": [1, 3, 4, 7, 11, 19, 20, 21, 27, 28, 30, 32, 33, 35, 40, 41, 44, 45, 46, 49, 52, 60, 62, 64, 71, 75, 76, 80, 81, 82, 86, 93, 96, 100, 104, 105, 109, 115, 119, 121, 123, 125, 127, 129, 130, 133, 134, 135, 137, 140, 141], "h1": 76, "h2": 76, "h_": [130, 133, 136], "h_1": [7, 30, 76], "h_2": [30, 76], "h_5": 76, "h_a": 19, "h_b": 19, "h_c": 127, "h_h": 7, "h_i": 49, "h_in": 1, "h_k": 89, "h_out": 1, "h_t": [130, 133, 136], "h_tild": 125, "ha": [1, 3, 4, 5, 6, 8, 9, 10, 11, 15, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 52, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 72, 73, 76, 77, 79, 80, 82, 83, 85, 87, 88, 89, 90, 92, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 139, 140, 141], "haben": 58, "habit": 58, "hack": [102, 126, 135], "had": [5, 6, 18, 34, 37, 39, 43, 44, 48, 58, 60, 62, 64, 72, 75, 82, 109, 113, 121, 127, 128, 135, 136, 137], "hadamard": [100, 117, 125, 127], "haibin": 113, "hairi": [61, 120], "half": [2, 12, 19, 27, 32, 34, 44, 90, 101, 104, 111, 114], "halv": [32, 36, 39, 43, 44, 53, 64, 107, 108, 109, 142], "hammer": 64, "hamper": 35, "han": 113, "hand": [2, 19, 34, 37, 39, 47, 48, 52, 55, 56, 58, 60, 61, 67, 69, 75, 77, 79, 80, 83, 86, 90, 91, 93, 100, 102, 105, 106, 108, 112, 113, 114, 115, 117, 119, 121, 122, 138], "handi": [3, 8, 39, 65, 71, 115, 117, 121, 132], "handili": 67, "handl": [1, 12, 15, 19, 43, 44, 46, 58, 68, 72, 79, 80, 90, 104, 120, 124, 127, 129, 130, 131, 136, 140], "handwrit": [126, 131], "handwritten": [4, 43, 58, 62], "hang": [117, 131], "hansent": 113, "haozhu233": 113, "happen": [2, 15, 34, 35, 39, 40, 41, 43, 46, 47, 48, 49, 58, 60, 61, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 79, 82, 101, 103, 105, 107, 108, 109, 110, 111, 113, 114, 115, 117, 119, 120, 121, 125, 133, 135, 136, 139, 140, 141], "happi": [17, 121, 131, 136], "happili": 113, "har": 18, "hard": [11, 25, 52, 58, 59, 61, 64, 69, 77, 80, 86, 90, 91, 110, 112, 122, 132, 135], "harder": 60, "hardli": [34, 44, 45, 64, 82, 131], "hardwar": [11, 13, 41, 58, 72, 81, 113], "harm": 58, "harmless": [60, 76], "harmon": 50, "harrison": 79, "harvest": 58, "has_one_axi": 115, "hasattr": [1, 23, 72, 115, 137], "hash": 23, "hashlib": [1, 113], "hasllllllllllllllllllll": 134, "hat": [2, 35, 47, 60, 61, 64, 65, 66, 67, 69, 70, 79, 86, 103, 132, 136, 140], "have": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 90, 93, 96, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "hazard": 118, "hazi": 5, "hc": [71, 127], "he": [4, 10, 58, 64, 76, 86, 92, 113, 129], "head": [5, 6, 9, 10, 11, 37, 38, 58, 92, 121, 142], "head_length": 1, "head_width": 1, "header": [25, 95], "headlin": 113, "health": [58, 77, 80], "healthcar": [58, 121], "healthi": [42, 60, 121], "hear": [34, 58], "heart": [39, 58, 61, 69, 108, 117, 121], "heat": [9, 60], "heatmap": 8, "heavi": [16, 32, 36, 64, 109, 120], "heavili": [3, 13, 15, 58, 60, 67, 70, 108, 136, 139], "hebb": 58, "hebbian": 58, "hebrew": 136, "heck": 134, "heel": 34, "hei": 58, "height": [11, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 49, 61, 62, 88, 105, 115, 117, 121], "heiligerl": 113, "held": [6, 38, 48, 58, 73, 77], "hello": 3, "help": [8, 22, 28, 44, 47, 48, 50, 51, 58, 60, 68, 71, 73, 74, 75, 77, 79, 80, 83, 90, 96, 102, 104, 105, 110, 113, 118, 120, 121, 125, 126, 127, 132, 134], "helper": [20, 44, 92, 94, 105], "henc": [2, 3, 17, 33, 34, 35, 45, 51, 52, 54, 55, 58, 60, 62, 64, 69, 71, 79, 90, 102, 103, 104, 105, 108, 109, 111, 112, 121, 130, 132, 133, 135, 136], "her": [67, 96], "herald": 41, "here": [8, 9, 10, 11, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 39, 40, 41, 44, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 60, 61, 62, 64, 65, 66, 67, 69, 71, 74, 75, 77, 79, 80, 82, 85, 91, 93, 95, 97, 101, 102, 103, 104, 105, 107, 109, 110, 112, 114, 115, 117, 119, 120, 121, 122, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 141], "hessian": [102, 104, 105, 110], "heurist": [2, 8, 34, 41, 58, 67, 74, 76, 77, 79, 82, 107, 120, 126, 135], "hexdigest": 1, "heytitl": 113, "hf": [1, 26, 127], "hf_hub_download": [1, 113], "hf_weights_split": 1, "hh": [123, 125, 130, 133], "hi": [43, 46, 58, 85, 98, 113, 127, 128], "hid_in_featur": [90, 92], "hidden": [3, 4, 9, 10, 15, 16, 17, 34, 35, 40, 41, 45, 46, 49, 50, 51, 58, 75, 76, 78, 81, 82, 90, 92, 94, 110, 113, 123, 126, 129, 130, 131, 134, 135], "hidden_st": [4, 129], "hide": [65, 75, 102, 121], "hierarch": [9, 27, 28, 34, 45, 58, 94, 131], "hierarchi": [58, 108], "high": [5, 6, 10, 13, 14, 19, 25, 26, 28, 30, 31, 33, 34, 35, 36, 39, 43, 45, 46, 47, 48, 49, 55, 58, 60, 61, 62, 64, 65, 67, 68, 69, 70, 72, 76, 77, 78, 80, 81, 86, 97, 98, 101, 103, 105, 110, 113, 116, 117, 118, 123, 125, 127, 129, 130, 132, 134], "higher": [6, 9, 11, 19, 26, 34, 36, 46, 49, 55, 58, 61, 64, 67, 75, 79, 80, 92, 96, 97, 105, 107, 109, 110, 112, 114, 117, 121, 129, 132], "highest": [19, 46, 56, 59, 61, 64, 83, 88, 122, 129], "highli": [34, 41, 48, 50, 65, 71, 108, 111, 121, 134, 135], "highlight": [6, 69, 72, 86, 94], "highwai": 39, "hilbert": [74, 80], "hill": 79, "him": [46, 67], "hindsight": [41, 55], "hing": 90, "hint": [2, 9, 10, 18, 28, 29, 46, 51, 52, 54, 59, 60, 64, 66, 67, 69, 70, 71, 73, 79, 80, 93, 96, 98, 105, 114, 115, 120, 121, 130, 136], "hinton": 34, "hire": 58, "hist": [87, 128], "histogram": [34, 87, 97, 128], "histor": [47, 58, 61, 69, 82, 132, 133, 136], "histori": [38, 51, 58, 103, 111, 114, 131, 135, 136], "hit": [1, 45, 52], "hiv": 121, "ho": [113, 127], "hoa": 113, "hoc": 61, "hochreit": [5, 127], "hoeffd": 61, "hog": 34, "hold": [19, 21, 32, 33, 41, 46, 48, 52, 58, 60, 61, 64, 67, 73, 74, 89, 93, 102, 104, 105, 109, 112, 115, 117, 120, 121, 136, 141], "holdout": [61, 67, 77], "hole": [43, 140, 141], "home": [4, 10, 58, 60, 69, 120, 121, 129], "homeless": 121, "homework": 58, "homunculusk": 113, "honest": 67, "hongshen": 113, "hood": [71, 75], "hoonos": 113, "hop": 58, "hope": [16, 31, 43, 58, 60, 61, 77, 79, 102, 104, 113, 121, 125, 135, 137], "hopefulli": [17, 64, 130], "horizont": [6, 25, 40, 41, 44, 48, 109, 117], "horizontalflip": [22, 23, 25, 26], "hormon": 60, "horribl": 79, "horror": 87, "hors": [25, 31, 85], "horsepow": 57, "hospit": [58, 64, 69, 121, 136], "hossain": 60, "host": [58, 64, 79, 119], "hot": [2, 24, 64, 66, 79, 82, 94, 114], "hotdog": 22, "hotdog_w": 22, "hotfix": 103, "hour": [34, 52, 54, 58, 106, 136], "hous": [35, 36, 57, 58, 64, 69, 78, 121, 138, 139, 142], "house_tini": 120, "housekeep": [12, 15], "how": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 93, 94, 95, 96, 97, 98, 99, 101, 102, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "howev": [3, 5, 6, 9, 10, 11, 14, 15, 16, 17, 20, 22, 25, 27, 28, 29, 31, 32, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 67, 69, 71, 72, 74, 75, 76, 77, 79, 80, 83, 84, 85, 89, 90, 93, 94, 96, 97, 102, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 133, 135, 136, 137, 140], "hparam": [1, 76], "hpo": [52, 53, 54, 55, 56], "hpo_objective_dropoutmlp_synetun": 54, "hpo_objective_lenet": [51, 56], "hpo_objective_lenet_synetun": [54, 55], "hpo_objective_softmax_classif": 52, "hposchedul": [51, 56], "hposearch": [51, 56], "hpotrain": [51, 52, 54, 55], "hpotun": [51, 56], "hq": [123, 133], "hr": 125, "hsneto": 113, "html": 57, "http": [1, 22, 23, 25, 26, 29, 31, 57, 79, 85, 86, 88, 91, 92, 95, 99, 107, 132], "hu": [8, 113], "huang": 113, "hub": [1, 28], "huber": 70, "huddl": 58, "hue": 23, "hug": 85, "huge": [34, 58, 61, 73, 83, 84, 89, 90, 91, 98, 99], "huggingfac": [1, 22, 26, 28, 91, 92], "huggingface_hub": 113, "human": [6, 39, 46, 58, 62, 77, 94, 113], "hunch": 35, "hundr": [15, 17, 34, 46, 47, 56, 58, 61, 67, 89, 113, 119, 137], "hunt": 121, "hurt": [5, 52, 55, 67, 77], "huski": 26, "hw": [11, 27, 28], "hwa": 32, "hwang": 113, "hx": 130, "hybrid": [22, 26, 107], "hybridsequenti": [21, 26, 107], "hyeonggyu": 113, "hymap": 62, "hyper": [47, 140], "hyperbol": [80, 105], "hypergradi": 52, "hyperparam": [101, 102, 103, 108, 109, 111], "hyperparamet": [1, 2, 4, 10, 11, 16, 21, 22, 25, 26, 28, 32, 33, 35, 37, 38, 39, 48, 49, 50, 54, 55, 60, 61, 66, 67, 69, 71, 72, 73, 74, 75, 79, 81, 85, 86, 87, 88, 89, 90, 97, 99, 106, 108, 109, 122, 123, 125, 127, 129, 132, 135, 142], "hyperspectr": [46, 62], "hypotenus": 117, "hypothes": [85, 86, 121], "hypothesi": [6, 61, 67, 77, 85, 86], "hypothet": 15, "hz": 125, "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142], "i_": 89, "i_1": 19, "i_2": 19, "i_t": 89, "iamorphen": 113, "ic": 93, "ichi": 34, "id": [25, 26, 54, 55, 58, 60, 79, 90, 113, 119], "idea": [4, 5, 10, 16, 21, 24, 34, 35, 36, 38, 39, 45, 46, 49, 52, 55, 56, 58, 60, 61, 62, 64, 66, 67, 69, 70, 74, 76, 77, 79, 81, 82, 84, 89, 96, 97, 101, 102, 105, 113, 114, 115, 121, 123, 125, 126, 127, 128, 130, 137, 138, 140, 141], "ideal": [1, 2, 28, 42, 46, 51, 58, 64, 67, 86, 91, 111, 113, 122, 132, 140], "idel": 55, "ident": [3, 8, 10, 15, 22, 34, 35, 39, 47, 49, 51, 58, 60, 67, 69, 73, 80, 100, 104, 107, 108, 110, 114, 118, 119, 121, 130, 133, 140, 141], "identif": [24, 142], "identifi": [22, 34, 37, 51, 52, 56, 58, 74, 77, 79, 85, 122], "idl": [54, 55, 56], "idx": [1, 15, 29, 31, 32, 79, 85, 91, 95, 97, 128, 132, 137], "idx1": 107, "idx3": 107, "idx_to_class": 25, "idx_to_in_channel": 32, "idx_to_token": [86, 88, 91, 95, 135, 137], "idx_to_vec": 95, "ignit": 58, "ignor": [1, 16, 22, 33, 35, 41, 42, 46, 61, 69, 71, 72, 105, 118, 125, 129, 130, 132, 137], "ignore_stale_grad": 23, "igor": 113, "ii": [4, 6, 15, 28, 32, 34, 35, 43, 49, 58, 64, 66, 69, 70, 71, 72, 77, 82, 83, 90, 91, 102, 113, 114, 115, 116, 119, 121, 122, 127, 133, 136, 137, 141], "iid": [47, 48, 67], "iii": [4, 6, 15, 28, 32, 34, 58, 66, 71, 72, 90, 91, 113, 114, 115, 116, 122, 127, 136, 137], "ij": [19, 28, 47, 48, 49, 60, 66, 69, 82, 86, 93, 100, 102, 105, 108, 110, 117], "ijk": [12, 117], "ik": [66, 86, 93], "il": [4, 10, 124, 129], "ilkermetinkursova": 60, "ill": [39, 60], "illeg": [29, 32], "illinoi": 58, "illus": 58, "illustr": [3, 6, 15, 18, 19, 28, 30, 33, 34, 39, 41, 49, 51, 58, 60, 62, 66, 67, 71, 73, 74, 75, 79, 80, 82, 83, 84, 86, 88, 89, 90, 93, 96, 104, 105, 107, 108, 109, 110, 113, 114, 117, 119, 122, 123, 125, 127, 129, 130, 133, 136], "iloc": [79, 120], "iluu": 113, "ilya": 34, "imag": [1, 2, 5, 6, 8, 9, 11, 12, 19, 20, 21, 22, 24, 27, 29, 30, 32, 33, 34, 35, 37, 40, 42, 43, 44, 45, 46, 47, 49, 58, 60, 61, 63, 64, 65, 66, 67, 73, 76, 77, 80, 81, 86, 88, 107, 108, 113, 115, 117, 120, 131, 136, 142], "image_path": [29, 31], "image_resize_if": 1, "image_shap": 28, "imagefold": [22, 26], "imagefolderdataset": [22, 26], "imagen": [6, 58], "imagenet": [8, 11, 15, 21, 22, 24, 28, 34, 37, 38, 39, 58, 62, 67, 107, 142], "imagereadmod": 31, "imageset": 31, "imagin": [5, 9, 15, 30, 46, 48, 49, 58, 60, 64, 67, 81, 82, 102, 104, 121, 137, 140, 141], "imagnet": 42, "imdb": [58, 87], "img": [1, 19, 20, 21, 23, 27, 28, 29, 31, 32, 62], "img_nam": 29, "img_shap": 28, "img_siz": 11, "imit": [46, 58, 138], "immedi": [6, 10, 34, 46, 47, 54, 55, 58, 61, 114, 121, 136, 139], "immens": 11, "immun": 47, "impact": [55, 58, 60, 67, 113, 127, 137], "impati": 60, "imper": [39, 58], "imperfectli": 136, "implement": [1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 15, 19, 21, 27, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 54, 55, 56, 58, 59, 60, 62, 63, 64, 68, 75, 77, 78, 79, 80, 82, 85, 86, 87, 88, 90, 91, 92, 95, 97, 99, 105, 106, 107, 113, 117, 118, 121, 124, 126, 128, 129, 131, 133, 138, 142], "implementaiton": 55, "impli": [46, 55, 67, 80, 98, 104, 110], "implic": 121, "implicit": [1, 44, 58, 67, 80], "implicitli": [44, 47, 58, 72, 140], "import": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 85, 86, 87, 88, 90, 91, 92, 95, 96, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 132, 133, 134, 135, 136, 137, 139, 140, 141], "importantli": [2, 41, 60, 121], "impos": [17, 46, 58, 69, 76, 104], "imposs": [41, 58, 60, 74, 82, 114, 121], "impract": 102, "impress": [58, 82], "improv": [6, 10, 11, 21, 22, 23, 24, 25, 26, 30, 32, 34, 35, 37, 38, 39, 42, 43, 45, 47, 51, 53, 58, 60, 61, 62, 64, 67, 69, 70, 77, 79, 83, 88, 90, 96, 99, 103, 105, 106, 107, 109, 112, 113, 121, 122, 129, 135, 136], "impuls": 64, "imput": 120, "imread": [19, 20, 21, 23, 27, 29, 31], "imshow": [1, 2, 8, 19, 20, 21, 23, 27, 28, 29, 32], "in_channel": [1, 21, 32, 37], "in_featur": 22, "in_height": 19, "in_unit": 12, "in_width": 19, "inaccess": 49, "inaccur": [31, 47], "inadvert": [58, 119], "inadvis": 67, "inappropri": 58, "inbox": 64, "incant": 106, "incent": 58, "incept": [38, 39], "inclin": [47, 60, 117], "includ": [3, 4, 5, 6, 9, 13, 15, 21, 25, 26, 29, 30, 32, 34, 35, 37, 38, 40, 41, 42, 44, 47, 48, 49, 50, 51, 52, 58, 60, 65, 66, 67, 68, 69, 71, 72, 74, 75, 77, 79, 80, 83, 85, 89, 90, 97, 99, 106, 113, 115, 117, 118, 119, 120, 121, 122, 123, 127, 128, 129, 133, 136], "inclus": 127, "incom": [80, 117], "incompat": 72, "incomplet": 38, "inconclus": 83, "inconveni": 70, "incorpor": [12, 15, 17, 46, 48, 58, 60, 67, 69, 79, 121, 125, 129, 133, 136], "incorrectli": [66, 77], "increas": [2, 5, 6, 7, 18, 21, 22, 25, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 48, 56, 58, 64, 65, 67, 69, 70, 71, 74, 76, 77, 79, 80, 93, 102, 104, 105, 107, 108, 109, 112, 115, 121, 123, 129, 130, 132, 133, 136, 140, 141], "increasingli": [6, 13, 36, 42, 48, 50], "incred": 43, "incredibli": [41, 132], "increment": [1, 19, 69], "incumb": [51, 54], "incumbent_error": 51, "incumbent_trajectori": 51, "incur": [47, 58, 60, 61, 64, 69, 108], "ind": 19, "inde": [5, 8, 35, 41, 47, 50, 58, 59, 60, 61, 64, 71, 72, 74, 79, 82, 90, 106, 109, 112, 115, 121], "indebt": 113, "indefinit": 100, "independ": [3, 7, 10, 30, 35, 39, 40, 46, 47, 48, 49, 52, 54, 58, 64, 67, 69, 73, 82, 83, 89, 94, 98, 100, 102, 108, 111, 112, 119, 121, 136], "index": [1, 9, 19, 25, 29, 31, 32, 43, 46, 47, 48, 56, 58, 59, 66, 69, 72, 79, 85, 86, 90, 92, 93, 95, 97, 98, 99, 105, 112, 116, 117, 120, 121, 129, 135, 136, 137], "indic": [1, 3, 19, 27, 28, 29, 31, 39, 40, 44, 45, 46, 47, 51, 58, 60, 61, 62, 66, 67, 72, 73, 79, 80, 85, 87, 89, 90, 91, 93, 95, 97, 99, 100, 101, 102, 105, 107, 108, 113, 115, 117, 119, 121, 128, 130, 132, 135, 137, 139, 140, 141], "indices_np": 19, "indices_tru": 19, "indiffer": 45, "indirectli": 30, "indiscrimin": 2, "indispens": [13, 23, 35], "individu": [6, 10, 13, 15, 17, 30, 34, 35, 41, 58, 60, 70, 76, 80, 85, 88, 91, 94, 97, 102, 114, 117, 121, 136, 137], "indivis": [21, 137], "induc": [6, 49], "induct": [39, 46, 52, 67, 77], "industri": [24, 34, 58, 83, 113], "ineffici": 73, "ineleg": 135, "inequ": [61, 112, 117, 121], "inevit": 132, "inexpens": 58, "inextric": [121, 131], "inf": 80, "infam": 49, "infeas": [4, 30, 31, 32, 35, 46, 52, 58, 83, 102, 130], "infect": 121, "infer": [6, 34, 35, 37, 48, 49, 50, 52, 58, 67, 69, 83, 84, 90, 108, 110, 113, 119, 121, 127, 142], "inferior": 60, "infin": [49, 60, 61, 64, 89, 132], "infinit": [46, 48, 49, 50, 61, 64, 67, 77, 80, 105, 121, 139, 140], "infinitesim": [67, 115], "inflect": 96, "influenc": [4, 39, 58, 66, 67, 69, 78, 80, 113, 114, 121, 123, 125, 126, 127, 129, 130, 135, 136], "influenti": [4, 24, 67], "influx": 58, "info": [51, 54, 55, 56], "infomatiqu": 46, "inform": [1, 4, 8, 18, 19, 20, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 42, 44, 45, 46, 48, 58, 60, 61, 63, 69, 73, 79, 80, 83, 85, 86, 93, 95, 96, 105, 117, 121, 123, 125, 126, 127, 128, 129, 131, 132, 133, 136, 137, 141], "informat": [58, 113], "infrequ": [60, 61, 91, 102, 128, 132, 137], "infti": [35, 49, 58, 61, 64, 104, 109, 121, 139, 140, 141], "ingeni": [37, 102], "ingenu": [38, 39, 58], "ingest": [15, 37, 39, 58, 116, 131, 135], "ingredi": [43, 52, 58, 80], "inher": [6, 34, 35, 58, 82, 102, 103, 107], "inherit": [6, 12, 15, 31, 72, 85, 124, 134], "inhibit": 69, "init": [1, 14, 21, 22, 23, 26, 33, 43, 57, 70, 72, 92, 99, 107, 108, 113, 129], "init_adadelta_st": 101, "init_adagrad_st": 102, "init_adam_st": 103, "init_cnn": [23, 34, 43, 51], "init_fn": 22, "init_model_weight": 23, "init_momentum_st": 109, "init_param": [134, 135], "init_rmsprop_st": 111, "init_seq2seq": [4, 129], "init_st": [4, 10, 124, 129], "init_weight": [1, 99, 125, 127], "initi": [4, 5, 6, 10, 11, 12, 13, 15, 17, 19, 23, 24, 26, 33, 34, 35, 37, 39, 41, 43, 44, 45, 47, 48, 51, 52, 55, 56, 57, 58, 61, 66, 69, 71, 75, 77, 78, 86, 88, 90, 92, 93, 96, 101, 102, 103, 105, 107, 108, 109, 110, 111, 112, 114, 117, 119, 121, 123, 129, 130, 134, 135, 136, 141, 142], "initial_config": [51, 54, 55, 56], "inject": [9, 35, 58, 76, 108, 112], "injustic": 58, "inlin": [19, 20, 21, 22, 23, 27, 28, 29, 31, 32, 62, 69, 71, 73, 74, 79, 80, 82, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 115, 121, 135, 136, 140, 141], "inner": [49, 100, 117, 119], "innermost": [10, 19, 20, 32], "innocu": [4, 73], "innov": [5, 58, 69, 77, 80, 105, 126, 127], "inprogress": [54, 55], "input": [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 55, 56, 58, 60, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 91, 92, 94, 95, 96, 97, 99, 105, 108, 110, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 142], "input_channel": [1, 36, 39], "input_dim": [17, 21, 22, 70, 99], "input_h": 1, "input_length": 1, "input_shap": 90, "input_w": 1, "inquiri": 113, "inscrib": 115, "insepar": 24, "insert": [1, 10, 35, 56, 81, 90, 91, 92, 96, 108, 128], "insid": [18, 20, 25, 35, 43, 54, 56, 60, 65, 104, 112, 115, 119, 141], "insidi": [60, 110], "insight": [5, 13, 34, 38, 49, 75, 102, 112, 113, 121, 131, 134, 138, 140], "insist": 83, "insofar": [38, 43, 58, 67, 77, 111], "inspect": [1, 2, 5, 16, 62, 73, 113, 119, 120, 137], "inspir": [4, 6, 10, 39, 42, 46, 58, 67, 69, 72, 78, 82, 103, 135], "instabl": [66, 126, 130, 135], "instal": [18, 60, 91, 113, 142], "instanc": [2, 3, 4, 8, 10, 11, 12, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 29, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 52, 54, 55, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 90, 93, 94, 95, 96, 97, 102, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 123, 127, 128, 132, 136, 137], "instant": [138, 141], "instantan": [60, 109, 112, 115, 141], "instanti": [4, 5, 10, 15, 17, 43, 69, 70, 90, 111, 125, 127, 129, 133], "instead": [3, 4, 5, 7, 8, 11, 16, 17, 23, 31, 32, 34, 35, 39, 40, 41, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 59, 60, 61, 64, 65, 66, 69, 72, 74, 82, 84, 85, 92, 96, 101, 103, 105, 107, 109, 110, 112, 115, 119, 121, 136, 138, 139, 141], "institut": [69, 121], "instruct": [6, 34, 38, 57, 70, 106, 118, 132, 135], "instructgpt": 6, "instrument": [69, 74], "insuffici": [58, 67, 73, 77, 85, 105], "insur": 58, "int": [1, 19, 30, 32, 39, 46, 47, 54, 55, 56, 60, 61, 62, 67, 72, 85, 91, 95, 96, 100, 104, 118, 119, 121, 129, 135, 137], "int32": [1, 17, 19, 21, 23, 25, 31, 91, 97, 99, 117, 119, 128, 129, 132, 135], "int64": [1, 4, 10, 62, 129, 135], "int8": 65, "int_": 49, "int_a": 100, "integ": [1, 19, 21, 25, 29, 51, 52, 64, 79, 97, 98, 100, 120], "integr": [15, 35, 46, 47, 50, 60, 67, 74, 100, 104, 109, 113, 115, 121, 125], "intel": [57, 58, 95, 97, 99], "intellectu": 61, "intellig": [58, 113, 121], "intend": [12, 47, 65, 84, 121], "intens": [18, 46, 52, 58, 61, 80, 117], "intent": [6, 58, 65, 121], "inter": 19, "inter_area": 19, "inter_lowerright": 19, "inter_upperleft": 19, "interact": [0, 3, 40, 46, 54, 62, 72, 79, 80, 94, 109, 113, 121, 130, 136], "intercept": [49, 69], "interconnect": 34, "interdepend": 75, "interest": [11, 15, 19, 20, 23, 28, 30, 32, 34, 35, 44, 49, 51, 52, 54, 58, 61, 64, 66, 67, 69, 75, 77, 80, 82, 102, 109, 112, 113, 114, 117, 121, 128, 131, 135, 136, 141], "interestingli": [15, 34, 60, 114, 121], "interfac": [4, 34, 51, 54, 58, 62, 108, 119, 124], "interleav": [46, 113], "intermedi": [4, 6, 15, 17, 21, 27, 28, 33, 35, 37, 39, 44, 45, 58, 69, 75, 76, 77, 90, 114, 127, 130, 141], "intern": [4, 35, 58, 59, 76, 96, 105, 118, 125, 126], "internet": [5, 22, 29, 58, 67, 79, 113, 121], "interpol": [2, 21, 30, 77, 136], "interpret": [3, 5, 8, 18, 35, 40, 48, 50, 57, 58, 61, 64, 69, 74, 77, 80, 94, 108, 115, 118, 121], "inters_diff": 19, "intersect": [24, 100, 104, 121], "interspers": [18, 72], "intertwin": 121, "interv": [23, 32, 34, 47, 48, 58, 61, 65, 80, 93, 104, 105, 115, 121, 125, 127], "interven": 34, "intervent": 77, "intra": 9, "intract": 58, "intrins": [11, 51, 73, 77, 121], "introduc": [2, 3, 4, 5, 6, 8, 13, 15, 19, 20, 21, 22, 25, 27, 30, 32, 33, 35, 37, 39, 42, 43, 45, 47, 48, 49, 50, 52, 53, 56, 58, 60, 61, 64, 66, 67, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 86, 88, 89, 90, 98, 104, 105, 107, 108, 110, 113, 115, 117, 121, 122, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 139], "introduct": [11, 12, 20, 23, 34, 47, 50, 61, 67, 72, 110, 113, 116, 117, 142], "introductori": [48, 50, 113], "intrud": 20, "intuit": [2, 5, 8, 15, 19, 27, 34, 35, 37, 38, 40, 46, 47, 48, 49, 50, 58, 64, 67, 73, 74, 76, 77, 79, 80, 93, 97, 102, 104, 105, 107, 109, 112, 113, 115, 117, 120, 121, 125, 126, 127, 130, 136, 141], "inv": 47, "invalid": 1, "invari": [2, 11, 34, 35, 40, 42, 45, 48, 49, 62, 64, 131], "invent": [12, 13, 35, 41, 46, 58, 64, 65, 69, 70, 76, 77, 82], "inventor": [34, 35, 80], "invers": [19, 58, 76, 100, 112, 115], "invert": [60, 69, 80, 105, 115], "invest": [41, 60, 121], "investig": [23, 24, 49, 61, 71, 85, 88, 114, 121], "investor": 136, "invit": 54, "invoc": [73, 101], "invoic": 58, "invok": [12, 15, 17, 19, 25, 28, 32, 37, 46, 51, 60, 62, 65, 69, 70, 72, 75, 81, 85, 91, 92, 102, 107, 115, 117, 118, 119, 121, 135], "involv": [1, 6, 46, 47, 48, 49, 51, 58, 60, 75, 76, 80, 89, 98, 110, 112, 114, 117, 121, 130, 132, 137], "io": [29, 31, 91], "iou": 24, "iou_threshold": 19, "iowa": 79, "ipad": 60, "iphon": 58, "ipython": [1, 113], "iren": 67, "iri": 58, "irreduc": 47, "irrelev": [105, 127, 129], "irrespect": [42, 140, 141], "is_next": 91, "is_resize_en": 1, "is_slipperi": 1, "is_tgt": 128, "is_train": [1, 23, 29, 31, 85, 87, 108], "ishan": 113, "isinst": [1, 4, 11, 19, 23, 30, 32, 34, 35, 43, 72, 85, 91, 115, 129, 137], "islam": 113, "isol": 58, "isomorph": 77, "issu": [9, 17, 21, 31, 35, 39, 44, 46, 47, 52, 58, 60, 65, 74, 78, 82, 96, 98, 102, 103, 109, 111, 114, 119], "istock": 60, "itali": 58, "item": [1, 7, 9, 19, 21, 23, 25, 40, 41, 51, 56, 58, 62, 64, 72, 74, 89, 96, 99, 112, 119, 135, 137, 140, 141], "iter": [1, 22, 23, 25, 26, 29, 31, 34, 35, 37, 40, 41, 47, 51, 52, 53, 54, 55, 56, 58, 60, 62, 66, 69, 70, 71, 72, 73, 75, 76, 77, 82, 84, 85, 86, 88, 92, 93, 96, 97, 98, 99, 102, 105, 107, 108, 110, 112, 114, 128, 132, 135, 136, 138, 140, 142], "iterrow": 29, "its": [3, 4, 6, 8, 9, 10, 11, 12, 14, 15, 16, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 93, 94, 96, 97, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 117, 119, 121, 123, 124, 128, 129, 131, 132, 136, 137, 139, 140, 141], "itself": [6, 8, 9, 15, 46, 47, 51, 57, 58, 64, 70, 73, 74, 76, 80, 101, 102, 103, 108, 117, 121, 130], "iv": [71, 90, 113, 114, 115, 116, 122], "j": [3, 4, 5, 8, 10, 12, 19, 28, 32, 33, 41, 44, 45, 46, 48, 49, 60, 64, 65, 69, 75, 79, 82, 83, 86, 89, 93, 96, 98, 100, 102, 108, 113, 117, 119, 121, 129, 130], "j_1": 19, "j_2": 19, "jaccard": 19, "jacob": [58, 113], "jacobian": 114, "jaedong": 113, "jake221": 113, "jamaoui": 113, "jame": [58, 75], "jancio": 113, "janmei": 113, "japan": 95, "japanes": 128, "jason": 113, "jassi": 113, "javascript": 113, "jax": [58, 70, 113], "je": [4, 10, 129], "jean": 113, "jensen": 112, "ji": [93, 110, 117], "jie": 113, "jiehang": 113, "jiekui": 113, "jitter": 47, "jiyang": 113, "jj": [83, 102], "jjangga0214": 113, "jk": 102, "jnp": 113, "job": [46, 47, 51, 54, 55, 56, 58, 60, 79], "joe": 113, "john": [83, 113], "join": [1, 4, 10, 22, 25, 26, 29, 31, 85, 87, 91, 95, 96, 97, 120, 128, 129, 135, 137], "joint": [6, 47, 48, 49, 58, 89, 121, 132, 136], "jointli": [7, 30, 34, 40, 58, 64, 76, 80, 81, 86, 121], "joji": 113, "joke": 50, "jonathanhrandal": 113, "jonbal": 113, "joseph": 113, "joseppinilla": 113, "josh": 113, "joshua": 113, "josiah": 113, "jour": 101, "journal": 97, "journei": [43, 117], "jpeg": 26, "jpegimag": 31, "jpg": [19, 20, 21, 23, 26, 27, 28, 31, 32], "jroberayala": 113, "judg": 83, "juergen": 34, "juli": 113, "julia": 114, "jump": [56, 85], "jun": 113, "juntian": 113, "jupyt": [57, 72, 113, 115, 118], "just": [2, 4, 6, 8, 11, 12, 13, 15, 16, 18, 19, 23, 25, 27, 28, 29, 32, 33, 34, 35, 37, 39, 40, 41, 43, 45, 46, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 67, 69, 70, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 86, 88, 89, 92, 102, 103, 104, 105, 107, 109, 110, 112, 113, 114, 115, 116, 117, 119, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 140], "justic": 77, "justif": [64, 76, 108], "justifi": [34, 58, 67, 68, 112], "k": [1, 2, 3, 4, 7, 8, 9, 10, 19, 25, 33, 40, 41, 46, 47, 48, 49, 54, 55, 56, 58, 60, 61, 64, 67, 69, 71, 74, 77, 78, 86, 88, 89, 93, 95, 96, 97, 99, 102, 105, 110, 117, 119, 121, 122, 129, 130, 136, 140, 141], "k1": 117, "k2": 117, "k_": [40, 41, 44, 47, 48, 49], "k_1": [40, 49], "k_2": [40, 49], "k_fold": 79, "k_fold_data": 79, "k_h": 33, "k_input": [3, 4], "k_step_pr": 136, "k_w": 33, "k_x_x": 47, "k_x_xstar": 47, "k_xstar_xstar": 47, "kaan": 113, "kaddour": 113, "kaftan": 113, "kaggl": [24, 78, 142], "kaggle_cifar10_tini": 25, "kaggle_dog_tini": 26, "kaggle_house_pred_test": 79, "kaggle_house_pred_train": 79, "kagglehous": 79, "kaixin": 113, "kale": 113, "kang": 113, "kapoor": 113, "kappa": 102, "karl": 67, "karolszk": 113, "karypi": 113, "kasparov": 58, "katarzyna": 113, "kavosh": 138, "kb": 58, "kcj": 132, "keen": 58, "keep": [3, 4, 8, 15, 16, 18, 19, 22, 26, 28, 33, 35, 36, 41, 45, 51, 54, 56, 58, 60, 61, 64, 65, 67, 69, 70, 72, 74, 76, 81, 82, 91, 97, 101, 102, 105, 107, 108, 109, 111, 117, 121, 123, 126, 127, 128, 130, 135, 136, 139, 140, 141], "keepdim": [1, 35, 66, 117, 121], "kei": [1, 2, 3, 4, 5, 7, 9, 10, 13, 15, 21, 22, 24, 25, 29, 34, 35, 36, 37, 41, 47, 55, 56, 60, 61, 62, 64, 69, 72, 76, 78, 80, 81, 82, 91, 96, 103, 105, 107, 109, 111, 113, 114, 115, 117, 118, 119, 125, 126, 127, 130, 131, 136, 137, 138, 140, 141, 142], "kept": [19, 58, 97, 112, 120], "kera": [58, 101, 102, 103, 107, 109, 111], "kernel": [1, 3, 5, 8, 9, 11, 21, 33, 34, 37, 39, 40, 42, 43, 44, 45, 46, 48, 50, 58, 67, 74, 77, 80, 88], "kernel2matrix": 33, "kernel_h": [1, 32], "kernel_s": [1, 11, 21, 32, 33, 34, 35, 36, 37, 39, 41, 43, 44, 88, 107], "kernel_term": 47, "kernel_w": [1, 32], "key_list": 91, "key_transform": [1, 29], "key_valu": 10, "keyerror": 1, "kf": 58, "khisamutdinov": 113, "ki": 56, "kick": 113, "killer": 119, "kilomet": 105, "kim": 113, "kind": [2, 15, 39, 41, 51, 60, 63, 80, 119, 122, 132, 136, 140, 142], "kink": 58, "kiplus1": 56, "kiss": 47, "kj": 86, "kl": 100, "klein": 53, "km": 117, "knack": 67, "knd": 9, "knn": 95, "knob": 58, "knock": 110, "know": [9, 12, 14, 16, 18, 19, 20, 21, 32, 35, 39, 41, 44, 46, 48, 49, 58, 60, 61, 62, 64, 65, 66, 67, 70, 71, 74, 75, 79, 80, 81, 82, 85, 97, 104, 105, 114, 117, 118, 119, 120, 121, 132, 133, 136, 138, 139, 140, 141], "knowledg": [6, 7, 15, 22, 25, 32, 34, 42, 46, 52, 58, 60, 61, 77, 79, 80, 98, 106, 113, 116, 121, 127, 138], "known": [6, 10, 19, 34, 35, 39, 45, 46, 47, 48, 50, 52, 58, 60, 64, 67, 69, 73, 74, 77, 85, 103, 109, 112, 114, 117, 121, 127, 137, 140, 141], "korfmann": 113, "krahet": 113, "kriz": 23, "krizhevski": 34, "kryder": 58, "kt": 64, "kulit": 113, "kumar": 113, "kwarg": [1, 3, 7, 28, 32, 37, 86, 88, 90], "kxxt": 113, "k\u00f6bel": 58, "l": [1, 3, 19, 23, 25, 26, 28, 32, 39, 46, 47, 49, 52, 58, 59, 60, 64, 67, 69, 70, 71, 72, 74, 75, 80, 82, 89, 92, 93, 96, 97, 99, 102, 104, 107, 112, 122, 123, 128, 129, 130, 135, 137], "l1": 108, "l1_loss": 32, "l2": [74, 108], "l2_penalti": 74, "l3": [34, 108], "l_": 59, "l_sum": 26, "lab": [1, 43, 58, 131], "label": [1, 2, 6, 11, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 37, 39, 47, 49, 59, 61, 62, 64, 66, 67, 69, 72, 73, 74, 75, 77, 79, 80, 83, 85, 86, 87, 90, 91, 94, 97, 98, 99, 104, 107, 109, 111, 112, 115, 120, 121, 126, 128, 129, 132, 133, 136], "label2imag": 21, "label_count": 25, "label_seq": 129, "label_set": 85, "label_sub": 129, "label_token": 129, "labels_batch": 97, "labor": 58, "laboratori": 62, "labrador": 26, "lack": [11, 34, 46, 48, 56, 58, 65, 111, 113, 115, 136], "lafeez": 60, "lag": 58, "lagrang": 104, "lai": 113, "laid": [51, 58, 113, 119], "laion": 34, "lake": 141, "lakshkd": 113, "lakshya": 113, "lam": 109, "lambd": 74, "lambda": [1, 2, 4, 19, 25, 29, 34, 35, 36, 37, 39, 43, 56, 64, 65, 69, 71, 74, 75, 76, 79, 81, 91, 102, 104, 107, 108, 109, 110, 112, 114, 125, 127, 128, 129, 135, 137], "lambda_": 130, "lambda_i": [102, 109, 130], "lame": 58, "land": [47, 138], "landscap": [5, 11, 28, 35, 58, 109], "lane": 113, "langevin": 107, "langl": [49, 100, 112, 117], "languag": [3, 5, 8, 10, 11, 15, 39, 46, 58, 64, 77, 80, 83, 88, 92, 95, 96, 98, 102, 113, 114, 116, 117, 120, 121, 122, 124, 125, 126, 128, 129, 131, 134, 136, 142], "languish": 58, "laplac": 118, "laps": 5, "laptop": [34, 57, 120], "larg": [2, 3, 5, 8, 11, 18, 19, 22, 23, 32, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 48, 49, 52, 54, 55, 58, 60, 61, 62, 64, 65, 66, 69, 71, 73, 74, 75, 77, 79, 80, 82, 83, 86, 87, 89, 92, 93, 94, 95, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 117, 120, 121, 125, 128, 130, 132, 135, 137, 139, 140, 142], "larger": [6, 11, 15, 18, 21, 22, 25, 26, 27, 28, 32, 33, 34, 35, 39, 40, 41, 44, 45, 46, 47, 48, 49, 54, 56, 57, 61, 64, 65, 67, 69, 74, 75, 77, 79, 81, 91, 93, 96, 102, 103, 109, 112, 119, 121, 128, 130, 137, 140], "largest": [6, 19, 29, 30, 34, 37, 58, 59, 61, 64, 65, 66, 67, 102, 122, 139, 141], "larroi": 113, "lasso": [74, 77], "last": [1, 3, 4, 5, 8, 13, 18, 21, 22, 28, 32, 33, 34, 46, 47, 50, 51, 54, 55, 58, 59, 86, 87, 88, 97, 102, 103, 107, 108, 109, 112, 119, 127, 130, 132], "last_batch": [26, 31], "lastli": [3, 35, 39, 41, 45, 59, 61, 62, 64, 107, 121], "late": [79, 81, 114], "latenc": [34, 108], "latent": [47, 48, 125, 127, 133, 136], "later": [2, 3, 4, 6, 8, 10, 12, 17, 18, 19, 23, 34, 35, 37, 38, 39, 40, 41, 45, 47, 48, 49, 51, 56, 58, 60, 64, 66, 67, 69, 71, 72, 73, 75, 77, 80, 82, 91, 95, 102, 103, 105, 108, 109, 111, 112, 113, 115, 117, 123, 124, 127, 128, 129, 130, 132, 136, 137, 140], "latest": [34, 82], "latex": 113, "latter": [6, 19, 35, 36, 37, 39, 40, 43, 55, 60, 73, 90, 92, 104, 108, 110, 112, 120, 127], "launch": [54, 55, 58, 60, 80, 113], "lausen": 113, "law": [6, 58, 71, 113, 121, 137, 139], "layer": [1, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 16, 17, 18, 22, 23, 24, 26, 27, 28, 30, 33, 34, 37, 38, 39, 42, 43, 44, 45, 49, 51, 52, 54, 55, 58, 63, 64, 65, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 81, 82, 83, 86, 88, 90, 92, 107, 108, 110, 113, 117, 123, 125, 126, 127, 129, 130, 131, 133, 134, 135, 142], "layer4": 21, "layer_nam": 1, "layer_summari": [34, 37, 39, 43], "layernorm": [10, 11, 90], "layerwis": [24, 27, 28, 32, 82], "layout": 58, "lazi": [36, 70], "lceil": 44, "ldot": [3, 7, 8, 9, 19, 28, 36, 60, 64, 69, 76, 86, 89, 93, 98, 104, 105, 109, 111, 112, 115, 117, 121, 122, 123, 129, 130, 132, 133, 135, 136, 139, 140, 141], "le": 113, "lead": [2, 3, 6, 8, 11, 12, 19, 22, 26, 28, 30, 35, 36, 39, 40, 41, 46, 47, 49, 52, 53, 54, 55, 58, 60, 64, 65, 67, 69, 70, 71, 74, 75, 77, 79, 80, 86, 93, 96, 97, 102, 103, 104, 105, 107, 109, 112, 114, 117, 121, 125, 127, 130, 132, 134, 135, 136], "leaderboard": 79, "leaf": 89, "leak": [61, 119], "leaki": [101, 103, 111], "lean": 6, "leap": [60, 67], "lear": 140, "learn": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 90, 94, 96, 98, 101, 103, 104, 106, 108, 109, 111, 114, 115, 116, 117, 119, 120, 121, 123, 126, 127, 131, 133, 134, 135, 137, 139, 141], "learnabl": [3, 7, 9, 10, 11, 34, 35, 46, 58, 72, 90, 123, 135], "learned_hyp": 47, "learner": [58, 77], "learning_r": [1, 21, 22, 23, 25, 26, 28, 32, 51, 52, 54, 55, 56, 59, 70, 74, 86, 88, 92, 99, 101, 102, 103, 107, 108, 109, 111, 129], "learningrateschedul": 107, "least": [1, 18, 25, 34, 35, 40, 43, 46, 47, 52, 53, 54, 55, 56, 58, 61, 64, 67, 72, 80, 82, 91, 97, 102, 104, 107, 108, 109, 110, 112, 121, 132, 136], "leav": [35, 45, 47, 51, 67, 74, 79, 82, 91, 104, 112, 113, 126], "lectur": [58, 112], "lecun": [34, 43], "led": [6, 35, 38, 39, 58, 102], "lefan": 113, "left": [1, 2, 3, 6, 9, 19, 20, 21, 23, 25, 28, 29, 30, 34, 36, 39, 41, 44, 45, 46, 47, 48, 49, 53, 58, 61, 69, 71, 74, 75, 79, 80, 82, 88, 89, 90, 92, 93, 97, 98, 100, 102, 103, 104, 105, 107, 109, 111, 112, 113, 115, 117, 119, 121, 122, 125, 129, 130, 131, 132, 135, 136, 138, 139, 140, 141], "leftarrow": [69, 71, 74, 79, 103, 104, 105, 107, 108, 109, 111, 112, 135, 140, 141], "leftchild": 89, "leftward": [124, 136], "legend": [1, 2, 9, 23, 25, 26, 28, 32, 47, 69, 72, 82, 92, 107, 108, 109, 115, 121, 128, 136, 137], "legendr": 69, "legion": 113, "lehrwerk": 58, "lei": 113, "lemma": 104, "len": [1, 4, 8, 10, 19, 22, 23, 25, 26, 28, 29, 31, 32, 35, 36, 49, 56, 62, 66, 72, 73, 79, 85, 86, 87, 88, 90, 91, 92, 95, 96, 97, 99, 107, 108, 115, 117, 123, 125, 127, 128, 129, 132, 134, 135, 137], "len_dataset": 25, "len_label": 129, "len_pr": 129, "lend": 58, "lenet": [34, 37, 38, 40, 42, 51, 54, 55, 62, 80, 107, 113, 142], "length": [1, 3, 4, 5, 6, 9, 10, 11, 27, 28, 29, 30, 33, 35, 43, 47, 48, 49, 58, 64, 66, 69, 73, 75, 81, 85, 86, 87, 89, 90, 91, 92, 96, 97, 98, 103, 104, 114, 117, 119, 121, 122, 123, 124, 126, 127, 129, 130, 131, 132, 135, 136, 137], "lengthscal": [47, 48, 49], "lenient": 109, "lens": 60, "leon": 43, "leonard": 113, "leq": [2, 3, 9, 32, 60, 65, 69, 79, 83, 89, 98, 102, 104, 105, 110, 112, 117, 121, 130, 135], "less": [1, 2, 6, 7, 10, 11, 22, 23, 26, 28, 35, 39, 43, 47, 48, 52, 55, 58, 60, 61, 71, 74, 79, 80, 82, 87, 90, 91, 97, 98, 99, 102, 104, 107, 108, 109, 110, 113, 114, 117, 121, 128, 132, 137, 139, 141], "lessapprox": 105, "lesson": 61, "lest": 119, "let": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 54, 56, 59, 60, 61, 62, 64, 66, 69, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 85, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 139, 140, 141], "letter": [1, 62, 91, 100, 117, 128], "level": [5, 6, 10, 13, 21, 24, 25, 26, 27, 30, 31, 33, 34, 35, 37, 41, 43, 45, 46, 47, 48, 49, 54, 55, 56, 58, 60, 61, 62, 64, 65, 69, 70, 72, 76, 77, 80, 81, 84, 86, 96, 101, 113, 117, 121, 123, 125, 127, 128, 131, 132, 134, 135, 137, 142], "leverag": [6, 13, 15, 22, 24, 26, 27, 28, 30, 42, 58, 60, 66, 69, 80, 83, 90, 93, 94, 113, 114, 119, 134, 135], "levi": 113, "lfloor": [25, 44, 132], "lgov": 113, "li": [8, 30, 32, 35, 51, 65, 77, 83, 88, 101, 112, 113], "liabl": 35, "liang": 113, "lib": [54, 55], "liber": 114, "liberti": 43, "librari": [3, 12, 13, 47, 51, 57, 58, 69, 70, 72, 76, 103, 108, 113, 114, 115, 116, 117, 118, 119, 120, 134, 135], "libratu": 58, "lie": [2, 51, 58, 61, 80, 121, 125], "life": [46, 50, 62, 65, 67, 101, 111], "lift": [16, 64, 119, 120], "lifu": 113, "light": [35, 58, 61, 71, 83, 112, 121, 141], "lighter": [125, 126], "lightli": 34, "lightn": 72, "lightweight": [6, 72, 105, 113], "like": [1, 6, 11, 12, 15, 18, 24, 27, 28, 32, 34, 35, 39, 45, 46, 47, 48, 49, 51, 52, 58, 60, 64, 65, 66, 67, 69, 70, 71, 73, 74, 77, 79, 80, 82, 84, 88, 91, 93, 102, 107, 109, 110, 112, 113, 117, 119, 120, 121, 122, 124, 125, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "likelihood": [19, 46, 47, 48, 58, 60, 61, 66, 69, 74, 77, 80, 83, 98, 104, 110, 121, 132, 136], "liken": [35, 58], "likewis": [3, 15, 33, 39, 58, 60, 64, 65, 69, 73, 80, 82, 86, 102, 105, 108, 114, 117, 119, 121, 125, 127, 132], "likun": 113, "lim_": [41, 49, 104, 115, 141], "limelight": 58, "limit": [2, 3, 4, 6, 8, 18, 21, 22, 30, 32, 34, 39, 40, 46, 47, 49, 54, 55, 58, 61, 64, 65, 66, 69, 74, 77, 84, 90, 104, 107, 109, 111, 112, 113, 115, 117, 120, 121, 132, 135], "lin": 113, "lin1": 76, "lin2": 76, "lin3": 76, "lin_func": 49, "linalg": [47, 114, 117], "line": [1, 6, 18, 25, 28, 32, 34, 39, 41, 47, 48, 49, 51, 57, 58, 61, 65, 66, 69, 70, 72, 76, 77, 80, 81, 85, 87, 91, 95, 97, 102, 104, 115, 117, 120, 121, 128, 137], "linear": [1, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 26, 28, 30, 34, 35, 36, 37, 39, 40, 43, 47, 49, 50, 52, 54, 58, 59, 60, 61, 62, 65, 66, 67, 72, 73, 76, 77, 79, 81, 82, 86, 88, 90, 102, 104, 105, 107, 108, 109, 113, 114, 115, 116, 119, 121, 129, 130, 131, 134, 136, 142], "linearli": [7, 9, 11, 69, 70, 71, 80, 89, 102, 111, 112], "linearregress": [70, 74, 79, 136], "linearregressionscratch": [71, 74], "linen": 113, "liner": 101, "linestyl": [1, 121], "linewidth": [1, 20, 47, 49], "lingual": 5, "linguist": [69, 83, 96], "link": [22, 76, 79, 113, 131], "linnaeu": 58, "linreg": [1, 108], "linspac": [47, 49, 110], "linux": [57, 58], "lipschitz": 135, "lipton": 8, "liqingnz": 113, "lisa": 113, "lisp": [43, 70, 80], "list": [1, 11, 15, 17, 19, 21, 23, 25, 26, 27, 29, 32, 47, 56, 58, 60, 62, 66, 72, 73, 83, 85, 91, 93, 95, 96, 97, 108, 113, 115, 118, 119, 121, 127, 128, 135, 136, 137], "listdir": [25, 26, 87], "lite": 35, "liter": [58, 76, 119], "literatur": [6, 35, 41, 58, 61, 69, 104], "littl": [2, 5, 6, 47, 61, 65, 67, 97, 104, 105, 108, 109, 121, 132, 136], "liujun": 113, "liusy182": 113, "live": [18, 24, 47, 58, 60, 70, 120], "livelihood": 58, "liweiwp": 113, "lkelihood": 47, "lkevinzc": 113, "ll": [1, 47], "llama": 6, "llm": 1, "ln": [10, 35, 115], "ln1": 11, "ln2": 11, "lo": [23, 25, 26, 79], "load": [1, 12, 13, 19, 20, 22, 25, 28, 29, 30, 31, 45, 63, 70, 72, 73, 86, 87, 91, 92, 94, 117, 120, 126, 127, 129, 134, 135, 137], "load_arrai": [1, 87, 108], "load_cifar10": 23, "load_data_banana": [29, 32], "load_data_fashion_mnist": [1, 107], "load_data_imdb": [87, 88], "load_data_nmt": 1, "load_data_ptb": [97, 99], "load_data_snli": [85, 86], "load_data_voc": [21, 31], "load_data_wiki": [91, 92], "load_experi": [54, 55], "load_fashion_mnist": 1, "load_imag": [25, 29, 31], "load_images_from_fold": 22, "load_weight": [1, 17], "loader": [52, 62, 68, 71, 72, 81, 132], "loan": [60, 80, 117], "loc": [1, 3, 40, 66, 71, 79, 82, 108, 112], "local": [1, 2, 9, 11, 12, 20, 28, 39, 40, 41, 47, 52, 54, 79, 88, 107, 108, 112], "local_backend": [54, 55], "local_var": 1, "localhost": 57, "localsearch": [51, 54], "locat": [2, 8, 18, 19, 20, 31, 35, 40, 41, 44, 45, 46, 47, 48, 49, 57, 58, 60, 72, 80, 108, 110, 115, 117, 119, 120, 136, 139, 140, 141], "lock": 18, "log": [18, 19, 25, 26, 32, 47, 49, 52, 54, 55, 56, 61, 65, 66, 69, 74, 79, 82, 83, 87, 89, 93, 98, 99, 100, 104, 105, 108, 114, 115, 122, 132, 137], "log_2": 100, "logarithm": [52, 64, 66, 69, 70, 79, 80, 89, 93, 100, 121, 122], "logdet": 47, "logic": [13, 34, 36, 58, 85, 86, 90, 113, 119, 132, 133], "logist": [52, 58, 60, 64, 80, 131], "logit": [15, 64, 65], "logsumexp": 65, "loguniform": [51, 52, 54, 55, 56], "long": [3, 4, 5, 8, 9, 10, 17, 18, 19, 21, 31, 34, 35, 38, 42, 47, 49, 51, 52, 54, 55, 58, 60, 62, 64, 69, 72, 75, 85, 90, 91, 92, 99, 104, 107, 109, 110, 111, 112, 114, 115, 121, 122, 125, 126, 130, 131, 132, 133, 136, 138, 139, 141, 142], "longer": [4, 6, 7, 20, 34, 35, 37, 46, 55, 56, 58, 62, 69, 76, 79, 80, 81, 85, 96, 102, 103, 104, 105, 109, 114, 117, 122, 129, 132, 137], "longest": [58, 96, 129], "longform": 5, "longrightarrow": 60, "look": [2, 9, 12, 14, 15, 21, 29, 31, 34, 35, 37, 39, 40, 41, 44, 46, 47, 48, 49, 51, 52, 54, 58, 60, 61, 62, 64, 66, 69, 72, 73, 74, 77, 79, 80, 82, 90, 91, 102, 104, 105, 107, 108, 109, 110, 112, 121, 122, 130, 131, 132, 133, 136, 137, 140], "loop": [12, 15, 16, 28, 34, 41, 52, 54, 58, 60, 62, 66, 69, 70, 71, 74, 81, 92, 114, 130, 135], "loos": 112, "lose": [17, 18, 40, 44, 58, 121], "loss": [1, 6, 16, 18, 21, 22, 23, 24, 25, 26, 30, 34, 37, 39, 41, 43, 47, 52, 55, 58, 59, 60, 61, 63, 65, 67, 68, 72, 74, 75, 77, 79, 80, 81, 83, 86, 88, 89, 90, 91, 92, 93, 97, 98, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 121, 126, 130, 132, 133, 135, 136], "loss_and_grad_fn": [1, 23, 28, 32, 99, 107, 108], "loss_fn": [1, 25, 26, 28, 32, 41, 72, 92, 99, 107, 108, 135], "lost": [4, 10, 35, 46, 121, 129, 137], "lot": [15, 18, 22, 28, 30, 33, 34, 38, 46, 47, 58, 60, 64, 69, 73, 87, 102, 105, 107, 109, 114, 117, 130, 132, 136, 137], "lotfrontag": 79, "loui": 113, "lousi": 70, "love": [6, 95, 98, 113], "low": [11, 13, 14, 34, 35, 37, 58, 60, 67, 69, 73, 77, 79, 80, 97, 117, 121, 123, 135], "lower": [1, 6, 9, 10, 19, 20, 29, 30, 34, 39, 41, 45, 46, 52, 58, 61, 64, 67, 69, 75, 76, 80, 91, 105, 107, 112, 115, 117, 121, 128, 129, 137], "lowercas": [1, 91, 96, 100, 117, 128], "lowest": [9, 34, 52, 55, 64, 104], "lr": [1, 4, 10, 11, 21, 22, 23, 25, 26, 28, 34, 35, 36, 37, 39, 41, 43, 51, 52, 54, 55, 59, 65, 66, 70, 71, 74, 76, 79, 81, 86, 88, 92, 99, 101, 102, 103, 107, 108, 109, 111, 112, 123, 125, 127, 129, 134, 135, 136], "lr_decai": [25, 26], "lr_decay_epoch": 28, "lr_mult": 22, "lr_period": [25, 26], "lr_schedul": [26, 107], "lstm": [4, 5, 90, 123, 125, 126, 129, 142], "lstmscratch": 127, "lucki": [34, 39, 60, 67, 105], "lukovenko": 113, "lump": 128, "lumsdain": 113, "lunch": 77, "lung": 121, "lurk": 46, "luxuri": 35, "lw": 19, "lw_bd": [47, 49], "lw_bd_observ": 47, "ly": [58, 104, 121, 122, 136], "l\u00fcer": 113, "m": [1, 2, 3, 4, 8, 10, 11, 19, 29, 35, 47, 48, 49, 58, 60, 75, 82, 86, 89, 93, 96, 98, 102, 104, 108, 110, 115, 117, 121, 129, 130, 132, 133, 137], "m1": [34, 117], "m2": 117, "m_": [47, 110], "m_1": 49, "m_2": 49, "m_i": 97, "mac": 57, "machin": [1, 4, 5, 6, 8, 10, 11, 13, 18, 30, 34, 35, 43, 46, 47, 48, 49, 50, 52, 53, 54, 57, 61, 62, 63, 64, 67, 69, 71, 72, 73, 74, 77, 79, 83, 84, 85, 86, 87, 94, 103, 104, 111, 113, 114, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 130, 131, 133, 134, 135, 136, 137, 138, 142], "machineri": 58, "mackai": 47, "maco": 57, "macosx": 57, "made": [5, 11, 34, 35, 36, 39, 43, 46, 50, 58, 60, 61, 64, 65, 82, 113, 120, 125, 127, 135, 138], "mae": [6, 32], "magic": [15, 35, 71], "magnitud": [3, 6, 34, 35, 46, 52, 58, 67, 69, 82, 102, 103, 105, 107, 117], "magnum": 132, "mahdi": 113, "mai": [3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 102, 103, 104, 105, 107, 110, 113, 117, 120, 121, 122, 124, 128, 129, 132, 133, 136, 138, 139], "mail": 58, "main": [18, 20, 28, 30, 34, 36, 39, 52, 54, 55, 58, 69, 71, 89, 91, 92, 98, 101, 102, 104, 108, 119, 136, 141], "mainli": [31, 32, 58, 60], "mainstai": [3, 34, 58, 77, 126], "maintain": [13, 35, 56, 58, 61, 67, 72, 82, 101, 102, 109, 113, 136, 141], "major": [3, 5, 6, 20, 24, 30, 34, 35, 39, 46, 51, 58, 61, 62, 86, 98, 113, 121, 124, 128, 136], "make": [1, 3, 5, 6, 8, 9, 11, 13, 15, 16, 17, 18, 23, 25, 26, 27, 28, 30, 31, 32, 34, 35, 37, 38, 39, 40, 43, 44, 46, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 74, 77, 79, 80, 81, 87, 89, 91, 93, 94, 102, 104, 105, 107, 108, 110, 112, 113, 114, 119, 121, 129, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141], "make_env": [1, 140, 141], "make_lay": 1, "make_list": 19, "makedir": [1, 25, 120], "maker": 83, "mal": 5, "male": 95, "malevol": 58, "malici": 71, "man": [83, 85, 95, 96, 98, 132, 137], "manag": [13, 58, 67, 77, 87, 107, 113, 121, 142], "manhattan": 117, "mani": [2, 4, 5, 6, 8, 15, 18, 19, 20, 22, 23, 24, 27, 28, 30, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 56, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 73, 76, 77, 79, 80, 82, 86, 89, 93, 94, 96, 97, 102, 103, 104, 105, 107, 108, 110, 112, 113, 115, 117, 121, 123, 126, 127, 128, 131, 132, 133, 135, 136, 137, 138, 140, 141], "mani2106": 113, "manifest": [60, 130], "manipul": [7, 10, 16, 19, 46, 48, 58, 60, 64, 73, 74, 113, 114, 115, 116, 117, 137, 142], "manner": [2, 8, 46, 53, 58, 60, 72, 76, 84, 103, 106, 107, 108, 109, 112, 114, 125, 137], "mansion": 64, "mantissa": 82, "manual": [6, 25, 34, 37, 39, 41, 45, 52, 58, 90, 120], "manuel": 113, "manufactur": 121, "mao": 113, "maomao": 113, "map": [9, 17, 21, 25, 27, 30, 31, 32, 33, 36, 37, 39, 40, 42, 43, 45, 46, 51, 52, 58, 64, 66, 80, 88, 96, 97, 98, 99, 104, 105, 108, 115, 117, 119, 121, 124, 127, 128, 130, 132, 137], "marcel": 113, "march": 120, "margin": [11, 34, 35, 47, 48, 60, 121], "mark": [1, 6, 30, 37, 41, 79, 83, 90, 113, 115, 118, 128, 129], "marker": [54, 55], "market": [34, 58, 60, 87, 131], "markov": [4, 58, 121, 133, 138, 140, 141, 142], "markovian": 139, "markovitz": 121, "marri": [38, 113], "marsel": 113, "marvel": [60, 113], "mask": [6, 10, 19, 21, 24, 31, 32, 58, 76, 83, 92, 97, 99, 126], "masked_softmax": 3, "masked_token": 91, "masked_x": 90, "masklm": 90, "masks_batch": 97, "mass": [49, 58, 83, 136], "massiv": [5, 30, 58, 67, 77, 79, 94, 114, 130, 135, 136], "master": [35, 58, 61, 80, 114, 127], "mastercard": 58, "mat": 52, "match": [1, 3, 6, 8, 9, 15, 34, 43, 44, 45, 46, 47, 58, 59, 64, 66, 73, 79, 85, 109, 114, 115, 119, 121, 125, 129], "materi": [24, 35, 60, 103, 113, 131], "matern": 47, "matern_kernel": 47, "math": [1, 3, 7, 9, 10, 25, 34, 47, 52, 64, 69, 72, 87, 91, 97, 99, 101, 102, 103, 107, 111, 112, 129, 135], "mathbb": [2, 3, 7, 8, 9, 10, 19, 28, 46, 52, 56, 60, 64, 69, 73, 75, 80, 86, 98, 100, 102, 104, 105, 108, 112, 115, 117, 119, 123, 125, 127, 130, 133, 136, 139, 140], "mathbf": [2, 3, 4, 7, 8, 9, 10, 15, 19, 28, 33, 35, 36, 39, 41, 46, 47, 52, 56, 60, 61, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 80, 82, 86, 89, 90, 93, 96, 98, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 114, 115, 117, 119, 121, 122, 123, 125, 127, 129, 130, 131, 132, 133, 135, 136], "mathcal": [8, 9, 19, 35, 39, 40, 47, 48, 49, 52, 56, 61, 64, 69, 71, 74, 76, 89, 93, 96, 98, 100, 102, 104, 105, 107, 108, 109, 111, 112, 121, 122, 133, 135, 139, 140, 141], "mathemat": [6, 7, 9, 15, 35, 36, 38, 39, 46, 58, 61, 64, 65, 66, 69, 74, 75, 76, 77, 80, 82, 93, 104, 109, 110, 113, 115, 117, 119, 121, 122, 125, 127, 130, 133, 139, 141], "mathematician": [58, 80, 115], "mathit": [3, 8, 11, 39, 122], "mathop": [2, 8, 39, 60, 103, 104, 107], "mathresearch": 113, "mathrm": [2, 3, 39, 52, 55, 56, 60, 64, 66, 80, 104, 107, 133, 140, 141], "mathsf": [33, 46, 75, 100, 117], "matmul": [1, 3, 12, 28, 33, 40, 66, 71, 73, 74, 81, 82, 86, 95, 108, 117, 125, 127, 133, 135], "matplotlib": [19, 20, 21, 22, 23, 27, 28, 29, 31, 32, 47, 55, 62, 69, 71, 73, 74, 79, 80, 82, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 120, 121, 135, 136, 140, 141], "matplotlib_inlin": [113, 115], "matric": [3, 8, 9, 14, 18, 28, 33, 34, 39, 46, 64, 74, 75, 81, 82, 100, 104, 108, 109, 113, 114, 115, 116, 119, 130, 133, 135], "matrix": [2, 8, 9, 18, 19, 24, 28, 34, 35, 39, 40, 41, 42, 43, 44, 47, 48, 49, 58, 59, 60, 64, 66, 69, 70, 71, 73, 75, 76, 80, 81, 82, 90, 99, 100, 102, 104, 105, 108, 109, 110, 114, 115, 116, 119, 121, 129, 130, 133, 135], "matteoferrara": 113, "matter": [6, 9, 34, 35, 37, 41, 43, 52, 58, 67, 69, 74, 78, 80, 81, 94, 105, 107, 108, 109, 111, 117, 121, 130, 133], "matthau": 87, "matthew": 113, "matthia": [53, 113], "matur": [13, 113], "max": [2, 19, 21, 25, 28, 30, 32, 34, 36, 37, 39, 43, 45, 54, 55, 56, 64, 80, 84, 90, 91, 96, 97, 104, 105, 107, 140, 141], "max_": [140, 141], "max_epoch": [4, 10, 11, 18, 34, 35, 36, 37, 39, 43, 51, 52, 54, 55, 56, 65, 66, 70, 71, 72, 74, 76, 79, 81, 123, 125, 127, 129, 134, 135, 136], "max_exampl": 128, "max_freq_pair": 96, "max_i": 97, "max_idx": 19, "max_iou": 19, "max_k": 65, "max_len": [9, 90, 91, 92, 97, 99], "max_norm": 1, "max_num_mlm_pr": 91, "max_number_of_epoch": [55, 56], "max_pixel_valu": 28, "max_resource_attr": 55, "max_step": 107, "max_t": 55, "max_upd": 107, "max_wallclock_tim": [54, 55], "max_window_s": [97, 99], "maxim": [47, 54, 64, 69, 77, 83, 89, 98, 104, 110, 117, 121, 122, 138, 140, 141], "maximilian": 113, "maximimum": 69, "maximum": [2, 9, 10, 24, 30, 32, 42, 52, 56, 60, 64, 67, 69, 80, 81, 88, 91, 92, 97, 98, 107, 110, 122], "maxlen": 3, "maxpool": 107, "maxpool2d": [1, 32, 34, 36, 37, 39, 45, 107], "mayb": 58, "maze": 114, "mb": [34, 58], "mcclenni": 113, "mcconchi": 60, "mcculloch": [69, 80], "mdp": [1, 138, 140, 141, 142], "me": 137, "mean": [1, 2, 3, 5, 8, 10, 12, 14, 19, 21, 22, 25, 26, 28, 31, 32, 34, 35, 36, 37, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71, 73, 74, 76, 77, 79, 80, 82, 83, 90, 92, 98, 99, 100, 102, 104, 105, 107, 108, 109, 112, 115, 117, 119, 120, 121, 127, 130, 132, 135, 137, 140, 141], "meaning": [34, 43, 79, 81, 89, 98, 102, 109, 112, 132, 139], "meaningfulli": 77, "meaningless": [47, 89, 107], "meansquarederror": 108, "meant": 35, "meanvec": 49, "meanwhil": 5, "measur": [7, 18, 19, 25, 26, 28, 43, 46, 47, 58, 59, 60, 61, 64, 67, 69, 71, 72, 74, 76, 77, 78, 80, 81, 83, 85, 93, 108, 117, 120, 121, 129, 131, 132], "meat": 83, "mechan": [2, 3, 7, 8, 9, 10, 34, 45, 47, 48, 49, 58, 60, 63, 64, 66, 71, 74, 75, 80, 84, 86, 88, 103, 113, 117, 119, 121, 125, 126, 127, 129, 142], "media": [87, 94], "median": [51, 79], "mediat": [54, 60], "medic": [24, 31, 58, 66, 67, 131, 137], "medicin": [58, 64, 91, 113, 136], "medina": 113, "meet": [22, 25, 80], "megabyt": [34, 43, 119], "megapixel": [34, 46, 67], "megatron": [3, 6], "mellon": 58, "mem": 87, "member": [51, 67, 72], "membership": [69, 80, 100, 117], "meme": 37, "memor": [35, 58, 61, 67, 77], "memori": [1, 3, 10, 17, 18, 26, 31, 34, 36, 37, 39, 40, 41, 44, 52, 58, 60, 62, 65, 67, 69, 73, 75, 81, 97, 102, 108, 114, 116, 117, 120, 125, 126, 130, 133, 137, 142], "men": [58, 60], "menac": 120, "menial": [58, 114], "mental": 60, "mention": [15, 19, 23, 26, 28, 32, 35, 36, 58, 93, 122, 130, 133, 135, 136], "mere": [58, 60, 61, 69, 77, 80, 130], "merg": [19, 96], "merge_symbol": 96, "mesh": 58, "meshgrid": [19, 105, 110], "messag": [41, 60], "messi": [81, 120], "met": [58, 69, 77], "meta": 58, "metadata": 34, "metamind": 91, "meteorologi": 46, "meter": [105, 121], "method": [2, 5, 6, 7, 8, 9, 10, 13, 14, 19, 20, 22, 24, 25, 27, 30, 31, 32, 34, 35, 38, 41, 46, 47, 48, 50, 51, 52, 54, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 80, 81, 82, 86, 88, 89, 91, 93, 97, 98, 99, 102, 104, 106, 107, 111, 113, 114, 117, 118, 121, 122, 123, 124, 128, 130, 131, 132, 135, 136, 137, 138, 140], "methodolog": 5, "methodologi": 51, "metric": [1, 23, 25, 26, 32, 47, 52, 54, 55, 56, 77, 92, 99, 107, 121], "mf": 58, "mflop": [34, 62], "michael": 113, "microphon": 58, "microprocessor": [34, 99], "microscop": 58, "microsoft": 58, "mid": [59, 60, 64, 69, 74, 89, 93, 98, 100, 104, 121, 122, 127, 129, 132, 133, 135, 136, 139, 140, 141], "middl": [19, 23, 37, 41, 58], "midrang": 108, "mietchen": 113, "might": [2, 4, 5, 8, 11, 15, 17, 18, 26, 34, 35, 39, 41, 43, 44, 45, 46, 47, 48, 52, 54, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 125, 130, 131, 132, 135, 136, 137, 139], "mike": 113, "mikhail": 113, "mild": [60, 77], "milder": 67, "mileston": 107, "millimet": 105, "million": [6, 11, 22, 27, 34, 46, 47, 58, 61, 67, 77, 79, 80, 83, 89, 90, 92], "mimic": 105, "mimick": 39, "min": [18, 19, 21, 30, 54, 55, 56, 60, 80, 85, 91, 97, 104, 105, 107, 110, 129, 135], "min_freq": [1, 85, 87, 91, 97, 128, 137], "min_number_of_epoch": [55, 56], "min_q": 140, "mind": [5, 9, 13, 58, 61, 67, 73, 88, 108, 139], "mine": 58, "minerva": 6, "ming": 113, "mini": [23, 47, 51, 52, 140], "mini1_r": 108, "mini2_r": 108, "minibatch": [1, 3, 4, 6, 10, 18, 23, 29, 31, 32, 35, 43, 58, 59, 60, 63, 64, 66, 70, 71, 73, 74, 75, 80, 82, 85, 86, 87, 91, 92, 93, 94, 99, 102, 103, 106, 107, 109, 110, 123, 125, 128, 129, 132, 133, 135, 142], "miniconda3": 57, "minim": [2, 6, 16, 28, 39, 43, 47, 52, 53, 54, 58, 59, 60, 61, 64, 69, 74, 77, 80, 83, 84, 90, 93, 98, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 117, 130, 140], "minima": [69, 112], "minimum": [19, 37, 40, 41, 45, 54, 56, 60, 69, 102, 104, 105, 107, 109, 110, 112], "minor": [1, 2, 3], "minu": 41, "minut": [43, 54, 55, 58, 60, 117, 122], "miotto": 113, "miracul": 122, "mirror": [44, 58], "misalign": 81, "misclassif": 60, "misclassifi": [32, 58, 60], "misestim": 61, "misgiv": 61, "mislabel": 77, "mislead": [6, 61], "mismatch": [3, 72, 90, 105], "misnom": [35, 41, 69], "misplac": 49, "miss": [1, 29, 48, 79, 117, 120, 132], "misshapen": 58, "mistak": [18, 58, 62], "mitig": [23, 45, 52, 58, 60, 74, 77, 80, 82, 102, 126, 128, 135, 140], "mitro": 113, "mix": [15, 40, 60, 61, 79, 109, 113], "mixtur": 47, "ml": [50, 52], "mlm": [90, 92], "mlm_in_featur": [90, 92], "mlm_input_token": 91, "mlm_l": [90, 92], "mlm_l_mean": 92, "mlm_label": [91, 92], "mlm_posit": 90, "mlm_pred_label": 91, "mlm_pred_label_id": 91, "mlm_pred_posit": 91, "mlm_weight": [91, 92], "mlm_weights_x": [91, 92], "mlm_weights_x_shard": 92, "mlm_y": [90, 91, 92], "mlm_y_hat": [90, 92], "mlm_y_shard": 92, "mlp": [3, 10, 11, 13, 15, 16, 17, 35, 36, 40, 42, 43, 51, 75, 76, 77, 80, 81, 82, 83, 84, 86, 90, 110, 123, 125, 130, 133], "mlp_num_hidden": 11, "mlp_num_input": 11, "mlp_num_output": 11, "mlpscratch": 81, "mlx": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 47, 49, 51, 52, 54, 55, 56, 59, 62, 65, 66, 69, 70, 71, 72, 73, 74, 76, 79, 80, 81, 82, 85, 86, 87, 88, 90, 91, 92, 95, 97, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 132, 133, 134, 135, 136, 137, 140, 141], "mlx_one_hot": 135, "mlx_reshap": 62, "mlxd": 113, "mlxdataload": 91, "mlxdataloadersnli": 85, "mlxim": [1, 21, 22, 26], "mn": [86, 117], "mnemon": 141, "mnist": [1, 11, 22, 23, 29, 34, 35, 37, 39, 43, 52, 58, 62, 65, 66, 76, 81, 102, 107, 111, 131], "mnist_test": 1, "mnist_test_it": 1, "mnist_train": 1, "mnist_train_it": 1, "mo": 113, "mobil": [34, 58], "mobilenet": 38, "modal": [2, 6, 58, 131], "mode": [6, 10, 21, 31, 35, 45, 54, 55, 58, 64, 73, 76, 107], "model": [1, 3, 5, 8, 9, 12, 13, 15, 16, 18, 19, 20, 23, 24, 27, 28, 29, 30, 31, 34, 35, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 60, 61, 62, 63, 68, 73, 75, 77, 78, 82, 83, 84, 85, 87, 89, 92, 94, 95, 97, 101, 102, 103, 104, 106, 107, 108, 110, 112, 113, 114, 115, 117, 120, 121, 122, 123, 124, 126, 128, 129, 130, 131, 137, 138, 139, 142], "model_config": 1, "model_nam": 1, "model_weight": 1, "model_zoo": [21, 22, 26], "moder": [35, 48, 56, 82, 109], "modern": [2, 3, 5, 8, 10, 34, 35, 37, 39, 42, 43, 58, 61, 62, 64, 70, 71, 77, 80, 82, 107, 113, 114, 117, 119, 128, 130, 131, 135, 136, 137, 142], "modest": [55, 113], "modif": [13, 37, 54, 58, 73, 91, 137], "modifi": [3, 4, 6, 11, 19, 26, 28, 30, 34, 36, 39, 47, 51, 58, 73, 87, 89, 102, 107, 108, 113, 115, 135, 140], "modul": [1, 3, 4, 7, 9, 10, 11, 12, 13, 14, 16, 17, 26, 28, 32, 34, 35, 36, 37, 39, 41, 43, 56, 59, 62, 70, 71, 72, 82, 86, 88, 90, 99, 113, 116, 123, 124, 125, 127, 129, 134, 135, 142], "modular": [70, 72, 81], "moham": 113, "mohammad": 113, "moi": [4, 10, 129], "molecul": 64, "moment": [3, 5, 41, 49, 58, 66, 77, 101, 103, 113, 132], "momentum": [21, 25, 26, 35, 52, 101, 102, 103, 105, 106, 111, 142], "momentum_2d": 109, "monarch": 35, "monei": [22, 60, 94, 121], "monik": 107, "monitor": [24, 31, 58, 60, 71, 77, 79], "monkei": 132, "monochromat": 42, "monomi": [74, 76], "monoton": [9, 64, 77, 80, 104], "mont": [47, 58], "month": [34, 43, 58, 70], "moor": 58, "moral": 58, "more": [1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 16, 18, 19, 22, 23, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 89, 90, 91, 93, 94, 96, 97, 98, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 122, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140], "moreov": [3, 5, 6, 8, 15, 18, 20, 30, 34, 36, 37, 44, 45, 46, 49, 51, 54, 55, 58, 60, 61, 64, 65, 67, 69, 71, 72, 74, 77, 80, 81, 82, 97, 101, 103, 104, 105, 107, 110, 112, 113, 114, 120, 121, 123, 129, 130, 131, 134], "morn": 60, "morpholog": 96, "morphologi": 96, "mortal": 77, "most": [0, 3, 4, 5, 6, 8, 14, 15, 16, 18, 22, 23, 24, 31, 34, 38, 40, 41, 42, 44, 47, 49, 52, 53, 55, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 69, 71, 72, 74, 75, 76, 77, 79, 80, 83, 88, 91, 95, 96, 99, 102, 104, 107, 108, 109, 110, 113, 114, 116, 117, 119, 120, 121, 122, 126, 127, 128, 129, 130, 134, 135, 136, 137, 140], "most_common": 25, "mostli": [34, 35, 46, 48, 51, 58, 76, 112], "motion": [58, 139], "motiv": [23, 35, 39, 41, 42, 44, 46, 61, 69, 74, 77, 90, 104, 113, 121, 131, 137, 142], "motorbik": 31, "mouill\u00e9": 10, "mount": 28, "mountain": 58, "mountaincar": 139, "mouth": 31, "move": [4, 12, 13, 16, 18, 19, 26, 27, 32, 35, 39, 43, 44, 45, 46, 47, 48, 49, 58, 69, 80, 82, 102, 103, 105, 107, 108, 111, 114, 115, 131, 132, 135, 138, 139, 140, 141], "movement": 45, "movi": [37, 58, 64, 87, 88, 90, 113, 136, 138], "moving_mean": 35, "moving_var": 35, "mpl_toolkit": [104, 110], "mplot3d": [104, 110], "mse": [79, 107], "mse_loss": [70, 108], "mseloss": 70, "mssubclass": 79, "mszone": 79, "mszoning_rl": 79, "mszoning_rm": 79, "mtfraeng": [4, 10, 128, 129], "mtn": 113, "mu": [8, 35, 47, 48, 49, 58, 60, 61, 69, 73, 79, 121], "mu_h": 19, "mu_i": [19, 47, 49, 121], "mu_w": 19, "mu_x": 19, "much": [2, 3, 4, 6, 18, 22, 29, 30, 32, 34, 35, 37, 39, 40, 43, 46, 47, 49, 50, 52, 55, 58, 60, 61, 62, 64, 66, 67, 69, 70, 72, 74, 79, 80, 81, 85, 86, 93, 94, 101, 102, 103, 104, 105, 108, 109, 112, 113, 114, 115, 116, 117, 120, 121, 125, 127, 128, 130, 131, 132, 135, 136, 137], "mucs\u00e1nyi": 113, "muddier": 67, "muhyun": 113, "mujoco": 58, "multi": [5, 6, 9, 10, 11, 18, 38, 39, 40, 45, 52, 53, 58, 64, 88, 103, 132, 142], "multibox": [24, 30, 142], "multibox_detect": [19, 32], "multibox_prior": [19, 27, 32], "multibox_target": [19, 32], "multichannel": 34, "multiclass": [2, 58, 59, 61, 79], "multidimension": [46, 104, 119], "multifactorschedul": 107, "multiheadattent": [7, 9, 10, 11], "multilay": [5, 11, 34, 58, 77, 113, 123, 129, 131, 142], "multilingu": 6, "multimod": 6, "multinomi": [8, 118, 121], "multipl": [1, 6, 7, 9, 10, 15, 16, 18, 20, 21, 22, 24, 27, 28, 30, 34, 35, 36, 37, 39, 41, 42, 43, 46, 51, 52, 54, 55, 61, 64, 65, 67, 69, 70, 72, 73, 75, 78, 79, 80, 81, 86, 88, 91, 93, 95, 98, 99, 107, 108, 109, 112, 115, 116, 119, 120, 123, 125, 126, 127, 128, 129, 130, 133, 140, 142], "multipli": [2, 3, 9, 10, 25, 26, 30, 33, 40, 41, 69, 75, 82, 88, 104, 108, 109, 115, 117, 121, 130, 133, 136], "multiscal": [24, 32, 142], "multiset": 93, "multistep": 136, "multistep_pr": 136, "multisteplr": 107, "multitask": 6, "multitud": 58, "multivari": [47, 48, 49, 74, 106, 115], "multivariate_norm": [47, 49, 118], "murat": 113, "murki": 67, "murphi": 46, "muscl": [65, 69], "mushroom": 58, "music": [58, 131], "musician": [58, 85], "must": [1, 6, 12, 15, 27, 32, 35, 39, 43, 58, 59, 60, 61, 62, 64, 67, 69, 71, 74, 75, 76, 77, 80, 81, 85, 93, 110, 113, 119, 120, 121, 128, 130, 131, 132, 135, 136, 137], "musthafa": 60, "musto": 113, "mutual": [58, 89, 121, 126], "mv": [95, 99], "mx": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 47, 49, 52, 59, 62, 65, 66, 69, 70, 71, 72, 73, 74, 76, 79, 80, 81, 82, 85, 86, 87, 88, 90, 91, 92, 95, 97, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 117, 119, 120, 123, 124, 125, 127, 128, 129, 132, 133, 134, 135, 136, 137], "mxnet": [1, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 33, 58, 70, 85, 86, 87, 91, 92, 95, 97, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 119], "my": [5, 121, 137], "mycologist": 58, "mydict": 17, "mydict2": 17, "mylinear": 12, "myopic": 79, "myriad": [77, 120, 126], "mysequenti": 15, "mysteri": [8, 77, 115], "mzz2017": 113, "m\u00fcller": 113, "n": [1, 2, 3, 9, 11, 19, 20, 21, 23, 25, 26, 28, 30, 31, 32, 35, 44, 47, 48, 49, 52, 55, 56, 60, 61, 64, 66, 67, 69, 72, 73, 74, 75, 76, 79, 80, 82, 85, 86, 87, 88, 89, 96, 97, 98, 100, 104, 105, 108, 112, 115, 117, 119, 121, 123, 125, 127, 128, 129, 130, 133, 135, 137, 140], "n0": 56, "n1": 117, "n2": 117, "n95": 83, "n_": [41, 44, 82, 121], "n_1": 89, "n_a": 19, "n_b": 19, "n_h": 33, "n_i": [97, 137], "n_k": 89, "n_sampl": 49, "n_train": 136, "n_valid_per_label": 25, "n_w": 33, "n_worker": [54, 55], "na": [1, 52, 79, 120], "nabla": [104, 105, 112, 115], "nabla_": [8, 33, 100, 115, 140], "nadaraya": [5, 8], "nadaraya_watson": 2, "naiv": [40, 47, 58, 61, 69, 102, 108], "name": [1, 2, 3, 4, 6, 8, 13, 14, 16, 17, 21, 22, 23, 24, 25, 26, 31, 33, 34, 35, 36, 39, 41, 43, 45, 46, 51, 52, 54, 55, 57, 58, 60, 62, 64, 72, 77, 81, 82, 90, 97, 98, 101, 106, 110, 111, 112, 113, 115, 118, 119, 120, 121, 133, 139, 140], "named_modul": [14, 16, 23], "named_paramet": 22, "namedtupl": 1, "nan": [21, 65, 79, 120], "nanobind": 118, "nantekoto": 113, "narr": 76, "narrow": [2, 47, 48, 58, 109, 113], "narrowli": 68, "nasa": 108, "nat": 64, "nation": [28, 58, 69], "nativ": [37, 113], "natur": [3, 5, 6, 8, 10, 11, 15, 17, 35, 39, 41, 46, 47, 54, 58, 60, 64, 69, 74, 77, 80, 83, 88, 89, 90, 92, 95, 96, 98, 100, 102, 104, 105, 110, 112, 113, 114, 117, 120, 121, 126, 128, 131, 132, 136, 139, 142], "navig": [20, 57, 58, 60, 113, 139, 141], "nb_func": 118, "nbatch": 10, "ncol": [1, 28, 62], "nd": [9, 117], "ndarrai": [18, 22, 119], "ndim": [1, 3, 43, 115, 129], "neal": 49, "nearbi": 42, "nearest": [2, 77, 95], "nearli": [5, 34, 35, 48, 58, 59, 61, 69, 70, 71, 77, 115], "nears": 80, "neat": 41, "neatli": [58, 86], "nec": 58, "necess": 38, "necessari": [5, 15, 37, 39, 41, 42, 46, 47, 58, 70, 75, 104, 110, 113, 136, 137], "necessarili": [36, 58, 60, 64, 67, 136, 137, 138, 140], "necessit": [3, 35], "need": [1, 2, 3, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 85, 86, 88, 91, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141], "needless": 45, "neg": [3, 19, 22, 32, 46, 58, 61, 64, 65, 66, 69, 80, 83, 87, 88, 94, 99, 105, 110, 119, 121, 135], "neg_mll": 47, "negat": 85, "neighbor": [2, 28, 72, 77, 95], "neighborhood": [46, 60], "neither": [15, 34, 61, 64, 82, 85, 96, 104, 110], "nempir": 110, "neocognitron": 46, "neq": [35, 60, 61, 64, 89, 98, 102, 105, 115, 117, 121], "ness": 58, "nest": [15, 16, 39, 41, 53, 115, 119], "nestmlp": [15, 16], "net": [1, 12, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 28, 32, 34, 35, 36, 37, 39, 43, 65, 70, 72, 76, 81, 86, 88, 92, 99, 107, 108, 130], "net1": 15, "net2": 15, "net_fn": 107, "net_lay": 28, "netflix": [58, 138], "network": [5, 8, 11, 12, 13, 15, 16, 17, 22, 23, 24, 26, 27, 28, 30, 40, 41, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 58, 60, 61, 62, 64, 65, 66, 67, 70, 71, 72, 74, 76, 78, 79, 80, 81, 82, 84, 90, 98, 102, 105, 107, 108, 111, 112, 113, 114, 115, 117, 119, 124, 127, 128, 130, 132, 136, 138, 140, 142], "netyst": 113, "neural": [5, 8, 13, 15, 16, 21, 22, 23, 24, 27, 32, 35, 39, 40, 41, 46, 47, 48, 50, 52, 53, 54, 56, 58, 61, 64, 66, 67, 70, 71, 72, 74, 76, 77, 78, 80, 81, 82, 84, 98, 105, 107, 113, 115, 117, 119, 124, 127, 128, 130, 132, 136, 137, 140, 142], "neurip": [35, 49], "neuristiqu": 70, "neuron": [13, 15, 58, 69, 76, 78, 80, 81, 82, 127], "neurophysiologi": 41, "neurophysiologist": 69, "neurosci": [45, 58, 69], "neutral": [85, 86], "never": [8, 15, 34, 35, 58, 60, 61, 64, 65, 67, 69, 80, 82, 90, 104, 110, 121, 130, 135, 136], "nevertheless": [61, 67, 73, 131], "new": [2, 4, 5, 12, 13, 15, 17, 19, 22, 26, 28, 30, 33, 34, 38, 39, 45, 47, 50, 51, 52, 54, 55, 56, 57, 58, 60, 61, 64, 65, 67, 69, 70, 73, 74, 76, 77, 79, 83, 85, 91, 94, 96, 98, 102, 104, 109, 113, 114, 118, 119, 121, 125, 127, 128, 133, 135, 136, 137, 138, 139, 140], "new_bia": 23, "new_kei": 1, "new_token": 96, "new_token_freq": 96, "new_weight": 23, "newli": [39, 69, 119], "newspap": 113, "newton": 139, "next": [1, 4, 7, 8, 9, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 35, 36, 41, 42, 43, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 79, 81, 86, 87, 92, 97, 105, 108, 110, 111, 112, 113, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "next1": [1, 141], "next2": [1, 141], "next_sent": 91, "next_stat": 140, "nextsentencepr": 90, "nextstat": [1, 141], "nextstate_idx": [1, 141], "ng": [34, 58], "nguyen": 113, "nhwc": 33, "ni": [56, 58], "nice": [5, 35, 60, 64, 69, 73, 74, 104, 109, 121, 132], "nick": 113, "nicola": 113, "night": 61, "nik": 113, "nikhil95": 113, "nil": [110, 113], "nin": [37, 38], "nine": [11, 41, 90, 136, 137], "niplus1": 56, "nishanttharani": 113, "nishiyama": 113, "nitti": [16, 42], "nivida": 34, "nk": 117, "nlabel": 73, "nlg": 6, "nlp": [85, 86, 95], "nltk": 91, "nm": 19, "nms_threshold": 19, "nn": [1, 3, 4, 7, 9, 10, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 28, 30, 32, 33, 34, 35, 36, 37, 39, 41, 43, 44, 45, 47, 52, 62, 65, 70, 72, 73, 74, 76, 79, 80, 81, 82, 83, 85, 86, 87, 88, 90, 92, 95, 99, 107, 108, 113, 123, 124, 125, 127, 129, 134, 135, 136], "nnnnninnnth": 137, "nnp": 83, "no_grad": [101, 102, 103, 107, 109, 111], "no_spac": [1, 128], "nobel": 121, "nobodi": [67, 108], "nodar": 113, "node": [34, 45, 52, 76, 77, 80, 89, 126, 131, 135], "noelo": 113, "nois": [1, 6, 26, 28, 35, 43, 45, 47, 48, 52, 58, 64, 66, 69, 73, 74, 76, 77, 89, 90, 97, 99, 102, 108, 109, 110, 112, 136], "noiseless": 69, "noisi": [35, 47, 52, 56, 69, 77, 109, 112], "non": [1, 4, 8, 24, 25, 30, 32, 33, 34, 35, 39, 47, 49, 58, 60, 67, 77, 89, 90, 93, 97, 99, 109, 112, 116, 121, 128, 136, 139, 141], "non_keep": 19, "nonconvex": [58, 102, 104, 105, 106, 111, 112], "nondecreas": 104, "nondifferenti": 80, "none": [1, 3, 4, 7, 8, 10, 11, 19, 21, 22, 23, 25, 26, 28, 29, 32, 39, 51, 52, 56, 62, 65, 71, 72, 73, 74, 79, 85, 90, 91, 92, 99, 105, 107, 108, 115, 118, 123, 125, 127, 128, 134, 135, 136, 137], "nonetheless": [6, 8, 34, 35, 40, 46, 58, 62, 64, 65, 67, 69, 73, 80, 81, 106, 107, 109, 110, 132], "nonexist": 82, "nonlinear": [35, 36, 39, 40, 46, 58, 69, 74, 82, 112], "nonneg": [3, 8, 64, 66, 69, 74, 103, 104, 117, 121], "nonparametr": [58, 78, 80], "nonsens": [132, 134], "nontrivi": [2, 34, 58, 60, 64, 70, 107, 113, 121, 123, 127, 132], "nonzero": [3, 12, 19, 41, 44, 60, 65, 77, 102, 105, 121, 132], "noon": 60, "nor": [15, 34, 47, 61, 64, 69, 82, 85, 96, 104, 110], "norm": [3, 10, 11, 15, 18, 32, 35, 60, 68, 75, 76, 77, 100, 104, 112, 114, 116, 135], "norm_shap": [10, 11], "norm_squar": 1, "normal": [1, 2, 3, 5, 6, 8, 11, 12, 14, 17, 21, 22, 23, 25, 26, 28, 31, 33, 36, 37, 38, 39, 40, 43, 48, 49, 58, 61, 64, 66, 68, 70, 71, 72, 73, 74, 76, 79, 80, 81, 82, 86, 90, 93, 99, 103, 104, 108, 111, 112, 114, 117, 118, 119, 121, 125, 127, 129, 133, 135, 136, 142], "normalize_imag": [21, 31], "nose": 34, "not_hotdog": 22, "notabl": [6, 10, 11, 67, 77, 92, 137, 140], "notanothersystem": 113, "notat": [4, 43, 46, 47, 60, 64, 67, 69, 71, 74, 75, 80, 93, 101, 105, 109, 115, 119, 121, 122, 130, 131, 141, 142], "notation": 69, "note": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 16, 17, 19, 21, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 86, 88, 90, 91, 92, 93, 96, 97, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 112, 114, 115, 119, 121, 122, 124, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 139, 140, 141], "notebook": [1, 47, 48, 49, 50, 54, 57, 58, 72, 118], "noteworthi": [41, 85, 90, 133], "noth": [22, 35, 58, 61, 80, 82, 89, 136], "notic": [11, 15, 26, 40, 48, 58, 59, 70, 72, 75, 79, 98, 109, 119, 120, 121, 136, 137, 141], "notimpl": 72, "notimplementederror": [4, 51, 62, 72, 124], "notion": [2, 35, 39, 40, 47, 58, 61, 67, 74, 76, 95, 115, 117, 123, 130, 135, 139], "notori": 126, "nou": 4, "noun": [34, 58, 83, 96], "novel": [34, 58, 127, 132], "novella": [84, 132], "now": [2, 3, 4, 5, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 21, 23, 25, 26, 27, 28, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 51, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 67, 69, 70, 71, 72, 74, 75, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 96, 97, 99, 102, 103, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 125, 127, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141], "nowadai": [6, 34, 43, 58], "np": [1, 2, 7, 8, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 47, 49, 52, 56, 62, 66, 69, 70, 72, 73, 74, 79, 82, 85, 87, 91, 92, 95, 97, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 119, 121, 134, 136, 140, 141], "np_random": 1, "npx": [19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 33, 85, 87, 91, 92, 95, 99, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113], "npy": 17, "npz": [1, 17], "nr": 25, "nrauschmayr": 113, "nrow": [1, 62], "nsp": [90, 92], "nsp_data_from_paragraph": 91, "nsp_in_featur": [90, 92], "nsp_l": [90, 92], "nsp_l_mean": 92, "nsp_label": [91, 92], "nsp_y": [90, 91, 92], "nsp_y_hat": [90, 92], "nsp_y_shard": 92, "nt": 140, "nucleu": 69, "nuisanc": 82, "null": 22, "num": 26, "num_act": [1, 140, 141], "num_anchor": [19, 32], "num_batch": [1, 23, 25, 26, 29, 31, 32, 86, 88, 91, 92, 97, 99, 107, 108], "num_blk": [10, 11, 90, 92], "num_channel": [1, 28, 30, 36, 39, 88], "num_class": [1, 11, 19, 21, 22, 25, 32, 34, 35, 36, 37, 39, 43, 51, 54, 55, 135], "num_col": [1, 8, 23, 62], "num_conv": 36, "num_dim": 35, "num_embed": 99, "num_epoch": [1, 21, 22, 23, 25, 26, 28, 32, 86, 88, 99, 107, 108, 109], "num_exampl": [1, 73, 107], "num_featur": 35, "num_filt": 32, "num_gpu": [4, 10, 11, 18, 34, 35, 36, 37, 39, 43, 51, 55, 56, 72, 123, 125, 127, 129, 134, 135], "num_gpus_per_tri": [54, 55], "num_gt_box": 19, "num_head": [7, 9, 10, 11, 90, 92], "num_hidden": [3, 4, 7, 9, 10, 11, 81, 86, 90, 92, 123, 125, 127, 129, 134, 135], "num_hiddens_1": [51, 76], "num_hiddens_2": [51, 76], "num_init_random": 51, "num_input": [4, 11, 32, 43, 51, 52, 54, 55, 65, 66, 70, 71, 74, 76, 79, 81, 86, 90, 123, 125, 127, 129, 134, 135, 136], "num_inputs_agg": 86, "num_inputs_attend": 86, "num_inputs_compar": 86, "num_it": [1, 140, 141], "num_iter": 52, "num_iters_al": 1, "num_kvpair": 7, "num_lay": [4, 123, 129], "num_match": 129, "num_merg": 96, "num_mlm_pr": 91, "num_noise_word": [97, 99], "num_output": [52, 65, 66, 76, 81, 86], "num_patch": 11, "num_pr": 135, "num_pred_posit": 90, "num_queri": [7, 9], "num_ratio": 19, "num_residu": [1, 39], "num_roi": 30, "num_row": [1, 8, 23, 62], "num_siz": 19, "num_stat": [1, 140, 141], "num_step": [1, 4, 9, 10, 11, 85, 86, 87, 92, 123, 125, 127, 128, 129, 132, 134, 135], "num_steps_reach": 92, "num_test_batch": [21, 25, 26, 31], "num_token": 97, "num_toss": 121, "num_train": [73, 74, 128, 132, 136], "num_train_batch": [21, 22, 23, 25, 26, 31, 72], "num_train_valid_batch": [25, 26], "num_upd": 107, "num_val": [73, 74, 128, 132], "num_val_batch": 72, "num_valid_batch": [25, 26], "num_work": [23, 31, 85, 91, 97], "number": [1, 3, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 140, 141], "number_of_tri": [51, 56], "numel": [19, 23, 26, 99], "numer": [16, 34, 35, 40, 42, 47, 48, 50, 58, 61, 62, 64, 65, 66, 69, 75, 77, 78, 79, 95, 99, 101, 103, 110, 113, 115, 119, 120, 126, 130, 131, 135, 137, 138, 142], "numeric_featur": 79, "numpi": [1, 2, 7, 8, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 47, 49, 52, 56, 58, 62, 66, 69, 70, 72, 73, 74, 79, 82, 91, 99, 104, 105, 107, 108, 109, 110, 111, 113, 115, 119, 120, 121, 134, 136, 140, 141], "numref": [1, 135], "numroom": 120, "nums_channel": 88, "nutshel": [18, 19, 27, 32, 46, 47, 49, 58, 64, 101, 132], "nvidia": [3, 18, 34, 54, 55, 57, 58, 65], "nxby": 113, "ny": [73, 132], "o": [1, 2, 9, 13, 22, 25, 26, 29, 31, 39, 40, 47, 54, 55, 61, 62, 64, 65, 75, 80, 82, 85, 87, 89, 91, 95, 96, 97, 98, 102, 105, 107, 109, 111, 112, 113, 120, 122, 123, 127, 128, 130, 133, 135, 142], "o_": [64, 82, 98, 130], "o_1": [64, 69, 98], "o_2": 64, "o_3": 64, "o_i": [64, 82, 98], "o_j": [64, 65], "o_k": [64, 65], "o_t": 130, "oak": 28, "oaklei": 113, "ob": [1, 60], "obfusc": 79, "obj": [19, 72], "object": [5, 6, 15, 16, 17, 19, 21, 22, 23, 24, 28, 30, 31, 32, 34, 38, 42, 45, 46, 47, 49, 51, 53, 56, 59, 60, 64, 67, 68, 69, 71, 73, 74, 75, 79, 83, 89, 102, 104, 105, 106, 107, 108, 109, 110, 116, 117, 118, 121, 122, 130, 135, 136, 137, 140, 141, 142], "obliter": 44, "obscur": 60, "observ": [1, 2, 3, 6, 8, 11, 16, 23, 34, 35, 39, 41, 47, 48, 51, 52, 54, 55, 56, 58, 60, 61, 64, 67, 69, 74, 77, 80, 93, 102, 103, 104, 105, 107, 108, 109, 111, 112, 113, 117, 121, 127, 129, 130, 132, 133, 136, 137, 140, 141], "observed_error_at_rung": 56, "obstacl": [20, 34, 67], "obtain": [2, 4, 6, 11, 19, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 37, 39, 41, 45, 46, 49, 54, 58, 59, 60, 61, 64, 73, 75, 76, 82, 86, 88, 90, 93, 96, 98, 99, 101, 103, 105, 107, 108, 109, 110, 112, 115, 117, 121, 122, 129, 132, 133, 135, 138, 139, 140, 141], "obviat": 136, "obviou": [22, 60, 64, 65, 80, 90, 102, 132], "obvious": [28, 31, 40, 107], "occam": 47, "occasion": [34, 90, 130], "occlud": 58, "occupi": [34, 55], "occur": [15, 35, 40, 44, 45, 58, 60, 64, 65, 93, 97, 102, 108, 109, 112, 121, 122, 128, 129, 130, 132, 136, 137], "occurr": [94, 96, 97, 121, 132], "ocr": [34, 43], "octob": 58, "odd": [44, 121], "odditi": 62, "odot": [35, 75, 100, 101, 103, 111, 117, 125, 127], "off": [34, 37, 38, 39, 40, 44, 46, 48, 58, 60, 61, 64, 74, 77, 79, 82, 83, 91, 100, 103, 108, 114, 117, 121, 122], "offend": 60, "offer": [6, 8, 13, 18, 34, 35, 38, 39, 40, 44, 58, 70, 74, 76, 79, 82, 94, 103, 108, 113, 114, 117, 118, 121, 125], "offic": [29, 60], "offici": [79, 116, 118, 129], "offlin": 58, "offset": [9, 27, 30, 32, 35, 46, 69, 71, 104], "offset_box": 19, "offset_h": 19, "offset_invers": 19, "offset_pr": 19, "offset_w": 19, "offset_wh": 19, "offset_xi": 19, "often": [3, 5, 6, 9, 10, 13, 14, 15, 16, 19, 20, 21, 25, 32, 34, 35, 37, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 58, 59, 60, 61, 62, 64, 67, 68, 69, 71, 73, 74, 75, 76, 77, 79, 80, 82, 89, 93, 97, 98, 99, 100, 102, 104, 107, 108, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 125, 128, 131, 134, 135, 136, 137, 138, 140, 141], "oftentim": [117, 120], "og": 21, "ohio": 79, "ohm": [58, 71], "oil": [28, 69, 83], "ok": 58, "okroshiashvili": 113, "old": [2, 40, 45, 58, 60, 61, 80, 125, 127], "older": [60, 136], "oliv": 113, "omega_j": 9, "omelett": 85, "omit": [4, 9, 32, 79, 93, 98, 103, 105, 112, 133], "onboard": 113, "onc": [12, 15, 18, 35, 48, 51, 54, 55, 56, 58, 60, 61, 65, 67, 70, 71, 72, 74, 75, 77, 105, 108, 110, 112, 113, 114, 117, 119, 121, 122, 129, 135], "one": [1, 2, 3, 4, 5, 6, 8, 9, 12, 15, 16, 18, 19, 20, 21, 22, 28, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 117, 119, 120, 121, 122, 123, 124, 125, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141], "one_hot": 135, "one_hot_matrix": 135, "onedevicestrategi": 107, "ones": [1, 3, 4, 7, 9, 10, 11, 18, 19, 27, 35, 39, 40, 41, 51, 55, 56, 61, 62, 68, 69, 74, 76, 80, 85, 91, 97, 99, 102, 104, 110, 111, 117, 118, 119, 121, 122, 128, 132, 135, 136, 139, 140], "oneself": 106, "onestep_pr": 136, "onli": [1, 2, 3, 4, 5, 8, 10, 11, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 55, 56, 58, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 93, 96, 97, 100, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 117, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 133, 135, 136, 137, 139, 140, 141], "onlin": [14, 22, 23, 57, 58, 62, 87, 113, 117, 138], "onto": [104, 119, 121, 135], "ontologi": 58, "op": 30, "open": [0, 1, 6, 13, 21, 23, 25, 26, 28, 31, 32, 34, 35, 41, 51, 56, 57, 58, 60, 70, 72, 77, 80, 85, 87, 91, 95, 97, 120, 126, 128, 137, 140, 141], "openai": [5, 58], "opencv": 34, "oper": [1, 7, 8, 9, 10, 11, 15, 16, 18, 21, 23, 24, 25, 26, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 58, 59, 60, 64, 66, 67, 69, 70, 74, 75, 76, 80, 82, 83, 86, 88, 89, 96, 98, 102, 108, 113, 115, 116, 117, 123, 125, 127, 129, 130, 133], "operand": 117, "operatornam": [64, 69, 80, 122], "opinion": 87, "oppon": [58, 138], "opportun": [18, 60, 71], "oppos": [60, 64], "opposit": [35, 58, 82, 89, 130], "opt": [6, 54, 55], "optax": 113, "optic": [34, 58, 67], "optim": [1, 2, 3, 5, 6, 15, 21, 22, 23, 25, 26, 28, 32, 34, 35, 38, 39, 40, 41, 46, 47, 59, 60, 64, 65, 68, 69, 72, 74, 75, 77, 79, 80, 81, 82, 86, 88, 92, 99, 101, 102, 103, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 121, 122, 129, 130, 134, 135, 136, 138, 142], "optima": [47, 52, 110], "optimum": [52, 110], "option": [1, 2, 8, 35, 39, 46, 57, 58, 62, 64, 69, 72, 79, 108, 109, 112, 113, 114, 118], "optuna": 51, "opu": 132, "orang": [47, 48, 64], "ord": 117, "order": [2, 3, 6, 9, 15, 16, 17, 18, 19, 21, 22, 23, 25, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 41, 42, 43, 46, 47, 48, 50, 51, 52, 54, 55, 56, 57, 58, 61, 64, 67, 69, 73, 75, 77, 80, 85, 86, 89, 91, 95, 102, 105, 108, 112, 113, 114, 115, 116, 117, 119, 120, 121, 128, 130, 131, 132, 135, 138, 139], "ordereddict": 1, "ordin": [64, 83], "ordinari": [58, 64, 117, 121, 127], "oren": 113, "organ": [24, 58, 121], "organiz": 113, "orient": [34, 58, 68, 71, 73, 142], "origin": [2, 4, 5, 6, 10, 11, 17, 19, 20, 21, 23, 25, 26, 28, 31, 32, 33, 34, 35, 37, 39, 43, 44, 46, 49, 52, 53, 58, 60, 61, 62, 67, 69, 72, 74, 76, 79, 80, 83, 85, 88, 89, 90, 91, 92, 97, 101, 104, 108, 109, 113, 114, 117, 121, 129, 131, 132, 133, 135, 137], "original_shap": 135, "ornithologi": 69, "ornstein": 49, "orthogon": [41, 81, 102, 109], "oscil": [105, 109], "ostens": 61, "other": [1, 4, 5, 6, 8, 9, 12, 14, 15, 16, 17, 18, 19, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 64, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 88, 90, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 121, 122, 123, 125, 126, 127, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141], "otherwis": [2, 18, 23, 32, 41, 43, 48, 51, 58, 67, 70, 71, 76, 89, 93, 97, 100, 104, 112, 119, 121, 128, 140], "ou": 49, "ought": [34, 66, 71, 75], "our": [3, 5, 6, 7, 8, 11, 12, 14, 15, 16, 17, 19, 21, 23, 24, 26, 27, 29, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 89, 99, 102, 103, 104, 105, 108, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "ourselv": [3, 15, 35, 40, 58, 61, 65, 66, 69, 71, 73, 81, 112, 117, 121, 136], "out": [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15, 18, 19, 25, 26, 31, 32, 35, 37, 40, 41, 43, 44, 46, 47, 49, 51, 52, 58, 60, 61, 62, 64, 66, 67, 69, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 87, 91, 92, 94, 96, 99, 102, 103, 104, 107, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 125, 127, 128, 129, 134, 136, 137, 141], "out_channel": [1, 21, 32], "out_grid": 19, "out_h": [30, 32], "out_img": 21, "out_w": [30, 32], "outbreak": 83, "outcom": [2, 3, 39, 43, 58, 64, 75, 80, 104, 112, 121, 130], "outdoor": 85, "outer": [117, 121], "outermost": [119, 135], "outfit": [6, 46], "outlai": 34, "outlandish": 132, "outlier": [64, 69, 117, 120], "outlin": [8, 20, 35, 58, 105, 135], "outmod": 113, "outnumb": 66, "outpac": 58, "outperform": [6, 11, 34, 51, 52, 61, 67, 76, 108], "output": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 21, 22, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 58, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 75, 76, 80, 81, 82, 83, 85, 86, 88, 90, 91, 93, 95, 96, 99, 105, 110, 114, 115, 117, 118, 119, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 136, 142], "output_concat": 7, "output_dim": [17, 21, 22, 70, 99], "output_featur": 26, "output_h": 1, "output_lay": [134, 135], "output_new": 26, "output_s": [1, 30, 32], "output_w": 1, "outset": 113, "outsid": [46, 60, 65, 74, 104, 112, 114, 132], "outsiz": [60, 74], "outstand": 43, "outweigh": [58, 112], "over": [1, 2, 4, 8, 9, 12, 13, 16, 17, 18, 24, 27, 28, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 60, 61, 62, 64, 66, 67, 69, 70, 71, 72, 73, 75, 76, 77, 79, 80, 81, 82, 84, 85, 89, 91, 93, 96, 97, 99, 100, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 117, 121, 127, 128, 129, 130, 131, 132, 135, 136, 137, 140, 141], "overal": [10, 53, 54, 56, 77, 82, 103, 109, 121, 123], "overcom": [52, 80, 126, 136], "overestim": [122, 137, 140], "overfit": [2, 22, 23, 25, 34, 35, 49, 52, 58, 61, 68, 74, 76, 78, 79, 88, 107, 110, 113, 134], "overflow": [64, 65], "overhead": [18, 54, 74, 75, 102, 108, 119], "overlai": 115, "overlap": [19, 27, 30, 46, 67, 83, 121], "overli": [46, 47, 61, 76, 105, 111], "overload": [64, 69, 117], "overlook": 60, "overparametr": 49, "overrid": 45, "overshoot": 105, "overst": 58, "overview": [10, 32, 44, 58, 64, 77, 107, 113], "overweight": [60, 130], "overwhelm": 64, "overwrit": 119, "ow": [35, 42, 58, 67, 71, 79, 93, 113, 127, 128, 131, 135], "own": [9, 12, 15, 35, 38, 39, 53, 58, 59, 61, 64, 65, 70, 71, 72, 73, 76, 82, 104, 107, 108, 113, 117, 121, 123, 131, 132, 136, 140], "oxford": 60, "ozgur": 113, "p": [1, 2, 4, 8, 9, 10, 11, 19, 25, 31, 32, 34, 35, 44, 45, 47, 49, 58, 59, 60, 61, 64, 67, 69, 74, 76, 89, 93, 96, 97, 98, 100, 101, 102, 103, 104, 108, 109, 110, 111, 112, 117, 121, 122, 129, 130, 132, 133, 135, 136, 139, 140, 141], "p1": [1, 37, 141], "p1_1": 37, "p2": [1, 37, 141], "p2_1": 37, "p2_2": 37, "p3": 37, "p3_1": 37, "p3_2": 37, "p4": 37, "p4_1": 37, "p4_2": 37, "p_": [9, 40, 44, 45, 60, 93, 110], "p_1": [93, 129], "p_2": [93, 129], "p_3": 129, "p_4": 129, "p_h": 45, "p_i": 83, "p_j": 32, "p_k": 7, "p_n": 129, "p_o": 7, "p_q": 7, "p_t": 60, "p_v": 7, "p_w": 45, "pace": [58, 77], "pack": [83, 138], "packag": [20, 47, 54, 55, 79, 113, 114, 115, 119, 137, 138], "pad": [1, 3, 4, 9, 10, 21, 24, 29, 30, 32, 34, 36, 37, 39, 40, 41, 42, 43, 65, 85, 87, 91, 97, 99, 107, 124, 128, 129, 136, 142], "pad_or_trim": 128, "padding_token": 1, "paddlepaddl": 113, "page": [57, 58, 60, 75, 79, 102, 113], "pagerank": 58, "pai": [5, 8, 39, 58, 72, 75, 110, 120, 121, 127], "paid": 46, "pain": 15, "paint": 28, "pair": [2, 3, 4, 6, 7, 8, 9, 10, 19, 41, 47, 48, 58, 64, 69, 84, 85, 86, 90, 91, 92, 94, 97, 98, 112, 119, 128, 132, 133, 137, 140], "pairwis": 19, "palett": 62, "palm": 6, "palo": 117, "pam": 64, "panda": [10, 25, 29, 79, 91, 113, 120], "pandit": 113, "paper": [5, 10, 21, 28, 32, 34, 35, 36, 39, 47, 58, 61, 64, 75, 76, 82, 93, 94, 96, 97, 98, 114, 126, 129], "pappa": 113, "par": 47, "parabola": 104, "paradigm": [5, 6, 34, 58], "paradox": 77, "paragraph": [91, 128, 137], "parallel": [5, 7, 9, 10, 15, 18, 34, 37, 42, 52, 54, 55, 56, 58, 72, 103, 108, 114], "param": [1, 14, 16, 17, 22, 23, 26, 69, 71, 101, 102, 103, 108, 109, 111], "param_group": [22, 107], "paramet": [1, 3, 4, 5, 6, 7, 8, 13, 15, 18, 21, 22, 23, 26, 28, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 58, 60, 61, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 86, 88, 90, 92, 93, 96, 98, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 115, 116, 119, 121, 123, 129, 130, 131, 132, 133, 135, 140, 142], "parametr": [7, 32, 36, 39, 46, 58, 60, 63, 64, 68, 69, 74, 77, 80, 82, 105, 121, 133], "params_1x": 22, "parent": [15, 113], "parentag": 69, "pari": 58, "pariti": 58, "park": 28, "parquet": [91, 92], "pars": [41, 58], "parsimoni": 43, "part": [1, 2, 4, 5, 7, 17, 25, 28, 30, 31, 34, 35, 39, 43, 52, 58, 60, 64, 65, 66, 67, 71, 72, 74, 75, 77, 80, 83, 85, 94, 103, 104, 105, 107, 111, 113, 123, 125, 128, 136, 140, 141], "parth": 113, "parti": 6, "partial": [6, 58, 60, 75, 98, 100, 104, 105, 113, 114, 116, 121, 130], "partial_": [64, 69, 71, 82, 102, 108, 109, 112, 115], "partial_b": 69, "partial_i": [41, 102, 115], "particip": [43, 79, 133], "particl": 58, "particular": [3, 4, 5, 8, 12, 15, 34, 35, 39, 40, 46, 48, 49, 54, 56, 58, 60, 64, 65, 66, 67, 69, 70, 72, 74, 75, 76, 77, 81, 102, 103, 105, 107, 109, 112, 113, 115, 117, 121, 126, 131, 132, 135, 136, 139, 140, 141], "particularli": [8, 28, 44, 48, 64, 80, 102, 104, 107, 108, 112, 121, 125, 132, 136, 137], "partit": [37, 58, 64, 66, 75, 79, 115, 120, 130, 131], "partli": [38, 40, 58, 71], "parzen": 2, "pascal": [21, 24], "pasricha": 113, "pass": [1, 5, 11, 15, 32, 34, 39, 43, 51, 52, 54, 56, 60, 63, 65, 66, 69, 71, 73, 75, 76, 92, 97, 103, 108, 112, 114, 117, 123, 127, 130, 131, 132, 135], "passag": [83, 131], "passiv": 60, "past": [4, 6, 8, 18, 35, 51, 58, 61, 67, 69, 70, 80, 95, 102, 103, 108, 109, 111, 113, 114, 117, 126, 130, 133, 135, 136, 138, 139], "patch": [5, 6, 38, 46, 58, 128], "patch_emb": 11, "patch_embed": 11, "patch_siz": 11, "patchembed": 11, "patchifi": 11, "path": [1, 6, 9, 10, 18, 22, 25, 26, 29, 31, 38, 39, 75, 85, 87, 89, 91, 95, 97, 107, 112, 113, 114, 120, 133], "pathak": 113, "pathbreak": 13, "patholog": 60, "pathwai": 6, "patienc": [46, 77], "patient": [58, 60, 64, 67, 69, 77, 117, 121, 136], "patrol": 60, "pattern": [5, 6, 11, 15, 35, 36, 37, 40, 45, 46, 58, 60, 61, 67, 69, 73, 76, 77, 113, 121, 123, 127], "paulaurel": 113, "paus": [55, 60, 137], "pave": 131, "pavelkomarov": 113, "payment": 58, "paypal": 58, "paywal": 113, "pcm": [2, 8], "pd": [10, 25, 29, 79, 91, 113, 120], "pdf": [100, 113], "peac": 132, "peak": [34, 46, 58, 69], "pearson": 100, "peculiar": [58, 103], "pedagog": [58, 113], "pedestrian": 20, "pedro": 113, "peel": 13, "peform": 76, "peilin": 113, "pen": [4, 114], "penal": [74, 77, 79, 122, 129], "penalti": [35, 39, 58, 59, 69, 77, 129], "pend": 55, "penn": [83, 97], "pennsylvania": 138, "pennystock": 69, "peopl": [18, 34, 47, 58, 60, 87, 102, 117, 121], "per": [2, 3, 25, 34, 35, 37, 40, 43, 44, 51, 52, 55, 58, 64, 81, 87, 97, 102, 103, 104, 108, 111, 117, 119, 128, 130], "perceiv": [58, 60], "perceptron": [5, 35, 52, 58, 77, 113, 131, 142], "perceptu": [46, 58], "perdu": [4, 10, 129], "perfect": [60, 61, 69, 113], "perfectli": [47, 48, 49, 58, 60, 61, 64, 65, 67, 71, 77, 102, 105, 121, 132], "perform": [2, 3, 5, 6, 7, 8, 10, 12, 15, 16, 17, 18, 19, 21, 22, 24, 25, 26, 28, 30, 32, 34, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 85, 88, 96, 101, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 117, 119, 123, 125, 129, 132, 133, 134, 135, 136, 141], "perhap": [15, 16, 17, 34, 38, 47, 49, 58, 61, 64, 67, 74, 77, 82], "perimet": 44, "period": [17, 48, 49, 67, 79, 91, 107, 135, 136, 140], "permit": [58, 60, 67, 74], "permut": [6, 21, 29, 31, 42, 62, 64, 73, 82, 85, 91, 99, 108, 118], "perp": [100, 121], "perplex": [107, 123, 125, 127, 131, 134, 135], "perplexingli": 107, "persist": [37, 61, 114, 120, 121], "person": [31, 58, 61, 85, 102, 113, 117, 121, 139], "perspect": [50, 62, 77, 93, 131, 136], "pertain": 107, "perturb": [35, 58, 60, 71, 76, 102, 109, 115, 127, 136], "perus": 113, "pervas": [10, 39, 58], "peski": 61, "pessimist": 61, "petaflop": 6, "peter": [58, 113], "pf": 58, "pggpl": 113, "ph": 58, "pham": 113, "phase": [58, 69, 77, 107], "phd": 114, "phenomena": [35, 136], "phenomenon": [67, 77, 105, 107, 121, 136, 137], "phi": [35, 49, 75, 77, 80, 130, 133], "phi_c": 49, "phi_i": 49, "phi_l": 123, "philosoph": [60, 67, 121], "phone": [18, 34, 58], "phonem": 126, "photo": [28, 29, 58, 60, 117], "photograph": [46, 58, 60, 67, 121], "photographi": 28, "photorealist": [6, 58], "phrase": [52, 96, 98, 132, 136], "phuc": 113, "phylogenet": 58, "physic": [58, 60, 64, 66, 104, 113, 120], "physician": 121, "physiologi": 69, "pi": [1, 5, 47, 49, 69, 104, 105, 107, 110, 115, 140, 141], "pi_": 141, "pi_0": 141, "pi_al": 1, "pi_e": 140, "pi_k": 141, "pi_t": 130, "pick": [2, 3, 5, 8, 44, 45, 46, 51, 61, 64, 66, 67, 69, 79, 82, 93, 103, 104, 105, 107, 108, 109, 112, 120, 122, 123, 132, 133, 135, 137, 140, 141], "pictur": [11, 43, 58, 60, 61, 67, 69, 77, 94, 141], "pid": 60, "piec": [4, 37, 64, 70, 71, 103, 135, 137], "piecewis": [80, 107, 112, 114], "pig": 46, "pil": [32, 113], "pile": 58, "pillow": 120, "pin": [34, 58, 107], "pioneer": [30, 58, 80], "piouw": 132, "pip": [57, 91], "pipe": 58, "pipelin": [34, 52, 58, 60, 73, 120, 137], "pitfal": [51, 113], "pithi": 77, "pitt": [69, 80], "pittsburgh": 58, "pivot": [38, 63, 68], "pixel": [8, 19, 21, 22, 23, 25, 27, 28, 30, 31, 33, 34, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 58, 62, 64, 66, 76, 80, 81, 88, 131], "place": [9, 11, 25, 29, 35, 45, 58, 60, 61, 64, 69, 70, 71, 74, 77, 79, 80, 91, 101, 103, 104, 108, 113, 114, 119, 121, 130, 136, 138], "placehold": 100, "plagu": [58, 61, 80, 82, 120], "plai": [6, 13, 35, 38, 39, 47, 52, 58, 60, 82, 104, 107, 112, 113, 127, 138, 140], "plain": [75, 80, 121], "plan": [20, 34, 58, 60, 72, 121], "planck": 71, "plane": [46, 83], "planet": 121, "plant": [31, 117, 121], "plate": 114, "plateau": [80, 107], "platform": [58, 72, 79, 87, 113], "plausibl": [47, 58, 80, 82, 121, 128, 132], "plausibli": 47, "player": 113, "playlist": 58, "pleas": [57, 58], "pleasant": 109, "plenti": [5, 58, 113, 118], "plethora": [38, 87], "plot": [1, 2, 9, 19, 32, 35, 39, 47, 48, 49, 51, 54, 55, 59, 62, 66, 69, 70, 72, 74, 75, 76, 77, 80, 81, 82, 87, 92, 97, 104, 105, 107, 108, 109, 110, 111, 112, 114, 115, 121, 128, 129, 135, 136, 137], "plot_train_per_epoch": 72, "plot_valid_per_epoch": 72, "plot_wirefram": 110, "plt": [1, 2, 8, 19, 20, 21, 23, 27, 28, 32, 47, 49, 54, 55, 56, 87, 104, 105, 108, 109, 110, 111, 113, 115, 121, 128], "plt_line": 1, "plu": [4, 34, 40, 47, 48, 58, 60, 62, 66], "plug": [60, 61, 64, 82, 105, 112, 115, 136], "plumb": 63, "pm": [48, 61, 67], "pmuen": 113, "png": [25, 31], "po": [58, 83, 87], "point": [1, 5, 12, 15, 17, 18, 19, 23, 25, 28, 29, 34, 35, 36, 37, 38, 39, 43, 47, 48, 49, 52, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 67, 69, 72, 76, 77, 79, 80, 104, 106, 107, 108, 109, 113, 114, 115, 117, 119, 120, 121, 126, 127, 131, 138], "pointer": 58, "points_to_evalu": [54, 55], "pointwis": 103, "poison": 58, "poisson": 69, "poker": 58, "polar": [85, 87], "polic": [58, 60], "polici": [1, 58, 87, 106, 113, 138, 140], "polit": 87, "pollut": 58, "polygon": 115, "polynomi": [49, 50, 61, 74, 107, 112], "polynomial_lr": 112, "polyschedul": 107, "polysemi": [90, 92], "polytechn": 120, "ponder": 58, "pong": 139, "poodl": [26, 58], "pool": [1, 3, 4, 5, 7, 8, 9, 10, 21, 22, 23, 30, 32, 33, 34, 36, 37, 39, 42, 43, 54, 83, 84, 142], "pool2d": 45, "pool_lay": 1, "pool_result": 30, "pool_siz": [45, 107], "pooled_featur": 30, "pooled_s": 30, "poor": [47, 52, 58, 67, 82, 103, 105, 140], "poorli": [52, 56, 74, 104, 132], "pop": [56, 58, 69, 113, 131], "popper": 67, "popul": [51, 58, 60, 61, 67, 77, 97, 110, 121], "popular": [3, 15, 24, 34, 35, 38, 40, 42, 44, 45, 47, 49, 50, 51, 58, 60, 61, 67, 69, 74, 77, 79, 80, 82, 83, 84, 85, 90, 91, 96, 103, 107, 111, 112, 125, 126, 128, 129, 131, 135, 136, 137, 138], "popularli": 74, "popvssoda": 60, "portabl": 69, "portfolio": 121, "portion": [27, 29, 33, 39, 40, 41, 44, 45, 58, 74, 80, 88, 122], "portrait": 28, "pos_embed": [11, 90], "pos_encod": [9, 10], "pos_threshold": 19, "pose": [58, 62, 80, 81, 82, 121, 130], "posit": [1, 4, 5, 10, 11, 19, 20, 21, 22, 23, 27, 29, 30, 32, 33, 34, 35, 40, 41, 44, 46, 47, 52, 58, 60, 64, 65, 69, 75, 80, 83, 87, 88, 89, 90, 91, 97, 98, 100, 104, 105, 109, 110, 112, 117, 119, 121, 132, 135, 142], "positionalencod": [9, 10], "positionwis": [5, 11, 90], "positionwiseffn": 10, "possess": [15, 46, 60, 61, 75, 77, 83, 121], "possibl": [6, 9, 10, 11, 19, 22, 27, 29, 34, 35, 41, 42, 43, 44, 46, 47, 48, 52, 55, 58, 60, 61, 62, 64, 66, 67, 69, 71, 77, 80, 82, 84, 86, 91, 93, 96, 102, 103, 108, 112, 113, 118, 119, 121, 122, 129, 132, 133, 135, 136, 139, 141], "possibli": [10, 34, 35, 58, 60, 61, 69, 70, 73, 77, 80, 82, 97, 105, 107, 119, 121, 136], "post": [11, 19, 58, 61, 73, 109, 113, 132], "post_cov": 47, "post_mean": 47, "post_sampl": 47, "post_sig_est": 47, "posterior": [48, 49, 50, 74, 121], "posteriori": 47, "postprocess": [24, 69, 73, 80], "postul": 35, "pot": 31, "potenti": [6, 19, 47, 51, 58, 60, 65, 69, 71, 77, 80, 87, 109, 113, 130, 133, 141], "pour": 77, "pow": [107, 129], "power": [5, 6, 9, 13, 17, 24, 34, 35, 39, 41, 42, 46, 47, 50, 57, 58, 61, 67, 69, 70, 72, 73, 74, 77, 79, 80, 81, 82, 90, 97, 108, 113, 114, 115, 130, 133, 136, 137, 141], "powerless": [61, 77], "ppl": 135, "pr": 141, "practic": [3, 5, 7, 10, 15, 17, 19, 22, 23, 25, 26, 29, 30, 34, 35, 40, 41, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 58, 60, 61, 64, 66, 67, 69, 70, 71, 73, 74, 77, 78, 79, 81, 82, 83, 90, 93, 94, 95, 102, 103, 104, 105, 106, 107, 108, 111, 112, 113, 118, 122, 126, 127, 130, 131, 133, 137], "practition": [5, 34, 35, 42, 53, 61, 64, 69, 77, 80, 82, 113, 114, 119, 120, 122], "prakash": 113, "prakhar": 113, "prasanth": 113, "pratik": 138, "pratikhack": 113, "pre": [6, 11, 18, 26, 61, 73, 80, 82, 90, 125], "preced": [36, 56, 91, 126, 129], "precis": [5, 34, 35, 41, 42, 44, 46, 47, 48, 49, 58, 61, 63, 64, 65, 67, 69, 71, 74, 77, 80, 113, 117, 121, 123, 129, 130, 131, 136, 137], "precomput": [28, 93], "preconceiv": 58, "precondit": 106, "precondition": [103, 105, 111], "precursor": [2, 34], "pred": [4, 10, 21, 23, 25, 26, 32, 49, 59, 66, 79, 99, 129, 136], "pred_bbox": 19, "pred_bbox_wh": 19, "pred_bbox_xi": 19, "pred_info": 19, "pred_posit": [90, 91, 92], "pred_positions_and_label": 91, "pred_positions_x": [91, 92], "pred_positions_x_shard": 92, "pred_seq": 129, "pred_shard": 23, "pred_token": 129, "predat": [39, 69], "predecessor": [6, 37, 113], "predefin": [15, 19, 52, 70, 85, 86, 89, 90, 96, 97, 111, 130, 132], "predetermin": [69, 136], "predic": 67, "predict": [1, 4, 6, 7, 10, 15, 16, 17, 23, 24, 25, 26, 27, 30, 31, 36, 37, 44, 46, 48, 49, 50, 58, 59, 60, 61, 63, 64, 67, 68, 71, 74, 75, 76, 77, 78, 80, 83, 86, 88, 92, 93, 94, 98, 99, 113, 117, 120, 121, 122, 123, 124, 125, 126, 128, 131, 132, 133, 135, 138, 142], "predict_senti": 88, "predict_snli": 86, "predict_step": [4, 10, 129], "predicted_bb": 19, "predicted_bbox": 19, "predictor": [34, 47, 48, 60, 77, 80], "predominantli": [60, 131], "prefac": 142, "prefact": 56, "prefer": [34, 35, 40, 45, 58, 64, 69, 77, 112, 113, 128, 132, 133, 136], "preferenti": 58, "prefilt": 34, "prefix": [6, 26, 96, 122, 125, 134, 135, 136], "prejudic": 58, "preliminari": [61, 113, 142], "prelu": 80, "prematur": 112, "premis": [85, 86], "preoccupi": 121, "prepar": [18, 58, 61, 67, 72, 113, 116, 129], "prepare_batch": [18, 52, 71], "prepare_data": 72, "prepare_model": [18, 72], "prepend": 6, "preposit": 137, "preprocess": [1, 24, 26, 35, 58, 62, 67, 72, 78, 80, 84, 108, 116, 126, 137, 142], "preprocess_nmt": 1, "prerequisit": [23, 60, 113, 115], "prescrib": 51, "present": [5, 6, 10, 20, 35, 36, 38, 53, 58, 61, 69, 72, 77, 95, 113, 115, 123, 128, 132], "preserv": [9, 10, 28, 30, 36, 42, 44, 61, 64, 80, 86], "preset": 14, "press": [6, 58, 60, 113, 122], "pressur": 82, "presum": 35, "pretend": 112, "pretrain": [1, 5, 21, 22, 24, 28, 30, 58, 83, 84, 86, 96, 113, 142], "pretrained_net": [21, 22, 28], "pretrained_net_lay": 21, "pretrained_w": 1, "pretrained_weight": 1, "pretti": [47, 58, 103, 121, 136], "prev_char": [1, 128], "preval": [60, 64, 121], "prevent": [6, 9, 35, 65, 77, 107, 109, 120, 127, 130], "previou": [4, 10, 15, 17, 22, 24, 25, 31, 32, 34, 36, 39, 40, 41, 43, 44, 51, 52, 54, 56, 58, 60, 67, 70, 73, 74, 76, 80, 82, 83, 99, 101, 108, 109, 112, 113, 117, 121, 122, 123, 124, 125, 126, 127, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "previous": [15, 34, 39, 40, 45, 46, 52, 58, 60, 61, 64, 67, 69, 76, 80, 81, 102, 107, 111, 114, 115, 119, 127, 132, 133, 135, 136, 137], "price": [34, 35, 36, 40, 46, 58, 60, 64, 65, 67, 69, 78, 120, 135, 136, 142], "pride": 58, "primari": [2, 5, 43, 58, 59, 61, 66, 69, 113, 116], "primarili": [1, 5, 6, 39, 43, 58, 59, 75, 80, 107, 110, 112, 130, 131], "prime": [58, 61, 129], "primer": 106, "primit": [51, 132], "princ": 132, "princip": 58, "principl": [11, 32, 35, 46, 52, 58, 60, 61, 67, 69, 77, 106, 112, 113, 115, 129, 130, 136, 138], "print": [1, 4, 9, 10, 14, 16, 18, 19, 21, 22, 23, 25, 26, 28, 29, 31, 32, 35, 41, 43, 51, 52, 62, 70, 71, 72, 73, 74, 76, 79, 82, 85, 86, 87, 91, 92, 95, 96, 97, 99, 105, 107, 108, 115, 118, 119, 120, 121, 125, 128, 129, 132, 137], "print_update_interv": [54, 55], "prior": [6, 11, 28, 35, 37, 39, 42, 47, 48, 50, 52, 54, 58, 74, 107, 110, 121, 142], "prior_sampl": [47, 49], "priori": [9, 35, 46, 49, 61, 73, 79, 114], "priorit": [58, 113], "prize": [58, 79, 121], "prob": [19, 140], "prob_idx": 141, "probab_loc": 51, "probabilist": [58, 61, 64, 69, 121, 136], "probabilti": 59, "probabl": [1, 8, 14, 19, 23, 28, 30, 32, 35, 43, 48, 51, 52, 58, 59, 60, 61, 64, 65, 66, 76, 79, 80, 82, 83, 86, 89, 94, 97, 98, 107, 110, 112, 113, 116, 117, 119, 122, 129, 130, 132, 133, 136, 139, 140, 141, 142], "probit": 64, "problem": [3, 6, 8, 15, 22, 26, 30, 31, 32, 34, 35, 36, 37, 39, 44, 45, 46, 47, 49, 51, 53, 59, 61, 62, 63, 64, 65, 66, 67, 69, 71, 73, 74, 77, 79, 80, 81, 82, 83, 84, 85, 87, 101, 102, 103, 104, 105, 106, 110, 111, 112, 113, 115, 117, 118, 120, 121, 122, 124, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 138, 139, 141, 142], "problemat": [52, 60, 67], "proce": [4, 16, 18, 19, 46, 56, 69, 75, 79, 107, 108, 109, 128, 136], "procedur": [37, 47, 48, 49, 58, 60, 69, 71, 77, 79, 92, 102, 106, 108, 109, 111, 112, 114, 115, 119, 130, 131], "process": [1, 3, 5, 6, 8, 9, 10, 11, 15, 16, 17, 19, 21, 28, 34, 37, 39, 41, 43, 45, 46, 51, 52, 53, 56, 58, 60, 62, 64, 67, 69, 71, 73, 77, 79, 81, 83, 86, 87, 88, 90, 92, 95, 96, 98, 103, 107, 108, 109, 113, 114, 119, 120, 121, 122, 126, 128, 129, 131, 132, 133, 135, 136, 138, 140, 141, 142], "process_sampl": [23, 25], "process_test_sampl": 22, "process_train_sampl": 22, "processor": [34, 58, 69, 108], "prod": [75, 100, 130], "prod_": [64, 69, 89, 98, 122, 129, 130, 132, 136], "produc": [1, 2, 5, 7, 25, 32, 33, 36, 41, 44, 58, 69, 70, 73, 77, 80, 82, 87, 88, 96, 107, 117, 119, 121, 122, 123, 124, 131, 132, 135, 136], "product": [2, 4, 5, 6, 7, 9, 10, 28, 34, 38, 43, 48, 49, 52, 58, 60, 64, 69, 71, 74, 82, 83, 87, 89, 94, 98, 99, 100, 108, 112, 113, 114, 115, 116, 118, 119, 121, 125, 127, 130, 133, 134, 135, 136], "profession": [58, 71, 113], "profil": 62, "profit": 60, "profound": [39, 58, 61, 121], "profoundli": 75, "program": [12, 15, 18, 34, 58, 69, 70, 72, 80, 113, 114, 117, 121, 136, 138], "programm": 58, "progress": [1, 13, 34, 37, 38, 39, 43, 46, 58, 60, 67, 70, 72, 102, 105, 107, 108, 109, 110, 111, 112, 113, 135], "progressboard": [1, 51, 72], "prohibit": [9, 47, 64, 105, 114, 122], "proj": 104, "project": [6, 7, 9, 11, 35, 38, 72, 85, 86, 95, 110, 113, 117, 128, 132, 135, 136], "prolifer": 87, "promin": [34, 58, 127, 131], "promis": [6, 25, 51, 56, 77], "promot": [55, 56, 58], "prompt": [6, 18, 57, 82, 128], "prone": 114, "pronoun": 137, "pronounc": [48, 74, 117], "proof": [105, 106, 112, 115], "prop": 101, "propag": [12, 13, 16, 21, 27, 28, 30, 32, 33, 36, 39, 40, 41, 45, 52, 76, 78, 82, 114, 124, 130, 131, 142], "proper": [6, 7, 14, 35, 51, 57, 58, 67, 83, 102, 103, 109, 120, 121, 123, 127], "properli": [14, 34, 41, 46, 70, 93, 104, 105, 132], "properti": [2, 3, 4, 8, 10, 34, 35, 47, 48, 49, 50, 58, 61, 73, 77, 79, 90, 105, 106, 108, 109, 110, 113, 115, 116, 118, 119, 120, 121, 130, 132, 135, 137, 138], "propon": 58, "proport": [39, 41, 60, 64, 75, 139], "proportion": 39, "propos": [2, 4, 5, 6, 8, 10, 11, 30, 35, 39, 43, 58, 61, 80, 82, 83, 86, 90, 96, 98, 101, 103, 107, 109, 111, 121, 127, 129, 130, 132, 133], "propto": [49, 64, 74, 121, 135, 137], "prose": 113, "prospect": 6, "protect": [65, 66], "protein": [77, 121], "protocol": [14, 60], "prototyp": [13, 58, 60, 105, 127], "protyp": 131, "proud": 37, "prove": [2, 8, 11, 34, 35, 40, 45, 46, 58, 61, 64, 67, 68, 69, 71, 76, 79, 80, 102, 104, 109, 110, 112, 115, 117, 121, 130, 135, 136], "proven": [35, 41, 104, 106, 114, 126, 133], "provid": [2, 5, 7, 8, 10, 12, 14, 15, 17, 21, 23, 25, 26, 30, 31, 32, 34, 35, 37, 39, 40, 42, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 69, 70, 71, 72, 73, 74, 75, 77, 79, 80, 97, 103, 105, 107, 108, 110, 113, 116, 118, 119, 121, 122, 124, 125, 132, 134, 135], "provision": 58, "prowess": 58, "proxi": [53, 56, 102, 107], "prune": 7, "pseudorandom": 73, "psychologi": [58, 69], "ptb": [91, 97, 99], "ptb_iterable_factori": 97, "ptbdataset": 97, "pu": 113, "public": [67, 82, 87, 101, 109, 113, 137], "publicli": 131, "publish": [43, 49, 61, 113, 127], "pubm": 58, "pulfer": 113, "pull": 60, "pullov": [1, 62], "punctuat": [1, 91, 128, 137], "punkt": 91, "punt": 78, "purchas": [22, 58, 120, 138], "pure": 58, "purpos": [3, 8, 11, 15, 16, 34, 35, 41, 42, 43, 45, 47, 52, 56, 57, 58, 61, 66, 73, 74, 79, 101, 104, 105, 107, 114, 117, 121, 122, 125, 140], "pursu": 49, "push": [34, 39, 56, 58, 69, 104, 135], "put": [5, 18, 35, 43, 46, 47, 58, 61, 62, 64, 72, 73, 79, 80, 84, 88, 91, 93, 94, 104, 115, 121, 122, 126, 129, 131, 138], "puzzl": 35, "pwepoiut": 132, "pxrd": [1, 141], "py": [54, 55], "py39_4": 57, "pyplot": [47, 55, 113, 115], "python": [15, 16, 18, 23, 35, 54, 55, 57, 58, 66, 69, 70, 71, 72, 73, 108, 113, 116, 117, 118, 120, 121, 127], "python3": [54, 55], "python_backend": [54, 55], "python_entrypoint": [54, 55], "pythonbackend": [54, 55], "pytorch": [1, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 33, 49, 50, 58, 70, 72, 85, 86, 87, 91, 92, 95, 97, 99, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 119], "q": [1, 2, 3, 7, 8, 30, 32, 35, 45, 58, 59, 60, 64, 65, 67, 75, 80, 93, 96, 100, 102, 109, 123, 129, 130, 133, 135, 138, 141, 142], "q_": [93, 140, 141], "q_0": 141, "q_input": [3, 4], "q_k": [140, 141], "q_learn": 140, "qbaza": 113, "qh": 130, "qingfengtommi": 113, "quad": [64, 86, 117], "quadrat": [9, 11, 34, 39, 64, 69, 74, 86, 102, 105, 111, 117, 121], "quake2005": 113, "qualifi": 102, "qualit": [3, 5, 49, 58, 62, 76, 137], "qualiti": [30, 39, 58, 60, 69, 71, 74, 79, 96, 107, 109, 112, 113, 118, 120, 121, 129, 131, 132, 136], "quanshangz": 113, "quantif": 121, "quantifi": [19, 51, 58, 61, 64, 69, 77, 121, 122], "quantit": [6, 76, 79], "quantiti": [47, 58, 59, 61, 76, 79, 117, 121, 130, 132, 139, 141], "quantiz": 12, "quarter": 45, "quaternion": 64, "queri": [2, 3, 4, 5, 7, 9, 10, 18, 45, 47, 49, 56, 58, 73, 83, 118, 142], "query_token": [95, 99], "quest": 77, "question": [2, 6, 11, 34, 35, 38, 39, 45, 47, 54, 58, 60, 61, 64, 67, 76, 77, 79, 80, 84, 85, 90, 102, 107, 113, 118, 121, 128, 132], "queue": [18, 56], "qui": 128, "quick": [8, 59, 72, 105, 109, 112, 118, 127], "quickli": [2, 29, 47, 48, 49, 51, 52, 55, 58, 60, 71, 82, 102, 103, 104, 111, 112, 113, 115, 118, 121, 132, 136, 137], "quicktak": 34, "quirk": 34, "quit": [1, 3, 4, 8, 19, 35, 36, 38, 39, 41, 46, 48, 52, 55, 59, 62, 64, 65, 72, 79, 80, 101, 102, 105, 107, 108, 109, 110, 114, 121, 122, 127, 130, 132, 135, 136, 137, 139, 141], "quotient": 115, "r": [1, 2, 3, 7, 8, 9, 10, 19, 24, 25, 28, 31, 46, 52, 55, 56, 58, 60, 61, 64, 67, 69, 73, 75, 80, 85, 86, 91, 95, 96, 98, 100, 102, 104, 105, 108, 109, 112, 115, 117, 119, 123, 125, 127, 130, 133, 136, 139, 140, 141, 142], "r1": [1, 141], "r2": [1, 141], "r_": [55, 56, 61, 67], "r_0": [139, 141], "r_1": [19, 139, 141], "r_2": [19, 139], "r_i": 56, "r_m": 19, "r_max": 56, "r_min": 56, "r_t": 139, "rabbit": 43, "rachel": 8, "racial": [58, 60], "rademach": 77, "radford": 49, "radial": [48, 50, 80], "radiat": 71, "radic": 77, "radiu": [35, 104, 115, 135], "rafael": 113, "rahimi": [35, 113], "rahul": 113, "rai": 51, "rain": 132, "rainfal": 58, "rainier": 28, "rais": [1, 2, 4, 51, 58, 60, 62, 72, 82, 97, 124], "rakib": 113, "ram": 62, "ramachandra": 113, "rambl": 58, "ramp": [13, 112, 117], "ran": [15, 55], "rand": [19, 21, 33], "rand_weight": 15, "randint": [51, 54, 55, 56, 90, 97, 118], "randn": 47, "random": [1, 2, 3, 6, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 31, 33, 36, 39, 40, 41, 43, 44, 45, 47, 49, 50, 51, 53, 55, 56, 58, 60, 61, 64, 66, 67, 69, 71, 72, 73, 74, 76, 79, 81, 82, 85, 90, 91, 97, 100, 104, 107, 108, 110, 112, 113, 114, 116, 117, 118, 119, 125, 127, 132, 133, 134, 135, 136, 137, 140, 141, 142], "random_crop": 31, "randombright": 23, "randomcolorjitt": [23, 26], "randomcrop": 31, "randomflipleftright": [22, 23, 26], "randomfliptopbottom": 23, "randomgener": 97, "randomhorizontalflip": [22, 23, 26], "randomhu": 23, "randomli": [6, 15, 17, 22, 23, 25, 26, 31, 41, 51, 52, 56, 58, 61, 62, 64, 67, 69, 71, 76, 77, 90, 93, 97, 98, 119, 132, 135, 136, 140], "randomlight": 26, "randomresizedcrop": [22, 23, 25, 26], "randomsearch": [51, 54, 56], "randomverticalflip": 23, "rang": [1, 2, 6, 7, 9, 10, 11, 12, 14, 18, 19, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 61, 62, 64, 65, 66, 67, 69, 72, 73, 79, 80, 82, 83, 84, 85, 87, 88, 90, 91, 96, 97, 99, 102, 105, 107, 108, 109, 110, 113, 115, 117, 119, 121, 123, 127, 129, 130, 132, 135, 136, 140, 141], "rangl": [49, 100, 112, 117], "rank": [25, 35, 55, 58, 64, 69, 79, 83, 137], "rapid": [5, 13, 18, 39, 58, 105, 113, 116], "rapidli": [6, 13, 48, 67, 74, 77, 80, 105, 107, 109, 112, 115, 121, 125, 136], "rare": [34, 43, 60, 65, 67, 93, 96, 97, 102, 105, 130, 132, 135, 137], "rasmussen": 47, "rasool": 138, "rate": [5, 22, 25, 26, 34, 35, 36, 39, 41, 43, 47, 48, 49, 51, 52, 58, 60, 61, 62, 65, 66, 67, 69, 70, 71, 81, 82, 97, 101, 103, 106, 108, 109, 111, 115, 121, 123, 135, 140, 142], "rather": [2, 3, 4, 5, 8, 16, 17, 18, 19, 22, 30, 31, 32, 34, 35, 36, 39, 40, 41, 45, 46, 47, 58, 60, 61, 62, 64, 67, 68, 69, 70, 71, 73, 74, 76, 77, 79, 80, 81, 85, 86, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 114, 117, 118, 120, 121, 127, 130, 132, 133, 135, 136], "ratio": [19, 21, 22, 23, 25, 26, 27, 30, 32, 37, 45, 60, 94, 97, 102, 107, 115, 121, 129], "ratio_arrai": 19, "ratio_tensor": 19, "rational": 77, "rattler": 58, "rattlesnak": 58, "ravi": 113, "raw": [15, 25, 26, 34, 58, 66, 91, 121, 128, 131, 142], "raw_point": 1, "raw_text": [97, 128, 137], "raw_token_freq": 96, "raw_train": 79, "raw_val": 79, "razor": 47, "rb": [1, 87], "rbf": [47, 48, 50, 80], "rbfkernel": [47, 49], "rceil": 44, "rcparam": 115, "rd": 117, "re": [46, 47, 49, 51, 52, 58, 64, 73, 85, 96, 103, 113, 137], "reach": [29, 34, 39, 54, 55, 56, 58, 62, 64, 66, 69, 77, 80, 81, 97, 105, 107, 108, 113, 122, 123, 128, 136, 139, 140, 141], "read": [1, 13, 17, 18, 24, 27, 34, 40, 52, 54, 58, 60, 63, 64, 68, 78, 82, 83, 84, 94, 106, 116, 119, 121, 126, 131, 132, 136], "read_csv": [29, 79, 120], "read_csv_label": [25, 26], "read_data_banana": 29, "read_data_nmt": 1, "read_imag": [29, 31], "read_imdb": 87, "read_parquet": 91, "read_ptb": 97, "read_snli": 85, "read_voc_imag": [21, 31], "readabl": 72, "reader": [2, 35, 46, 47, 52, 54, 58, 60, 74, 79, 91, 102, 107, 109, 113, 121, 131, 136], "readi": [18, 32, 41, 60, 62, 63, 66, 71, 78, 79, 91, 103, 120, 125, 135, 140], "readili": [8, 58], "readlin": [25, 85, 91], "readthetrainingset": 97, "real": [15, 21, 29, 30, 35, 46, 48, 49, 58, 60, 61, 67, 69, 73, 77, 78, 79, 80, 98, 100, 101, 104, 105, 110, 111, 113, 117, 119, 120, 121, 122, 132, 136, 137, 138, 139, 140], "realist": [34, 51, 62, 69], "realiti": [40, 45, 46, 58, 60, 64, 79], "realiz": [18, 27, 34, 50, 77, 80, 82, 109, 113, 114, 117, 121], "realli": [9, 36, 39, 40, 48, 49, 58, 60, 61, 67, 71, 74, 85, 101, 105, 107, 110, 112, 121, 132, 136, 140], "realm": 60, "realsoftmax": 64, "reap": [13, 135], "reason": [4, 6, 15, 17, 34, 35, 37, 39, 40, 46, 47, 48, 49, 50, 58, 59, 60, 61, 64, 65, 67, 68, 69, 74, 75, 79, 80, 82, 85, 93, 98, 101, 104, 106, 107, 109, 110, 111, 112, 113, 115, 116, 119, 121, 122, 132, 135, 136], "recal": [2, 4, 5, 6, 12, 15, 21, 23, 26, 27, 31, 32, 35, 36, 41, 44, 61, 62, 65, 66, 67, 69, 70, 71, 74, 75, 76, 77, 79, 80, 81, 89, 90, 91, 92, 96, 99, 104, 105, 108, 109, 110, 111, 114, 117, 120, 121, 126, 128, 129, 130, 133, 135, 136, 140], "recalcul": 75, "recalibr": 60, "recap": [103, 117], "recast": 58, "receiv": [5, 8, 18, 46, 58, 60, 61, 69, 73, 78, 83, 102, 115, 121, 136, 140, 141], "recent": [3, 6, 10, 11, 24, 34, 38, 41, 42, 47, 52, 53, 58, 60, 61, 75, 77, 94, 98, 113, 117, 131, 136, 140], "recept": [9, 27, 32, 42, 45], "reciproc": 132, "recogn": [20, 22, 26, 31, 37, 40, 43, 45, 46, 49, 58, 67, 80, 85, 131, 132], "recognit": [4, 5, 15, 20, 24, 34, 39, 45, 58, 60, 62, 67, 77, 90, 113, 126, 131, 132, 136], "recogniz": [5, 35], "recommend": [22, 35, 42, 60, 72, 77, 107, 113, 117, 136, 138], "reconfigur": 119, "reconsid": 60, "reconstruct": [6, 60], "record": [8, 23, 26, 48, 51, 58, 69, 77, 79, 92, 99, 107, 108, 114, 117, 120, 121, 128, 131, 140, 141], "recov": [17, 35, 71, 73, 74, 96, 109, 117, 121, 122, 125], "recoveri": 136, "rect": [19, 31], "rectangl": [6, 20, 61], "rectangular": [19, 20, 21, 31, 45], "rectifi": 80, "recur": [35, 136], "recurr": [5, 9, 10, 39, 42, 80, 86, 88, 113, 127, 129, 130, 142], "recurs": [15, 16, 25, 109, 130], "recycl": [13, 67], "red": [2, 6, 8, 20, 22, 40, 46, 58, 62, 104, 117, 139], "redefin": 4, "redesign": [93, 113], "rediscov": 58, "redress": 102, "reduc": [2, 6, 19, 21, 22, 23, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 39, 43, 44, 45, 46, 47, 48, 54, 55, 56, 58, 61, 62, 64, 67, 69, 71, 74, 77, 80, 85, 88, 89, 102, 103, 105, 107, 108, 109, 110, 112, 117, 119, 121, 125, 135, 136, 140], "reduce_sum": 1, "reduct": [1, 12, 21, 22, 23, 25, 26, 28, 32, 37, 39, 40, 43, 44, 46, 65, 92, 99, 107, 108, 109, 116, 121], "reduction_factor": 55, "redund": [64, 69, 79, 85, 103, 119], "refer": [6, 8, 9, 10, 16, 19, 20, 23, 28, 30, 36, 39, 40, 41, 44, 45, 46, 47, 51, 52, 58, 62, 64, 69, 71, 75, 90, 96, 100, 101, 102, 108, 110, 114, 117, 119, 121, 128, 130, 132, 133], "referenc": [119, 121], "refin": [35, 45, 103, 107], "reflect": [55, 58, 60, 61, 77, 83, 98, 132], "refresh": [66, 107, 113], "regard": [9, 35, 41, 46, 60, 66, 104, 105, 112, 113, 124, 129, 130], "regardless": [2, 3, 8, 40, 42, 45, 46, 49, 59, 61, 90], "regim": [34, 35, 58, 77], "region": [19, 23, 24, 27, 31, 34, 42, 45, 46, 47, 48, 58, 105, 142], "regist": [25, 71, 72, 73, 79, 108, 113], "regnetx": [38, 39], "regob": 113, "regress": [1, 5, 6, 8, 15, 28, 30, 32, 43, 48, 50, 52, 59, 60, 61, 63, 67, 72, 77, 79, 80, 81, 82, 84, 108, 113, 131, 132, 133, 136, 142], "regressor": 58, "regular": [3, 4, 10, 11, 33, 34, 35, 37, 38, 39, 48, 52, 60, 67, 71, 75, 76, 78, 79, 82, 108, 109, 113, 125, 127, 130], "regularli": 130, "reign": 58, "reimplement": [8, 15, 113, 134], "reinforc": [5, 6, 8, 10, 39, 113, 121, 139, 140, 141, 142], "reinstat": [11, 17], "reinvent": 70, "reject": [49, 132], "rel": [2, 5, 19, 21, 26, 27, 32, 34, 36, 37, 43, 45, 47, 48, 49, 58, 60, 61, 64, 66, 67, 75, 79, 80, 97, 100, 102, 107, 108, 109, 112, 113, 117, 119, 121, 129, 130, 131, 132, 136], "relat": [2, 4, 9, 22, 24, 35, 41, 42, 47, 58, 60, 61, 67, 69, 71, 77, 78, 80, 81, 93, 102, 117, 120, 121, 125, 132, 136, 141], "relationship": [5, 6, 46, 58, 61, 67, 69, 74, 80, 84, 85, 86, 90, 93, 96, 98, 110, 121, 123, 133], "relax": 67, "releas": [6, 13, 34, 58, 62], "relev": [4, 8, 19, 46, 50, 52, 57, 58, 59, 62, 67, 71, 79, 80, 83, 137], "reli": [1, 2, 3, 5, 8, 10, 13, 15, 16, 23, 34, 35, 39, 58, 60, 61, 62, 64, 67, 69, 70, 71, 74, 75, 76, 77, 81, 84, 98, 107, 113, 129, 134, 135], "reliabl": [47, 58, 70, 77, 108, 140, 141], "relianc": 80, "reload": 69, "relu": [1, 5, 10, 11, 12, 14, 15, 16, 17, 21, 26, 32, 34, 36, 37, 39, 43, 45, 52, 76, 81, 82, 86, 88, 90, 107, 110, 135], "remain": [2, 3, 5, 6, 11, 15, 19, 25, 29, 30, 32, 34, 35, 38, 41, 43, 46, 52, 55, 56, 58, 60, 61, 63, 64, 67, 76, 77, 82, 90, 91, 94, 103, 104, 107, 108, 113, 115, 118, 127, 128, 131, 135, 137], "remaind": [3, 19, 46, 58, 60, 76, 128, 140, 141], "remark": [5, 8, 39, 41, 43, 58, 61, 71, 77, 117], "rememb": [8, 35, 57, 58, 60, 111, 114, 117, 125, 141], "remind": [43, 58], "remot": 135, "remov": [2, 3, 6, 19, 25, 30, 32, 33, 34, 35, 48, 58, 72, 74, 76, 79, 85, 88, 95, 97, 99, 105, 108, 130], "renam": 81, "rename_kei": [1, 22], "render": [35, 60, 64, 82, 113], "renorm": 121, "rent": 121, "reopen": 57, "reorg_cifar10_data": 25, "reorg_dog_data": 26, "reorg_test": [25, 26], "reorg_train_valid": [25, 26], "repai": [60, 80], "repair": 58, "reparametr": 110, "repay": [60, 80], "repeat": [3, 4, 7, 15, 19, 30, 37, 38, 48, 51, 56, 58, 71, 90, 108, 112, 115, 121, 130, 135], "repeat_interleav": 19, "repeatedli": [35, 46, 49, 58, 61, 104, 115], "repertoir": 68, "repetit": [13, 51, 54, 70, 113, 121], "replac": [1, 2, 3, 4, 6, 10, 11, 26, 28, 30, 32, 33, 35, 39, 41, 43, 45, 56, 58, 70, 72, 74, 76, 79, 80, 87, 88, 90, 91, 93, 96, 97, 102, 103, 108, 109, 112, 115, 119, 120, 123, 125, 126, 127, 128, 129, 130, 135, 140], "repli": [34, 58, 128], "replic": [108, 119], "repo_id": 1, "repo_typ": 1, "report": [6, 18, 34, 46, 51, 54, 55, 58, 59, 61, 66, 67, 72, 79, 83, 121, 136], "repositori": [113, 120], "repres": [6, 8, 9, 10, 12, 15, 16, 20, 24, 27, 28, 29, 31, 32, 34, 41, 42, 43, 46, 47, 48, 49, 52, 54, 55, 56, 58, 60, 61, 62, 64, 66, 69, 70, 76, 77, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 93, 94, 96, 97, 98, 100, 109, 113, 114, 117, 119, 120, 121, 122, 128, 130, 131, 133, 135, 136, 137], "represent": [2, 4, 5, 6, 7, 8, 9, 10, 11, 15, 20, 24, 27, 28, 32, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 58, 64, 65, 80, 82, 83, 84, 86, 88, 92, 94, 96, 98, 99, 113, 114, 117, 120, 129, 136, 137, 142], "reprint": 41, "reproduc": [47, 48, 49, 74, 80, 141], "reproduct": [34, 43, 76], "reput": 47, "request": [1, 18, 58, 113], "requir": [1, 2, 3, 6, 8, 10, 12, 15, 17, 18, 19, 21, 22, 23, 25, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 66, 67, 69, 70, 71, 72, 73, 75, 76, 77, 79, 80, 82, 83, 84, 89, 90, 93, 98, 101, 102, 103, 104, 105, 106, 108, 109, 112, 113, 114, 115, 119, 120, 121, 123, 124, 127, 129, 130, 131, 133, 136, 140, 141], "required_lib": [140, 141], "requires_grad": [22, 26], "requisit": 121, "rerun": 129, "rescal": [3, 10, 28, 31, 35, 76, 79, 101, 102, 103, 108], "rescu": [58, 121], "research": [5, 6, 8, 11, 12, 13, 18, 22, 34, 35, 38, 43, 46, 47, 49, 58, 60, 61, 64, 69, 70, 76, 77, 79, 80, 82, 87, 90, 91, 94, 105, 113, 125, 128, 131], "resembl": [5, 34, 35, 58, 77, 82, 109, 119, 125, 127], "reserv": [71, 117], "reserved_token": [1, 85, 87, 91, 137], "reset": [1, 23, 25, 26, 32, 56, 85, 86, 88, 99, 107, 108, 126, 127, 140], "reset_ctx": [21, 22, 26], "reshap": [1, 2, 3, 4, 7, 8, 9, 10, 19, 21, 28, 30, 32, 33, 35, 40, 41, 44, 45, 59, 65, 66, 70, 71, 73, 76, 79, 81, 86, 90, 92, 95, 97, 99, 108, 117, 119, 129, 135, 136], "reshuffl": [71, 73], "resid": 35, "residu": [1, 5, 11, 35, 36, 37, 38, 62, 127, 142], "resili": [76, 79, 103], "resist": [58, 71], "resistor": 58, "resiz": [1, 11, 22, 25, 26, 28, 30, 32, 34, 36, 37, 39, 62], "resnet": [1, 10, 11, 15, 21, 22, 23, 26, 32, 38, 43, 52, 58, 113, 142], "resnet18": [1, 21, 22, 23, 25, 39], "resnet18_v2": [21, 22], "resnet34": 26, "resnet34_v2": 26, "resnet_block": 1, "resnetblock": 39, "resnext": [38, 40, 142], "resnextblock": 39, "resolut": [11, 34, 37, 39, 40, 44, 45, 46, 58, 62, 67, 80, 82, 90, 131], "resolv": [77, 80, 91, 92, 107, 112, 132, 140], "reson": 35, "resort": [8, 58], "resourc": [5, 51, 52, 54, 55, 56, 58, 74, 83, 113, 117], "resource_attr": 55, "respect": [2, 3, 6, 9, 11, 12, 15, 16, 17, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 54, 58, 60, 62, 63, 64, 66, 67, 69, 71, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 96, 97, 98, 99, 100, 102, 104, 105, 108, 110, 112, 113, 114, 115, 117, 119, 120, 121, 122, 129, 130, 132, 133, 136, 141], "respir": 83, "respond": [40, 41, 46, 58, 60], "respons": [6, 34, 41, 58, 60, 64, 107, 121, 127, 140], "responsibli": 60, "rest": [10, 19, 22, 30, 31, 41, 56, 58, 61, 72, 76, 79, 90, 96, 108, 119, 127, 132], "restat": 15, "restor": [19, 28], "restrict": [17, 46, 60, 61, 67, 69, 74, 77, 121, 139], "result": [1, 2, 3, 5, 6, 7, 9, 10, 11, 15, 17, 18, 19, 21, 22, 23, 24, 28, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 54, 55, 58, 59, 60, 61, 65, 66, 67, 69, 71, 73, 76, 77, 79, 80, 81, 83, 85, 86, 88, 89, 90, 92, 93, 95, 96, 97, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 117, 119, 121, 122, 125, 127, 129, 130, 131, 132, 133, 135, 136, 137, 139, 140, 141], "resum": [55, 58], "resurg": [80, 140], "ret": 79, "ret_typ": [95, 99], "retail": [58, 69, 138], "retain": [5, 13, 15, 28, 31, 43, 71, 75, 76, 80, 91, 119, 123, 125, 127, 133], "retent": 28, "retrain": [25, 26], "retriev": [8, 55, 58, 85, 131], "return": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 56, 58, 59, 62, 65, 66, 69, 70, 71, 72, 73, 74, 76, 79, 81, 83, 85, 86, 87, 88, 90, 91, 92, 95, 96, 97, 99, 101, 102, 103, 105, 107, 108, 109, 110, 111, 112, 114, 115, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 132, 134, 135, 136, 137, 138, 140, 141], "return_count": 19, "reus": [15, 16, 17, 26, 32, 36, 56, 63, 66, 72, 75, 81, 119, 130], "reusabl": 72, "reveal": [61, 77, 117, 131], "revenu": 117, "revers": [7, 25, 33, 58, 75, 121, 136, 137], "review": [2, 3, 6, 8, 34, 35, 39, 46, 58, 65, 69, 70, 74, 81, 87, 94, 99, 103, 105, 107, 109, 114, 117, 121, 131, 136], "revis": 71, "revisit": [5, 15, 35, 37, 38, 61, 63, 67, 78, 93, 109, 133], "reviv": 74, "revolut": [58, 131], "revolution": [58, 90, 113], "revolutionari": 61, "revolv": 136, "reward": [1, 58, 60, 70, 121, 139, 140, 141], "reward_idx": [1, 141], "reweigh": 60, "rewrit": [33, 46, 89, 102, 103, 109], "rewritten": [93, 98], "rfloor": [25, 44, 132], "rgb": [22, 25, 26, 28, 29, 31, 40], "rgb_mean": [28, 31], "rgb_std": [28, 31], "rho": [100, 101, 111], "ri": 56, "riccardo": 113, "rich": [6, 42, 46, 58, 69, 80, 93, 94, 104, 114], "richard": 141, "richer": 85, "richychen": 113, "rid": [55, 105], "riddl": 77, "ridg": [74, 77], "riemann": 49, "righli": 48, "right": [1, 2, 3, 6, 9, 11, 19, 20, 23, 28, 29, 30, 34, 35, 36, 39, 41, 44, 45, 46, 47, 48, 49, 58, 60, 61, 69, 71, 74, 75, 77, 79, 80, 82, 88, 89, 90, 93, 97, 98, 102, 103, 104, 105, 107, 109, 111, 112, 115, 117, 121, 122, 125, 129, 130, 131, 132, 135, 136, 139, 140, 141], "rightarrow": [35, 52, 104, 105, 115, 119, 121, 129, 140, 141], "rightli": 67, "rightward": 75, "rigid": [58, 61], "rigor": [34, 35, 80, 113, 115, 117], "rigtorp": 113, "riplus1": 56, "rise": [4, 42, 58, 60, 127, 136], "risk": [58, 61, 67, 78, 80, 82, 108, 110, 112, 117], "riski": [65, 121], "rkh": 74, "rl": [1, 47, 79, 112, 138], "rm": [79, 101], "rmsprop": [101, 103, 105, 106, 142], "rmsprop_2d": 111, "rnn": [4, 5, 8, 10, 83, 84, 88, 113, 123, 124, 125, 126, 127, 128, 129, 131, 134, 136, 137], "rnn_block": 123, "rnn_output": 135, "rnnlm": [123, 125, 127, 134], "rnnlmscratch": [123, 125, 127, 134, 135], "rnnscratch": [123, 134, 135], "road": [20, 65, 142], "roadsid": 60, "roberta": [5, 6, 96], "robot": [6, 20, 58, 131, 139, 140, 141], "robust": [34, 35, 47, 48, 54, 60, 66, 70, 74, 103, 104, 110, 130, 135], "rohankarthikeyan": 113, "roi": 30, "roi_end_h": 30, "roi_end_w": 30, "roi_featur": 30, "roi_height": 30, "roi_idx": 30, "roi_pool": 30, "roi_start_h": 30, "roi_start_w": 30, "roi_width": 30, "role": [13, 38, 39, 47, 52, 58, 60, 82, 83, 90, 104, 106, 113, 137], "roll": [13, 104, 109, 121], "rome": 58, "ron": 113, "ronald": 58, "rongruosong": 113, "roof": [79, 120], "rooftyp": 120, "rooftype_nan": 120, "rooftype_sl": 120, "room": [47, 58, 120], "roost": 34, "rooster": [58, 64], "root": [1, 10, 23, 25, 47, 54, 55, 62, 72, 74, 79, 89, 112, 115, 117, 121, 128, 137, 142], "rose": [127, 131], "rosenblatt": 58, "rotat": [2, 6, 29, 102, 105, 109, 111, 117], "rough": 52, "roughli": [6, 44, 49, 51, 52, 58, 61, 75, 113, 122, 136, 137, 140], "round": [30, 39, 55, 56, 61, 65, 67, 91], "rout": [20, 46, 58], "routin": [12, 35, 47, 58, 74, 102, 115, 119, 120], "row": [2, 3, 8, 9, 10, 19, 21, 27, 28, 32, 33, 43, 44, 46, 58, 59, 60, 64, 66, 69, 73, 80, 85, 90, 95, 99, 100, 108, 117, 119, 120, 121, 129, 130, 131, 133], "row_ax": 8, "row_discard": 19, "row_matric": 8, "rowwis": [64, 80], "rstride": 110, "rstrip": [25, 95], "rubinfeld": 79, "rule": [18, 33, 34, 52, 55, 58, 59, 61, 67, 75, 100, 103, 105, 114, 116, 121, 130, 132, 136], "run": [0, 6, 16, 17, 18, 23, 34, 35, 37, 41, 43, 44, 46, 47, 48, 50, 51, 52, 54, 55, 56, 58, 61, 62, 66, 69, 71, 72, 74, 75, 78, 85, 91, 92, 97, 101, 108, 114, 117, 118, 119, 121, 122, 125, 127, 128, 129, 133, 134, 135, 140, 141], "runawai": 60, "rung": [55, 56], "rung_index": 56, "rung_level": 56, "runnabl": 113, "runner": 38, "runtim": [18, 47, 51, 56, 57, 108, 125], "runtimeerror": 1, "rural": 79, "rush": 60, "ruslan": 113, "rv": [51, 52], "rx": 110, "ryan": 113, "s1": [102, 105, 109, 111, 112], "s2": [102, 105, 109, 111, 112], "s3": [22, 25, 26, 29, 31, 79, 86, 88, 91, 95, 99, 107, 132], "s_": [40, 44, 45, 47, 139, 140, 141], "s_0": [139, 140, 141], "s_1": [19, 139, 141], "s_2": [19, 139], "s_3": 19, "s_b": [101, 102, 103, 111], "s_bias_corr": 103, "s_i": [83, 121], "s_n": 19, "s_t": [139, 140, 141], "s_w": [101, 102, 103, 111], "sa": 88, "sad": 113, "saddl": [69, 104, 109], "sadli": 110, "safe": [79, 102], "safeguard": 62, "safetensor": [1, 26, 28], "sagemak": 54, "saha": 113, "sahoo": 113, "sai": [3, 6, 14, 15, 17, 19, 21, 27, 29, 30, 35, 41, 45, 46, 48, 56, 58, 60, 61, 64, 67, 74, 76, 77, 80, 83, 105, 108, 110, 114, 115, 117, 121, 122, 132, 133, 135, 136, 139], "said": [24, 41, 45, 47, 58, 61, 67, 69, 115, 121, 133, 135], "saint": 132, "sake": [35, 41, 60, 75], "salari": 58, "sale": [58, 69], "salecondit": 79, "salepric": 79, "salesforc": [91, 92], "saletyp": 79, "salient": [5, 127], "salli": 58, "salut": 128, "salvag": 60, "same": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 44, 45, 46, 47, 49, 51, 52, 54, 55, 56, 58, 59, 60, 61, 63, 64, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 83, 85, 88, 90, 92, 93, 94, 96, 98, 99, 100, 101, 102, 105, 107, 108, 109, 111, 114, 115, 117, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 139, 140, 141], "samoi": 26, "sampl": [1, 6, 19, 20, 22, 23, 25, 26, 27, 31, 34, 35, 40, 41, 42, 46, 47, 48, 49, 51, 52, 54, 56, 58, 59, 60, 61, 66, 67, 69, 76, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 98, 99, 106, 107, 108, 118, 119, 121, 129, 132, 135, 136, 140, 141], "sample_configur": [51, 56], "sample_submiss": [25, 26], "sample_transform": [22, 23, 25], "sampler": 58, "samplesubmiss": 25, "sampling_weight": 97, "san": [58, 132], "sancak": 113, "sanctiti": 61, "sandal": [1, 62], "sandwich": 39, "saniti": [8, 12, 62, 79], "sanjar": 113, "santa": 60, "sate": 141, "satellit": [46, 58], "satisfact": [104, 113], "satisfi": [2, 15, 19, 46, 60, 61, 64, 66, 82, 102, 104, 105, 110, 117, 121, 130, 132, 136, 138], "satur": [23, 26], "sauc": 58, "save": [1, 3, 4, 7, 8, 9, 10, 12, 13, 16, 18, 19, 20, 22, 23, 25, 26, 29, 31, 32, 34, 39, 41, 43, 49, 51, 52, 54, 55, 56, 59, 62, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 87, 90, 91, 92, 95, 97, 105, 108, 110, 113, 115, 116, 123, 124, 125, 127, 128, 129, 132, 133, 134, 135, 137], "save_attention_weight": 129, "save_hyperparamet": [1, 11, 18, 34, 35, 36, 37, 39, 43, 51, 56, 62, 65, 66, 70, 71, 72, 73, 74, 76, 79, 81, 123, 125, 127, 128, 129, 132, 134, 135, 136], "savez": 17, "saw": [19, 41, 46, 49, 64, 76, 80, 102, 103, 107, 109, 110, 121, 128, 132, 137], "scalabl": [5, 11, 47, 50, 51, 58, 78, 109, 113], "scalar": [2, 7, 8, 15, 32, 35, 41, 64, 66, 71, 73, 75, 83, 88, 93, 100, 105, 108, 110, 115, 116, 119, 121, 130, 135], "scale": [1, 2, 4, 5, 7, 9, 10, 11, 18, 19, 21, 22, 23, 25, 26, 27, 29, 30, 34, 35, 37, 38, 39, 40, 47, 48, 49, 50, 52, 54, 58, 61, 62, 64, 66, 67, 71, 74, 79, 82, 83, 87, 102, 103, 105, 108, 111, 112, 114, 115, 117, 121, 123, 132, 142], "scale_factor": 21, "scan": [40, 43, 58], "scarc": [58, 67], "scarciti": 58, "scatter": [47, 56, 77, 113], "scenario": [55, 61, 112, 132], "scene": [15, 46, 58], "sceneri": 28, "schedul": [5, 25, 26, 28, 53, 56, 106, 108, 111, 112, 142], "scheme": [9, 11, 19, 60, 61, 82], "schlatter": 113, "schlessing": 113, "schmidhub": 34, "schnauzer": 58, "scholar": [58, 121], "schole": 69, "schon": 58, "school": [117, 120, 121], "schwartz": 113, "scienc": [58, 67, 69, 77, 113, 120], "scientif": [6, 16, 35, 61, 67, 77, 119], "scientist": [58, 60, 67, 79, 80, 113, 118, 131, 132, 136], "scipi": [47, 49, 51, 52, 56, 113], "scope": [52, 60, 72, 102, 107, 121], "score": [4, 5, 9, 10, 19, 32, 46, 55, 58, 59, 60, 61, 64, 79, 83, 121, 122, 129, 142], "scrape": 137, "scratch": [6, 13, 15, 22, 38, 50, 54, 55, 58, 59, 60, 62, 63, 64, 68, 70, 78, 80, 82, 83, 90, 103, 106, 113, 115, 121, 126, 131, 134, 136, 142], "scratch_net": 22, "screen": [58, 65], "script": [47, 54, 57], "sea": [5, 47], "seaborn": 120, "search": [8, 30, 34, 38, 51, 53, 55, 56, 57, 60, 69, 83, 95, 126, 129, 135, 136, 142], "searcher": [53, 54, 56], "seattl": 28, "sec": [1, 21, 22, 23, 25, 26, 32, 55, 62, 69, 86, 88, 92, 99, 101, 102, 103, 108, 109, 111], "sec_cnn": [37, 39], "sec_d2l": 113, "sec_how_to_contribut": 113, "sec_mf_hpo": 52, "sec_mf_hpo_sh": [], "sec_multi_gpu": 86, "sec_multi_gpu_concis": 23, "sec_nin": 32, "sec_rnn": 135, "sec_sentiment_rnn": 88, "sec_softmax_concis": 1, "sec_util": 1, "sec_vgg": 28, "secant": 115, "second": [2, 3, 9, 10, 11, 14, 16, 18, 19, 28, 32, 34, 35, 37, 39, 41, 43, 44, 45, 46, 51, 52, 58, 59, 60, 64, 66, 68, 69, 71, 72, 75, 76, 79, 81, 82, 83, 90, 96, 101, 102, 103, 105, 108, 110, 114, 115, 117, 119, 121, 122, 126, 129, 130, 132, 136, 137, 140, 141], "secondari": [35, 52, 80], "secondli": 107, "secret": 58, "section": [1, 2, 3, 6, 8, 9, 10, 12, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 56, 57, 59, 60, 62, 64, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 79, 82, 83, 86, 87, 88, 89, 91, 92, 93, 96, 97, 98, 102, 103, 105, 107, 109, 110, 112, 113, 117, 119, 120, 121, 122, 123, 124, 126, 128, 129, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141], "secur": [20, 136], "sedlmey": 113, "see": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 15, 16, 18, 19, 20, 21, 22, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 102, 104, 105, 107, 108, 109, 110, 112, 114, 115, 117, 118, 119, 121, 124, 127, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "seed": [1, 51, 118, 140, 141], "seeger": 53, "seek": [46, 58, 61, 62, 69, 113], "seem": [34, 35, 40, 46, 47, 48, 49, 58, 61, 69, 75, 77, 82, 105, 109, 113, 122, 131, 137, 139], "seemingli": [46, 73, 77, 136], "seen": [33, 41, 47, 48, 52, 54, 55, 56, 58, 60, 62, 67, 80, 84, 90, 93, 104, 105, 107, 108, 112, 127, 130, 132, 136, 137, 138], "seer": 69, "segment": [5, 21, 24, 33, 37, 38, 46, 58, 79, 83, 90, 91, 92, 96, 104, 121, 128, 130, 142], "segment_bp": 96, "segment_embed": 90, "segmentationclass": 31, "segments_x": [91, 92], "segments_x_shard": 92, "seldom": [60, 61, 67, 69, 77, 121, 131, 136], "select": [4, 5, 8, 19, 23, 25, 26, 28, 30, 35, 37, 47, 51, 52, 58, 59, 61, 66, 68, 71, 74, 78, 84, 90, 104, 105, 113, 119, 120, 122, 123, 139, 140], "self": [1, 3, 4, 5, 6, 7, 10, 11, 12, 15, 17, 18, 20, 24, 26, 28, 29, 31, 32, 34, 35, 36, 37, 39, 41, 43, 51, 52, 56, 59, 62, 65, 66, 70, 71, 72, 73, 74, 76, 79, 81, 85, 86, 88, 90, 91, 92, 94, 95, 97, 99, 107, 108, 113, 123, 124, 125, 127, 128, 129, 132, 134, 135, 136, 137, 138, 142], "selipski": 113, "sell": 69, "seller": 58, "semant": [5, 21, 24, 30, 33, 45, 83, 85, 86, 90, 93, 95, 98, 99, 132, 142], "semerci": 113, "semi": 38, "semiconductor": 13, "semidefinit": 104, "semin": [58, 61, 70], "send": [12, 108, 138], "senorcinco": 113, "sens": [38, 39, 40, 47, 48, 58, 60, 61, 64, 66, 74, 77, 79, 80, 104, 107, 114, 121, 123, 135], "sensibl": [51, 52, 132], "sensit": [6, 23, 35, 45, 47, 58, 59, 60, 69, 76, 92, 94, 107, 111, 117], "sensor": [34, 35, 41, 58, 62, 69, 120, 136], "sent": [18, 58, 69], "sent_token": 91, "sentenc": [3, 4, 5, 6, 10, 58, 83, 85, 86, 88, 92, 97, 128, 129, 132, 136, 137], "sentient": 58, "sentiment": [6, 83, 84, 85, 90, 136, 142], "sep": [83, 90, 91, 92], "separ": [10, 17, 21, 34, 35, 39, 40, 45, 58, 69, 72, 76, 77, 79, 81, 83, 86, 88, 90, 92, 97, 108, 111, 113, 114, 120, 128, 129, 134, 135], "sepp": 5, "seq": [90, 128], "seq2seq": [4, 10, 128, 129], "seq2seqattentiondecod": 4, "seq2seqdecod": 129, "seq2seqencod": [4, 129], "sequel": 51, "sequenc": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 18, 36, 42, 46, 52, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 98, 106, 112, 118, 121, 122, 123, 124, 125, 126, 127, 130, 131, 133, 135, 138, 139, 142], "sequenti": [1, 8, 9, 11, 12, 13, 14, 16, 18, 21, 26, 28, 32, 34, 35, 36, 37, 39, 43, 51, 52, 54, 65, 75, 76, 81, 86, 90, 99, 107, 108, 113, 123, 131, 136, 138], "serendipit": [34, 35], "seri": [6, 19, 23, 30, 37, 41, 42, 49, 50, 58, 61, 77, 113, 115, 127, 131], "serial": [6, 12, 17], "seriou": [58, 66, 67, 82, 113], "serv": [4, 38, 39, 45, 51, 58, 60, 62, 74, 79, 101, 107, 112, 137], "server": [17, 18, 34, 57, 61, 108, 120], "servic": [5, 64, 113, 132], "set": [1, 2, 3, 6, 7, 8, 9, 11, 15, 16, 17, 18, 19, 21, 22, 23, 24, 27, 28, 29, 31, 34, 36, 39, 40, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 71, 73, 74, 76, 77, 79, 80, 82, 83, 85, 86, 87, 89, 90, 91, 92, 93, 97, 98, 99, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 132, 133, 135, 136, 137, 139, 140, 141], "set_ax": [1, 115], "set_default_devic": 18, "set_figs": [19, 20, 21, 23, 27, 28, 32, 47, 49, 54, 55, 56, 87, 104, 105, 108, 109, 110, 111, 115, 121, 128], "set_hatch": 128, "set_index": 29, "set_learning_r": [26, 107, 108], "set_matplotlib_format": 115, "set_np": [19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 33, 85, 87, 91, 92, 95, 99, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112], "set_printopt": 19, "set_titl": [1, 8], "set_vis": 1, "set_xlabel": [1, 2, 8, 115, 121], "set_xlim": [1, 115], "set_xscal": [1, 108, 115], "set_xtick": 1, "set_ylabel": [1, 8, 115, 121], "set_ylim": [1, 115], "set_yscal": [1, 115], "set_ytick": 1, "set_ztick": 110, "setattr": [1, 22, 32, 72], "setminu": 100, "settl": [58, 64, 113], "setup": [54, 58, 60, 69, 140, 141], "setuptool": [140, 141], "seven": 4, "sever": [16, 17, 18, 20, 24, 31, 32, 34, 39, 48, 51, 52, 54, 58, 61, 65, 67, 77, 81, 90, 93, 102, 113, 115, 120, 126, 128, 136], "sewag": 58, "sexual": 76, "sfermigi": 113, "sfilip": 113, "sgd": [1, 21, 22, 25, 26, 32, 52, 59, 69, 70, 71, 74, 102, 106, 107, 108, 109, 112], "sgd_momentum": 109, "sgd_re": 108, "sgn": 103, "sh": [55, 57], "sha": 79, "sha1": 1, "sha1_hash": [1, 79], "shade": [19, 33, 40, 41, 44, 45, 48, 88, 130], "shadow": 60, "shall": [30, 43, 86], "shallow": [34, 58, 68, 75], "shampoo": 35, "shan": 113, "shannon": [58, 64], "shape": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 49, 58, 59, 62, 65, 66, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 85, 86, 87, 88, 90, 91, 92, 97, 99, 102, 107, 108, 109, 112, 114, 115, 117, 118, 119, 121, 124, 125, 127, 128, 129, 130, 133, 135, 136], "shape_aug": 23, "shard": 92, "share": [4, 6, 12, 15, 16, 30, 34, 39, 58, 69, 79, 82, 88, 96, 108, 111, 113, 121, 131], "sharei": [2, 8], "sharex": 8, "sharp": [45, 65, 90], "sharpen": [41, 121], "sharper": 28, "shazbot": 113, "she": 67, "shed": [35, 58, 83, 112], "sheep": 31, "sheer": [52, 70], "shelf": [38, 58, 60, 91], "shell": 57, "sheng": 113, "sherrington": 58, "shift": [2, 5, 6, 35, 38, 39, 41, 44, 45, 46, 58, 63, 67, 69, 80, 82, 128, 129, 132, 133, 142], "shift_i": 19, "shift_x": 19, "shiftnet": [38, 39], "shine": 34, "ship": [58, 60], "shirt": [1, 62], "shivam": 113, "shjustinbaek": 113, "shoe": [121, 137], "shop": 58, "short": [4, 18, 42, 45, 46, 47, 49, 58, 60, 61, 64, 67, 72, 74, 75, 102, 104, 107, 108, 110, 112, 116, 121, 123, 125, 126, 130, 136, 139, 141, 142], "shortcom": 52, "shortcut": 39, "shorten": [97, 114], "shorter": [3, 7, 9, 58, 85, 98, 108, 128, 129, 132], "shortest": [9, 10, 58], "shorthand": 121, "shortli": 127, "shot": [6, 24, 30, 142], "should": [1, 2, 5, 8, 10, 12, 17, 18, 19, 20, 25, 35, 37, 39, 40, 41, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 64, 66, 67, 69, 70, 71, 74, 76, 79, 80, 83, 86, 93, 101, 104, 105, 107, 112, 113, 114, 117, 118, 119, 120, 121, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 139, 140, 141], "shoulder": 58, "show": [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 19, 23, 24, 25, 26, 27, 28, 30, 31, 34, 38, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 58, 59, 60, 62, 64, 66, 69, 70, 72, 76, 77, 80, 85, 86, 88, 90, 94, 95, 99, 101, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 117, 119, 125, 128, 130, 132, 134, 135, 140, 141], "show_bbox": [19, 27, 29, 32], "show_heatmap": [3, 4, 8, 9, 10], "show_imag": [1, 21, 22, 23, 29, 31, 62], "show_list_len_pair_hist": [97, 128], "show_q_function_progress": [1, 140], "show_trac": 105, "show_trace_2d": [102, 105, 109, 111, 112], "show_value_function_progress": [1, 141], "shown": [6, 10, 11, 18, 19, 21, 22, 23, 25, 26, 30, 32, 36, 37, 40, 41, 49, 58, 60, 64, 83, 88, 98, 104, 127, 130, 139, 141], "shreshtha13": 113, "shrimali": 113, "shrink": [2, 8, 36, 74, 77, 115, 135], "shrinkag": 44, "shuai": 113, "shuangchi": 113, "shuffl": [1, 22, 23, 25, 26, 29, 31, 62, 72, 73, 85, 91, 97], "shuffle_if": [1, 22, 23, 25, 29, 31], "shukla": 113, "shun": 34, "shutil": [25, 113], "shutter": 45, "sibas_minich": 60, "sich": 58, "sick": 60, "side": [20, 33, 35, 44, 48, 64, 77, 80, 93, 100, 104, 105, 109, 113, 115, 119, 121, 135], "sie": 58, "sift": [34, 58], "sig": 47, "sight": [58, 94, 121], "sigma": [2, 32, 35, 47, 48, 49, 52, 61, 64, 66, 69, 70, 71, 73, 74, 76, 79, 80, 81, 82, 89, 100, 121, 123, 125, 127, 135], "sigma_": 35, "sigma_1": 80, "sigma_2": 80, "sigma_b": 49, "sigma_h": 19, "sigma_i": [19, 100], "sigma_v": 49, "sigma_w": 19, "sigma_x": [19, 100], "sigmd": 99, "sigmoid": [34, 35, 43, 82, 89, 99, 107, 125, 127], "sigmoidbceloss": 99, "sign": [58, 64, 103, 105, 110, 117, 139], "signal": [1, 15, 35, 44, 45, 58, 64, 80, 97, 136], "signatur": [72, 108, 119], "signifi": [75, 117, 137], "signific": [5, 7, 8, 11, 18, 19, 23, 34, 35, 38, 39, 40, 41, 42, 43, 44, 46, 58, 60, 61, 67, 71, 77, 80, 81, 82, 103, 105, 107, 108, 113, 117, 134], "significantli": [6, 22, 34, 35, 36, 37, 43, 47, 56, 58, 60, 67, 69, 75, 78, 80, 89, 90, 92, 97, 102, 108, 109, 112, 121, 127, 128, 136, 137], "sim": [14, 23, 47, 48, 49, 52, 60, 61, 64, 67, 69, 74, 76, 89, 95, 99, 100, 104, 121, 132, 141], "similar": [3, 5, 6, 10, 11, 15, 19, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 51, 54, 58, 59, 60, 61, 62, 64, 70, 71, 74, 76, 80, 82, 83, 86, 87, 89, 90, 94, 96, 97, 98, 99, 108, 109, 111, 112, 123, 125, 127, 128, 129, 130, 132, 133, 135, 137, 140, 141, 142], "similarli": [9, 11, 18, 23, 26, 35, 43, 46, 49, 58, 61, 64, 65, 74, 77, 82, 88, 92, 100, 101, 113, 115, 119, 135, 140], "simon": [71, 113], "simonwardjon": 113, "simpl": [5, 6, 7, 8, 9, 12, 15, 24, 28, 29, 32, 34, 36, 38, 39, 41, 43, 45, 47, 48, 50, 51, 52, 54, 55, 56, 58, 60, 62, 64, 67, 69, 74, 75, 76, 79, 80, 81, 82, 88, 90, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 120, 122, 123, 125, 127, 128, 129, 130, 133, 135, 136, 139, 140, 141], "simpler": [3, 16, 34, 35, 39, 60, 67, 77, 80, 86, 104, 107, 121, 127, 130], "simplest": [5, 8, 23, 47, 56, 57, 58, 69, 72, 73, 74, 77, 78, 112], "simpli": [2, 3, 4, 6, 8, 12, 15, 18, 26, 28, 32, 34, 35, 37, 39, 40, 41, 44, 46, 47, 48, 49, 52, 57, 58, 60, 61, 64, 67, 69, 71, 72, 74, 75, 76, 77, 79, 80, 82, 88, 101, 102, 104, 107, 108, 112, 115, 117, 120, 121, 122, 123, 125, 130, 132, 133, 135, 136, 139], "simplic": [2, 19, 21, 32, 41, 47, 52, 56, 58, 60, 70, 72, 75, 76, 79, 80, 91, 105, 107, 108, 137], "simplifi": [2, 3, 4, 8, 11, 15, 19, 28, 34, 36, 37, 40, 43, 44, 46, 58, 59, 69, 72, 75, 78, 79, 83, 98, 102, 109, 117, 121, 125, 130, 133, 137], "simplist": 60, "simul": [58, 112, 121, 141], "simulateur": 70, "simultan": [23, 31, 35, 37, 60, 61, 64, 69, 77, 82, 104, 113, 121, 131], "sin": [2, 9, 47, 49, 72, 105, 112, 114, 136], "sinc": [3, 4, 6, 9, 10, 11, 16, 17, 18, 19, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 49, 52, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 80, 81, 82, 87, 89, 92, 93, 96, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 124, 125, 127, 128, 129, 130, 132, 133, 136, 137, 141], "sine": 9, "singl": [1, 3, 5, 6, 7, 10, 11, 15, 18, 24, 30, 34, 35, 36, 40, 41, 45, 46, 47, 48, 54, 55, 56, 58, 61, 64, 65, 67, 69, 70, 74, 75, 76, 80, 81, 82, 84, 85, 86, 88, 90, 92, 96, 105, 108, 110, 113, 115, 118, 119, 120, 121, 122, 123, 129, 130, 131, 132, 133, 135, 136, 137, 142], "singleton": 132, "singular": [47, 58, 83], "sinh": 105, "sink": 46, "siri": 58, "sit": [55, 61, 90, 94], "site": [1, 54, 55, 58, 60], "situat": [16, 34, 39, 58, 60, 67, 70, 74, 77, 79, 82, 102, 103, 105, 110, 121, 132, 139, 140], "sivasubramanian": 113, "six": [19, 41, 58, 83, 90, 92, 122], "sixth": 3, "sizabl": 52, "size": [1, 3, 6, 8, 9, 10, 11, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 56, 58, 59, 61, 62, 66, 69, 71, 72, 73, 74, 75, 76, 77, 82, 85, 86, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 104, 105, 108, 109, 111, 112, 114, 115, 117, 119, 121, 122, 127, 128, 129, 130, 132, 133, 135, 137, 140, 141], "size_arrai": 19, "size_tensor": 19, "sketch": [52, 58], "skew": 62, "ski": [47, 113], "skill": [63, 67, 113, 116, 120, 121], "skin": [28, 58], "skip": [2, 13, 25, 35, 39, 44, 47, 57, 58, 62, 64, 79, 89, 94, 95, 96, 97, 104, 117, 125, 127, 128], "skip_gram": 99, "sl7423": 113, "slate": 120, "sleep": [85, 86, 121], "sleight": 60, "slew": [60, 130], "slice": [44, 67, 73, 74, 79, 104, 116, 117, 128, 132, 136], "slid": 45, "slide": [33, 41, 44, 45, 88], "slight": [6, 51, 56, 91, 102, 103, 109, 121, 130], "slightli": [3, 6, 11, 34, 35, 37, 41, 44, 45, 51, 61, 62, 64, 99, 102, 103, 105, 107, 108, 109, 121, 122, 132], "slope": [49, 115], "slot": 55, "slow": [9, 18, 30, 37, 47, 62, 69, 97, 103, 105, 107, 108, 109, 121, 130, 135], "slower": [18, 34, 102, 109], "slowli": [47, 48, 60, 66, 69, 102, 103, 105, 107, 111, 112, 127], "small": [6, 11, 12, 18, 22, 25, 26, 27, 29, 32, 34, 35, 36, 41, 44, 46, 47, 48, 49, 52, 58, 61, 64, 66, 67, 69, 71, 74, 75, 76, 77, 79, 82, 83, 92, 95, 101, 102, 104, 105, 107, 108, 109, 112, 113, 115, 121, 122, 132, 135, 139], "smaller": [1, 6, 15, 22, 27, 28, 31, 32, 34, 36, 39, 40, 41, 44, 46, 62, 66, 69, 74, 75, 89, 91, 93, 102, 103, 105, 107, 108, 110, 112, 130, 132, 135, 137], "smallest": [51, 56, 61, 64, 65, 69, 102, 121], "smart": [24, 34, 58, 60, 65], "smarter": 79, "smartest": 58, "smell": 121, "smi": [18, 54, 55], "smilei": 58, "smirnov": 113, "smith": 83, "smola": 8, "smooth": [2, 32, 37, 49, 72, 76, 80, 107, 109, 110, 112, 135], "smooth_l1": 32, "smoother": [11, 32, 35, 102], "smoothli": 6, "smorgasbord": 39, "sn": 43, "sn2": 70, "snake": 58, "snap": 58, "snapshot": 28, "sneaker": [1, 60, 62], "snippet": [9, 10, 15, 33, 43, 58, 73, 90, 97, 113, 114, 117, 119, 128, 133], "snli": [84, 86], "snli_1": [85, 86], "snlidataset": 85, "so": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 16, 17, 18, 19, 22, 25, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 54, 56, 57, 58, 60, 61, 62, 64, 66, 67, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 85, 88, 93, 96, 97, 101, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 128, 129, 130, 132, 133, 135, 136, 137, 139, 140], "sober": 60, "social": [58, 59, 87, 94], "societ": [58, 60], "societi": [58, 113], "socket": [34, 108], "sofa": 31, "soft": [19, 60, 64, 86], "softli": [19, 86], "softmax": [8, 15, 21, 26, 30, 32, 43, 45, 52, 60, 61, 63, 68, 80, 81, 82, 83, 86, 94, 98, 104, 129, 132, 133, 140, 142], "softmaxceloss": 92, "softmaxcrossentropyloss": [21, 22, 23, 26, 107], "softmaxregress": [52, 65], "softmaxregressionscratch": 66, "softmin": 64, "softwar": [13, 16, 58, 113, 117], "sold": [64, 69], "sole": [10, 58, 67], "solicit": 60, "solid": [28, 39, 51, 87, 93, 113, 121], "solut": [2, 22, 36, 39, 44, 47, 48, 56, 58, 60, 61, 64, 65, 67, 70, 71, 77, 79, 90, 105, 107, 109, 110, 112, 113, 127, 132, 135, 138, 140], "solv": [6, 37, 39, 47, 58, 60, 61, 64, 66, 67, 69, 71, 80, 102, 103, 104, 109, 113, 117, 121, 133, 138], "solvabl": 69, "solver": [35, 109, 112, 121], "some": [1, 2, 3, 4, 5, 6, 8, 12, 13, 15, 16, 17, 18, 19, 21, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 60, 61, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 90, 91, 93, 94, 98, 99, 100, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141], "somebodi": 61, "somehow": [58, 74, 77], "someon": [58, 61, 64, 121, 136], "someth": [15, 18, 35, 52, 58, 61, 65, 79, 80, 83, 102, 104, 108, 121], "sometim": [2, 5, 14, 15, 16, 28, 35, 40, 41, 44, 45, 46, 53, 58, 60, 64, 72, 74, 77, 79, 80, 102, 113, 114, 117, 119, 121, 129, 131, 135, 136], "somewhat": [18, 34, 35, 45, 48, 52, 102, 104, 109, 132], "somewher": 46, "son": [95, 98], "song": 58, "soon": [5, 11, 47, 54, 55, 60, 61, 69, 127], "sooner": 12, "sophist": [7, 34, 51, 52, 54, 58, 80, 117, 129, 130], "sort": [2, 19, 25, 26, 56, 58, 61, 62, 64, 70, 79, 91, 121, 123, 124, 136, 137], "sorted_id": 25, "sorted_rung": 56, "sought": 58, "sound": [58, 60, 104, 132], "sourc": [0, 1, 4, 6, 10, 13, 22, 35, 40, 47, 51, 54, 58, 60, 69, 70, 72, 73, 77, 80, 86, 113, 116, 118, 123, 128, 137], "space": [1, 3, 4, 8, 9, 21, 30, 32, 38, 39, 40, 41, 43, 47, 48, 50, 51, 54, 55, 56, 58, 64, 67, 74, 80, 82, 83, 84, 85, 91, 96, 97, 102, 104, 117, 121, 122, 128, 139, 140], "spaci": 91, "spam": [58, 59, 60, 64], "spammer": [58, 60], "span": [6, 8, 50, 58, 77, 83, 128, 131], "spanbert": 6, "spanish": 96, "sparcstat": 62, "spare": 15, "spark": 11, "spars": [33, 34, 103, 104, 106], "sparsecategoricalcrossentropi": 107, "sparser": [6, 38], "sparsif": 35, "sparsiti": 102, "spatial": [1, 20, 21, 27, 30, 32, 33, 35, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 66, 81, 113, 117], "spatial_scal": 30, "spatiotempor": 50, "speak": [15, 28, 41, 64, 69, 133, 135], "speaker": 58, "speci": 58, "special": [3, 6, 8, 11, 34, 37, 38, 39, 41, 45, 46, 50, 58, 60, 61, 64, 74, 79, 80, 82, 83, 85, 88, 90, 91, 92, 95, 96, 105, 115, 117, 118, 119, 120, 121, 122, 127, 128, 129, 130, 135, 136, 137, 141], "specif": [3, 4, 6, 7, 8, 9, 10, 11, 12, 16, 18, 19, 20, 30, 31, 32, 35, 37, 39, 47, 58, 59, 60, 62, 64, 66, 69, 76, 77, 80, 83, 84, 89, 91, 94, 95, 97, 98, 100, 102, 104, 108, 110, 112, 114, 116, 117, 121, 127, 128, 129, 130, 133, 136, 137, 140], "specifi": [1, 3, 4, 7, 10, 11, 13, 15, 17, 18, 19, 21, 22, 23, 25, 30, 31, 32, 33, 35, 37, 41, 45, 47, 48, 49, 50, 54, 55, 56, 58, 61, 68, 70, 71, 72, 73, 76, 77, 82, 85, 86, 88, 91, 92, 95, 96, 115, 117, 118, 119, 121, 122, 123, 124, 127, 128, 132, 134, 135, 140], "spectacularli": [105, 136], "spectral": [47, 71, 117], "spectral_mixture_kernel": 47, "spectrogram": 46, "spectrum": [61, 122], "specul": [34, 35], "sped": 56, "speech": [4, 5, 10, 15, 35, 39, 45, 58, 83, 113, 131, 132, 136], "speed": [7, 10, 18, 34, 37, 43, 52, 54, 56, 60, 68, 71, 81, 97, 108, 109, 112, 113, 117, 122, 123, 125, 135], "speedup": [13, 69, 97], "spell": [58, 60, 117, 127, 132], "spend": [56, 58, 64, 132], "spent": [22, 52, 56, 58, 70], "sphere": 2, "sphinx": 113, "spike": 135, "spiral": 79, "spirit": [47, 58], "spit": 58, "spline": 80, "split": [1, 4, 11, 22, 25, 26, 31, 32, 58, 66, 67, 71, 72, 85, 91, 95, 96, 97, 118, 128, 129, 137], "split_and_load": 92, "split_batch": [23, 26, 86], "split_batch_multi_input": 86, "split_f": 23, "splitext": 1, "spoke": [34, 121], "spoken": 58, "sponsor": 79, "sporad": 113, "sport": [34, 64], "sportsthu": 113, "spot": [58, 60, 62], "spread": [27, 49, 69, 120], "spreadsheet": 120, "spring": 119, "sprinkl": 17, "sprung": 61, "spur": 5, "sq": 58, "sqrt": [1, 3, 10, 19, 32, 35, 47, 49, 61, 69, 79, 82, 95, 97, 99, 101, 102, 103, 111, 112, 117, 121, 135], "squad": 83, "squar": [1, 3, 6, 10, 25, 26, 28, 32, 41, 46, 47, 58, 64, 67, 68, 70, 71, 74, 75, 79, 83, 93, 100, 101, 102, 103, 108, 111, 112, 115, 117, 121], "squared_loss": [1, 108], "squarerootschedul": 107, "squash": [34, 80], "squeez": [3, 8, 19, 32, 44, 62, 88], "squish": 64, "src": [128, 129], "src_arrai": [1, 128], "src_sentenc": 128, "src_valid_len": [1, 72, 128, 129], "src_vocab": [1, 4, 10, 128, 129], "srivastav": 113, "ssd": 32, "st": 117, "st_checkpoint_dir": [54, 55], "st_tuner_tim": [54, 55], "stabil": [35, 37, 65, 78, 95, 99, 101, 103, 130, 142], "stabl": [35, 64, 65, 82, 109, 130], "stack": [9, 10, 11, 16, 19, 20, 26, 30, 37, 38, 39, 40, 43, 46, 80, 85, 91, 117, 119, 123, 126, 134, 135, 136], "stackedgru": 123, "stackedgruscratch": 123, "stackedrnnscratch": 123, "stackrel": [8, 35, 39, 60, 64, 65, 82, 93, 100, 102, 104, 105, 108, 109, 112, 121, 140], "stage": [58, 102, 111, 138, 141], "stai": [30, 58, 60, 69, 136, 139], "stake": 61, "stakehold": 79, "stale": [23, 119], "stall": [18, 107, 108, 109, 110, 112], "stand": [2, 58, 107, 136], "standard": [1, 13, 14, 15, 16, 21, 22, 25, 26, 28, 31, 34, 35, 40, 41, 47, 48, 51, 52, 55, 57, 58, 61, 62, 65, 67, 69, 70, 71, 73, 74, 76, 79, 80, 82, 100, 107, 108, 109, 119, 121, 122, 123, 124, 125, 127, 131, 134, 135, 136, 137, 138], "standpoint": [15, 130], "stanford": [83, 84, 86, 87, 95], "stapl": 131, "star": [52, 58], "starcraft": [58, 60], "start": [1, 2, 5, 10, 11, 12, 13, 15, 16, 17, 19, 21, 23, 25, 26, 28, 32, 34, 35, 38, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 61, 64, 66, 69, 70, 72, 75, 77, 79, 83, 84, 85, 91, 92, 96, 105, 107, 108, 110, 111, 112, 113, 114, 116, 117, 118, 121, 127, 129, 130, 132, 135, 139, 140, 141], "start_axi": [1, 11, 32, 34, 35, 36, 37, 39, 43, 65, 76, 81, 86, 90, 107], "start_h": 30, "start_tim": 51, "start_w": 30, "starter": 60, "startswith": 1, "startup": [60, 103, 113], "stat": [51, 52, 56], "state": [1, 4, 5, 6, 8, 9, 10, 11, 34, 44, 47, 49, 50, 52, 53, 54, 55, 58, 60, 61, 62, 64, 66, 67, 76, 77, 81, 83, 90, 101, 102, 103, 105, 107, 108, 109, 111, 115, 118, 121, 123, 124, 126, 128, 129, 130, 131, 132, 135, 137, 139, 140, 141], "statement": [3, 32, 58, 61, 67, 72, 104, 113, 114, 115, 119, 121, 130, 132], "stationar": [49, 136], "stationari": [45, 49, 60, 69, 107, 136], "statist": [1, 2, 4, 35, 41, 44, 46, 47, 51, 53, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 74, 77, 80, 81, 94, 96, 101, 108, 110, 113, 114, 116, 128, 131, 132, 136, 142], "statistician": [41, 60, 61, 64, 69, 121, 136], "statu": [5, 54, 55, 108, 121, 136], "std": [14, 21, 25, 28, 31, 69, 70, 79, 108], "steam": 93, "steepest": [105, 109], "steinsag": 113, "stem": [11, 37, 104, 126, 130], "step": [1, 4, 5, 6, 9, 10, 19, 23, 24, 25, 26, 30, 34, 35, 44, 47, 49, 57, 58, 60, 65, 66, 69, 71, 74, 75, 79, 81, 86, 87, 88, 89, 90, 92, 98, 99, 101, 103, 105, 107, 108, 109, 111, 112, 114, 115, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 135, 136, 137, 139, 140], "step_decai": [25, 26, 28], "steplr": 26, "steps_h": 19, "steps_w": 19, "stepsiz": 107, "steve": 113, "stevenjok": 113, "stewart": 113, "stick": [41, 58, 60, 69, 74, 135], "still": [2, 3, 6, 10, 12, 13, 15, 22, 32, 34, 37, 40, 43, 45, 46, 47, 48, 49, 52, 54, 55, 56, 58, 59, 61, 64, 65, 66, 69, 71, 72, 74, 77, 80, 82, 90, 91, 93, 102, 105, 108, 109, 110, 112, 113, 114, 119, 121, 123, 125, 128, 131, 132, 135, 136, 137, 139], "stimul": 60, "stimuli": 41, "stink": 58, "stitch": [71, 117], "stochast": [1, 2, 34, 43, 45, 47, 52, 58, 59, 71, 74, 75, 77, 82, 93, 98, 102, 103, 104, 105, 106, 107, 109, 110, 113, 133, 135, 138, 142], "stock": [58, 60, 67, 69, 79, 121, 136], "stolen": 87, "stop": [1, 4, 23, 25, 26, 32, 48, 52, 54, 55, 56, 60, 69, 78, 80, 92, 99, 105, 107, 108, 112, 119, 129, 137], "stop_criterion": [54, 55], "stop_factor_lr": 107, "stopiter": 72, "stopping_criterion": [54, 55], "stoppingcriterion": [54, 55], "storag": [5, 34, 47, 52, 58, 64, 67, 70, 75, 127, 133], "store": [4, 10, 15, 17, 18, 26, 31, 34, 52, 54, 58, 59, 62, 64, 69, 72, 73, 74, 75, 85, 88, 101, 103, 105, 109, 113, 116, 119, 120, 129, 130, 132, 133, 136], "stori": [6, 34, 60, 77, 131, 142], "str": [1, 2, 19, 23, 25, 26, 29, 31, 85, 92, 99], "straggler": [54, 55], "straight": [49, 54, 137], "straightforward": [11, 41, 44, 55, 61, 66, 75, 77, 83, 90, 95, 101, 103, 105, 107, 109, 111, 114, 117, 122, 129, 130, 131, 136], "straightforwardli": 61, "strang": [14, 61, 77], "stranger": 77, "strateg": 136, "strategi": [2, 4, 8, 11, 35, 37, 39, 40, 58, 60, 69, 77, 81, 102, 104, 105, 107, 108, 112, 122, 129, 132, 135, 136], "stream": [1, 34, 64, 67, 73, 118, 136], "stream_python_iter": 97, "streamlin": [34, 72, 125], "street": [79, 97, 117], "strength": [34, 37, 77], "strengthen": 104, "stress": 67, "stretch": [58, 109], "strict": [1, 41], "strictest": 61, "strictli": [1, 39, 41, 47, 64, 69], "stride": [1, 11, 21, 24, 30, 32, 34, 35, 36, 37, 39, 40, 42, 43, 107, 142], "stride_h": [1, 30, 32], "stride_w": [1, 30, 32], "strike": [34, 41, 58, 113, 122], "strikingli": [34, 123], "string": [3, 4, 17, 57, 91, 120, 125, 128, 134, 137], "strip": [40, 44, 85, 91], "stripe": 58, "strive": 64, "stroke": [28, 58], "strong": [48, 49, 58, 62, 67, 80, 121], "stronger": [48, 58, 60, 136], "strongest": 60, "strongli": [41, 47, 48, 52, 58, 65, 72, 121], "structur": [15, 26, 34, 36, 37, 39, 41, 42, 43, 46, 49, 51, 52, 53, 58, 64, 66, 71, 72, 79, 81, 89, 96, 102, 108, 117, 121, 125, 128, 131, 132, 133, 136, 137, 138], "structureless": 46, "struggl": [46, 58, 69], "stu": 113, "stubbornli": 58, "stuck": [58, 104, 105, 109, 110, 116], "student": [34, 58, 60, 67, 113, 121], "studi": [6, 8, 24, 31, 43, 54, 58, 60, 67, 69, 80, 83, 85, 87, 94, 96, 109, 110, 117, 118, 121, 138], "stumbl": [82, 121], "stun": 58, "stunningli": 79, "style": [24, 38, 43, 60, 72, 113, 127, 142], "style_img": 28, "style_lay": 28, "style_loss": 28, "style_weight": 28, "style_x": 28, "styles_i": 28, "styles_l": 28, "styles_y_gram": 28, "styles_y_hat": 28, "sub": [6, 16, 30, 52, 54, 85, 121, 137], "subclass": [15, 51, 56, 71, 72, 73, 74], "subconsci": 58, "subfield": [61, 64, 117], "subfold": [22, 26], "subject": [18, 39, 57, 58, 60, 64, 69, 104, 109, 112, 114, 117, 121], "sublay": [6, 10], "submiss": [25, 26, 79], "submit": [24, 78], "suboptim": [53, 55, 56, 58, 107], "subplot": [1, 2, 8, 104], "subpopul": 60, "subprocess": [54, 55], "subsampl": 94, "subscript": [46, 64, 69, 117], "subsec_vgg": 32, "subsequ": [2, 6, 11, 15, 30, 32, 35, 39, 41, 43, 46, 51, 58, 60, 61, 62, 75, 76, 77, 78, 80, 98, 102, 108, 109, 113, 114, 119, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136], "subset": [6, 26, 52, 56, 58, 67, 76, 83, 95, 117, 121], "subseteq": [39, 121], "subspac": [7, 10, 58, 104], "substanti": [6, 54, 55, 60, 67, 74], "substitut": [62, 67, 85, 120, 130], "subsum": [68, 69], "subtensor": [41, 45, 88], "subtl": [28, 60, 80, 108, 121, 130], "subtli": [39, 64], "subtract": [12, 22, 35, 65, 69, 100, 119, 135], "suburb": 28, "subvert": 140, "subwindow": 30, "subword": [94, 142], "succ": 109, "succe": 61, "succeed": 58, "succeq": 104, "success": [5, 6, 12, 23, 35, 37, 41, 44, 53, 60, 67, 71, 77, 113, 114, 121, 126, 127, 129, 140, 142], "successfulli": [24, 42, 43, 78, 113, 126], "successivehalvingschedul": 56, "succinct": [73, 113], "suddenli": [58, 60, 61, 127], "sudo": 57, "suffer": [58, 104, 111, 121, 135, 136], "suffic": [37, 41, 102, 108, 133], "suffici": [4, 34, 58, 59, 60, 61, 62, 66, 67, 69, 77, 80, 83, 102, 104, 105, 107, 113, 130, 132, 133, 135, 136, 137], "suffix": [25, 26, 96], "suggest": [6, 18, 40, 51, 52, 56, 61, 69, 70, 76, 79, 80, 82, 93, 97, 102, 108, 109, 128, 132], "sui": [4, 10, 129], "suit": [1, 34, 63, 64, 113, 120, 132, 138], "suitabl": [2, 3, 11, 12, 22, 30, 32, 35, 39, 41, 46, 58, 64, 74, 80, 82, 91, 105, 107, 110, 112, 124], "sum": [1, 2, 3, 4, 5, 8, 9, 10, 11, 15, 18, 23, 25, 26, 28, 32, 33, 40, 41, 45, 46, 47, 48, 49, 58, 59, 60, 64, 66, 67, 69, 71, 74, 79, 80, 86, 88, 89, 90, 92, 93, 95, 96, 97, 99, 100, 104, 107, 108, 111, 112, 114, 115, 116, 119, 121, 128, 129, 130, 135, 141], "sum_": [3, 4, 8, 12, 28, 35, 46, 49, 60, 61, 64, 67, 69, 71, 74, 79, 82, 86, 89, 93, 96, 98, 102, 103, 104, 108, 109, 112, 117, 121, 122, 130, 132, 139, 140, 141], "sum_a": [46, 117, 121, 141], "sum_b": 46, "sum_c": 46, "sum_i": [2, 8, 64, 66, 69, 74, 104, 109], "sum_j": [2, 8, 64], "sum_k": [46, 65, 66], "sum_l": 46, "sum_v": 121, "sum_x": 121, "summabl": 46, "summar": [4, 6, 15, 34, 43, 58, 76, 86, 129, 132], "summari": [5, 13, 24, 38, 42, 50, 53, 63, 68, 78, 84, 94, 106, 116, 126, 131, 138, 142], "summat": [69, 89, 100, 117, 122, 127, 133, 140, 141], "sun": [62, 113], "sundeepteki": 113, "super": [1, 3, 4, 7, 9, 10, 11, 12, 15, 17, 26, 28, 32, 34, 35, 36, 37, 39, 41, 43, 62, 65, 66, 70, 71, 72, 73, 74, 76, 79, 81, 82, 86, 88, 90, 99, 123, 124, 125, 127, 128, 129, 132, 134, 135], "superfici": 85, "superhuman": 58, "superintellig": 58, "superior": [6, 11, 58], "superl": 95, "superresolut": 5, "superscript": 69, "supersed": 58, "supervis": [5, 6, 38, 43, 64, 67, 83, 90, 94, 120, 121, 129, 140], "supervisor": 58, "suppli": [15, 17, 108, 119, 134, 135], "support": [1, 6, 18, 23, 30, 34, 35, 43, 46, 47, 48, 55, 58, 59, 62, 70, 72, 73, 79, 87, 92, 113, 119, 127], "suppos": [4, 7, 8, 9, 19, 22, 28, 30, 31, 32, 33, 41, 46, 47, 48, 49, 57, 60, 61, 64, 69, 73, 82, 83, 86, 90, 93, 98, 104, 110, 112, 114, 115, 121, 122, 123, 124, 125, 127, 128, 129, 132, 136, 139], "suppress": [24, 30, 32], "suprem": 58, "surbhi": 113, "sure": [16, 18, 40, 51, 54, 56, 58, 61, 67, 71, 81, 87], "surf": 34, "surfac": [35, 47, 49, 58, 64, 69, 82, 115, 121, 136], "surg": 58, "surgeri": 58, "surpass": [34, 70], "surpris": [41, 60, 61, 67, 76, 77, 80, 105, 113, 132, 136], "surprisingli": [15, 39, 46, 61, 64, 69, 75, 79], "surrog": [58, 115], "surround": [19, 58, 80, 94, 98], "survei": [10, 28, 80, 112, 113], "surveil": 69, "surviv": [56, 58, 64, 116], "survivor": 76, "suscept": 82, "suspect": 121, "sutskev": 34, "svg": 115, "swami": 113, "swap": [3, 75], "swapax": [99, 129], "swath": 58, "sweater": 43, "sweep": 46, "sweet": 58, "swim": 46, "swin": [6, 11, 38], "swish": 80, "switch": [6, 46, 58, 76, 82, 93, 98, 103, 125], "sword": 69, "sy": 113, "symbol": [4, 6, 58, 69, 96, 100, 115, 117, 121, 125], "symmetr": [41, 44, 46, 47, 93, 110, 117, 130], "symmetri": [35, 64, 80, 121], "symptom": [60, 121], "synaps": 69, "synapt": 69, "synchron": [54, 55, 131], "synchronis": [54, 55], "syne": [51, 54, 55], "syne_tun": [54, 55], "synonym": [5, 117], "synset": 26, "syntact": [95, 137], "syntax": [58, 95], "synthes": [24, 71], "synthesi": 131, "synthesized_net": 28, "synthesizedimag": 28, "synthet": [58, 60, 68, 71, 74, 120, 121, 136, 142], "synthetic_data": 1, "syntheticregressiondata": [70, 71, 73], "system": [5, 6, 15, 20, 24, 34, 38, 42, 46, 47, 55, 57, 60, 62, 64, 69, 71, 73, 77, 80, 83, 98, 102, 113, 115, 119, 132, 136, 138, 139], "systemat": [6, 46, 53], "t": [1, 4, 8, 9, 19, 28, 31, 32, 33, 39, 41, 43, 47, 49, 58, 60, 61, 62, 64, 69, 71, 85, 89, 96, 97, 98, 101, 102, 103, 107, 108, 109, 111, 112, 117, 121, 122, 123, 125, 127, 128, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "t10k": 107, "t_": 112, "t_i": [112, 136], "ta": 96, "tab": [1, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 33, 49, 57, 79, 85, 86, 87, 91, 92, 95, 97, 99, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 128], "tab_intro_decad": 18, "tabl": [36, 39, 58, 73, 93, 117, 120, 121, 131], "tabular": [46, 120, 131], "tackl": [52, 58, 61, 69, 77, 136], "tag": [6, 64, 84, 90, 136], "tagger": 90, "taglm": 90, "tail": [121, 137], "tailor": 58, "take": [6, 8, 11, 12, 15, 18, 19, 20, 22, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 97, 98, 100, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 119, 120, 121, 124, 125, 127, 128, 129, 130, 132, 133, 135, 136, 138, 139, 140, 141], "takeawai": [35, 76], "taken": [6, 11, 18, 22, 28, 41, 43, 46, 48, 58, 60, 64, 67, 69, 74, 76, 80, 93, 113, 121, 139, 141], "tal": 96, "tale": 58, "talent": [46, 58], "talk": [0, 44, 58, 64, 67, 69, 83, 112, 135], "tall": [96, 121], "tall_": 96, "taller": [34, 96], "taller_": 96, "tallest_": 96, "talneoran": 113, "tandem": 6, "tang": 113, "tangent": [49, 62, 77, 80, 115], "tanh": [3, 52, 90, 110, 125, 127, 135], "tank": 60, "tao": 113, "tap": 70, "tar": [1, 23, 31, 79, 87, 88], "tarfil": [1, 113], "target": [1, 4, 5, 6, 10, 21, 22, 23, 25, 29, 35, 47, 48, 58, 60, 62, 63, 65, 69, 72, 86, 99, 106, 107, 114, 119, 120, 121, 124, 128, 129, 130, 131, 132, 133, 136], "target_dir": 25, "task": [5, 6, 10, 11, 12, 15, 18, 20, 24, 26, 28, 29, 31, 32, 34, 36, 38, 39, 40, 41, 42, 43, 45, 51, 52, 58, 60, 61, 63, 67, 69, 73, 77, 80, 83, 84, 85, 86, 87, 92, 94, 95, 109, 113, 115, 121, 126, 128, 129, 131, 132, 136, 139], "tast": [113, 114, 136], "tatoeba": 128, "tau": [49, 109, 130, 136, 139, 141], "taught": 113, "taxonomi": 63, "tayfunun": 113, "taylor": [36, 105], "tbaum": 113, "tconv": 33, "td": 58, "tdnn": 46, "teach": [8, 58, 71, 113], "teacher": 126, "team": [34, 43, 64], "technic": [6, 28, 32, 35, 58, 60, 97, 101, 109, 113, 116, 133], "techniqu": [2, 13, 20, 21, 22, 23, 24, 32, 34, 35, 38, 42, 44, 47, 53, 58, 64, 67, 69, 70, 74, 75, 76, 77, 79, 91, 94, 98, 103, 105, 111, 112, 113, 114, 116, 122, 127, 128, 132, 136, 138], "technologi": [5, 43, 58, 60, 113], "tediou": [15, 16, 17, 49, 75, 114], "telescop": 112, "tell": [28, 34, 47, 48, 58, 61, 67, 82, 102, 108, 113, 115, 117, 119, 121, 136], "temp_cl": 11, "temperatur": [47, 60, 64, 71, 80, 117, 135, 140], "templat": 58, "tempor": [58, 60, 113, 136], "temporari": 127, "tempt": [77, 135], "ten": [11, 15, 22, 27, 29, 34, 35, 44, 46, 52, 56, 58, 61, 113, 121, 122, 137], "tend": [22, 34, 35, 42, 44, 47, 60, 61, 64, 67, 70, 72, 74, 77, 79, 101, 121, 122, 125, 129, 136, 137], "tendenc": 58, "tenfold": 121, "tens": 95, "tensor": [1, 3, 7, 8, 9, 10, 12, 13, 16, 19, 20, 21, 25, 27, 29, 30, 31, 32, 33, 37, 40, 41, 44, 45, 46, 59, 62, 66, 70, 71, 72, 73, 75, 76, 79, 81, 85, 87, 88, 90, 91, 92, 99, 100, 104, 105, 114, 115, 116, 118, 119, 129, 135], "tensorboard": 72, "tensordot": [108, 114, 117], "tensorflow": [1, 20, 34, 58, 70, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 119], "tensorflow_dataset": 113, "tenth": [22, 108], "term": [2, 3, 8, 13, 15, 18, 27, 34, 35, 36, 37, 39, 41, 47, 51, 52, 58, 59, 60, 61, 64, 65, 66, 69, 72, 74, 75, 77, 80, 82, 93, 102, 103, 104, 105, 107, 108, 109, 111, 112, 114, 115, 117, 121, 122, 125, 126, 128, 129, 130, 132, 133, 136, 140, 142], "termin": [69, 77, 130, 140], "terminologi": [41, 69, 90, 122], "ternari": 64, "terri": 64, "terribl": 105, "terrier": 26, "terrif": 113, "terrifi": 121, "tesla": 58, "tessera": 113, "test": [1, 4, 6, 7, 15, 17, 21, 22, 23, 24, 29, 31, 32, 35, 43, 47, 52, 57, 58, 60, 62, 63, 66, 67, 70, 73, 76, 77, 79, 81, 83, 85, 86, 87, 88, 95, 97, 104, 107, 108, 113, 118, 121, 122, 129, 131, 137, 138], "test_acc": [1, 23, 107], "test_aug": [22, 23], "test_d": [25, 26], "test_data": [85, 87], "test_dataset": 22, "test_ds_class": [25, 26], "test_featur": 87, "test_fil": 25, "test_i": 47, "test_imag": 21, "test_img": 22, "test_it": [1, 21, 22, 23, 25, 26, 31, 85, 86, 87, 88, 107], "test_label": 21, "test_set": 85, "test_token": 87, "test_x": 47, "testimoni": 58, "text": [1, 2, 4, 6, 8, 9, 10, 11, 12, 19, 28, 31, 42, 46, 54, 55, 56, 58, 60, 62, 66, 77, 84, 85, 86, 87, 88, 89, 90, 93, 94, 97, 98, 110, 113, 114, 120, 122, 123, 128, 130, 131, 132, 133, 135, 136, 142], "text_color": 19, "text_label": [1, 62, 66], "textbf": 47, "textbook": [58, 74, 113], "textcnn": 84, "textrm": [2, 3, 8, 9, 10, 14, 19, 32, 35, 39, 40, 41, 44, 45, 47, 48, 49, 52, 56, 58, 59, 60, 61, 64, 65, 67, 69, 70, 74, 75, 76, 79, 82, 89, 92, 93, 95, 97, 98, 99, 100, 102, 103, 104, 105, 108, 109, 110, 112, 115, 117, 119, 121, 123, 125, 127, 128, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "textual": [58, 83, 85], "textur": [22, 28, 34, 46, 60], "tf": [20, 58, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113], "tf32": 65, "tfd": 113, "tflop": 34, "tgt": [128, 129], "tgt_arrai": [1, 128], "tgt_pad": [4, 10, 129], "tgt_sentenc": 128, "tgt_valid_len": 1, "tgt_vocab": [1, 4, 10, 128, 129], "th": [9, 10, 19, 52, 60, 69, 79, 89, 97, 99, 100, 105, 115, 117, 119, 123, 128, 129, 135, 136, 137, 141], "than": [1, 3, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 22, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 85, 86, 87, 90, 91, 92, 93, 97, 98, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 117, 118, 119, 120, 121, 122, 127, 128, 130, 132, 133, 135, 136, 137], "thanh": 113, "thank": [5, 38, 58, 96, 113], "theano": [13, 34, 58, 70], "thei": [2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 25, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 88, 90, 97, 98, 99, 103, 104, 105, 106, 107, 108, 109, 113, 114, 117, 119, 120, 121, 124, 125, 127, 128, 130, 131, 133, 135, 136, 137, 140], "them": [2, 3, 6, 8, 10, 11, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 48, 49, 52, 55, 56, 58, 60, 61, 62, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 79, 80, 81, 82, 86, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 102, 103, 104, 105, 108, 110, 113, 114, 117, 119, 120, 121, 122, 128, 129, 132, 135, 136, 137, 140], "theme": [28, 35, 77], "themselv": [8, 17, 34, 40, 41, 42, 58, 113, 114, 115, 136], "theorem": [35, 49, 61, 64, 77, 102, 104, 109, 113, 121], "theoret": [11, 35, 47, 58, 60, 61, 67, 77, 82, 102, 106, 112, 113, 121], "theori": [34, 41, 42, 58, 60, 63, 67, 74, 76, 77, 102, 107, 113, 121, 130, 132], "theorist": [61, 77], "thereaft": [15, 43, 60, 141], "therebi": [19, 23, 33, 44, 58, 61, 140], "therefor": [9, 10, 15, 22, 26, 27, 30, 32, 33, 34, 39, 47, 49, 67, 72, 75, 93, 104, 105, 112, 122, 130, 132, 133, 139, 140], "thereof": [110, 127], "thermodynam": [64, 66], "theses": 121, "thesi": [114, 127], "theta": [1, 47, 104, 135], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "thick": 48, "thing": [2, 8, 34, 40, 46, 47, 58, 60, 61, 62, 64, 65, 67, 69, 71, 73, 74, 77, 79, 80, 90, 93, 102, 105, 107, 108, 109, 115, 117, 119, 120, 121, 123, 130, 132, 136, 137, 141], "think": [3, 6, 13, 15, 27, 31, 35, 36, 39, 40, 45, 46, 48, 58, 60, 62, 64, 66, 67, 69, 71, 76, 77, 80, 81, 88, 110, 113, 117, 120, 121, 124, 130, 132, 135, 136, 138, 139, 141], "third": [2, 9, 10, 16, 19, 28, 35, 37, 45, 46, 58, 66, 71, 85, 117, 119, 121, 130, 132, 135, 136, 137], "thorough": [46, 102, 113], "thoroughli": 113, "those": [6, 8, 10, 11, 13, 15, 16, 19, 21, 22, 26, 28, 29, 30, 32, 34, 35, 36, 39, 43, 44, 46, 48, 49, 58, 60, 64, 66, 67, 69, 71, 75, 76, 77, 78, 80, 83, 84, 89, 91, 92, 97, 100, 107, 110, 111, 113, 114, 120, 121, 123, 132, 133], "though": [3, 8, 10, 32, 34, 35, 37, 39, 40, 41, 46, 52, 58, 61, 62, 64, 65, 69, 80, 81, 82, 84, 86, 88, 90, 93, 102, 103, 104, 107, 110, 113, 114, 117, 121, 129, 133, 135, 136], "thought": [6, 27, 28, 35, 39, 47, 58, 69, 90, 113, 117, 131, 137], "thousand": [5, 22, 30, 34, 35, 46, 47, 58, 61, 67, 77, 89, 130, 135, 136, 137], "threaten": 82, "three": [2, 3, 6, 10, 19, 22, 25, 26, 28, 31, 32, 35, 36, 37, 40, 43, 44, 46, 50, 58, 61, 62, 64, 66, 67, 71, 72, 80, 83, 85, 86, 90, 92, 93, 95, 104, 105, 113, 115, 117, 122, 125, 127, 130, 132, 133, 135, 137], "threshold": [19, 32, 58, 60, 80, 82], "thrill": 61, "thrive": 34, "through": [0, 8, 12, 15, 16, 19, 27, 28, 30, 32, 34, 35, 37, 39, 40, 41, 42, 45, 47, 48, 50, 51, 52, 57, 58, 60, 61, 63, 64, 66, 69, 70, 71, 72, 74, 75, 76, 79, 80, 82, 88, 89, 94, 97, 98, 108, 112, 114, 121, 123, 129, 131, 132, 133, 135, 136, 139, 142], "throughout": [6, 15, 17, 19, 20, 34, 35, 38, 43, 57, 58, 60, 67, 69, 72, 73, 74, 76, 77, 78, 79, 82, 100, 108, 112, 113, 115, 120, 130, 131, 136, 137], "throughput": 34, "throw": [58, 136], "thu": [2, 3, 5, 6, 7, 8, 10, 15, 16, 17, 19, 22, 28, 29, 32, 33, 34, 35, 37, 39, 40, 41, 43, 44, 46, 47, 51, 58, 60, 61, 64, 65, 66, 67, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 90, 91, 93, 94, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 114, 115, 117, 119, 121, 123, 124, 125, 127, 130, 131, 132, 133, 136, 140], "thumb": [18, 52, 58, 67, 100], "thumbnail": 34, "ti": [13, 40, 82, 140], "tian": 113, "tibshirani": 112, "tic": 62, "tick": 110, "tick_param": 1, "tie": [140, 141], "tiep": 113, "tight_layout": 1, "tighter": 34, "tightli": 67, "tijssel": 113, "tik": 108, "tikhonov": 76, "tild": [49, 102, 125, 127], "tile": [10, 19, 129], "tim": 113, "time": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 83, 84, 86, 87, 89, 90, 91, 93, 96, 97, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142], "time_attr": 55, "time_stamp": 51, "timemachin": [123, 125, 127, 132, 134, 135, 137], "timer": [1, 23, 25, 26, 32, 92, 99, 108], "times0": [40, 41, 44, 122], "times1": [40, 41, 44, 88, 119], "times10": 122, "times11": 34, "times2": [21, 32, 40, 41, 43, 44, 64, 88, 119], "times200": 58, "times256": 32, "times28": 43, "times3": [32, 34, 40, 41, 44, 58, 88], "times4": [40, 88], "times480": 21, "times5": 34, "times6": 32, "timestep": [139, 140], "tini": [34, 35, 135], "tinker": 42, "tiny_dataset": 97, "tinyimag": 34, "tinyssd": 32, "tire": 86, "titl": [1, 8, 10, 58, 60, 62], "to_csv": [25, 79], "to_numpi": 120, "to_stream": [1, 22, 23, 25, 29, 31], "to_token": [4, 10, 97, 99, 128, 129, 137], "tobia": 113, "todai": [34, 46, 58, 62, 69, 113, 128, 136, 138], "toddler": 64, "togeth": [5, 15, 19, 35, 36, 38, 39, 40, 43, 46, 48, 58, 60, 64, 71, 77, 82, 84, 88, 91, 93, 94, 113, 117, 121, 123, 126, 128, 129, 131, 133, 135, 139, 140, 141], "toi": [3, 7, 52, 106, 112, 114], "token": [1, 3, 4, 5, 6, 8, 9, 10, 11, 25, 64, 84, 85, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 99, 122, 123, 124, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 142], "token_a": 95, "token_b": 95, "token_c": 95, "token_embed": 90, "token_freq": [96, 137], "token_id": [91, 92], "token_to_idx": [95, 137], "tokenembed": [86, 88, 95], "tokenize_nmt": 1, "tokens_a": [90, 91, 92], "tokens_b": [90, 91, 92], "tokens_x": [91, 92], "tokens_x_shard": 92, "tokyo": 95, "told": [67, 108], "tolist": [1, 4, 10, 91, 108, 128, 129], "tolstoi": 132, "tom": 58, "tomasino": 113, "tomer": 113, "tomographi": 58, "tomorrow": [58, 60, 67], "ton": 58, "too": [2, 4, 8, 16, 19, 27, 34, 36, 47, 52, 54, 55, 58, 60, 61, 62, 67, 73, 74, 75, 76, 77, 80, 82, 93, 96, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 117, 121, 130], "took": [29, 34, 58, 60, 61, 64, 65, 71, 82, 108, 115, 121, 138, 139], "tool": [3, 13, 34, 35, 37, 41, 43, 44, 46, 58, 60, 61, 68, 69, 70, 71, 74, 76, 77, 79, 98, 104, 106, 107, 110, 113, 114, 117, 120, 121, 131, 132, 136, 137, 142], "toolkit": [5, 72, 80], "top": [3, 8, 15, 28, 32, 33, 39, 41, 44, 45, 46, 47, 49, 51, 52, 56, 57, 58, 69, 73, 74, 75, 80, 86, 89, 93, 95, 98, 100, 102, 104, 105, 109, 114, 115, 117, 121, 123, 130], "top_": 117, "top_i": 117, "top_m": 117, "top_n": 117, "topecongiro": 113, "topic": [5, 37, 47, 58, 60, 61, 64, 69, 77, 82, 85, 113, 115, 136], "topk": [95, 99], "torch": [1, 18, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 33, 49, 58, 62, 73, 74, 79, 85, 87, 90, 91, 92, 95, 97, 99, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113], "torch_weight": 1, "torchvis": [21, 22, 23, 26, 29, 30, 31, 62, 113], "toronto": 23, "torqu": [6, 58], "toss": [74, 116], "total": [3, 19, 25, 32, 33, 34, 37, 39, 44, 46, 54, 55, 56, 60, 69, 97, 108, 117, 121, 130, 132, 136, 139], "total_norm": 1, "total_sampl": [85, 91], "totensor": [21, 22, 23, 26, 62], "touch": [67, 72, 74, 80, 104], "tour": 38, "toward": [6, 11, 47, 49, 55, 61, 62, 63, 64, 69, 71, 74, 75, 77, 87, 90, 103, 107, 121, 130, 135, 136], "town": 58, "toy_text": 1, "tpdi": 113, "tpu": 18, "tra": 137, "trace": [4, 60, 105, 109, 114, 115], "track": [5, 8, 16, 35, 37, 38, 41, 51, 58, 80, 81, 102, 112, 114], "track_running_stat": 21, "tractabl": 46, "traction": 34, "trade": [34, 37, 39, 40, 60, 61, 64, 69, 74, 103, 108, 122, 136], "trader": [60, 136], "tradiat": 50, "tradit": [5, 8, 34, 35, 49, 58, 69, 77, 110, 126], "tradition": [58, 101], "traffic": 60, "trail": 58, "train": [1, 2, 5, 6, 7, 8, 12, 15, 16, 17, 22, 24, 29, 30, 31, 38, 41, 42, 46, 47, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 68, 69, 73, 77, 78, 79, 80, 82, 83, 84, 85, 87, 90, 91, 92, 93, 94, 95, 96, 102, 103, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 120, 121, 122, 123, 126, 128, 130, 131, 132, 133, 137, 138, 142], "train_": 72, "train_2d": [102, 105, 109, 111, 112], "train_acc": [1, 107], "train_acc_sum": 23, "train_aug": [22, 23], "train_batch_ch13": [23, 25, 26], "train_batch_idx": [71, 72], "train_bert": 92, "train_ch11": [101, 102, 103, 108, 109, 111], "train_ch13": [21, 22, 23, 86, 88, 92], "train_ch6": [1, 107], "train_concise_ch11": [101, 102, 103, 108, 109, 111], "train_d": [25, 26], "train_data": [62, 85, 87], "train_dataload": [62, 71, 72, 73, 128, 132], "train_dataset": 22, "train_ds_class": [25, 26], "train_featur": [31, 87], "train_fil": 25, "train_fine_tun": 22, "train_i": 47, "train_img": 22, "train_it": [1, 21, 22, 23, 25, 26, 29, 31, 32, 85, 86, 87, 88, 91, 92, 107], "train_l": 1, "train_label": 31, "train_len": 29, "train_loss": 107, "train_loss_sum": 23, "train_momentum": 109, "train_scratch": 74, "train_set": [85, 91], "train_sgd": 108, "train_stat": 113, "train_step": [23, 25, 26], "train_target": 62, "train_token": 87, "train_valid": [25, 26], "train_valid_d": [25, 26], "train_valid_ds_class": [25, 26], "train_valid_it": [25, 26], "train_valid_test": [25, 26], "train_valid_test_tini": 26, "train_with_data_aug": 23, "train_x": 47, "trainabl": [30, 35, 80, 88], "trainable_paramet": 22, "traincallback": 107, "trainer": [1, 4, 10, 11, 18, 21, 22, 23, 25, 26, 28, 32, 34, 35, 36, 37, 39, 43, 51, 52, 54, 55, 65, 66, 70, 71, 72, 74, 76, 79, 81, 86, 88, 92, 99, 101, 102, 103, 105, 107, 108, 109, 111, 123, 125, 127, 129, 134, 135, 136], "trainer_fn": 108, "training_step": [71, 72, 135], "trainlabel": 25, "trajectori": [51, 54, 58, 102, 105, 109, 111, 112, 136, 139, 140, 141], "tran": 62, "tranah": 113, "tranform": 127, "trans_conv": 33, "trans_prob_idx": [1, 141], "transact": [58, 121], "transcend": 34, "transcod": 62, "transcript": 58, "transfer": [6, 18, 22, 24, 49, 52, 142], "transform": [1, 3, 4, 7, 8, 15, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 37, 38, 39, 40, 43, 58, 62, 64, 69, 71, 79, 80, 81, 82, 83, 87, 88, 92, 94, 97, 99, 113, 114, 117, 119, 124, 127, 129, 130, 131, 136, 137, 142], "transform_first": [22, 23, 26], "transform_test": [25, 26], "transform_train": [25, 26], "transformerdecod": 10, "transformerdecoderblock": 10, "transformerencod": [10, 90], "transformerencoderblock": [10, 90], "transistor": 13, "transit": [1, 38, 58, 139, 140, 141], "transition_block": 36, "translat": [1, 2, 3, 4, 5, 6, 8, 10, 11, 35, 40, 45, 48, 49, 58, 60, 64, 69, 77, 79, 83, 84, 85, 86, 87, 94, 122, 124, 126, 131, 132, 136, 142], "transmiss": 18, "transmit": [58, 64, 74], "transpar": 63, "transpir": 136, "transport": 138, "transpos": [1, 3, 4, 7, 10, 24, 28, 29, 31, 32, 41, 86, 100, 117, 135, 142], "transpose_conv": 21, "transpose_output": 7, "transpose_qkv": 7, "transposit": [7, 24, 75, 117], "trap": [58, 139], "travel": [20, 117, 123, 137, 139, 141], "travers": [19, 44, 45, 75, 89, 108, 112, 115, 130], "tread": 113, "treat": [4, 11, 28, 39, 42, 46, 58, 60, 64, 66, 67, 72, 79, 87, 94, 97, 106, 115, 120, 122, 123, 128, 133, 135, 136], "treatment": [60, 102, 116], "trebeljahr": 113, "tree": [16, 28, 58, 60, 67, 80, 89, 97, 132], "tree_flatten": [1, 17, 113, 129, 135], "tree_map": [1, 4, 34, 43, 129, 135], "tree_reduc": 1, "tree_unflatten": [1, 47, 113], "treebank": 83, "tremend": [43, 58, 79, 126], "trend": [6, 35, 58, 61], "tri": [4, 35, 37, 58, 60, 96], "trial": [38, 51, 52, 53, 54, 55, 56, 113, 121, 140, 141], "trial_backend": [54, 55], "trial_id": [54, 55], "triangl": [6, 115, 117], "trick": [2, 34, 37, 39, 58, 64, 65, 74, 77, 82, 86, 104, 121], "tricki": [35, 44, 60, 71, 105, 110, 130, 132], "trickier": 130, "trigger": [18, 49, 58, 127], "trigonometr": [9, 136], "trigram": [132, 137], "trigram_freq": 137, "trigram_token": 137, "trigram_vocab": 137, "trillion": [6, 61], "trim": [43, 58, 85], "trip": 17, "tripadvisor": 58, "tripl": [37, 125, 127, 130, 137], "tripod": 45, "trivial": [2, 8, 40, 44, 47, 54, 55, 60, 83, 90], "troubl": [35, 58, 60, 65, 67, 69, 73, 80, 112, 121], "trouser": [1, 62], "truck": [25, 138], "true": [1, 2, 4, 8, 10, 16, 17, 19, 20, 21, 22, 23, 25, 26, 28, 29, 31, 33, 35, 39, 40, 47, 48, 51, 54, 55, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 77, 79, 85, 86, 87, 89, 90, 91, 92, 97, 99, 100, 104, 107, 108, 113, 114, 115, 117, 119, 120, 121, 128, 130, 135, 136, 137], "truli": [8, 37, 43, 46, 64, 67, 69, 77, 78, 80, 122], "truncat": [1, 30, 32, 87, 128, 132], "truncate_pad": [1, 85, 87], "truncated_norm": 118, "trust": [61, 113], "truth": [21, 27, 29, 30, 32, 34, 39, 47, 48, 58, 59, 60, 71, 73, 83, 85, 90, 117, 129], "try": [1, 15, 18, 20, 21, 28, 34, 36, 37, 39, 41, 43, 47, 52, 56, 58, 60, 64, 66, 67, 69, 70, 71, 73, 74, 79, 80, 81, 82, 91, 99, 102, 103, 108, 109, 111, 114, 117, 120, 128, 130, 136, 140, 141], "try_all_gpu": [18, 21, 22, 23, 26, 92], "try_gpu": [4, 10, 18, 99, 107, 123, 125, 127, 129, 134, 135], "tulder": 113, "tunabl": [15, 26, 69, 135], "tune": [2, 5, 8, 21, 23, 24, 25, 28, 34, 37, 39, 49, 50, 51, 52, 54, 55, 58, 60, 61, 69, 77, 79, 84, 88, 90, 92, 99, 106, 123, 142], "tune_funct": [54, 55], "tune_function_hash": [54, 55], "tune_function_root": [54, 55], "tuner": [53, 54, 55, 56], "tuning_experi": 54, "tupl": [1, 8, 11, 19, 58, 72, 73, 96, 113, 117, 137, 139, 140], "ture": [6, 58], "turk": 34, "turn": [3, 4, 15, 35, 37, 40, 41, 46, 58, 60, 61, 64, 66, 67, 69, 71, 75, 77, 78, 80, 82, 104, 110, 112, 115, 121, 122, 123, 125, 130, 132, 139, 141], "tutori": [54, 113, 120], "tv": [28, 31], "tv_l": 28, "tv_loss": 28, "tv_weight": 28, "tweak": [23, 25, 58, 74, 113], "twelv": 90, "twice": [20, 61, 70, 91, 93, 104, 108, 121, 128], "two": [1, 3, 4, 6, 7, 9, 10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 55, 58, 60, 61, 64, 67, 69, 72, 73, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 96, 97, 98, 99, 101, 102, 104, 105, 107, 108, 109, 110, 113, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 132, 133, 135, 136, 137, 141], "txt": [1, 31, 85, 95, 97, 128, 132, 137], "txt_fname": 31, "ty": [16, 130], "type": [1, 3, 14, 16, 19, 22, 31, 32, 33, 35, 39, 41, 47, 48, 49, 51, 52, 55, 58, 59, 63, 64, 65, 72, 73, 79, 83, 84, 85, 90, 99, 100, 108, 109, 113, 118, 119, 120, 122, 124, 127], "typevar": [1, 113], "typewrit": 132, "typic": [1, 6, 8, 9, 15, 18, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 55, 56, 58, 59, 60, 61, 62, 67, 69, 76, 77, 79, 81, 82, 97, 98, 102, 103, 104, 107, 108, 111, 112, 113, 115, 117, 121, 127, 129, 132, 136, 137, 138, 139, 140], "typifi": 126, "u": [8, 12, 14, 15, 18, 23, 28, 29, 36, 37, 39, 40, 41, 43, 46, 47, 48, 49, 50, 51, 52, 54, 56, 58, 60, 61, 64, 66, 67, 69, 70, 72, 73, 74, 75, 76, 79, 80, 81, 82, 85, 89, 93, 96, 98, 99, 102, 103, 104, 105, 106, 108, 109, 112, 113, 114, 115, 117, 119, 121, 122, 125, 129, 130, 132, 135, 136, 137, 138, 139, 140, 141], "u202f": [1, 128], "u_": 115, "u_0": 49, "u_1": 115, "u_2": 115, "u_i": [49, 102, 115, 119], "u_j": 49, "u_m": 115, "ubiquit": [15, 41, 42, 58, 74, 120, 135], "ubitiqu": 50, "ubyt": 107, "uci": [34, 120], "uelwer": 113, "ugurkap": 113, "uhlenbeck": 49, "uint64": 32, "uint8": [21, 22, 28], "uk": 60, "ulm": 120, "ultim": [34, 45, 49, 60, 65, 66, 67, 69, 115, 136, 137], "unabl": 67, "unaccount": [60, 121], "unaffect": 41, "unalign": [58, 124, 128, 129, 136], "unambigu": [83, 90, 121, 131], "unanticip": 60, "unari": 119, "unavail": 60, "unbias": [59, 61, 76, 112], "uncertain": [58, 121], "uncertainti": [47, 48, 58, 76, 112, 116, 121], "unchang": [2, 30, 32, 33, 39, 41, 45, 60, 76, 90, 91, 104, 108, 111, 117, 127, 135], "unclear": [46, 102], "uncontrol": 138, "uncontroversi": 121, "uncorrel": 48, "undefin": 47, "undemand": 122, "under": [3, 25, 35, 36, 49, 58, 60, 61, 67, 69, 71, 75, 77, 79, 90, 107, 109, 115, 116, 119, 121, 122, 128, 138, 140, 141], "underbrac": [82, 140], "underdetermin": 73, "underestim": [46, 61], "underfit": [61, 68], "underflow": [64, 65, 82], "undergradu": 113, "underli": [5, 16, 35, 37, 39, 44, 47, 53, 58, 61, 67, 69, 71, 74, 77, 82, 105, 108, 115, 121, 122, 131, 136, 138], "underperform": 55, "underpin": [5, 58, 67], "underscor": 77, "underset": 141, "understand": [6, 16, 31, 35, 36, 38, 39, 40, 41, 43, 48, 49, 50, 51, 58, 62, 64, 65, 67, 68, 71, 75, 77, 85, 90, 94, 103, 104, 105, 106, 109, 113, 117, 125, 132], "understood": [102, 108, 113, 132], "understudi": 129, "underweight": 60, "undesir": [44, 58, 109, 119, 130], "undiagnos": 67, "undo": 135, "uneven": 102, "unfair": 121, "unfit": 69, "unfold": [131, 136], "unfortun": [36, 39, 47, 52, 58, 60, 61, 62, 69, 74, 82, 89, 102, 107, 108, 111, 112, 121, 122, 130, 132, 136], "unfreez": 26, "unidirect": [4, 129], "unif": 6, "unifi": [6, 35, 58, 113], "uniform": [2, 3, 4, 12, 14, 15, 16, 18, 19, 21, 23, 33, 41, 44, 52, 60, 61, 66, 76, 82, 97, 118, 132, 140], "uniform_fn": 14, "uniformli": [14, 19, 27, 51, 97, 108, 112, 132, 140], "unigram": [132, 137], "uninhibit": 127, "uninterpret": [48, 49], "union": [1, 21, 24, 96, 100, 104, 113, 118], "union_area": 19, "uniqu": [19, 54, 55, 61, 69, 71, 113, 120, 121, 131, 132, 137], "unit": [2, 3, 10, 11, 12, 15, 27, 30, 32, 34, 35, 39, 43, 45, 46, 49, 50, 52, 58, 60, 64, 69, 76, 79, 80, 81, 82, 90, 92, 98, 104, 108, 117, 121, 123, 126, 127, 129, 133, 135, 137, 142], "uniti": 35, "univari": 105, "univers": [49, 50, 58, 60, 108, 113, 138], "unk": [4, 95, 96, 97, 128, 137], "unknown": [1, 25, 26, 58, 61, 77, 85, 95, 96, 97, 117, 121, 128, 137, 138, 140, 141], "unknown_idx": 95, "unlabel": [6, 19, 58, 60, 61, 67], "unless": [15, 18, 23, 44, 46, 60, 61, 67, 81, 82, 104, 132], "unlik": [9, 10, 16, 21, 26, 34, 45, 46, 47, 58, 60, 61, 69, 77, 93, 98, 103, 122, 128, 132, 133], "unlock": 58, "unnecessari": [69, 113], "unnecessarili": [79, 119], "unnorm": 97, "unobserv": 104, "unpract": 52, "unpreced": 34, "unpredict": 82, "unrealist": [2, 105], "unreason": [60, 79, 105], "unrel": [60, 93, 121], "unremark": 87, "unrepres": 58, "unrol": [130, 131], "unsatisfactori": 64, "unsatisfi": [42, 61], "unseen": [35, 46, 58, 61, 67, 69, 76, 77, 113, 115], "unspecifi": 118, "unsqueez": [19, 21, 29, 32, 92], "unstabl": [65, 82, 107, 130, 135], "unsuit": [62, 132, 137], "unsupervis": [121, 136], "unsurprisingli": [4, 105], "until": [15, 19, 29, 34, 39, 40, 44, 48, 52, 54, 55, 56, 58, 67, 69, 71, 73, 75, 77, 80, 82, 85, 97, 105, 107, 109, 111, 122, 123, 127, 128, 131, 136], "untun": 79, "unusu": [15, 130, 132], "unwieldi": [16, 44, 46, 47, 132], "unzip": [22, 25, 26, 57], "up": [1, 3, 4, 5, 6, 8, 10, 11, 13, 14, 15, 18, 21, 25, 27, 28, 30, 32, 34, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 51, 52, 54, 56, 57, 58, 60, 61, 64, 66, 67, 69, 70, 71, 74, 76, 77, 79, 80, 82, 86, 87, 89, 90, 93, 96, 102, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 125, 130, 131, 132, 133, 135, 136, 139, 140, 141], "up_bd": [47, 49], "up_bd_observ": 47, "upadhyai": 113, "uparrow": [140, 141], "upcom": [50, 58], "updat": [1, 4, 6, 9, 15, 22, 23, 28, 32, 34, 35, 41, 43, 51, 56, 57, 58, 59, 60, 63, 69, 71, 72, 73, 74, 75, 77, 80, 82, 92, 93, 98, 99, 101, 102, 103, 105, 106, 107, 108, 109, 113, 115, 119, 121, 126, 127, 129, 130, 135, 136, 140, 141], "upfront": 58, "upload": 79, "upon": [13, 15, 34, 35, 38, 46, 51, 58, 64, 69, 72, 74, 80, 120, 121, 129, 131, 139, 140, 141], "upper": [6, 19, 20, 21, 25, 29, 30, 39, 41, 44, 45, 52, 54, 55, 61, 75, 112, 121, 132, 135], "uppercas": [1, 91, 128], "upsampl": [21, 33, 34], "upscal": 62, "upsid": 58, "upstream": 94, "upward": 75, "urbana": 58, "urg": 65, "url": [1, 79], "us": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142], "usag": [18, 60, 118], "use_1x1conv": [1, 39], "use_bia": [10, 11], "use_svg_displai": [1, 2, 8, 62, 104, 115], "usefulli": 58, "useless": [61, 136], "user": [13, 16, 18, 22, 28, 51, 52, 54, 55, 56, 57, 58, 60, 64, 65, 69, 79, 113, 122, 135, 139, 140], "usp": 62, "usr": [54, 55], "usual": [10, 19, 20, 22, 23, 28, 29, 30, 31, 35, 46, 52, 55, 58, 60, 61, 65, 67, 69, 71, 85, 90, 98, 102, 104, 110, 112, 113, 117, 118, 121, 122, 137], "utf": [1, 87, 128], "util": [0, 4, 17, 22, 23, 26, 29, 31, 34, 35, 43, 44, 47, 61, 62, 68, 79, 85, 91, 92, 97, 113, 116, 121, 129, 135, 138, 142], "uwsd": 113, "v": [1, 2, 3, 7, 8, 25, 41, 46, 47, 58, 59, 67, 82, 86, 89, 90, 91, 93, 96, 98, 99, 102, 103, 104, 107, 108, 109, 110, 113, 116, 117, 119, 121, 122, 130, 133, 140, 141], "v1": [1, 83, 91, 92, 109, 140, 141], "v2": 109, "v3": 38, "v_": [47, 109, 141], "v_0": [109, 141], "v_1": 41, "v_2": 41, "v_a": 86, "v_all": 1, "v_b": [86, 103, 109], "v_bias_corr": 103, "v_i": [49, 102, 119], "v_k": 141, "v_w": [103, 109], "va": [1, 4, 10, 19, 128, 129], "vaessen": 113, "vagu": [35, 58], "val": [31, 52, 62, 79], "val_": 72, "val_batch_idx": [52, 71, 72], "val_data": 62, "val_dataload": [52, 62, 66, 71, 72], "val_err": 54, "val_it": 29, "val_len": 29, "val_loss": 79, "val_target": 62, "valid": [1, 2, 3, 4, 6, 8, 10, 24, 29, 32, 33, 34, 35, 39, 40, 41, 45, 51, 52, 53, 54, 56, 59, 60, 61, 64, 65, 66, 69, 71, 72, 73, 74, 77, 78, 80, 83, 88, 97, 117, 124, 136], "valid_acc": 25, "valid_d": [25, 26], "valid_ds_class": [25, 26], "valid_it": [25, 26, 101, 102, 103, 108, 109, 111], "valid_len": [1, 3, 7, 9, 10, 11, 90, 91, 92, 128], "valid_lens_x": [91, 92], "valid_lens_x_shard": 92, "valid_loss": 26, "valid_ratio": [25, 26], "validation_error": [51, 52, 54, 55], "validation_step": [59, 71, 72, 129, 135], "valu": [1, 2, 3, 4, 5, 7, 9, 10, 11, 14, 15, 16, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 61, 64, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 86, 88, 89, 93, 96, 97, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 135, 136, 137, 138, 139, 140, 142], "valuabl": [47, 113], "value_and_grad": [1, 23, 28, 32, 41, 72, 92, 99, 107, 108, 135], "value_and_grads_fn": 92, "value_iter": 141, "valueerror": 1, "van": 113, "vanilla": [56, 123, 125, 127], "vanish": [3, 8, 35, 41, 52, 64, 76, 78, 80, 105, 112, 117, 126, 127, 130, 135], "vapnik": 61, "var": [35, 82, 100, 121], "varadgunj": 113, "varatharajan": 113, "vari": [8, 19, 21, 22, 26, 27, 29, 32, 35, 38, 47, 48, 49, 58, 61, 67, 70, 74, 87, 97, 104, 121, 124, 129, 130, 131, 136, 137], "variabl": [1, 3, 4, 8, 10, 14, 15, 17, 18, 19, 25, 26, 27, 28, 32, 35, 36, 40, 47, 48, 49, 52, 58, 61, 64, 66, 67, 69, 72, 74, 75, 76, 77, 79, 93, 96, 97, 99, 100, 101, 102, 103, 104, 105, 109, 111, 112, 115, 116, 117, 119, 120, 122, 123, 124, 127, 129, 130, 132, 133, 136, 138, 140], "varianc": [2, 3, 10, 28, 35, 47, 48, 49, 61, 64, 69, 71, 76, 79, 82, 100, 102, 103, 107, 108, 109, 112, 121, 130, 136], "variant": [3, 6, 34, 35, 37, 39, 55, 58, 60, 80, 96, 101, 102, 104, 107, 108, 109, 127, 132], "variat": [2, 35, 47, 48, 49, 55, 58, 70, 80, 104, 110], "varieti": [8, 12, 34, 37, 47, 49, 50, 58, 59, 60, 72, 79, 80, 82, 94, 107, 112, 113, 116, 119, 138], "variou": [7, 11, 14, 15, 16, 17, 20, 23, 24, 27, 28, 34, 35, 36, 37, 48, 51, 58, 60, 62, 67, 72, 76, 79, 83, 84, 90, 94, 111, 113, 117, 118, 119, 121, 127, 139], "vast": [32, 61, 77, 94, 97], "vastli": 45, "vb": 83, "vc": [61, 67, 77], "vdot": [7, 48, 117, 136], "vec": 95, "vector": [2, 3, 5, 7, 9, 10, 11, 15, 17, 28, 30, 33, 34, 35, 41, 42, 43, 45, 46, 47, 48, 49, 58, 60, 62, 65, 66, 68, 70, 71, 73, 74, 75, 76, 77, 79, 81, 82, 86, 89, 90, 94, 96, 99, 100, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 114, 115, 116, 119, 121, 129, 130, 131, 133, 135, 136, 142], "vehicl": [20, 24, 31, 58], "vein": [36, 115], "veloc": [58, 109, 139], "vendor": 34, "venn": 121, "verb": [58, 83, 96], "verbatim": 66, "verbos": [1, 107], "veri": [2, 3, 4, 9, 10, 12, 17, 32, 34, 35, 39, 43, 46, 47, 48, 49, 52, 58, 60, 62, 64, 65, 66, 67, 69, 71, 72, 79, 80, 82, 92, 94, 97, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 120, 121, 123, 130, 132, 133, 135, 137, 139, 141], "verifi": [1, 12, 17, 20, 79, 89, 95, 104, 114], "vermicelli": 113, "versa": [20, 28, 86, 93, 95, 121], "versatil": [15, 47], "version": [6, 10, 11, 12, 34, 35, 36, 37, 39, 45, 57, 58, 62, 64, 65, 70, 74, 80, 83, 92, 95, 104, 105, 107, 112, 113, 121, 122, 125, 126, 138, 140, 141], "versu": [47, 48, 55, 61, 120, 121], "vertic": [6, 41, 44, 48, 104, 115, 117], "verticalflip": 23, "vex": [82, 110], "vfdev": 113, "vga": 34, "vgg": [1, 28, 32, 37, 38, 39], "vgg19": [1, 28], "vi": [66, 116, 122], "via": [3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 19, 21, 22, 23, 28, 29, 32, 33, 35, 36, 39, 41, 43, 45, 51, 54, 58, 60, 65, 69, 71, 72, 73, 74, 75, 79, 80, 81, 90, 91, 97, 99, 101, 104, 105, 107, 109, 112, 113, 114, 115, 117, 119, 120, 121, 122, 127, 130, 131, 132, 133, 135, 138], "vibrat": 45, "vice": [20, 28, 86, 93, 95, 121], "vicin": [46, 110], "victor": 113, "victori": 127, "video": [20, 58, 62, 77, 79, 131, 136, 140], "view": [1, 8, 18, 24, 31, 36, 39, 49, 58, 61, 64, 76, 77, 79, 86, 93, 98, 104, 117, 122, 131, 132, 133, 135], "viewpoint": [35, 115], "vigil": 61, "vii": 116, "vijayvargeeya": 113, "vincent": 113, "vinnei": 113, "violat": [61, 80, 82, 104], "virtu": [15, 104], "virtual": [34, 35, 47, 54], "virtuoso": 75, "viru": 83, "vis_indx": 1, "visa": 58, "vishaal": 113, "vishwesh": 113, "visibl": [62, 103], "vision": [5, 6, 10, 15, 20, 21, 22, 23, 25, 26, 31, 34, 38, 39, 40, 41, 42, 43, 46, 58, 60, 77, 88, 107, 113, 120, 142], "visit": [57, 58, 79, 136, 140], "visual": [1, 2, 4, 5, 6, 7, 10, 16, 19, 21, 34, 39, 41, 47, 48, 49, 51, 53, 56, 58, 63, 66, 69, 71, 75, 105, 111, 116, 117, 120, 130, 137, 140], "vit": 11, "vital": [58, 94, 104, 114, 117, 130], "vitblock": 11, "vitmlp": 11, "vivid": 28, "vkramdev": 113, "vladimir": 61, "vmap": [80, 82, 113], "vn09": 113, "voc": 31, "voc2012": [21, 24], "voc_class": 31, "voc_colormap": [21, 31], "voc_colormap2label": 31, "voc_dataset": 31, "voc_dir": [21, 31], "voc_label_indic": 31, "voc_rand_crop": 31, "voc_test": 31, "voc_train": 31, "vocab": [1, 85, 86, 87, 88, 91, 92, 97, 99, 123, 125, 127, 128, 132, 134, 135, 137], "vocab_s": [4, 10, 88, 90, 92, 123, 125, 127, 129, 134, 135], "vocabulari": [1, 66, 85, 87, 89, 90, 91, 93, 95, 96, 97, 98, 99, 122, 128, 129, 131, 132, 133, 135, 136], "vocdevkit": [21, 31], "vocsegdatas": 31, "vocsegdataset": 31, "voctrainval_11": 31, "voic": 58, "voltag": [58, 71], "voraci": 34, "vu": 113, "vzlamal": 113, "w": [1, 11, 14, 15, 19, 20, 21, 26, 27, 28, 29, 30, 32, 33, 35, 40, 41, 44, 45, 46, 49, 62, 64, 66, 69, 70, 71, 73, 74, 75, 80, 82, 88, 89, 95, 96, 97, 98, 99, 102, 104, 108, 109, 112, 117, 119, 120, 123, 125, 127, 130, 133, 137], "w1": 81, "w2": 81, "w_": [12, 64, 69, 82, 98, 130], "w_0": [49, 67], "w_0w_1x": 49, "w_1": [30, 49, 69, 112], "w_1w_0x": 49, "w_1x": 49, "w_2": [30, 112], "w_3": 89, "w_a": 19, "w_b": 19, "w_c": [89, 98], "w_d": 69, "w_hc": 127, "w_hf": 127, "w_hh": [125, 133, 135], "w_hi": 127, "w_ho": 127, "w_hq": 135, "w_hr": 125, "w_hz": 125, "w_i": [7, 49, 67, 69, 74, 93, 97, 117], "w_in": 1, "w_j": [49, 93, 98], "w_k": [3, 7, 89, 93], "w_o": [7, 89, 98], "w_out": 1, "w_q": [3, 7], "w_v": [3, 7], "w_xc": 127, "w_xf": 127, "w_xh": [125, 133, 135], "w_xi": 127, "w_xo": 127, "w_xr": 125, "w_xz": 125, "wa": [4, 5, 6, 8, 10, 11, 15, 18, 22, 23, 34, 35, 37, 38, 42, 43, 45, 46, 47, 49, 51, 58, 59, 60, 61, 62, 64, 66, 67, 69, 74, 77, 79, 80, 82, 87, 90, 95, 96, 98, 99, 101, 102, 105, 107, 108, 109, 110, 112, 113, 114, 115, 117, 121, 124, 127, 128, 130, 131, 134, 136, 137, 139, 141], "wai": [5, 8, 11, 12, 15, 16, 18, 19, 22, 23, 26, 27, 30, 32, 33, 34, 35, 37, 39, 44, 45, 46, 48, 51, 52, 53, 55, 56, 58, 60, 61, 64, 65, 66, 67, 69, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 86, 88, 94, 95, 98, 99, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 119, 120, 121, 128, 129, 130, 131, 132, 133, 135, 136, 138, 139, 140], "wait": [1, 18, 54, 55], "waital": 92, "wake": [58, 61, 121], "waldo": 46, "walk": [42, 47, 50, 58, 72, 79, 97, 105, 121], "wall": [51, 54, 55, 56, 97, 104], "wallclock": [54, 55], "walsh": 113, "walter": 69, "wang": 113, "want": [1, 2, 3, 7, 8, 14, 15, 16, 17, 18, 20, 21, 22, 29, 35, 36, 39, 41, 44, 45, 46, 47, 48, 49, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 86, 93, 102, 104, 107, 108, 110, 111, 112, 113, 114, 117, 119, 121, 123, 125, 129, 130, 132, 133, 134, 135, 136, 137, 139], "war": [132, 135], "warehous": 138, "warm": [107, 135], "warmup_begin_lr": 107, "warmup_step": 107, "warn": [1, 54, 55], "warp": 34, "warrant": 59, "warren": 69, "washington": 58, "wasn": 8, "wast": [3, 60, 112, 128, 134], "watch": [64, 67, 121, 124, 138], "water": [67, 93], "watersh": 34, "watson": [5, 8], "wave": 58, "wavelength": [46, 71], "wavi": 58, "waymo": 58, "wb": 1, "wd": [21, 22, 25, 26, 74, 79], "we": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "weak": 34, "weaker": [62, 80], "wealth": 6, "wear": 60, "weather": [58, 113, 136], "web": [6, 25, 26, 57, 58, 60, 70, 113, 132], "webentwicklung": 113, "webpag": [25, 26, 58, 113], "websit": [26, 57, 79, 95, 107, 137], "wechat": 58, "weed": 16, "week": [52, 58, 106], "weigh": [46, 60], "weight": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 18, 21, 22, 23, 26, 28, 32, 33, 34, 35, 39, 40, 41, 43, 44, 46, 47, 48, 50, 51, 52, 60, 63, 64, 66, 67, 68, 69, 70, 71, 75, 76, 77, 79, 80, 81, 82, 86, 88, 90, 91, 93, 97, 99, 103, 104, 107, 108, 111, 117, 121, 123, 125, 126, 127, 129, 130, 133, 134, 135, 142], "weight_decai": [21, 22, 25, 26, 32, 74], "weight_fn": [1, 14, 43, 70, 108, 129], "weightdecai": 74, "weightdecayscratch": 74, "weights_path": 1, "weird": [9, 60, 77], "weirdli": 58, "welfar": 60, "well": [3, 5, 6, 8, 10, 19, 32, 33, 34, 35, 37, 39, 40, 41, 44, 45, 46, 47, 49, 50, 51, 52, 55, 56, 58, 60, 61, 62, 64, 67, 69, 70, 71, 76, 77, 79, 80, 81, 82, 85, 88, 90, 101, 104, 105, 106, 107, 109, 110, 112, 113, 114, 115, 121, 130, 132, 135, 136, 137, 140, 141], "wen": 113, "went": [13, 37, 90, 95, 105, 121], "wenxiang": 113, "wer": 8, "were": [3, 5, 6, 11, 15, 22, 34, 35, 37, 38, 39, 43, 46, 47, 48, 58, 59, 60, 61, 64, 67, 69, 71, 76, 77, 80, 81, 82, 88, 106, 113, 114, 115, 117, 121, 127, 128, 131, 132, 135, 136, 137, 138, 139, 140], "werner": 113, "west": 77, "wet": 64, "wh": [19, 96], "what": [1, 2, 3, 5, 6, 8, 9, 10, 15, 17, 18, 19, 23, 25, 26, 27, 29, 30, 31, 34, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 53, 55, 58, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 86, 87, 91, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 125, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142], "whatev": [4, 46, 69, 133, 136], "whatsoev": 35, "whe": 96, "wheel": [70, 139, 140, 141], "when": [2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 51, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "whenev": [3, 18, 39, 42, 46, 51, 57, 58, 59, 61, 62, 64, 65, 67, 69, 70, 77, 102, 103, 104, 105, 107, 108, 109, 112, 113, 114, 118, 119, 120, 121, 125, 127, 129, 130, 136, 137], "where": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 15, 16, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 64, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 139, 140, 141], "wherea": [35, 56, 58, 61, 73, 74, 102, 104, 105, 108, 109, 110, 114, 117, 119, 121, 127, 132, 136, 140], "wherebi": 74, "wherev": [46, 93], "whet": [58, 64], "whether": [1, 2, 3, 6, 16, 19, 24, 30, 34, 35, 40, 41, 42, 45, 46, 47, 48, 49, 54, 57, 58, 60, 61, 66, 69, 71, 73, 74, 79, 80, 83, 85, 90, 104, 105, 112, 117, 121, 127, 129, 135, 136, 137, 138], "which": [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 15, 16, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 93, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141], "whichev": [112, 129], "while": [1, 4, 5, 6, 8, 9, 13, 14, 15, 16, 19, 22, 23, 25, 26, 27, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 85, 86, 90, 91, 92, 96, 97, 98, 100, 102, 104, 105, 107, 108, 109, 110, 111, 113, 114, 115, 117, 119, 120, 121, 122, 127, 129, 130, 131, 132, 135, 136, 137, 138, 140], "whip": 135, "whistl": [34, 71], "white": [31, 41, 45, 60, 62, 123], "whiteboard": 58, "whited3vil": 113, "whiten": [28, 108], "whitespac": [44, 85], "whnm": 19, "who": [4, 58, 60, 64, 65, 67, 69, 70, 79, 83, 113, 121, 128, 139], "whole": [13, 34, 35, 38, 45, 46, 49, 58, 69, 119, 132], "wholli": 41, "whop": [34, 62], "whose": [3, 6, 9, 10, 11, 15, 19, 22, 25, 26, 30, 35, 37, 42, 43, 45, 57, 58, 61, 67, 75, 80, 82, 86, 89, 90, 91, 95, 97, 99, 113, 114, 117, 119, 120, 129, 130, 133, 135, 136, 140], "why": [2, 6, 10, 15, 16, 18, 20, 23, 27, 33, 34, 35, 36, 37, 39, 40, 41, 45, 46, 48, 49, 51, 52, 58, 59, 61, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 81, 82, 90, 91, 92, 93, 98, 101, 102, 103, 105, 107, 109, 110, 111, 112, 113, 114, 115, 117, 121, 122, 123, 127, 128, 129, 133, 135, 136, 140], "wide": [5, 10, 12, 20, 22, 23, 26, 30, 32, 34, 35, 40, 43, 47, 58, 60, 62, 68, 74, 77, 79, 80, 82, 83, 84, 85, 87, 88, 90, 108, 112, 113, 117, 127, 135], "wider": [26, 27, 34, 67, 69, 80, 108, 113], "widespread": [39, 70, 128], "width": [2, 11, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 49, 52, 62, 77, 81, 88, 117, 123], "wiener": 113, "wiggili": 48, "wiggli": 48, "wiki": [91, 95], "wikipedia": [2, 6, 90, 91, 95, 108, 132], "wikitext": [91, 92], "wild": [60, 77, 120], "wildli": [15, 38, 67], "william": [46, 47], "willing": [56, 58, 64, 81], "wilson": 50, "win": [58, 60, 64, 79, 121, 138], "wind": [44, 58, 67], "window": [2, 30, 33, 34, 37, 38, 40, 41, 43, 44, 45, 46, 57, 58, 88, 89, 93, 97, 98, 118, 136], "window_s": 97, "wing": 108, "winner": 38, "winter": [60, 132], "wipe": 114, "wire": [38, 64, 69], "wisdom": 80, "wise": [35, 38, 40, 60, 69, 102, 108, 109, 111, 127], "wish": [16, 18, 44, 47, 49, 58, 60, 61, 64, 69, 70, 72, 77, 79, 86, 114, 115, 117, 119, 121, 123, 136], "wit": [5, 70], "with_logit": 99, "withheld": 67, "within": [2, 3, 7, 9, 10, 14, 15, 35, 39, 41, 44, 46, 47, 48, 58, 61, 64, 74, 75, 93, 96, 104, 108, 109, 112, 121, 135, 138, 139], "without": [3, 4, 6, 8, 10, 11, 13, 15, 18, 21, 22, 23, 26, 30, 32, 34, 35, 39, 44, 46, 47, 49, 50, 52, 54, 58, 60, 61, 64, 65, 69, 70, 72, 73, 80, 82, 84, 86, 89, 90, 94, 96, 98, 101, 103, 105, 107, 108, 109, 111, 112, 113, 115, 117, 119, 121, 127, 129, 130, 131, 132, 135, 136, 139, 140], "woman": [83, 95], "women": 85, "won": [15, 34, 37, 39, 58, 87], "wonder": [2, 11, 64, 73, 74, 95, 121, 136], "word": [1, 4, 5, 30, 34, 35, 39, 43, 46, 48, 58, 60, 61, 64, 66, 75, 76, 82, 83, 85, 86, 87, 89, 90, 91, 94, 96, 102, 104, 105, 108, 109, 113, 117, 121, 127, 128, 131, 133, 135, 136, 137, 141, 142], "word2vec": [90, 91, 93, 94, 95, 96, 97, 142], "wordnet": 34, "wordpiec": 91, "work": [3, 5, 8, 11, 12, 13, 15, 16, 19, 27, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 48, 50, 51, 52, 58, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 88, 96, 99, 101, 102, 103, 104, 105, 107, 109, 112, 113, 114, 115, 117, 119, 120, 121, 123, 125, 128, 130, 131, 132, 134, 135, 137, 140, 142], "workabl": 2, "worker": [54, 55, 56], "workflow": [52, 113], "workhors": 58, "workload": [69, 108], "world": [3, 6, 15, 29, 30, 40, 48, 58, 60, 67, 69, 77, 80, 94, 108, 113, 117, 120, 135, 138], "worri": [15, 19, 35, 57, 58, 60, 61, 68, 69, 70, 73, 75, 113, 136], "worryingli": 67, "wors": [18, 39, 52, 55, 69, 76, 77, 108, 109, 112, 132, 136], "worst": [56, 61, 67, 95, 105, 132, 135], "worth": [17, 30, 35, 43, 49, 52, 58, 59, 64, 67, 69, 72, 80, 121, 133], "worthi": [35, 58, 60], "worthwhil": 132, "would": [2, 8, 10, 11, 15, 16, 17, 18, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 72, 73, 74, 76, 79, 80, 82, 102, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 120, 121, 122, 123, 125, 127, 130, 132, 133, 135, 136, 137, 139, 140], "wow": 128, "wrangl": 80, "wrap": [58, 87, 117], "wrapper": 72, "wreck": 132, "write": [1, 6, 12, 13, 15, 17, 18, 26, 34, 35, 47, 49, 58, 69, 73, 77, 82, 103, 104, 105, 111, 113, 114, 115, 117, 119, 120, 121, 134, 135, 136, 139, 140, 141], "written": [3, 18, 36, 49, 58, 94, 104, 105, 117, 127, 135, 141], "wrong": [55, 58, 60, 66, 69, 81, 105, 123, 130, 135, 136], "wrote": [15, 43], "wu": 113, "www": [1, 23, 25, 26, 79], "x": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 52, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 85, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 114, 115, 117, 119, 120, 121, 123, 124, 125, 127, 129, 130, 131, 132, 133, 135, 136, 137], "x0": [47, 85], "x1": [20, 49, 85, 102, 105, 109, 111, 112], "x2": [10, 17, 20, 49, 102, 105, 109, 111, 112], "x86_64": 57, "x_": [19, 28, 41, 47, 48, 69, 93, 100, 109, 115, 117, 130, 132, 133, 135, 136], "x_0": 109, "x_1": [47, 48, 49, 64, 69, 74, 97, 102, 105, 109, 111, 112, 115, 117, 129, 130, 131, 132, 133, 135, 136], "x_2": [48, 64, 69, 74, 97, 102, 105, 109, 111, 112, 115, 117, 132], "x_3": [64, 74, 132], "x_4": [64, 132], "x_5": 74, "x_a": 19, "x_b": 19, "x_d": [69, 105, 131, 132], "x_exp": 66, "x_grad": 114, "x_hat": 35, "x_i": [2, 12, 35, 47, 48, 49, 64, 69, 74, 93, 100, 104, 105, 109, 112, 115, 117, 121], "x_ij": 19, "x_j": [12, 47, 48, 49, 69, 82, 131], "x_max": 21, "x_min": 21, "x_n": [47, 48, 49, 69, 112, 115, 117], "x_point": 49, "x_prob": 66, "x_shape": 43, "x_shard": [23, 26], "x_t": [109, 129, 130, 132, 133, 135, 136], "x_train": 2, "x_transpos": 1, "x_val": 2, "xa0": [1, 128], "xavier": [14, 21, 22, 23, 26, 43, 92, 107], "xavier_uniform_": [22, 99], "xc": 127, "xf": 127, "xh": [123, 125, 133], "xi": [56, 104, 105, 112, 127], "xi_t": 130, "xiaot": 113, "xie": 113, "xlabel": [1, 3, 4, 8, 9, 10, 23, 25, 26, 28, 32, 47, 49, 51, 54, 55, 56, 69, 72, 87, 92, 99, 105, 107, 108, 109, 110, 111, 115, 128, 137], "xlarg": 52, "xlim": [1, 18, 23, 25, 26, 28, 32, 56, 72, 92, 99, 107, 108, 115, 136], "xlist": 128, "xmax": 19, "xmin": 19, "xo": 127, "xr": 125, "xscale": [1, 72, 115, 137], "xtick": [56, 110], "xu": 113, "xw": [1, 71], "xx": 49, "xxl": 6, "xy": [19, 20, 110], "xytext": 110, "xz": 125, "y": [1, 2, 6, 7, 9, 10, 12, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 44, 45, 47, 48, 49, 52, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 79, 80, 82, 85, 86, 87, 88, 96, 98, 100, 104, 107, 108, 110, 112, 114, 115, 117, 119, 120, 121, 122, 129, 132, 135, 136, 137, 140], "y1": [20, 32, 40], "y2": [10, 17, 20, 32, 40], "y_": [47, 122, 129, 136], "y_1": [60, 112, 122, 129, 130, 136], "y_2": [122, 129], "y_3": 122, "y_5": 71, "y_a": 19, "y_b": 19, "y_clone": 17, "y_hat": [1, 2, 23, 25, 26, 28, 41, 52, 59, 65, 66, 70, 71, 72, 74, 86, 107, 108, 129, 135], "y_i": [2, 60, 66, 79, 112, 117], "y_j": [60, 64, 65], "y_k": 12, "y_max": 21, "y_min": 21, "y_n": [60, 112], "y_shard": [23, 26], "y_t": [60, 102, 130, 136], "y_train": 2, "y_val": 2, "yang": 113, "yann": [34, 43], "yayab": 113, "ye": [52, 58, 113], "year": [3, 5, 6, 24, 34, 35, 50, 58, 60, 61, 67, 69, 79, 98, 113, 121, 127, 136], "yellow": [31, 104], "yesterdai": 67, "yet": [1, 6, 8, 12, 34, 35, 37, 43, 46, 51, 52, 55, 56, 57, 58, 60, 61, 67, 71, 72, 76, 77, 80, 90, 95, 101, 102, 107, 111, 113, 127], "yfc100m": 67, "yida": 113, "yield": [2, 3, 4, 33, 34, 37, 40, 41, 44, 45, 46, 58, 59, 60, 64, 67, 69, 72, 73, 75, 76, 77, 80, 85, 91, 97, 101, 103, 105, 109, 111, 112, 114, 119, 121, 129, 130], "yime": [60, 113], "ying": 113, "ylabel": [1, 3, 4, 8, 9, 10, 28, 47, 49, 51, 54, 55, 56, 69, 72, 87, 92, 99, 105, 108, 110, 115, 128, 137], "ylim": [1, 23, 72, 108, 115], "ylist": 128, "ymax": 19, "ymin": 19, "yoder": 113, "yogi": [35, 106], "yolo": 30, "york": [50, 58, 98], "yorkshir": 26, "yoshua": 34, "you": [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 86, 87, 88, 91, 92, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139], "young": 64, "your": [2, 15, 18, 26, 34, 35, 38, 40, 47, 51, 53, 54, 57, 58, 60, 61, 62, 64, 65, 66, 67, 70, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 107, 108, 113, 115, 116, 117, 118, 120, 121, 122, 134, 138], "yourself": [13, 39, 52, 58, 66, 77], "ypandya": 113, "yscale": [1, 72, 74, 79, 115, 137], "ysraell": 113, "ytick": 110, "yuan": 113, "yuanxiang": 113, "yue": 113, "yuhong": 113, "yuntai": 113, "yutaro": 113, "z": [6, 10, 18, 33, 41, 45, 46, 49, 60, 75, 96, 100, 102, 104, 109, 110, 114, 115, 117, 119, 121, 125, 136, 137], "z_m": 121, "z_t": 130, "za": 137, "zachari": 8, "zebra": 58, "zeme": 113, "zero": [1, 2, 3, 4, 6, 8, 9, 10, 11, 14, 17, 19, 21, 27, 30, 31, 32, 33, 35, 39, 41, 44, 45, 47, 48, 49, 52, 58, 60, 66, 67, 69, 71, 74, 76, 77, 79, 80, 81, 82, 88, 92, 93, 97, 101, 102, 103, 107, 108, 109, 110, 111, 112, 115, 117, 119, 121, 125, 127, 129, 135, 136, 139, 140, 141], "zero_": [101, 102, 103, 109, 111], "zero_grad": [23, 26, 92, 99, 107], "zeros_lik": [2, 76, 81, 119], "zha": 113, "zhang": [8, 113], "zhao": 113, "zhmou": 113, "zhu": 113, "zip": [1, 2, 4, 8, 10, 22, 23, 25, 26, 28, 29, 32, 40, 51, 66, 72, 79, 85, 86, 87, 88, 91, 92, 95, 97, 99, 101, 102, 103, 104, 105, 108, 109, 111, 115, 128, 129, 137], "zipf": 137, "zipfian": 137, "zipfil": [1, 113], "zone": 82, "zoom": 61, "zxydi1992": 113, "zyhazwraith": 113, "\u00e0": 66, "\u00e7a": 128, "\u4e00\u4e2a\u77e9\u9635": 82, "\u4e4b\u524d": 97, "\u4e4b\u540e": 97, "\u4e58\u4ee5100\u4e2a\u77e9\u9635\u540e": 82, "\u4ece\u56fe\u50cf\u4e2d\u5fc3\u88c1\u5207224x224\u5927\u5c0f\u7684\u56fe\u7247": 26, "\u503c": 22, "\u53551x1\u5377\u79ef\u5c42": 37, "\u56fe\u50cf": 22, "\u5728\u901a\u9053\u7ef4\u5ea6\u4e0a\u8fde\u7ed3\u8f93\u51fa": 37, "\u5f53ax": 117, "\u5f62\u72b6": 22, "\u6570\u636e\u7c7b\u578b": 22, "\u6807\u51c6\u5316\u56fe\u50cf\u7684\u6bcf\u4e2a\u901a\u9053": 25, "\u6807\u7b7e": 22, "\u6d4b\u8bd5\u6837\u672c\u6570\u91cf": 22, "\u7684\u6570\u91cf": 97, "\u76f8\u5f53\u4e8enumpi": 117, "\u7b2c\u4e00\u4e2a\u8bad\u7ec3\u6837\u672c\u952e": 22, "\u7c7b\u578b": 22, "\u7ebf\u8def1": 37, "\u7ebf\u8def2": 37, "\u7ebf\u8def3": 37, "\u7ebf\u8def4": 37, "\u8bad\u7ec3\u6837\u672c\u6570\u91cf": 22, "\u8fde\u63a5\u901a\u9053\u7ef4\u5ea6\u4e0a\u6bcf\u4e2a\u5757\u7684\u8f93\u5165\u548c\u8f93\u51fa": 36, "\u8fed\u4ee3\u5377\u79ef\u6838": 41}, "titles": ["<span class=\"section-number\">19. </span>Appendix: Tools for Deep Learning", "<span class=\"section-number\">19.1. </span>Utility Functions and Classes", "<span class=\"section-number\">11.2. </span>Attention Pooling by Similarity", "<span class=\"section-number\">11.3. </span>Attention Scoring Functions", "<span class=\"section-number\">11.4. </span>The Bahdanau Attention Mechanism", "<span class=\"section-number\">11. </span>Attention Mechanisms and Transformers", "<span class=\"section-number\">11.9. </span>Large-Scale Pretraining with Transformers", "<span class=\"section-number\">11.5. </span>Multi-Head Attention", "<span class=\"section-number\">11.1. </span>Queries, Keys, and Values", "<span class=\"section-number\">11.6. </span>Self-Attention and Positional Encoding", "<span class=\"section-number\">11.7. </span>The Transformer Architecture", "<span class=\"section-number\">11.8. </span>Transformers for Vision", "<span class=\"section-number\">6.4. </span>Custom Layers", "<span class=\"section-number\">6. </span>Builders\u2019 Guide", "<span class=\"section-number\">6.3. </span>Parameter Initialization", "<span class=\"section-number\">6.1. </span>Layers and Modules", "<span class=\"section-number\">6.2. </span>Parameter Management", "<span class=\"section-number\">6.5. </span>File I/O", "<span class=\"section-number\">6.6. </span>GPUs", "<span class=\"section-number\">13.4. </span>Anchor Boxes", "<span class=\"section-number\">13.3. </span>Object Detection and Bounding Boxes", "<span class=\"section-number\">13.11. </span>Fully Convolutional Networks", "<span class=\"section-number\">13.2. </span>Fine-Tuning", "<span class=\"section-number\">13.1. </span>Image Augmentation", "<span class=\"section-number\">13. </span>Computer Vision", "<span class=\"section-number\">13.13. </span>Image Classification (CIFAR-10) on Kaggle", "<span class=\"section-number\">13.14. </span>Dog Breed Identification (ImageNet Dogs) on Kaggle", "<span class=\"section-number\">13.5. </span>Multiscale Object Detection", "<span class=\"section-number\">13.12. </span>Neural Style Transfer", "<span class=\"section-number\">13.6. </span>The Object Detection Dataset", "<span class=\"section-number\">13.8. </span>Region-based CNNs (R-CNNs)", "<span class=\"section-number\">13.9. </span>Semantic Segmentation and the Dataset", "<span class=\"section-number\">13.7. </span>Single Shot Multibox Detection", "<span class=\"section-number\">13.10. </span>Transposed Convolution", "<span class=\"section-number\">8.1. </span>Deep Convolutional Neural Networks (AlexNet)", "<span class=\"section-number\">8.3. </span>Batch Normalization", "<span class=\"section-number\">8.5. </span>Densely Connected Networks (DenseNet)", "<span class=\"section-number\">8.2. </span>Multi-Branch Networks (GoogLeNet)", "<span class=\"section-number\">8. </span>Modern Convolutional Neural Networks", "<span class=\"section-number\">8.4. </span>Residual Networks (ResNet) and ResNeXt", "<span class=\"section-number\">7.4. </span>Multiple Input and Multiple Output Channels", "<span class=\"section-number\">7.2. </span>Convolutions for Images", "<span class=\"section-number\">7. </span>Convolutional Neural Networks", "<span class=\"section-number\">7.6. </span>Convolutional Neural Networks (LeNet)", "<span class=\"section-number\">7.3. </span>Padding and Stride", "<span class=\"section-number\">7.5. </span>Pooling", "<span class=\"section-number\">7.1. </span>From Fully Connected Layers to Convolutions", "<span class=\"section-number\">17.3. </span>Gaussian Process Inference", "<span class=\"section-number\">17.1. </span>Introduction to Gaussian Processes", "<span class=\"section-number\">17.2. </span>Gaussian Process Priors", "<span class=\"section-number\">17. </span>Gaussian Processes", "<span class=\"section-number\">18.2. </span>Hyperparameter Optimization API", "<span class=\"section-number\">18.1. </span>What Is Hyperparameter Optimization?", "<span class=\"section-number\">18. </span>Hyperparameter Optimization", "<span class=\"section-number\">18.3. </span>Asynchronous Random Search", "<span class=\"section-number\">18.5. </span>Asynchronous Successive Halving", "<span class=\"section-number\">18.4. </span>Multi-Fidelity Hyperparameter Optimization", "Installation", "<span class=\"section-number\">1. </span>Introduction", "<span class=\"section-number\">4.3. </span>The Base Classification Model", "<span class=\"section-number\">4.7. </span>Environment and Distribution Shift", "<span class=\"section-number\">4.6. </span>Generalization in Classification", "<span class=\"section-number\">4.2. </span>The Image Classification Dataset", "<span class=\"section-number\">4. </span>Linear Neural Networks for Classification", "<span class=\"section-number\">4.1. </span>Softmax Regression", "<span class=\"section-number\">4.5. </span>Concise Implementation of Softmax Regression", "<span class=\"section-number\">4.4. </span>Softmax Regression Implementation from Scratch", "<span class=\"section-number\">3.6. </span>Generalization", "<span class=\"section-number\">3. </span>Linear Neural Networks for Regression", "<span class=\"section-number\">3.1. </span>Linear Regression", "<span class=\"section-number\">3.5. </span>Concise Implementation of Linear Regression", "<span class=\"section-number\">3.4. </span>Linear Regression Implementation from Scratch", "<span class=\"section-number\">3.2. </span>Object-Oriented Design for Implementation", "<span class=\"section-number\">3.3. </span>Synthetic Regression Data", "<span class=\"section-number\">3.7. </span>Weight Decay", "<span class=\"section-number\">5.3. </span>Forward Propagation, Backward Propagation, and Computational Graphs", "<span class=\"section-number\">5.6. </span>Dropout", "<span class=\"section-number\">5.5. </span>Generalization in Deep Learning", "<span class=\"section-number\">5. </span>Multilayer Perceptrons", "<span class=\"section-number\">5.7. </span>Predicting House Prices on Kaggle", "<span class=\"section-number\">5.1. </span>Multilayer Perceptrons", "<span class=\"section-number\">5.2. </span>Implementation of Multilayer Perceptrons", "<span class=\"section-number\">5.4. </span>Numerical Stability and Initialization", "<span class=\"section-number\">15.5. </span>Fine-Tuning BERT for Sequence-Level and Token-Level Applications", "<span class=\"section-number\">15. </span>Natural Language Processing: Applications", "<span class=\"section-number\">15.3. </span>Natural Language Inference and the Dataset", "<span class=\"section-number\">15.4. </span>Natural Language Inference: Using Attention", "<span class=\"section-number\">15.1. </span>Sentiment Analysis and the Dataset", "<span class=\"section-number\">15.2. </span>Sentiment Analysis: Using Convolutional Neural Networks", "<span class=\"section-number\">14.2. </span>Approximate Training", "<span class=\"section-number\">14.8. </span>Bidirectional Encoder Representations from Transformers (BERT)", "<span class=\"section-number\">14.9. </span>The Dataset for Pretraining BERT", "<span class=\"section-number\">14.10. </span>Pretraining BERT", "<span class=\"section-number\">14.5. </span>Word Embedding with Global Vectors (GloVe)", "<span class=\"section-number\">14. </span>Natural Language Processing: Pretraining", "<span class=\"section-number\">14.7. </span>Word Similarity and Analogy", "<span class=\"section-number\">14.6. </span>Subword Embedding", "<span class=\"section-number\">14.3. </span>The Dataset for Pretraining Word Embeddings", "<span class=\"section-number\">14.1. </span>Word Embedding (word2vec)", "<span class=\"section-number\">14.4. </span>Pretraining word2vec", "Notation", "<span class=\"section-number\">12.9. </span>Adadelta", "<span class=\"section-number\">12.7. </span>Adagrad", "<span class=\"section-number\">12.10. </span>Adam", "<span class=\"section-number\">12.2. </span>Convexity", "<span class=\"section-number\">12.3. </span>Gradient Descent", "<span class=\"section-number\">12. </span>Optimization Algorithms", "<span class=\"section-number\">12.11. </span>Learning Rate Scheduling", "<span class=\"section-number\">12.5. </span>Minibatch Stochastic Gradient Descent", "<span class=\"section-number\">12.6. </span>Momentum", "<span class=\"section-number\">12.1. </span>Optimization and Deep Learning", "<span class=\"section-number\">12.8. </span>RMSProp", "<span class=\"section-number\">12.4. </span>Stochastic Gradient Descent", "Preface", "<span class=\"section-number\">2.5. </span>Automatic Differentiation", "<span class=\"section-number\">2.4. </span>Calculus", "<span class=\"section-number\">2. </span>Preliminaries", "<span class=\"section-number\">2.3. </span>Linear Algebra", "<span class=\"section-number\">2.7. </span>Documentation", "<span class=\"section-number\">2.1. </span>Data Manipulation", "<span class=\"section-number\">2.2. </span>Data Preprocessing", "<span class=\"section-number\">2.6. </span>Probability and Statistics", "<span class=\"section-number\">10.7. </span>Beam Search", "<span class=\"section-number\">10.3. </span>Deep Recurrent Neural Networks", "<span class=\"section-number\">10.5. </span>The Encoder\u2013Decoder Architecture", "<span class=\"section-number\">10.2. </span>Gated Recurrent Units (GRU)", "<span class=\"section-number\">10. </span>Modern Recurrent Neural Networks", "<span class=\"section-number\">10.1. </span>Long Short-Term Memory (LSTM)", "<span class=\"section-number\">10.4. </span>Machine Translation and the Dataset", "<span class=\"section-number\">10.6. </span>Sequence-to-Sequence Learning for Machine Translation", "<span class=\"section-number\">9.7. </span>Backpropagation Through Time", "<span class=\"section-number\">9. </span>Recurrent Neural Networks", "<span class=\"section-number\">9.3. </span>Language Models", "<span class=\"section-number\">9.4. </span>Recurrent Neural Networks", "<span class=\"section-number\">9.6. </span>Concise Implementation of Recurrent Neural Networks", "<span class=\"section-number\">9.5. </span>Recurrent Neural Network Implementation from Scratch", "<span class=\"section-number\">9.1. </span>Working with Sequences", "<span class=\"section-number\">9.2. </span>Converting Raw Text into Sequence Data", "<span class=\"section-number\">16. </span>Reinforcement Learning", "<span class=\"section-number\">16.1. </span>Markov Decision Process (MDP)", "<span class=\"section-number\">16.3. </span>Q-Learning", "<span class=\"section-number\">16.2. </span>Value Iteration", "Dive into Deep Learning"], "titleterms": {"": [104, 105], "1": 40, "10": 25, "2": 6, "3": 6, "A": [15, 49, 58, 60, 114, 121], "It": [11, 31, 85, 86, 87, 90, 97, 137], "One": [88, 98, 105, 113, 135], "The": [4, 10, 15, 21, 29, 31, 32, 41, 49, 52, 58, 59, 61, 62, 64, 66, 69, 85, 86, 88, 91, 93, 96, 97, 98, 99, 101, 102, 103, 109, 111, 124, 136, 140], "about": 113, "absolut": 9, "access": [16, 79], "account": 60, "accuraci": 59, "acknowledg": 113, "action": 141, "activ": [34, 80], "adadelta": 101, "adagrad": 102, "adam": 103, "adapt": [2, 105], "addit": 3, "aggreg": 86, "agnost": 90, "alexnet": 34, "algebra": 117, "algorithm": [51, 58, 70, 71, 101, 102, 103, 106, 111, 140], "all": [11, 16, 31, 85, 86, 87, 90, 97, 137], "an": [19, 58, 109, 121, 139, 140], "analogi": 95, "analysi": [87, 88, 105, 109, 112, 130], "analyt": 69, "anchor": [19, 27], "anecdot": 60, "answer": 83, "api": 51, "appendix": 0, "appli": [95, 99], "applic": [83, 84], "approxim": [80, 89], "ar": [98, 104], "architectur": [10, 34, 124], "arithmet": 117, "assign": 19, "assumpt": 139, "asynchron": [54, 55], "attend": 86, "attent": [2, 3, 4, 5, 7, 9, 86], "audienc": 113, "augment": [23, 25, 26], "automat": 114, "autoregress": 136, "averag": [45, 109], "backpropag": [75, 130], "backward": [75, 114], "bad": 98, "bag": 98, "bahdanau": 4, "bandit": 60, "base": [30, 32, 59, 133, 135], "basi": 49, "basic": [33, 64, 69, 109, 117], "batch": [3, 35, 60], "beam": 122, "below": 104, "bert": [6, 83, 90, 91, 92], "best": 90, "beyond": [6, 82], "bidirect": 90, "binari": 99, "biologi": 69, "block": [32, 36, 37, 39], "book": 113, "bookkeep": 51, "both": 90, "bound": [19, 20, 32], "box": [19, 20, 27, 32], "branch": 37, "break": 82, "breed": 26, "broadcast": 119, "builder": 13, "built": 14, "byte": 96, "cach": 108, "calculu": [100, 115], "candid": 125, "capac": 34, "car": 60, "cbow": 98, "cell": 127, "center": 97, "chain": 115, "challeng": 110, "chang": 23, "channel": [33, 40, 45, 46], "charact": 133, "choic": 98, "cifar": 25, "class": [1, 19, 31, 32, 39, 59, 85, 118], "classic": 77, "classif": [25, 58, 59, 61, 62, 63, 64, 83], "classifi": [25, 26, 59], "clip": 135, "cnn": [9, 30], "co": 93, "code": [15, 57, 113], "coin": 121, "color": 23, "combin": [23, 90, 113], "common": 23, "compar": [9, 51, 86, 130], "complet": 32, "complex": 67, "compon": 58, "comput": [18, 24, 75, 114, 130], "concaten": 32, "concept": 60, "concis": [35, 65, 70, 73, 74, 76, 81, 102, 108, 109, 111, 123, 125, 127, 134], "condit": 109, "configur": 52, "connect": [10, 33, 35, 36, 46], "consid": 60, "constrain": 46, "constraint": 104, "content": [28, 113], "context": [90, 97], "continu": 98, "control": [34, 60, 114], "conveni": 3, "converg": [105, 112], "convers": [119, 120], "convert": 137, "convex": [104, 109, 112], "convolut": [21, 33, 34, 35, 38, 40, 41, 42, 43, 46, 51, 88], "copi": 18, "corpu": 93, "correct": [60, 140], "correl": 41, "cosin": 107, "covari": 60, "creat": [86, 87], "crop": 23, "cross": [41, 64, 66, 67, 79, 99], "curv": 67, "custom": [12, 14, 15, 31], "d2l": 57, "data": [2, 19, 31, 34, 58, 72, 73, 79, 87, 119, 120, 137], "dataset": [21, 22, 25, 26, 29, 31, 32, 62, 67, 73, 79, 85, 86, 87, 91, 97, 108, 120, 128, 137], "decai": 74, "decis": 139, "decod": [4, 6, 10, 124, 129, 135, 136], "deep": [0, 34, 35, 57, 58, 77, 110, 123, 142], "default": 82, "defin": [4, 22, 25, 26, 28, 32, 65, 70, 71, 74, 76, 85, 88, 91, 99, 125, 134], "definit": [49, 104, 139], "demonstr": 29, "dens": 36, "densenet": 36, "deriv": [104, 115], "descent": [69, 105, 108, 112], "design": 72, "detach": 114, "detail": 130, "detect": [20, 27, 29, 32, 41], "devic": 18, "diagnost": 60, "differenti": [114, 115], "dimension": [74, 88, 105], "discount": 139, "discuss": [6, 11, 34, 35, 36, 37, 39, 40, 44, 46, 64, 79, 80, 114, 115, 117, 120, 121, 132, 139], "distribut": [60, 69], "dive": 142, "do": 113, "document": 118, "dog": [22, 26], "dot": [3, 117], "download": [25, 26, 29, 57, 79, 128], "downsampl": 32, "drive": 60, "dropout": 76, "dure": 35, "dynam": [112, 141], "earli": 77, "easi": 47, "edg": 41, "effect": 109, "ell_2": 74, "embed": [11, 93, 96, 97, 98, 99], "empir": 60, "encod": [6, 9, 10, 11, 90, 96, 124, 129, 135], "entropi": [64, 66, 99], "environ": [58, 60], "equat": 47, "error": [67, 79], "essenc": 58, "evalu": [32, 86, 88, 129, 141], "exampl": [19, 47, 51, 58, 60, 97, 121], "execut": 15, "exercis": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 139, 140, 141], "exhaust": 122, "expect": 121, "experi": 109, "explod": 82, "explor": 140, "exploratori": 137, "extract": [28, 97], "factor": [107, 139], "fair": 60, "fast": 30, "faster": 30, "fasttext": 96, "featur": [28, 41, 102], "feed": 10, "fidel": 56, "field": 41, "file": 17, "fine": [6, 22, 26, 83], "finit": 112, "fit": 67, "fix": 128, "flip": 23, "flow": 114, "fold": 79, "forc": 129, "forget": 127, "formal": 121, "format": 120, "forum": 113, "forward": [10, 15, 75, 99], "framework": 57, "frequenc": 132, "from": [35, 36, 46, 47, 49, 66, 71, 74, 76, 77, 80, 81, 90, 93, 102, 108, 109, 111, 123, 125, 127, 135], "full": 130, "fulli": [21, 35, 46], "function": [1, 3, 25, 26, 28, 32, 34, 39, 49, 52, 54, 55, 58, 64, 69, 70, 71, 80, 91, 100, 104, 109, 114, 118, 129, 141], "gate": [125, 127], "gaussian": [47, 48, 49, 50], "gener": [19, 61, 67, 73, 77, 91], "get": 119, "github": 113, "global": [93, 104], "glove": 93, "goal": 110, "googlenet": 37, "gp": 47, "gpt": 6, "gpu": [18, 23], "gpytorch": 47, "gradient": [69, 82, 105, 108, 110, 112, 114, 115, 130, 135], "gram": [93, 98, 99, 132], "graph": 75, "greedi": 122, "ground": 19, "gru": 125, "guid": 13, "halv": [55, 56], "hardwar": 34, "head": 7, "helper": 91, "hidden": [80, 125, 127, 133], "hierarch": 89, "high": 74, "hot": [22, 98, 135], "hous": 79, "hpo": 51, "html": 113, "hyperparamet": [47, 51, 52, 53, 56], "i": [17, 52], "identif": 26, "ill": 109, "imag": [23, 25, 26, 28, 31, 41, 62], "imagenet": 26, "implement": [7, 35, 65, 66, 70, 71, 72, 73, 74, 76, 81, 101, 102, 103, 108, 109, 111, 123, 125, 127, 134, 135, 140, 141], "incept": 37, "incorpor": 80, "independ": 90, "index": 119, "inequ": 104, "infer": [47, 85, 86], "inform": [9, 64, 100], "ingredi": 34, "initi": [14, 21, 22, 28, 32, 81, 82, 99, 125, 127], "input": [40, 90, 127], "inspir": 77, "instal": 57, "instanc": 31, "interact": 58, "intern": 127, "interpret": [47, 93], "intersect": 19, "introduct": [48, 58], "invari": 46, "iou": 19, "iter": [87, 141], "jensen": 104, "k": 79, "kaggl": [25, 26, 79], "kei": [8, 58], "kernel": [2, 41, 47, 49], "kind": 58, "label": [19, 52, 58, 60, 93], "lagrangian": 104, "languag": [6, 84, 85, 86, 90, 91, 94, 132, 133, 135, 137], "laplac": 132, "larg": 6, "layer": [10, 12, 15, 21, 32, 35, 36, 40, 41, 46, 80, 99], "leaki": 109, "learn": [0, 34, 41, 47, 57, 58, 60, 61, 77, 102, 105, 107, 110, 112, 113, 129, 132, 138, 140, 142], "lenet": [35, 43], "length": 128, "level": [83, 133], "life": 47, "likelihood": 64, "limit": 80, "line": 105, "linear": [63, 64, 68, 69, 70, 71, 74, 80, 117], "load": [17, 62, 85, 88, 95, 97, 128], "loader": 73, "local": [46, 104, 105, 110], "log": 64, "long": 127, "loop": 99, "loss": [28, 32, 64, 66, 69, 70, 71, 99, 129], "lstm": 127, "machin": [58, 60, 128, 129], "make": 47, "manag": 16, "manipul": 119, "map": 41, "markov": [132, 136, 139], "mask": [3, 30, 90, 91, 129], "math": 113, "matric": 117, "matrix": [3, 33, 117], "max": 88, "maximum": [19, 45], "mdp": 139, "measur": 79, "mechan": [4, 5], "medic": 60, "medium": 113, "memori": [119, 127], "method": [15, 23, 28, 77, 105, 109], "minibatch": [62, 69, 97, 108], "miniconda": 57, "minima": [104, 105, 110], "miss": 34, "mlp": 46, "model": [4, 6, 7, 10, 11, 17, 21, 22, 25, 26, 32, 36, 37, 39, 58, 59, 64, 65, 66, 67, 69, 70, 71, 72, 74, 76, 79, 80, 81, 86, 88, 90, 91, 93, 96, 98, 99, 125, 127, 132, 133, 134, 135, 136], "modern": [38, 126], "modul": [15, 118], "momentum": 109, "more": [60, 121], "motiv": 58, "multi": [7, 23, 37, 56, 107], "multibox": 32, "multilay": [78, 80, 81], "multipl": [3, 19, 23, 32, 33, 40, 45, 117, 121], "multiscal": 27, "multivari": 105, "n": 132, "nadaraya": 2, "natur": [84, 85, 86, 94], "neg": [89, 97], "network": [10, 18, 21, 32, 34, 35, 36, 37, 38, 39, 42, 43, 49, 51, 63, 68, 69, 75, 77, 88, 123, 126, 131, 133, 134, 135], "neural": [18, 28, 34, 38, 42, 43, 49, 51, 63, 68, 69, 75, 88, 123, 126, 131, 133, 134, 135], "newton": 105, "next": [90, 91], "node": 127, "non": [19, 114, 117], "nonlinear": 80, "nonparametr": 77, "nonstationari": 60, "norm": [74, 117], "normal": [10, 35, 69], "notat": 100, "note": 18, "notebook": 113, "numer": [82, 100], "o": 17, "object": [20, 27, 29, 41, 52, 54, 55, 58, 72, 100, 112, 119], "obtain": [25, 26], "occurr": 93, "offset": 19, "onc": 16, "onli": 6, "onlin": 60, "oper": [3, 33, 41, 100, 119], "optim": [51, 52, 53, 54, 55, 56, 58, 70, 71, 106, 110, 140, 141], "order": 136, "organ": [25, 26], "orient": 72, "other": 119, "output": [40, 127, 135], "over": [19, 88], "overfit": [67, 77], "packag": 57, "pad": [33, 44, 45], "pair": [83, 96], "paramet": [12, 14, 16, 17, 81, 82, 99, 125, 127], "partial": 115, "partit": 132, "pascal": 31, "patch": 11, "penalti": [74, 104], "perceptron": [78, 80, 81], "perform": 51, "perplex": 132, "point": 110, "polici": [107, 141], "polynomi": 67, "pool": [2, 45, 88], "posit": 9, "positionwis": 10, "posterior": 47, "postprocess": 28, "practic": [76, 109], "precondit": [102, 105], "predict": [19, 21, 32, 35, 47, 66, 69, 79, 90, 91, 127, 129, 134, 136], "prefac": 113, "preliminari": 116, "prepar": 120, "preprocess": [28, 31, 34, 79, 87, 120, 128], "pretrain": [6, 26, 88, 90, 91, 92, 94, 95, 97, 99], "price": 79, "principl": 141, "prior": 49, "probabl": [93, 100, 121], "problem": [52, 58, 60, 107, 109, 140], "process": [47, 48, 49, 50, 54, 55, 84, 94, 139], "product": [3, 117], "program": 141, "project": 104, "propag": [15, 75, 99], "properti": [104, 117, 140], "put": [11, 31, 85, 86, 87, 90, 97, 124, 137], "python": [114, 119], "q": 140, "quadrat": 109, "queri": 8, "question": 83, "r": 30, "radial": 49, "random": [52, 54, 121, 130], "rate": [102, 105, 107, 112], "ratio": 93, "raw": 137, "rbf": 49, "read": [21, 22, 25, 26, 28, 29, 31, 32, 62, 73, 79, 85, 86, 87, 97, 108, 120, 128, 137], "recept": 41, "recognit": 22, "recommend": 58, "recurr": [123, 125, 126, 131, 133, 134, 135], "reduct": 117, "region": 30, "regress": [2, 47, 58, 64, 65, 66, 68, 69, 70, 71, 73, 74, 83], "regular": [74, 77], "reinforc": [58, 60, 138], "rel": 9, "relu": 80, "repres": 92, "represent": [34, 90], "reset": 125, "residu": [10, 39], "resnet": [36, 39], "resnext": 39, "result": [25, 26], "return": 139, "reus": 61, "revisit": [64, 65, 77], "risk": 60, "rmsprop": 111, "rnn": [9, 130, 133, 135], "road": 58, "root": 58, "rule": 115, "run": 57, "saddl": 110, "sampl": [89, 97, 109, 112], "save": [17, 119], "scalabl": 6, "scalar": [109, 114, 117], "scale": [3, 6, 32], "schedul": [51, 54, 55, 107], "score": 3, "scratch": [35, 47, 66, 71, 74, 76, 81, 102, 108, 109, 111, 123, 125, 127, 135], "search": [52, 54, 58, 105, 122], "searcher": 51, "second": 104, "segment": 31, "select": [67, 79], "self": [9, 58, 60, 98, 140], "semant": 31, "sensit": 90, "sentenc": [90, 91], "sentiment": [87, 88], "sequenc": [58, 83, 128, 129, 132, 136, 137], "sequenti": 15, "set": [25, 26, 61, 100, 104], "shift": 60, "short": 127, "shot": 32, "side": 18, "sigmoid": 80, "similar": [2, 95], "simpl": [49, 114, 121], "singl": [32, 83], "size": 67, "skip": [93, 98, 99], "slice": 119, "smooth": 132, "snli": 85, "softmax": [3, 64, 65, 66, 89], "solut": 69, "space": [49, 52], "spars": 102, "specif": [90, 118], "speed": 69, "squar": 69, "stabil": 82, "stanford": 85, "start": 119, "state": [125, 127, 133], "statist": [61, 93, 121, 137], "step": [22, 130], "stochast": [69, 108, 112, 141], "stop": 77, "storag": 18, "stori": 58, "strategi": 130, "stride": [33, 44, 45], "structur": 113, "style": 28, "submit": [25, 26, 79], "subsampl": 97, "subword": 96, "success": [55, 56, 58], "sum": 117, "summari": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 39, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 119, 122, 123, 124, 125, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 139, 140, 141], "supervis": [58, 98], "suppress": 19, "surpris": 64, "symmetri": 82, "synthes": 28, "synthet": 73, "system": 58, "t5": 6, "tab_example_configspac": 52, "tab_glov": 93, "tab_intro_decad": 58, "tag": [58, 83], "tanh": 80, "target": [16, 113], "task": [90, 91], "taxonomi": 60, "teacher": 129, "tensor": [17, 18, 117, 120], "term": 127, "test": [25, 26, 61], "text": [83, 91, 92, 137], "textcnn": 88, "theoret": 109, "theori": [61, 64, 100], "thi": 113, "through": 130, "ti": 16, "time": [40, 88, 130], "togeth": [11, 31, 85, 86, 87, 90, 97, 124, 137], "toi": 107, "token": [83, 128, 137], "tool": 0, "toss": 121, "total": 28, "train": [4, 10, 11, 19, 21, 23, 25, 26, 28, 32, 34, 35, 36, 37, 39, 43, 65, 66, 67, 70, 71, 72, 74, 75, 76, 81, 86, 88, 89, 97, 98, 99, 125, 127, 129, 134, 135, 136], "transfer": 28, "transform": [5, 6, 10, 11, 90, 91, 135], "transit": 36, "translat": [46, 128, 129], "transpar": 60, "transpos": [21, 33], "transposit": 33, "treatment": 121, "truncat": 130, "truth": 19, "tune": [6, 22, 26, 83], "tuner": 51, "type": 60, "underfit": 67, "underli": 140, "union": 19, "unit": 125, "univers": 80, "unsupervis": 58, "updat": [112, 125], "us": [74, 86, 88], "util": [1, 72, 115], "valid": [25, 26, 67, 79], "valu": [8, 141], "vanish": [82, 110], "variabl": [114, 121], "variat": 28, "vector": [64, 69, 88, 93, 95, 98, 108, 117], "via": 2, "vision": [11, 24], "visual": [8, 54, 55, 62, 115], "voc2012": 31, "vocabulari": 137, "warmup": 107, "watson": 2, "websit": 113, "weight": [49, 74, 109], "what": 52, "without": [12, 74, 133], "word": [88, 93, 95, 97, 98, 99, 132], "word2vec": [98, 99], "work": [47, 136], "world": 90, "xavier": 82, "yogi": 103}})