Search.setIndex({"docnames": ["chapter_appendix-tools-for-deep-learning/index", "chapter_appendix-tools-for-deep-learning/utils", "chapter_attention-mechanisms-and-transformers/attention-pooling", "chapter_attention-mechanisms-and-transformers/attention-scoring-functions", "chapter_attention-mechanisms-and-transformers/bahdanau-attention", "chapter_attention-mechanisms-and-transformers/index", "chapter_attention-mechanisms-and-transformers/large-pretraining-transformers", "chapter_attention-mechanisms-and-transformers/multihead-attention", "chapter_attention-mechanisms-and-transformers/queries-keys-values", "chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding", "chapter_attention-mechanisms-and-transformers/transformer", "chapter_attention-mechanisms-and-transformers/vision-transformer", "chapter_builders-guide/custom-layer", "chapter_builders-guide/index", "chapter_builders-guide/init-param", "chapter_builders-guide/model-construction", "chapter_builders-guide/parameters", "chapter_builders-guide/read-write", "chapter_builders-guide/use-gpu", "chapter_computer-vision/anchor", "chapter_computer-vision/bounding-box", "chapter_computer-vision/fcn", "chapter_computer-vision/fine-tuning", "chapter_computer-vision/image-augmentation", "chapter_computer-vision/index", "chapter_computer-vision/kaggle-cifar10", "chapter_computer-vision/kaggle-dog", "chapter_computer-vision/multiscale-object-detection", "chapter_computer-vision/neural-style", "chapter_computer-vision/object-detection-dataset", "chapter_computer-vision/rcnn", "chapter_computer-vision/semantic-segmentation-and-dataset", "chapter_computer-vision/ssd", "chapter_computer-vision/transposed-conv", "chapter_convolutional-modern/alexnet", "chapter_convolutional-modern/batch-norm", "chapter_convolutional-modern/densenet", "chapter_convolutional-modern/googlenet", "chapter_convolutional-modern/index", "chapter_convolutional-modern/resnet", "chapter_convolutional-neural-networks/channels", "chapter_convolutional-neural-networks/conv-layer", "chapter_convolutional-neural-networks/index", "chapter_convolutional-neural-networks/lenet", "chapter_convolutional-neural-networks/padding-and-strides", "chapter_convolutional-neural-networks/pooling", "chapter_convolutional-neural-networks/why-conv", "chapter_gaussian-processes/gp-inference", "chapter_gaussian-processes/gp-intro", "chapter_gaussian-processes/gp-priors", "chapter_gaussian-processes/index", "chapter_hyperparameter-optimization/hyperopt-api", "chapter_hyperparameter-optimization/hyperopt-intro", "chapter_hyperparameter-optimization/index", "chapter_hyperparameter-optimization/rs-async", "chapter_hyperparameter-optimization/sh-async", "chapter_hyperparameter-optimization/sh-intro", "chapter_installation/index", "chapter_introduction/index", "chapter_linear-classification/classification", "chapter_linear-classification/environment-and-distribution-shift", "chapter_linear-classification/generalization-classification", "chapter_linear-classification/image-classification-dataset", "chapter_linear-classification/index", "chapter_linear-classification/softmax-regression", "chapter_linear-classification/softmax-regression-concise", "chapter_linear-classification/softmax-regression-scratch", "chapter_linear-regression/generalization", "chapter_linear-regression/index", "chapter_linear-regression/linear-regression", "chapter_linear-regression/linear-regression-concise", "chapter_linear-regression/linear-regression-scratch", "chapter_linear-regression/oo-design", "chapter_linear-regression/synthetic-regression-data", "chapter_linear-regression/weight-decay", "chapter_multilayer-perceptrons/backprop", "chapter_multilayer-perceptrons/dropout", "chapter_multilayer-perceptrons/generalization-deep", "chapter_multilayer-perceptrons/index", "chapter_multilayer-perceptrons/kaggle-house-price", "chapter_multilayer-perceptrons/mlp", "chapter_multilayer-perceptrons/mlp-implementation", "chapter_multilayer-perceptrons/numerical-stability-and-init", "chapter_natural-language-processing-applications/finetuning-bert", "chapter_natural-language-processing-applications/index", "chapter_natural-language-processing-applications/natural-language-inference-and-dataset", "chapter_natural-language-processing-applications/natural-language-inference-attention", "chapter_natural-language-processing-applications/sentiment-analysis-and-dataset", "chapter_natural-language-processing-applications/sentiment-analysis-cnn", "chapter_natural-language-processing-pretraining/approx-training", "chapter_natural-language-processing-pretraining/bert", "chapter_natural-language-processing-pretraining/bert-dataset", "chapter_natural-language-processing-pretraining/bert-pretraining", "chapter_natural-language-processing-pretraining/glove", "chapter_natural-language-processing-pretraining/index", "chapter_natural-language-processing-pretraining/similarity-analogy", "chapter_natural-language-processing-pretraining/subword-embedding", "chapter_natural-language-processing-pretraining/word-embedding-dataset", "chapter_natural-language-processing-pretraining/word2vec", "chapter_natural-language-processing-pretraining/word2vec-pretraining", "chapter_notation/index", "chapter_optimization/adadelta", "chapter_optimization/adagrad", "chapter_optimization/adam", "chapter_optimization/convexity", "chapter_optimization/gd", "chapter_optimization/index", "chapter_optimization/lr-scheduler", "chapter_optimization/minibatch-sgd", "chapter_optimization/momentum", "chapter_optimization/optimization-intro", "chapter_optimization/rmsprop", "chapter_optimization/sgd", "chapter_preface/index", "chapter_preliminaries/autograd", "chapter_preliminaries/calculus", "chapter_preliminaries/index", "chapter_preliminaries/linear-algebra", "chapter_preliminaries/lookup-api", "chapter_preliminaries/ndarray", "chapter_preliminaries/pandas", "chapter_preliminaries/probability", "chapter_recurrent-modern/beam-search", "chapter_recurrent-modern/deep-rnn", "chapter_recurrent-modern/encoder-decoder", "chapter_recurrent-modern/gru", "chapter_recurrent-modern/index", "chapter_recurrent-modern/lstm", "chapter_recurrent-modern/machine-translation-and-dataset", "chapter_recurrent-modern/seq2seq", "chapter_recurrent-neural-networks/bptt", "chapter_recurrent-neural-networks/index", "chapter_recurrent-neural-networks/language-model", "chapter_recurrent-neural-networks/rnn", "chapter_recurrent-neural-networks/rnn-concise", "chapter_recurrent-neural-networks/rnn-scratch", "chapter_recurrent-neural-networks/sequence", "chapter_recurrent-neural-networks/text-sequence", "chapter_reinforcement-learning/index", "chapter_reinforcement-learning/mdp", "chapter_reinforcement-learning/qlearning", "chapter_reinforcement-learning/value-iter", "index"], "filenames": ["chapter_appendix-tools-for-deep-learning/index.rst", "chapter_appendix-tools-for-deep-learning/utils.rst", "chapter_attention-mechanisms-and-transformers/attention-pooling.rst", "chapter_attention-mechanisms-and-transformers/attention-scoring-functions.rst", "chapter_attention-mechanisms-and-transformers/bahdanau-attention.rst", "chapter_attention-mechanisms-and-transformers/index.rst", "chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.rst", "chapter_attention-mechanisms-and-transformers/multihead-attention.rst", "chapter_attention-mechanisms-and-transformers/queries-keys-values.rst", "chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.rst", "chapter_attention-mechanisms-and-transformers/transformer.rst", "chapter_attention-mechanisms-and-transformers/vision-transformer.rst", "chapter_builders-guide/custom-layer.rst", "chapter_builders-guide/index.rst", "chapter_builders-guide/init-param.rst", "chapter_builders-guide/model-construction.rst", "chapter_builders-guide/parameters.rst", "chapter_builders-guide/read-write.rst", "chapter_builders-guide/use-gpu.rst", "chapter_computer-vision/anchor.rst", "chapter_computer-vision/bounding-box.rst", "chapter_computer-vision/fcn.rst", "chapter_computer-vision/fine-tuning.rst", "chapter_computer-vision/image-augmentation.rst", "chapter_computer-vision/index.rst", "chapter_computer-vision/kaggle-cifar10.rst", "chapter_computer-vision/kaggle-dog.rst", "chapter_computer-vision/multiscale-object-detection.rst", "chapter_computer-vision/neural-style.rst", "chapter_computer-vision/object-detection-dataset.rst", "chapter_computer-vision/rcnn.rst", "chapter_computer-vision/semantic-segmentation-and-dataset.rst", "chapter_computer-vision/ssd.rst", "chapter_computer-vision/transposed-conv.rst", "chapter_convolutional-modern/alexnet.rst", "chapter_convolutional-modern/batch-norm.rst", "chapter_convolutional-modern/densenet.rst", "chapter_convolutional-modern/googlenet.rst", "chapter_convolutional-modern/index.rst", "chapter_convolutional-modern/resnet.rst", "chapter_convolutional-neural-networks/channels.rst", "chapter_convolutional-neural-networks/conv-layer.rst", "chapter_convolutional-neural-networks/index.rst", "chapter_convolutional-neural-networks/lenet.rst", "chapter_convolutional-neural-networks/padding-and-strides.rst", "chapter_convolutional-neural-networks/pooling.rst", "chapter_convolutional-neural-networks/why-conv.rst", "chapter_gaussian-processes/gp-inference.rst", "chapter_gaussian-processes/gp-intro.rst", "chapter_gaussian-processes/gp-priors.rst", "chapter_gaussian-processes/index.rst", "chapter_hyperparameter-optimization/hyperopt-api.rst", "chapter_hyperparameter-optimization/hyperopt-intro.rst", "chapter_hyperparameter-optimization/index.rst", "chapter_hyperparameter-optimization/rs-async.rst", "chapter_hyperparameter-optimization/sh-async.rst", "chapter_hyperparameter-optimization/sh-intro.rst", "chapter_installation/index.rst", "chapter_introduction/index.rst", "chapter_linear-classification/classification.rst", "chapter_linear-classification/environment-and-distribution-shift.rst", "chapter_linear-classification/generalization-classification.rst", "chapter_linear-classification/image-classification-dataset.rst", "chapter_linear-classification/index.rst", "chapter_linear-classification/softmax-regression.rst", "chapter_linear-classification/softmax-regression-concise.rst", "chapter_linear-classification/softmax-regression-scratch.rst", "chapter_linear-regression/generalization.rst", "chapter_linear-regression/index.rst", "chapter_linear-regression/linear-regression.rst", "chapter_linear-regression/linear-regression-concise.rst", "chapter_linear-regression/linear-regression-scratch.rst", "chapter_linear-regression/oo-design.rst", "chapter_linear-regression/synthetic-regression-data.rst", "chapter_linear-regression/weight-decay.rst", "chapter_multilayer-perceptrons/backprop.rst", "chapter_multilayer-perceptrons/dropout.rst", "chapter_multilayer-perceptrons/generalization-deep.rst", "chapter_multilayer-perceptrons/index.rst", "chapter_multilayer-perceptrons/kaggle-house-price.rst", "chapter_multilayer-perceptrons/mlp.rst", "chapter_multilayer-perceptrons/mlp-implementation.rst", "chapter_multilayer-perceptrons/numerical-stability-and-init.rst", "chapter_natural-language-processing-applications/finetuning-bert.rst", "chapter_natural-language-processing-applications/index.rst", "chapter_natural-language-processing-applications/natural-language-inference-and-dataset.rst", "chapter_natural-language-processing-applications/natural-language-inference-attention.rst", "chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.rst", "chapter_natural-language-processing-applications/sentiment-analysis-cnn.rst", "chapter_natural-language-processing-pretraining/approx-training.rst", "chapter_natural-language-processing-pretraining/bert.rst", "chapter_natural-language-processing-pretraining/bert-dataset.rst", "chapter_natural-language-processing-pretraining/bert-pretraining.rst", "chapter_natural-language-processing-pretraining/glove.rst", "chapter_natural-language-processing-pretraining/index.rst", "chapter_natural-language-processing-pretraining/similarity-analogy.rst", "chapter_natural-language-processing-pretraining/subword-embedding.rst", "chapter_natural-language-processing-pretraining/word-embedding-dataset.rst", "chapter_natural-language-processing-pretraining/word2vec.rst", "chapter_natural-language-processing-pretraining/word2vec-pretraining.rst", "chapter_notation/index.rst", "chapter_optimization/adadelta.rst", "chapter_optimization/adagrad.rst", "chapter_optimization/adam.rst", "chapter_optimization/convexity.rst", "chapter_optimization/gd.rst", "chapter_optimization/index.rst", "chapter_optimization/lr-scheduler.rst", "chapter_optimization/minibatch-sgd.rst", "chapter_optimization/momentum.rst", "chapter_optimization/optimization-intro.rst", "chapter_optimization/rmsprop.rst", "chapter_optimization/sgd.rst", "chapter_preface/index.rst", "chapter_preliminaries/autograd.rst", "chapter_preliminaries/calculus.rst", "chapter_preliminaries/index.rst", "chapter_preliminaries/linear-algebra.rst", "chapter_preliminaries/lookup-api.rst", "chapter_preliminaries/ndarray.rst", "chapter_preliminaries/pandas.rst", "chapter_preliminaries/probability.rst", "chapter_recurrent-modern/beam-search.rst", "chapter_recurrent-modern/deep-rnn.rst", "chapter_recurrent-modern/encoder-decoder.rst", "chapter_recurrent-modern/gru.rst", "chapter_recurrent-modern/index.rst", "chapter_recurrent-modern/lstm.rst", "chapter_recurrent-modern/machine-translation-and-dataset.rst", "chapter_recurrent-modern/seq2seq.rst", "chapter_recurrent-neural-networks/bptt.rst", "chapter_recurrent-neural-networks/index.rst", "chapter_recurrent-neural-networks/language-model.rst", "chapter_recurrent-neural-networks/rnn.rst", "chapter_recurrent-neural-networks/rnn-concise.rst", "chapter_recurrent-neural-networks/rnn-scratch.rst", "chapter_recurrent-neural-networks/sequence.rst", "chapter_recurrent-neural-networks/text-sequence.rst", "chapter_reinforcement-learning/index.rst", "chapter_reinforcement-learning/mdp.rst", "chapter_reinforcement-learning/qlearning.rst", "chapter_reinforcement-learning/value-iter.rst", "index.rst"], "titles": ["<span class=\"section-number\">19. </span>Appendix: Tools for Deep Learning", "<span class=\"section-number\">19.1. </span>Utility Functions and Classes", "<span class=\"section-number\">11.2. </span>Attention Pooling by Similarity", "<span class=\"section-number\">11.3. </span>Attention Scoring Functions", "<span class=\"section-number\">11.4. </span>The Bahdanau Attention Mechanism", "<span class=\"section-number\">11. </span>Attention Mechanisms and Transformers", "<span class=\"section-number\">11.9. </span>Large-Scale Pretraining with Transformers", "<span class=\"section-number\">11.5. </span>Multi-Head Attention", "<span class=\"section-number\">11.1. </span>Queries, Keys, and Values", "<span class=\"section-number\">11.6. </span>Self-Attention and Positional Encoding", "<span class=\"section-number\">11.7. </span>The Transformer Architecture", "<span class=\"section-number\">11.8. </span>Transformers for Vision", "<span class=\"section-number\">6.4. </span>Custom Layers", "<span class=\"section-number\">6. </span>Builders\u2019 Guide", "<span class=\"section-number\">6.3. </span>Parameter Initialization", "<span class=\"section-number\">6.1. </span>Layers and Modules", "<span class=\"section-number\">6.2. </span>Parameter Management", "<span class=\"section-number\">6.5. </span>File I/O", "<span class=\"section-number\">6.6. </span>GPUs", "<span class=\"section-number\">13.4. </span>Anchor Boxes", "<span class=\"section-number\">13.3. </span>Object Detection and Bounding Boxes", "<span class=\"section-number\">13.11. </span>Fully Convolutional Networks", "<span class=\"section-number\">13.2. </span>Fine-Tuning", "<span class=\"section-number\">13.1. </span>Image Augmentation", "<span class=\"section-number\">13. </span>Computer Vision", "<span class=\"section-number\">13.13. </span>Image Classification (CIFAR-10) on Kaggle", "<span class=\"section-number\">13.14. </span>Dog Breed Identification (ImageNet Dogs) on Kaggle", "<span class=\"section-number\">13.5. </span>Multiscale Object Detection", "<span class=\"section-number\">13.12. </span>Neural Style Transfer", "<span class=\"section-number\">13.6. </span>The Object Detection Dataset", "<span class=\"section-number\">13.8. </span>Region-based CNNs (R-CNNs)", "<span class=\"section-number\">13.9. </span>Semantic Segmentation and the Dataset", "<span class=\"section-number\">13.7. </span>Single Shot Multibox Detection", "<span class=\"section-number\">13.10. </span>Transposed Convolution", "<span class=\"section-number\">8.1. </span>Deep Convolutional Neural Networks (AlexNet)", "<span class=\"section-number\">8.3. </span>Batch Normalization", "<span class=\"section-number\">8.5. </span>Densely Connected Networks (DenseNet)", "<span class=\"section-number\">8.2. </span>Multi-Branch Networks (GoogLeNet)", "<span class=\"section-number\">8. </span>Modern Convolutional Neural Networks", "<span class=\"section-number\">8.4. </span>Residual Networks (ResNet) and ResNeXt", "<span class=\"section-number\">7.4. </span>Multiple Input and Multiple Output Channels", "<span class=\"section-number\">7.2. </span>Convolutions for Images", "<span class=\"section-number\">7. </span>Convolutional Neural Networks", "<span class=\"section-number\">7.6. </span>Convolutional Neural Networks (LeNet)", "<span class=\"section-number\">7.3. </span>Padding and Stride", "<span class=\"section-number\">7.5. </span>Pooling", "<span class=\"section-number\">7.1. </span>From Fully Connected Layers to Convolutions", "<span class=\"section-number\">17.3. </span>Gaussian Process Inference", "<span class=\"section-number\">17.1. </span>Introduction to Gaussian Processes", "<span class=\"section-number\">17.2. </span>Gaussian Process Priors", "<span class=\"section-number\">17. </span>Gaussian Processes", "<span class=\"section-number\">18.2. </span>Hyperparameter Optimization API", "<span class=\"section-number\">18.1. </span>What Is Hyperparameter Optimization?", "<span class=\"section-number\">18. </span>Hyperparameter Optimization", "<span class=\"section-number\">18.3. </span>Asynchronous Random Search", "<span class=\"section-number\">18.5. </span>Asynchronous Successive Halving", "<span class=\"section-number\">18.4. </span>Multi-Fidelity Hyperparameter Optimization", "Installation", "<span class=\"section-number\">1. </span>Introduction", "<span class=\"section-number\">4.3. </span>The Base Classification Model", "<span class=\"section-number\">4.7. </span>Environment and Distribution Shift", "<span class=\"section-number\">4.6. </span>Generalization in Classification", "<span class=\"section-number\">4.2. </span>The Image Classification Dataset", "<span class=\"section-number\">4. </span>Linear Neural Networks for Classification", "<span class=\"section-number\">4.1. </span>Softmax Regression", "<span class=\"section-number\">4.5. </span>Concise Implementation of Softmax Regression", "<span class=\"section-number\">4.4. </span>Softmax Regression Implementation from Scratch", "<span class=\"section-number\">3.6. </span>Generalization", "<span class=\"section-number\">3. </span>Linear Neural Networks for Regression", "<span class=\"section-number\">3.1. </span>Linear Regression", "<span class=\"section-number\">3.5. </span>Concise Implementation of Linear Regression", "<span class=\"section-number\">3.4. </span>Linear Regression Implementation from Scratch", "<span class=\"section-number\">3.2. </span>Object-Oriented Design for Implementation", "<span class=\"section-number\">3.3. </span>Synthetic Regression Data", "<span class=\"section-number\">3.7. </span>Weight Decay", "<span class=\"section-number\">5.3. </span>Forward Propagation, Backward Propagation, and Computational Graphs", "<span class=\"section-number\">5.6. </span>Dropout", "<span class=\"section-number\">5.5. </span>Generalization in Deep Learning", "<span class=\"section-number\">5. </span>Multilayer Perceptrons", "<span class=\"section-number\">5.7. </span>Predicting House Prices on Kaggle", "<span class=\"section-number\">5.1. </span>Multilayer Perceptrons", "<span class=\"section-number\">5.2. </span>Implementation of Multilayer Perceptrons", "<span class=\"section-number\">5.4. </span>Numerical Stability and Initialization", "<span class=\"section-number\">15.5. </span>Fine-Tuning BERT for Sequence-Level and Token-Level Applications", "<span class=\"section-number\">15. </span>Natural Language Processing: Applications", "<span class=\"section-number\">15.3. </span>Natural Language Inference and the Dataset", "<span class=\"section-number\">15.4. </span>Natural Language Inference: Using Attention", "<span class=\"section-number\">15.1. </span>Sentiment Analysis and the Dataset", "<span class=\"section-number\">15.2. </span>Sentiment Analysis: Using Convolutional Neural Networks", "<span class=\"section-number\">14.2. </span>Approximate Training", "<span class=\"section-number\">14.8. </span>Bidirectional Encoder Representations from Transformers (BERT)", "<span class=\"section-number\">14.9. </span>The Dataset for Pretraining BERT", "<span class=\"section-number\">14.10. </span>Pretraining BERT", "<span class=\"section-number\">14.5. </span>Word Embedding with Global Vectors (GloVe)", "<span class=\"section-number\">14. </span>Natural Language Processing: Pretraining", "<span class=\"section-number\">14.7. </span>Word Similarity and Analogy", "<span class=\"section-number\">14.6. </span>Subword Embedding", "<span class=\"section-number\">14.3. </span>The Dataset for Pretraining Word Embeddings", "<span class=\"section-number\">14.1. </span>Word Embedding (word2vec)", "<span class=\"section-number\">14.4. </span>Pretraining word2vec", "Notation", "<span class=\"section-number\">12.9. </span>Adadelta", "<span class=\"section-number\">12.7. </span>Adagrad", "<span class=\"section-number\">12.10. </span>Adam", "<span class=\"section-number\">12.2. </span>Convexity", "<span class=\"section-number\">12.3. </span>Gradient Descent", "<span class=\"section-number\">12. </span>Optimization Algorithms", "<span class=\"section-number\">12.11. </span>Learning Rate Scheduling", "<span class=\"section-number\">12.5. </span>Minibatch Stochastic Gradient Descent", "<span class=\"section-number\">12.6. </span>Momentum", "<span class=\"section-number\">12.1. </span>Optimization and Deep Learning", "<span class=\"section-number\">12.8. </span>RMSProp", "<span class=\"section-number\">12.4. </span>Stochastic Gradient Descent", "Preface", "<span class=\"section-number\">2.5. </span>Automatic Differentiation", "<span class=\"section-number\">2.4. </span>Calculus", "<span class=\"section-number\">2. </span>Preliminaries", "<span class=\"section-number\">2.3. </span>Linear Algebra", "<span class=\"section-number\">2.7. </span>Documentation", "<span class=\"section-number\">2.1. </span>Data Manipulation", "<span class=\"section-number\">2.2. </span>Data Preprocessing", "<span class=\"section-number\">2.6. </span>Probability and Statistics", "<span class=\"section-number\">10.7. </span>Beam Search", "<span class=\"section-number\">10.3. </span>Deep Recurrent Neural Networks", "<span class=\"section-number\">10.5. </span>The Encoder\u2013Decoder Architecture", "<span class=\"section-number\">10.2. </span>Gated Recurrent Units (GRU)", "<span class=\"section-number\">10. </span>Modern Recurrent Neural Networks", "<span class=\"section-number\">10.1. </span>Long Short-Term Memory (LSTM)", "<span class=\"section-number\">10.4. </span>Machine Translation and the Dataset", "<span class=\"section-number\">10.6. </span>Sequence-to-Sequence Learning for Machine Translation", "<span class=\"section-number\">9.7. </span>Backpropagation Through Time", "<span class=\"section-number\">9. </span>Recurrent Neural Networks", "<span class=\"section-number\">9.3. </span>Language Models", "<span class=\"section-number\">9.4. </span>Recurrent Neural Networks", "<span class=\"section-number\">9.6. </span>Concise Implementation of Recurrent Neural Networks", "<span class=\"section-number\">9.5. </span>Recurrent Neural Network Implementation from Scratch", "<span class=\"section-number\">9.1. </span>Working with Sequences", "<span class=\"section-number\">9.2. </span>Converting Raw Text into Sequence Data", "<span class=\"section-number\">16. </span>Reinforcement Learning", "<span class=\"section-number\">16.1. </span>Markov Decision Process (MDP)", "<span class=\"section-number\">16.3. </span>Q-Learning", "<span class=\"section-number\">16.2. </span>Value Iteration", "Dive into Deep Learning"], "terms": {"To": [0, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 46, 47, 48, 51, 52, 55, 57, 58, 60, 61, 62, 64, 66, 67, 69, 70, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 128, 129, 130, 132, 133, 135, 136, 137, 140, 141], "get": [0, 1, 2, 13, 16, 17, 18, 19, 23, 25, 26, 28, 30, 33, 35, 36, 39, 40, 42, 43, 45, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58, 60, 61, 64, 65, 66, 67, 68, 69, 70, 73, 75, 77, 79, 80, 81, 82, 83, 85, 86, 87, 90, 91, 93, 95, 96, 101, 102, 104, 105, 109, 110, 112, 113, 114, 116, 117, 118, 120, 121, 122, 123, 130, 131, 132, 135, 136, 137, 139, 141], "most": [0, 3, 4, 5, 6, 8, 14, 15, 16, 18, 22, 23, 24, 31, 34, 38, 40, 41, 42, 44, 47, 49, 52, 53, 55, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 69, 71, 72, 74, 75, 76, 77, 79, 80, 83, 88, 91, 95, 96, 99, 102, 104, 107, 108, 109, 110, 113, 114, 116, 117, 119, 120, 121, 122, 126, 127, 128, 129, 130, 134, 135, 136, 137, 140], "out": [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15, 18, 19, 25, 26, 31, 32, 35, 37, 40, 41, 43, 44, 46, 47, 49, 51, 52, 58, 60, 61, 62, 64, 66, 67, 69, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 87, 91, 92, 94, 96, 102, 103, 104, 107, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 125, 127, 128, 129, 134, 136, 137, 141], "dive": [0, 2, 3, 42, 51, 64, 72, 75, 78, 82, 85, 90, 113, 116], "we": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "talk": [0, 44, 58, 64, 67, 69, 83, 112, 135], "you": [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 86, 87, 88, 91, 92, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139], "through": [0, 8, 12, 15, 16, 19, 27, 28, 30, 32, 34, 35, 37, 39, 40, 41, 42, 45, 47, 48, 50, 51, 52, 57, 58, 60, 61, 63, 64, 66, 69, 70, 71, 72, 74, 75, 76, 79, 80, 82, 88, 89, 94, 97, 98, 108, 112, 114, 121, 123, 129, 131, 132, 133, 135, 136, 139, 142], "differ": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 60, 61, 64, 65, 67, 69, 71, 72, 73, 74, 76, 77, 79, 81, 82, 83, 84, 86, 87, 88, 90, 92, 93, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 119, 121, 122, 123, 124, 127, 128, 129, 130, 132, 133, 135, 136, 139, 140, 141], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "run": [0, 6, 16, 17, 18, 23, 34, 35, 37, 41, 43, 44, 46, 47, 48, 50, 51, 52, 54, 55, 56, 58, 61, 62, 66, 69, 71, 72, 74, 75, 78, 85, 91, 92, 97, 101, 108, 114, 117, 118, 119, 121, 122, 125, 127, 128, 129, 133, 134, 135, 140, 141], "contribut": [0, 3, 37, 47, 58, 61, 69, 82, 113], "interact": [0, 3, 40, 46, 54, 62, 72, 79, 80, 94, 109, 113, 121, 130, 136], "open": [0, 1, 6, 13, 21, 23, 25, 26, 28, 31, 32, 34, 35, 41, 51, 56, 57, 58, 60, 70, 72, 77, 80, 85, 87, 95, 97, 120, 126, 128, 137, 140, 141], "sourc": [0, 1, 4, 6, 10, 13, 22, 35, 40, 47, 51, 54, 58, 60, 69, 70, 72, 73, 77, 80, 86, 113, 116, 118, 123, 128, 137], "book": [0, 1, 4, 6, 10, 24, 35, 51, 57, 58, 59, 62, 64, 65, 67, 69, 70, 71, 72, 74, 79, 80, 84, 91, 94, 100, 106, 108, 112, 115, 116, 117, 118, 121, 123, 131, 135, 136, 137], "util": [0, 4, 17, 34, 35, 43, 44, 47, 61, 62, 68, 79, 113, 116, 121, 129, 135, 138, 142], "function": [0, 2, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 33, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 53, 56, 57, 59, 60, 61, 62, 63, 65, 66, 67, 68, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 105, 106, 107, 108, 110, 111, 112, 113, 115, 116, 117, 119, 121, 123, 125, 126, 127, 130, 133, 134, 135, 136, 138, 139, 140, 142], "class": [0, 3, 4, 7, 9, 10, 11, 12, 15, 16, 17, 21, 22, 25, 26, 27, 28, 29, 30, 34, 35, 36, 37, 38, 41, 43, 46, 47, 48, 49, 50, 51, 52, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 86, 88, 90, 91, 95, 97, 107, 108, 113, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129, 134, 135, 136, 137, 139, 142], "section": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141], "contain": [1, 8, 9, 10, 15, 16, 17, 19, 20, 21, 22, 25, 26, 27, 29, 30, 31, 33, 34, 35, 39, 40, 41, 45, 46, 47, 48, 49, 50, 54, 57, 58, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 72, 75, 76, 79, 80, 81, 85, 87, 88, 89, 91, 95, 96, 97, 98, 100, 102, 104, 113, 114, 115, 117, 119, 120, 122, 125, 127, 132, 136, 137, 138, 140, 141], "implement": [1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 15, 19, 21, 27, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 54, 55, 56, 58, 59, 60, 62, 63, 64, 68, 75, 77, 78, 79, 80, 82, 85, 86, 87, 88, 90, 91, 92, 95, 97, 99, 105, 106, 107, 113, 117, 118, 121, 124, 126, 128, 129, 131, 133, 138, 142], "us": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142], "import": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 85, 86, 87, 88, 90, 91, 92, 95, 96, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 132, 133, 134, 135, 136, 137, 139, 140, 141], "collect": [1, 8, 22, 25, 29, 34, 35, 42, 46, 47, 48, 49, 52, 55, 56, 58, 60, 61, 67, 69, 74, 77, 79, 85, 86, 96, 100, 113, 117, 121, 129, 136, 137, 140], "inspect": [1, 2, 5, 16, 62, 73, 113, 119, 120, 137], "from": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 45, 48, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 75, 78, 79, 82, 83, 85, 86, 87, 88, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142], "type": [1, 3, 14, 16, 19, 22, 31, 32, 33, 35, 39, 41, 47, 48, 49, 51, 52, 55, 58, 59, 63, 64, 65, 72, 73, 79, 83, 84, 85, 90, 100, 108, 109, 113, 118, 119, 120, 122, 124, 127], "ani": [1, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 19, 21, 27, 28, 29, 30, 31, 32, 34, 35, 39, 41, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 57, 58, 60, 61, 64, 66, 67, 69, 70, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 96, 97, 98, 99, 104, 105, 107, 108, 109, 110, 112, 113, 115, 117, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 135, 136, 137, 139, 140, 141], "dict": [1, 17, 19, 22, 23, 25, 29, 31, 51, 56, 96, 110, 113], "list": [1, 11, 15, 17, 19, 25, 26, 27, 32, 47, 56, 58, 60, 62, 66, 72, 73, 83, 85, 91, 93, 95, 96, 97, 108, 113, 115, 118, 119, 121, 127, 128, 135, 136, 137], "option": [1, 2, 8, 35, 39, 46, 57, 58, 62, 64, 69, 72, 79, 108, 109, 112, 113, 114, 118], "tupl": [1, 8, 11, 19, 58, 72, 73, 96, 113, 117, 137, 139, 140], "typevar": [1, 113], "union": [1, 21, 24, 96, 100, 104, 113, 118], "mlx": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 47, 49, 51, 52, 54, 55, 56, 59, 62, 65, 66, 69, 70, 71, 72, 73, 74, 76, 79, 80, 81, 82, 85, 86, 87, 88, 90, 91, 92, 95, 97, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 132, 133, 134, 135, 136, 137, 140, 141], "core": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 49, 52, 54, 58, 59, 62, 65, 66, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 85, 86, 87, 88, 90, 91, 92, 95, 97, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 123, 124, 125, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137], "mx": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 47, 49, 52, 59, 62, 65, 66, 69, 70, 71, 72, 73, 74, 76, 79, 80, 81, 82, 85, 86, 87, 88, 90, 91, 92, 95, 97, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 117, 119, 120, 123, 124, 125, 127, 128, 129, 132, 133, 134, 135, 136, 137], "nn": [1, 3, 4, 7, 9, 10, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 28, 30, 32, 33, 34, 35, 36, 37, 39, 41, 43, 44, 45, 47, 52, 62, 65, 70, 72, 73, 74, 76, 79, 80, 81, 82, 83, 86, 88, 90, 92, 95, 99, 107, 108, 113, 123, 124, 125, 127, 129, 134, 135, 136], "ipython": [1, 113], "displai": [1, 8, 27, 32, 43, 57, 58, 72, 79, 113, 115, 118], "d2l": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 45, 47, 49, 51, 52, 54, 55, 56, 59, 62, 65, 66, 69, 70, 71, 72, 73, 74, 76, 79, 80, 81, 82, 85, 86, 87, 88, 90, 91, 92, 95, 97, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 121, 123, 124, 125, 127, 128, 129, 132, 133, 134, 135, 136, 137, 140, 141], "hyperparamet": [1, 2, 4, 10, 11, 16, 21, 22, 25, 26, 28, 32, 33, 35, 37, 38, 39, 48, 49, 50, 54, 55, 60, 61, 66, 67, 69, 71, 72, 73, 74, 75, 79, 81, 85, 86, 87, 88, 89, 90, 97, 99, 106, 108, 109, 122, 123, 125, 127, 129, 132, 135, 142], "add_to_class": [1, 7, 18, 36, 37, 39, 43, 51, 56, 59, 62, 65, 66, 70, 71, 72, 73, 79, 81, 123, 125, 127, 128, 129, 132, 135, 136, 137], "save": [1, 3, 4, 7, 8, 9, 10, 12, 13, 16, 18, 19, 20, 22, 23, 25, 26, 29, 31, 32, 34, 39, 41, 43, 49, 51, 52, 54, 55, 56, 59, 62, 65, 70, 71, 72, 73, 76, 77, 79, 85, 86, 87, 90, 91, 92, 95, 97, 105, 108, 110, 113, 115, 116, 123, 124, 125, 127, 128, 129, 132, 133, 134, 135, 137], "def": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 47, 49, 51, 52, 54, 55, 56, 59, 60, 62, 64, 65, 66, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 114, 115, 121, 123, 124, 125, 127, 128, 129, 132, 134, 135, 136, 137, 140, 141], "save_hyperparamet": [1, 11, 18, 34, 35, 36, 37, 39, 43, 51, 56, 62, 65, 66, 70, 71, 72, 73, 74, 76, 79, 81, 123, 125, 127, 128, 129, 132, 134, 135, 136], "self": [1, 3, 4, 5, 6, 7, 10, 11, 12, 15, 17, 18, 20, 24, 26, 28, 31, 32, 34, 35, 36, 37, 39, 41, 43, 51, 52, 56, 59, 62, 65, 66, 70, 71, 72, 73, 74, 76, 79, 81, 85, 86, 88, 90, 91, 92, 94, 95, 97, 107, 108, 113, 123, 124, 125, 127, 128, 129, 132, 134, 135, 136, 137, 138, 142], "ignor": [1, 16, 22, 33, 35, 41, 42, 46, 61, 69, 71, 72, 105, 118, 125, 129, 130, 132, 137], "argument": [1, 2, 3, 7, 12, 15, 18, 19, 20, 23, 25, 30, 32, 34, 35, 37, 39, 41, 46, 51, 54, 64, 65, 66, 71, 72, 73, 75, 76, 80, 85, 86, 91, 96, 97, 100, 105, 107, 115, 121, 124, 128, 132, 135, 136, 137], "attribut": [1, 5, 23, 54, 58, 72, 79, 117, 118, 119, 121, 131], "frame": [1, 30, 52, 58, 61], "currentfram": 1, "f_back": 1, "_": [1, 4, 8, 10, 11, 19, 23, 28, 29, 31, 32, 35, 39, 46, 47, 52, 56, 61, 66, 69, 75, 82, 86, 89, 92, 93, 96, 97, 98, 100, 101, 102, 103, 104, 108, 109, 111, 112, 115, 117, 118, 121, 122, 123, 125, 127, 128, 129, 130, 133, 135, 136, 139, 140, 141], "local_var": 1, "getargvalu": 1, "hparam": [1, 76], "k": [1, 2, 3, 4, 7, 8, 9, 10, 19, 25, 33, 40, 41, 46, 47, 48, 49, 54, 55, 56, 58, 60, 61, 64, 67, 69, 71, 74, 77, 78, 86, 88, 89, 93, 95, 96, 97, 99, 102, 105, 110, 117, 119, 121, 122, 129, 130, 136, 140, 141], "v": [1, 2, 3, 7, 8, 25, 41, 46, 47, 58, 59, 67, 82, 86, 89, 90, 91, 93, 96, 98, 99, 102, 103, 104, 107, 108, 109, 110, 113, 116, 117, 119, 121, 122, 130, 133, 140, 141], "item": [1, 7, 9, 19, 21, 23, 25, 40, 41, 51, 56, 58, 62, 64, 72, 74, 89, 96, 99, 112, 119, 135, 137, 140, 141], "set": [1, 2, 3, 6, 7, 8, 9, 11, 15, 16, 17, 18, 19, 21, 22, 23, 24, 27, 28, 29, 31, 34, 36, 39, 40, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 71, 73, 74, 76, 77, 79, 80, 82, 83, 85, 86, 87, 89, 90, 91, 92, 93, 97, 98, 99, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 132, 133, 135, 136, 137, 139, 140, 141], "startswith": 1, "setattr": [1, 32, 72], "progress": [1, 13, 34, 37, 38, 39, 43, 46, 58, 60, 67, 70, 72, 102, 105, 107, 108, 109, 110, 111, 112, 113, 135], "bar": [1, 47, 48, 60, 65, 98, 102, 112, 136], "progressboard": [1, 51, 72], "draw": [1, 2, 4, 19, 20, 31, 46, 48, 49, 51, 58, 64, 69, 71, 72, 75, 76, 82, 97, 102, 104, 112, 121, 125, 130, 132], "x": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 52, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 85, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 114, 115, 117, 119, 120, 121, 123, 124, 125, 127, 129, 130, 131, 132, 133, 135, 136, 137], "y": [1, 2, 6, 7, 9, 10, 12, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 44, 45, 47, 48, 49, 52, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 79, 80, 82, 85, 86, 87, 88, 96, 98, 100, 104, 107, 108, 110, 112, 114, 115, 117, 119, 120, 121, 122, 129, 132, 135, 136, 137, 140], "label": [1, 2, 6, 11, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 37, 39, 47, 49, 59, 61, 62, 64, 66, 67, 69, 72, 73, 74, 75, 77, 79, 80, 83, 85, 86, 87, 90, 91, 94, 97, 98, 99, 104, 109, 111, 112, 115, 120, 121, 126, 128, 129, 132, 133, 136], "every_n": [1, 51, 72], "1": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141], "point": [1, 5, 12, 15, 17, 18, 19, 23, 25, 28, 29, 34, 35, 36, 37, 38, 39, 43, 47, 48, 49, 52, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 67, 69, 72, 76, 77, 79, 80, 104, 106, 107, 108, 109, 113, 114, 115, 117, 119, 120, 121, 126, 127, 131, 138], "namedtupl": 1, "hasattr": [1, 23, 72, 115, 137], "raw_point": 1, "ordereddict": 1, "data": [1, 4, 5, 6, 8, 10, 11, 12, 15, 17, 18, 22, 23, 24, 25, 26, 28, 29, 30, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 80, 81, 84, 85, 88, 89, 91, 94, 97, 98, 99, 102, 103, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 121, 123, 124, 125, 127, 128, 129, 131, 132, 133, 134, 135, 136, 140, 142], "line": [1, 6, 18, 25, 28, 32, 34, 39, 41, 47, 48, 49, 51, 57, 58, 61, 65, 66, 69, 70, 72, 76, 77, 80, 81, 85, 87, 91, 95, 97, 102, 104, 115, 117, 120, 121, 128, 137], "append": [1, 4, 10, 11, 15, 19, 25, 26, 28, 29, 30, 31, 32, 36, 39, 51, 52, 56, 69, 79, 82, 85, 86, 87, 88, 90, 91, 95, 96, 97, 105, 108, 125, 127, 128, 129, 135, 136], "len": [1, 4, 8, 10, 19, 22, 23, 25, 28, 29, 31, 32, 35, 36, 49, 56, 62, 66, 72, 73, 79, 85, 86, 87, 88, 90, 91, 92, 95, 96, 97, 99, 108, 115, 117, 123, 125, 127, 128, 129, 132, 134, 135, 137], "return": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 56, 58, 59, 62, 65, 66, 69, 70, 71, 72, 73, 74, 76, 79, 81, 83, 85, 86, 87, 88, 90, 91, 92, 95, 96, 97, 99, 101, 102, 103, 105, 107, 108, 109, 110, 111, 112, 114, 115, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 132, 134, 135, 136, 137, 138, 140, 141], "mean": [1, 2, 3, 5, 8, 10, 12, 14, 19, 21, 22, 25, 26, 28, 31, 32, 34, 35, 36, 37, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71, 73, 74, 76, 77, 79, 80, 82, 83, 90, 92, 98, 100, 102, 104, 105, 107, 108, 109, 112, 115, 117, 119, 120, 121, 127, 130, 132, 135, 137, 140, 141], "lambda": [1, 2, 4, 19, 25, 29, 34, 35, 36, 37, 39, 43, 56, 64, 65, 69, 71, 74, 75, 76, 79, 81, 91, 102, 104, 107, 108, 109, 110, 112, 114, 125, 127, 128, 129, 135, 137], "sum": [1, 2, 3, 4, 5, 8, 9, 10, 11, 15, 18, 23, 25, 26, 28, 32, 33, 40, 41, 45, 46, 47, 48, 49, 58, 59, 60, 64, 66, 67, 69, 71, 74, 79, 80, 86, 88, 89, 90, 92, 93, 95, 96, 97, 99, 100, 104, 108, 111, 112, 114, 115, 116, 119, 121, 128, 129, 130, 135, 141], "p": [1, 2, 4, 8, 9, 10, 11, 19, 25, 31, 32, 34, 35, 44, 45, 47, 49, 58, 59, 60, 61, 64, 67, 69, 74, 76, 89, 93, 96, 97, 98, 100, 101, 102, 103, 104, 108, 109, 110, 111, 112, 117, 121, 122, 129, 130, 132, 133, 135, 136, 139, 140, 141], "clear": [1, 2, 4, 14, 35, 37, 44, 47, 58, 74, 76, 80, 103, 113, 117, 121, 135], "use_svg_displai": [1, 2, 8, 62, 104, 115], "fig": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 15, 18, 19, 20, 21, 22, 25, 26, 28, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 43, 44, 45, 46, 54, 55, 56, 58, 60, 64, 67, 69, 70, 72, 75, 76, 77, 79, 80, 83, 84, 86, 88, 89, 90, 94, 98, 104, 113, 115, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 139], "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142], "none": [1, 3, 4, 7, 8, 10, 11, 19, 23, 25, 26, 28, 29, 32, 39, 51, 52, 56, 62, 65, 71, 72, 73, 74, 79, 85, 90, 91, 92, 99, 105, 107, 108, 115, 118, 123, 125, 127, 128, 134, 135, 136, 137], "plt": [1, 2, 8, 19, 20, 21, 23, 27, 28, 32, 47, 49, 54, 55, 56, 87, 104, 105, 108, 109, 110, 111, 113, 115, 121, 128], "figur": [1, 6, 30, 39, 41, 46, 48, 49, 55, 58, 61, 69, 72, 110, 112, 113, 115, 137], "figsiz": [1, 2, 8, 9, 10, 28, 69, 72, 80, 82, 104, 115, 136], "plt_line": 1, "l": [1, 3, 19, 23, 25, 26, 28, 32, 39, 46, 47, 49, 52, 58, 59, 60, 64, 67, 69, 70, 71, 72, 74, 75, 80, 82, 89, 92, 93, 96, 97, 99, 102, 104, 107, 112, 122, 123, 128, 129, 130, 135, 137], "color": [1, 19, 20, 21, 22, 25, 26, 28, 29, 31, 34, 40, 42, 47, 49, 54, 55, 58, 62, 72, 105, 117, 121, 141], "zip": [1, 2, 4, 8, 10, 22, 25, 26, 28, 29, 32, 40, 51, 66, 72, 79, 85, 87, 88, 95, 97, 101, 102, 103, 104, 105, 108, 109, 111, 115, 128, 129, 137], "plot": [1, 2, 9, 19, 32, 35, 39, 47, 48, 49, 51, 54, 55, 59, 62, 66, 69, 70, 72, 74, 75, 76, 77, 80, 81, 82, 87, 92, 97, 104, 105, 107, 108, 109, 110, 111, 112, 114, 115, 121, 128, 129, 135, 136, 137], "linestyl": [1, 121], "0": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "ax": [1, 2, 8, 19, 20, 27, 28, 29, 32, 46, 72, 104, 108, 110, 114, 115, 117, 119], "els": [1, 2, 3, 10, 18, 19, 21, 22, 25, 26, 29, 30, 31, 32, 35, 39, 51, 55, 59, 60, 61, 62, 65, 67, 72, 73, 74, 79, 85, 86, 87, 90, 91, 96, 105, 114, 115, 123, 127, 128, 132, 135, 136, 140], "gca": [1, 108, 110, 115, 121], "xlim": [1, 18, 23, 25, 26, 28, 32, 56, 72, 92, 99, 107, 108, 115, 136], "set_xlim": [1, 115], "ylim": [1, 23, 72, 108, 115], "set_ylim": [1, 115], "xlabel": [1, 3, 4, 8, 9, 10, 23, 25, 26, 28, 32, 47, 49, 51, 54, 55, 56, 69, 72, 87, 92, 99, 105, 107, 108, 109, 110, 111, 115, 128, 137], "set_xlabel": [1, 2, 8, 115, 121], "set_ylabel": [1, 8, 115, 121], "ylabel": [1, 3, 4, 8, 9, 10, 28, 47, 49, 51, 54, 55, 56, 69, 72, 87, 92, 99, 105, 108, 110, 115, 128, 137], "set_xscal": [1, 108, 115], "xscale": [1, 72, 115, 137], "set_yscal": [1, 115], "yscale": [1, 72, 74, 79, 115, 137], "legend": [1, 2, 9, 23, 25, 26, 28, 32, 47, 69, 72, 82, 92, 107, 108, 109, 115, 121, 128, 136, 137], "clear_output": 1, "wait": [1, 18, 54, 55], "true": [1, 2, 4, 8, 10, 16, 17, 19, 20, 21, 22, 23, 25, 26, 28, 29, 31, 33, 35, 39, 40, 47, 48, 51, 54, 55, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 77, 79, 85, 86, 87, 89, 90, 91, 92, 97, 99, 100, 104, 108, 113, 114, 115, 117, 119, 120, 121, 128, 130, 135, 136, 137], "add": [1, 6, 10, 11, 18, 19, 22, 23, 25, 26, 28, 32, 34, 35, 36, 37, 39, 40, 41, 44, 46, 47, 51, 56, 58, 64, 65, 69, 71, 73, 74, 75, 76, 80, 81, 88, 89, 92, 93, 95, 96, 99, 104, 107, 108, 109, 112, 121, 124, 132, 133], "frozenlak": [1, 140, 141], "enviro": [1, 141], "frozen_lak": 1, "seed": [1, 51, 118, 140, 141], "see": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 15, 16, 18, 19, 20, 21, 22, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 102, 104, 105, 107, 108, 109, 110, 112, 114, 115, 117, 118, 119, 121, 124, 127, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "http": [1, 22, 25, 26, 57, 79, 85, 91, 95, 132], "www": [1, 25, 26, 79], "gymlibrari": 1, "dev": 1, "environ": [1, 20, 54, 57, 63, 121, 138, 140, 141, 142], "toy_text": 1, "learn": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 90, 94, 96, 98, 101, 103, 104, 106, 108, 109, 111, 114, 115, 116, 117, 119, 120, 121, 123, 126, 127, 131, 133, 134, 135, 137, 139, 141], "more": [1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 16, 18, 19, 22, 23, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 89, 90, 91, 93, 94, 96, 97, 98, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 122, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140], "about": [1, 3, 4, 6, 9, 13, 15, 17, 18, 19, 31, 34, 35, 38, 44, 45, 47, 48, 49, 50, 52, 54, 55, 58, 59, 60, 61, 64, 67, 68, 69, 70, 72, 73, 75, 76, 77, 79, 80, 82, 83, 85, 96, 102, 112, 117, 120, 121, 127, 130, 131, 132, 135, 136, 137], "env": [1, 54, 55, 140], "how": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 93, 94, 95, 96, 97, 98, 99, 101, 102, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "process": [1, 3, 5, 6, 8, 9, 10, 11, 15, 16, 17, 19, 21, 28, 34, 37, 39, 41, 43, 45, 46, 51, 52, 53, 56, 58, 60, 62, 64, 67, 69, 71, 73, 77, 79, 81, 83, 86, 87, 88, 90, 92, 95, 96, 98, 103, 107, 108, 109, 113, 114, 119, 120, 121, 122, 126, 128, 129, 131, 132, 133, 135, 136, 138, 140, 141, 142], "adpat": 1, "site": [1, 54, 55, 58, 60], "googl": [1, 34, 58], "com": [1, 25, 26, 60, 79, 132], "view": [1, 8, 18, 24, 31, 36, 39, 49, 58, 61, 64, 76, 77, 79, 86, 93, 98, 104, 117, 122, 131, 132, 133, 135], "deep": [1, 2, 3, 4, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 30, 32, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 52, 54, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 84, 85, 86, 90, 94, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 119, 120, 126, 131, 132, 134, 135, 136, 137, 138, 140], "rl": [1, 47, 79, 112, 138], "bootcamp": 1, "lab": [1, 43, 58, 131], "gym": [1, 140, 141], "make": [1, 3, 5, 6, 8, 9, 11, 13, 15, 16, 17, 18, 23, 25, 26, 27, 28, 30, 31, 32, 34, 35, 37, 38, 39, 40, 43, 44, 46, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 74, 77, 79, 80, 81, 87, 89, 91, 93, 94, 102, 104, 105, 107, 108, 110, 112, 113, 114, 119, 121, 129, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141], "v1": [1, 83, 91, 109, 140, 141], "is_slipperi": 1, "fals": [1, 2, 3, 7, 8, 10, 11, 20, 21, 22, 23, 25, 26, 29, 31, 33, 39, 41, 59, 61, 62, 72, 79, 85, 86, 87, 90, 91, 92, 119, 120, 121, 128, 129, 135, 140], "action_spac": [1, 140], "np_random": 1, "env_info": [1, 140, 141], "desc": [1, 140, 141], "2d": [1, 3, 9, 35, 41, 105, 109, 137, 140, 141], "arrai": [1, 2, 3, 7, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 40, 41, 43, 44, 45, 47, 58, 62, 65, 66, 70, 71, 72, 73, 76, 79, 81, 82, 85, 86, 87, 88, 90, 91, 92, 95, 97, 99, 104, 105, 106, 107, 108, 114, 117, 118, 119, 120, 121, 128, 129, 132, 133, 135, 136, 140, 141], "specifi": [1, 3, 4, 7, 10, 11, 13, 15, 17, 18, 19, 21, 22, 23, 25, 30, 31, 32, 33, 35, 37, 41, 45, 47, 48, 49, 50, 54, 55, 56, 58, 61, 68, 70, 71, 72, 73, 76, 77, 82, 85, 86, 88, 91, 92, 95, 96, 115, 117, 118, 119, 121, 122, 123, 124, 127, 128, 132, 134, 135, 140], "what": [1, 2, 3, 5, 6, 8, 9, 10, 15, 17, 18, 19, 23, 25, 26, 27, 29, 30, 31, 34, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 53, 55, 58, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 86, 87, 91, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 125, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142], "each": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 15, 16, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99, 101, 102, 105, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "grid": [1, 19, 30, 42, 46, 52, 58, 81, 115, 131, 140, 141], "num_stat": [1, 140, 141], "n": [1, 2, 3, 9, 11, 19, 20, 21, 23, 25, 26, 28, 30, 31, 32, 35, 44, 47, 48, 49, 52, 55, 56, 60, 61, 64, 66, 67, 69, 72, 73, 74, 75, 76, 79, 80, 82, 85, 86, 87, 88, 89, 96, 97, 98, 100, 104, 105, 108, 112, 115, 117, 119, 121, 123, 125, 127, 128, 129, 130, 133, 135, 137, 140], "number": [1, 3, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 140, 141], "observ": [1, 2, 3, 6, 8, 11, 16, 23, 34, 35, 39, 41, 47, 48, 51, 52, 54, 55, 56, 58, 60, 61, 64, 67, 69, 74, 77, 80, 93, 102, 103, 104, 105, 107, 108, 109, 111, 112, 113, 117, 121, 127, 129, 130, 132, 133, 136, 137, 140, 141], "state": [1, 4, 5, 6, 8, 9, 10, 11, 34, 44, 47, 49, 50, 52, 53, 54, 55, 58, 60, 61, 62, 64, 66, 67, 76, 77, 81, 83, 90, 101, 102, 103, 105, 107, 108, 109, 111, 115, 118, 121, 123, 124, 126, 128, 129, 130, 131, 132, 135, 137, 139, 140, 141], "ob": [1, 60], "dim": [1, 99], "num_act": [1, 140, 141], "na": [1, 52, 79, 120], "action": [1, 2, 3, 43, 58, 60, 66, 72, 121, 125, 127, 138, 139, 140], "defin": [1, 2, 5, 7, 8, 12, 14, 15, 16, 18, 19, 20, 23, 24, 27, 29, 31, 33, 35, 36, 37, 41, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 58, 60, 63, 64, 66, 67, 68, 69, 72, 73, 75, 80, 81, 82, 86, 89, 90, 92, 94, 95, 96, 97, 104, 105, 107, 108, 110, 112, 114, 115, 117, 121, 123, 127, 128, 129, 131, 132, 133, 135, 137, 139, 141], "indic": [1, 3, 19, 27, 28, 29, 31, 39, 40, 44, 45, 46, 47, 51, 58, 60, 61, 62, 66, 67, 72, 73, 79, 80, 85, 87, 89, 90, 91, 93, 95, 97, 99, 100, 101, 102, 105, 107, 108, 113, 115, 117, 119, 121, 128, 130, 132, 135, 137, 139, 140, 141], "transit": [1, 38, 58, 139, 140, 141], "probabl": [1, 8, 14, 19, 23, 28, 30, 32, 35, 43, 48, 51, 52, 58, 59, 60, 61, 64, 65, 66, 76, 79, 80, 82, 83, 86, 89, 94, 97, 98, 107, 110, 112, 113, 116, 117, 119, 122, 129, 130, 132, 133, 136, 139, 140, 141, 142], "nextstat": [1, 141], "reward": [1, 58, 60, 70, 121, 139, 140, 141], "done": [1, 3, 17, 43, 49, 51, 52, 56, 60, 71, 79, 80, 119, 140], "trans_prob_idx": [1, 141], "index": [1, 9, 19, 25, 29, 31, 32, 43, 46, 47, 48, 56, 58, 59, 66, 69, 72, 79, 85, 86, 90, 92, 93, 95, 97, 98, 99, 105, 112, 116, 117, 120, 121, 129, 135, 136, 137], "entri": [1, 3, 15, 41, 47, 56, 58, 59, 64, 65, 66, 69, 71, 73, 100, 102, 105, 110, 114, 117, 119, 120, 125, 129, 132, 135], "nextstate_idx": [1, 141], "next": [1, 4, 7, 8, 9, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 35, 36, 41, 42, 43, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 79, 81, 86, 87, 92, 97, 105, 108, 110, 111, 112, 113, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "reward_idx": [1, 141], "2": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 60, 61, 62, 64, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 125, 127, 128, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "done_idx": 1, "3": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 44, 45, 46, 47, 48, 50, 52, 54, 55, 56, 57, 58, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 141], "mdp": [1, 138, 140, 141, 142], "": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 54, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "other": [1, 4, 5, 6, 8, 9, 12, 14, 15, 16, 17, 18, 19, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 64, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 88, 90, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 121, 122, 123, 125, 126, 127, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141], "a0": 1, "a1": 1, "pxrd": [1, 141], "p1": [1, 37, 141], "next1": [1, 141], "r1": [1, 141], "d1": [1, 141], "p2": [1, 37, 141], "next2": [1, 141], "r2": [1, 141], "d2": [1, 141], "e": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 16, 18, 20, 21, 22, 23, 26, 28, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 55, 56, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 73, 74, 76, 77, 79, 80, 81, 82, 83, 86, 87, 88, 90, 93, 96, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141], "g": [1, 3, 4, 5, 6, 7, 8, 11, 16, 18, 19, 20, 22, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 52, 55, 56, 58, 60, 64, 67, 69, 71, 74, 75, 77, 79, 80, 82, 83, 86, 87, 88, 90, 93, 96, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 124, 125, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141], "4": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 14, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 56, 58, 60, 64, 65, 66, 69, 70, 71, 72, 73, 74, 77, 79, 80, 81, 82, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 114, 115, 117, 118, 119, 120, 121, 122, 124, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 140, 141], "creat": [1, 9, 10, 12, 14, 15, 18, 19, 21, 22, 23, 25, 26, 28, 29, 31, 32, 33, 35, 39, 40, 41, 44, 47, 48, 54, 57, 58, 60, 61, 62, 66, 69, 72, 73, 79, 84, 88, 90, 95, 97, 98, 103, 108, 113, 114, 117, 118, 119, 120, 129, 133, 134, 136, 139], "make_env": [1, 140, 141], "name": [1, 2, 3, 4, 6, 8, 13, 14, 16, 17, 21, 22, 23, 24, 25, 26, 31, 33, 34, 35, 36, 39, 41, 43, 45, 46, 51, 52, 54, 55, 57, 58, 60, 62, 64, 72, 77, 81, 82, 90, 97, 98, 101, 106, 110, 111, 112, 113, 115, 118, 119, 120, 121, 133, 139, 140], "input": [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 55, 56, 58, 60, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 91, 92, 94, 95, 96, 97, 99, 105, 108, 110, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 142], "paramet": [1, 3, 4, 5, 6, 7, 8, 13, 15, 18, 21, 22, 23, 26, 28, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 58, 60, 61, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 86, 88, 90, 92, 93, 96, 98, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 115, 116, 119, 121, 123, 129, 130, 131, 132, 133, 135, 140, 142], "For": [1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141], "valu": [1, 2, 3, 4, 5, 7, 9, 10, 11, 14, 15, 16, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 61, 64, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 86, 88, 89, 93, 96, 97, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 135, 136, 137, 138, 139, 140, 142], "iter": [1, 22, 25, 26, 29, 31, 34, 35, 37, 40, 41, 47, 51, 52, 53, 54, 55, 56, 58, 60, 62, 66, 69, 70, 71, 72, 73, 75, 76, 77, 82, 84, 85, 86, 88, 92, 93, 96, 97, 98, 99, 102, 105, 107, 108, 110, 112, 114, 128, 132, 135, 136, 138, 140, 142], "onli": [1, 2, 3, 4, 5, 8, 10, 11, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 55, 56, 58, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 93, 96, 97, 100, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 117, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 133, 135, 136, 137, 139, 140, 141], "support": [1, 6, 18, 23, 30, 34, 35, 43, 46, 47, 48, 55, 58, 59, 62, 70, 72, 73, 79, 87, 92, 113, 119, 127], "rais": [1, 2, 4, 51, 58, 60, 62, 72, 82, 97, 124], "valueerror": 1, "notebook": [1, 47, 48, 49, 50, 54, 57, 58, 72, 118], "show": [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 19, 23, 24, 25, 26, 27, 28, 30, 31, 34, 38, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 58, 59, 60, 62, 64, 66, 69, 70, 72, 76, 77, 80, 85, 86, 88, 90, 94, 95, 99, 101, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 117, 119, 125, 128, 130, 132, 134, 135, 140, 141], "show_value_function_progress": [1, 141], "env_desc": [1, 140, 141], "pi": [1, 5, 47, 49, 69, 104, 105, 107, 110, 115, 140, 141], "visual": [1, 2, 4, 5, 6, 7, 10, 16, 19, 21, 34, 39, 41, 47, 48, 49, 51, 53, 56, 58, 63, 66, 69, 71, 75, 105, 111, 116, 117, 120, 130, 137, 140], "polici": [1, 58, 87, 106, 113, 138, 140], "chang": [1, 3, 5, 8, 10, 11, 15, 16, 19, 21, 22, 26, 28, 30, 32, 33, 34, 35, 36, 37, 39, 41, 43, 45, 47, 48, 49, 54, 57, 58, 60, 64, 66, 69, 70, 72, 73, 74, 75, 76, 77, 81, 83, 84, 85, 90, 93, 97, 101, 102, 105, 107, 108, 109, 112, 113, 114, 115, 117, 119, 121, 122, 127, 130, 135, 136, 137, 139, 141], "over": [1, 2, 4, 8, 9, 12, 13, 16, 17, 18, 24, 27, 28, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 60, 61, 62, 64, 66, 67, 69, 70, 71, 72, 73, 75, 76, 77, 79, 80, 81, 82, 84, 85, 89, 91, 93, 96, 97, 99, 100, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 117, 121, 127, 128, 129, 130, 131, 132, 135, 136, 137, 140, 141], "time": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 83, 84, 86, 87, 89, 90, 91, 93, 96, 97, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142], "num_it": [1, 140, 141], "adapt": [1, 5, 6, 11, 35, 42, 43, 46, 47, 52, 55, 56, 58, 60, 61, 63, 64, 72, 76, 82, 93, 94, 101, 104, 106, 111, 113, 131], "shape": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 49, 58, 59, 62, 65, 66, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 85, 86, 87, 88, 90, 91, 92, 97, 99, 102, 107, 108, 109, 112, 114, 115, 117, 118, 119, 121, 124, 125, 127, 128, 129, 130, 133, 135, 136], "subplot": [1, 2, 8, 104], "15": [1, 19, 21, 27, 30, 45, 54, 55, 61, 66, 70, 76, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 105, 113, 117, 130, 132, 137], "rang": [1, 2, 6, 7, 9, 10, 11, 12, 14, 18, 19, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 61, 62, 64, 65, 66, 67, 69, 72, 73, 79, 80, 82, 83, 84, 85, 87, 88, 90, 91, 96, 97, 99, 102, 105, 107, 108, 109, 110, 113, 115, 117, 119, 121, 123, 127, 129, 130, 132, 135, 136, 140, 141], "imshow": [1, 2, 8, 19, 20, 21, 23, 27, 28, 29, 32], "reshap": [1, 2, 3, 4, 7, 8, 9, 10, 19, 21, 28, 30, 32, 33, 35, 40, 41, 44, 45, 59, 65, 66, 70, 71, 73, 76, 79, 81, 86, 90, 92, 95, 97, 99, 108, 117, 119, 129, 135, 136], "cmap": [1, 2, 8, 9], "bone": [1, 65, 121], "set_xtick": 1, "np": [1, 2, 7, 8, 19, 21, 23, 25, 26, 27, 28, 29, 31, 32, 47, 49, 52, 56, 62, 66, 69, 70, 72, 73, 74, 79, 82, 91, 104, 105, 108, 110, 112, 113, 115, 119, 121, 134, 136, 140, 141], "arang": [1, 2, 3, 9, 10, 17, 19, 21, 30, 32, 33, 45, 56, 69, 72, 76, 80, 82, 85, 90, 91, 104, 105, 107, 109, 110, 111, 114, 115, 117, 119, 135, 136], "5": [1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 14, 15, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 47, 48, 49, 51, 52, 54, 55, 56, 58, 60, 61, 62, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 85, 87, 88, 89, 90, 91, 93, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 115, 117, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 140, 141], "minor": [1, 2, 3], "set_ytick": 1, "which": [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 15, 16, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 93, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141], "w": [1, 11, 14, 15, 19, 20, 21, 26, 27, 28, 29, 30, 32, 33, 35, 40, 41, 44, 45, 46, 49, 62, 64, 66, 69, 70, 71, 73, 74, 75, 80, 82, 88, 89, 95, 96, 97, 98, 99, 102, 104, 108, 109, 112, 117, 119, 120, 123, 125, 127, 130, 133, 137], "linewidth": [1, 20, 47, 49], "tick_param": 1, "bottom": [1, 41, 44, 45, 58, 79, 113, 130], "left": [1, 2, 3, 6, 9, 19, 20, 21, 23, 25, 28, 29, 30, 34, 36, 39, 41, 44, 45, 46, 47, 48, 49, 53, 58, 61, 69, 71, 74, 75, 79, 80, 82, 88, 89, 90, 92, 93, 97, 98, 100, 102, 103, 104, 105, 107, 109, 111, 112, 113, 115, 117, 119, 121, 122, 125, 129, 130, 131, 132, 135, 136, 138, 139, 140, 141], "down": [1, 20, 37, 40, 43, 44, 47, 58, 62, 65, 67, 85, 90, 94, 102, 105, 107, 108, 109, 121, 134, 135, 136, 137, 140, 141], "right": [1, 2, 3, 6, 9, 11, 19, 20, 23, 28, 29, 30, 34, 35, 36, 39, 41, 44, 45, 46, 47, 48, 49, 58, 60, 61, 69, 71, 74, 75, 77, 79, 80, 82, 88, 89, 90, 93, 97, 98, 102, 103, 104, 105, 107, 109, 111, 112, 115, 117, 121, 122, 125, 129, 130, 131, 132, 135, 136, 139, 140, 141], "up": [1, 3, 4, 5, 6, 8, 10, 11, 13, 14, 15, 18, 21, 25, 27, 28, 30, 32, 34, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 51, 52, 54, 56, 57, 58, 60, 61, 64, 66, 67, 69, 70, 71, 74, 76, 77, 79, 80, 82, 86, 87, 89, 90, 93, 96, 102, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 125, 130, 131, 132, 133, 135, 136, 139, 140, 141], "action2dxdi": 1, "25": [1, 19, 28, 41, 47, 48, 49, 54, 55, 56, 58, 61, 80, 82, 109, 110, 117], "dx": [1, 22, 23, 25, 28, 29, 31, 80, 97, 100, 114, 115, 121], "dy": [1, 58, 60, 61, 67, 100, 104, 115], "decod": [1, 5, 9, 43, 64, 87, 88, 90, 122, 126, 128, 131, 142], "h": [1, 3, 4, 7, 11, 19, 20, 21, 27, 28, 30, 32, 33, 35, 40, 41, 44, 45, 46, 49, 52, 60, 62, 64, 71, 75, 76, 80, 81, 82, 86, 93, 96, 100, 104, 105, 109, 115, 119, 121, 123, 125, 127, 129, 130, 133, 134, 135, 137, 140, 141], "text": [1, 2, 4, 6, 8, 9, 10, 11, 12, 19, 28, 31, 42, 46, 54, 55, 56, 58, 60, 62, 66, 77, 84, 85, 86, 87, 88, 89, 90, 93, 94, 97, 98, 110, 113, 114, 120, 122, 123, 128, 130, 131, 132, 133, 135, 136, 142], "str": [1, 2, 19, 25, 26, 31, 85], "ha": [1, 3, 4, 5, 6, 8, 9, 10, 11, 15, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 52, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 72, 73, 76, 77, 79, 80, 82, 83, 85, 87, 88, 89, 90, 92, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 139, 140, 141], "center": [1, 5, 19, 20, 21, 27, 30, 32, 34, 35, 44, 46, 58, 61, 79, 89, 93, 94, 96, 98, 99, 121], "va": [1, 4, 10, 19, 128, 129], "size": [1, 3, 6, 8, 9, 10, 11, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 56, 58, 59, 61, 62, 66, 69, 71, 72, 73, 74, 75, 76, 77, 82, 85, 86, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 104, 105, 108, 109, 111, 112, 114, 115, 117, 119, 121, 122, 127, 128, 129, 130, 132, 133, 135, 137, 140, 141], "20": [1, 3, 15, 17, 25, 30, 32, 33, 34, 47, 49, 51, 54, 55, 58, 61, 70, 74, 76, 79, 88, 90, 97, 99, 102, 105, 107, 109, 111, 117, 123, 125, 127, 128, 134, 135], "fontweight": 1, "bold": [1, 89, 113, 117], "elif": [1, 19, 23, 32, 45, 115], "No": [1, 6, 61, 72, 113, 121], "arrow": [1, 28, 75, 130, 141], "cell": [1, 60, 123, 125, 126, 140, 141], "r": [1, 2, 3, 7, 8, 9, 10, 19, 24, 25, 28, 31, 46, 52, 55, 56, 58, 60, 61, 64, 67, 69, 73, 75, 80, 85, 86, 95, 96, 98, 100, 102, 104, 105, 108, 109, 112, 115, 117, 119, 123, 125, 127, 130, 133, 136, 139, 140, 141, 142], "head_width": 1, "head_length": 1, "set_titl": [1, 8], "step": [1, 4, 5, 6, 9, 10, 19, 24, 25, 26, 30, 34, 35, 44, 47, 49, 57, 58, 60, 65, 66, 69, 71, 74, 75, 79, 81, 86, 87, 88, 89, 90, 92, 98, 101, 103, 105, 107, 108, 109, 111, 112, 114, 115, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 135, 136, 137, 139, 140], "fontsiz": [1, 19, 47, 49], "tight_layout": 1, "q": [1, 2, 3, 7, 8, 30, 32, 35, 45, 58, 59, 60, 64, 65, 67, 75, 80, 93, 96, 100, 102, 109, 123, 129, 130, 133, 135, 138, 141, 142], "show_q_function_progress": [1, 140], "v_all": 1, "pi_al": 1, "want": [1, 2, 3, 7, 8, 14, 15, 16, 17, 18, 20, 21, 22, 29, 35, 36, 39, 41, 44, 45, 46, 47, 48, 49, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 86, 93, 102, 104, 107, 108, 110, 111, 112, 113, 114, 117, 119, 121, 123, 125, 129, 130, 132, 133, 134, 135, 136, 137, 139], "few": [1, 3, 4, 5, 6, 10, 15, 20, 21, 26, 34, 38, 39, 44, 46, 47, 48, 49, 50, 52, 55, 56, 57, 58, 60, 62, 65, 67, 68, 69, 72, 74, 76, 80, 81, 84, 104, 105, 107, 112, 113, 115, 116, 117, 119, 129, 130, 131, 132, 136, 137, 139, 140], "num_iters_al": 1, "10": [1, 3, 4, 5, 6, 8, 9, 10, 11, 14, 15, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 41, 43, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 61, 62, 65, 66, 69, 70, 72, 74, 76, 79, 80, 81, 82, 83, 84, 87, 88, 90, 91, 92, 94, 96, 97, 98, 99, 101, 102, 103, 105, 107, 108, 109, 110, 111, 112, 113, 115, 117, 119, 121, 122, 123, 124, 125, 127, 128, 129, 131, 132, 137, 141, 142], "vis_indx": 1, "tolist": [1, 4, 10, 91, 108, 128, 129], "zero": [1, 2, 3, 4, 6, 8, 9, 10, 11, 14, 17, 19, 21, 27, 30, 31, 32, 33, 35, 39, 41, 44, 45, 47, 48, 49, 52, 58, 60, 66, 67, 69, 71, 74, 76, 77, 79, 80, 81, 82, 88, 92, 93, 97, 101, 102, 103, 107, 108, 109, 110, 111, 112, 115, 117, 119, 121, 125, 127, 129, 135, 136, 139, 140, 141], "c": [1, 3, 4, 11, 15, 19, 21, 25, 26, 27, 28, 30, 32, 35, 39, 40, 43, 45, 46, 47, 49, 56, 58, 60, 61, 62, 69, 71, 72, 79, 80, 82, 88, 90, 93, 95, 96, 97, 98, 102, 105, 108, 109, 114, 115, 117, 119, 121, 122, 127, 129, 133, 136, 137], "enumer": [1, 8, 10, 15, 19, 23, 25, 26, 31, 32, 36, 39, 46, 58, 69, 79, 91, 95, 99, 107, 122, 128, 137], "trainer": [1, 4, 10, 11, 18, 21, 22, 23, 25, 26, 28, 32, 34, 35, 36, 37, 39, 43, 51, 52, 54, 55, 65, 66, 70, 71, 72, 74, 76, 79, 81, 86, 88, 92, 101, 102, 103, 105, 107, 108, 109, 111, 123, 125, 127, 129, 134, 135, 136], "A": [1, 2, 6, 8, 11, 13, 18, 19, 21, 22, 23, 25, 26, 28, 30, 31, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 57, 61, 62, 63, 64, 65, 67, 69, 72, 76, 77, 80, 82, 83, 85, 86, 87, 90, 98, 100, 102, 103, 104, 105, 107, 108, 110, 112, 115, 116, 117, 119, 120, 122, 126, 127, 129, 131, 132, 133, 135, 136, 137, 139, 140, 141, 142], "bunch": [1, 38], "deprec": 1, "load_arrai": [1, 87, 108], "data_arrai": 1, "batch_siz": [1, 3, 4, 7, 9, 10, 11, 19, 21, 22, 23, 25, 26, 29, 31, 32, 34, 35, 36, 37, 39, 43, 51, 52, 54, 55, 56, 62, 65, 66, 72, 73, 74, 76, 79, 81, 85, 86, 87, 88, 90, 91, 92, 97, 99, 101, 102, 103, 107, 108, 109, 111, 123, 125, 127, 128, 129, 132, 134, 135, 136], "is_train": [1, 23, 29, 31, 85, 87, 108], "construct": [1, 8, 10, 12, 13, 15, 16, 19, 21, 22, 28, 32, 33, 34, 36, 40, 41, 44, 45, 46, 49, 50, 51, 58, 64, 65, 70, 71, 79, 80, 85, 88, 89, 98, 103, 105, 109, 114, 117, 118, 119, 121, 123, 129, 133, 136, 137, 139], "dset": [1, 25], "buffer_from_vector": [1, 25, 29, 31], "shuffle_if": [1, 22, 23, 25, 29, 31], "to_stream": [1, 22, 23, 25, 29, 31], "batch": [1, 5, 9, 10, 11, 18, 19, 22, 23, 25, 26, 29, 31, 32, 34, 36, 37, 38, 39, 41, 43, 44, 45, 47, 51, 52, 54, 55, 58, 59, 62, 66, 69, 71, 72, 73, 75, 80, 85, 86, 87, 88, 90, 91, 92, 97, 99, 103, 108, 109, 114, 127, 129, 133, 135, 140, 142], "synthetic_data": 1, "b": [1, 3, 19, 23, 35, 39, 40, 45, 46, 48, 49, 51, 57, 58, 59, 64, 66, 69, 70, 71, 72, 73, 74, 80, 86, 90, 95, 96, 100, 102, 104, 105, 108, 109, 114, 115, 117, 119, 121, 122, 123, 125, 127, 129, 133, 137], "num_exampl": [1, 73, 107], "gener": [1, 3, 4, 5, 6, 8, 10, 11, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 37, 38, 39, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 60, 62, 63, 64, 66, 68, 69, 70, 71, 72, 74, 76, 78, 79, 80, 83, 84, 89, 90, 92, 93, 94, 97, 98, 100, 102, 104, 107, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142], "xw": [1, 71], "nois": [1, 6, 28, 35, 43, 45, 47, 48, 52, 58, 64, 66, 69, 73, 74, 76, 77, 89, 90, 97, 99, 102, 108, 109, 110, 112, 136], "random": [1, 2, 3, 6, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 31, 33, 36, 39, 40, 41, 43, 44, 45, 47, 49, 50, 51, 53, 55, 56, 58, 60, 61, 64, 66, 67, 69, 71, 72, 73, 74, 76, 79, 81, 82, 85, 90, 91, 97, 100, 104, 107, 108, 110, 112, 113, 114, 116, 117, 118, 119, 125, 127, 132, 133, 134, 135, 136, 137, 140, 141, 142], "normal": [1, 2, 3, 5, 6, 8, 11, 12, 14, 17, 21, 22, 23, 25, 26, 28, 31, 33, 36, 37, 38, 39, 40, 43, 48, 49, 58, 61, 64, 66, 68, 70, 71, 72, 73, 74, 76, 79, 80, 81, 82, 86, 90, 93, 99, 103, 104, 108, 111, 112, 114, 117, 118, 119, 121, 125, 127, 129, 133, 135, 136, 142], "loc": [1, 3, 40, 66, 71, 79, 82, 108, 112], "scale": [1, 2, 4, 5, 7, 9, 10, 11, 18, 19, 21, 22, 23, 25, 26, 27, 29, 30, 34, 35, 37, 38, 39, 40, 47, 48, 49, 50, 52, 54, 58, 61, 62, 64, 66, 67, 71, 74, 79, 82, 83, 87, 102, 103, 105, 108, 111, 112, 114, 115, 117, 121, 123, 132, 142], "matmul": [1, 3, 12, 28, 33, 40, 66, 71, 73, 74, 81, 82, 86, 95, 108, 117, 125, 127, 133, 135], "01": [1, 14, 19, 26, 32, 34, 36, 37, 39, 47, 61, 66, 69, 70, 71, 73, 74, 79, 81, 92, 103, 104, 105, 107, 108, 109, 110, 111, 121, 123, 125, 127, 135, 136], "sgd": [1, 21, 22, 25, 26, 32, 52, 59, 69, 70, 71, 74, 102, 106, 107, 108, 109, 112], "param": [1, 14, 16, 17, 22, 23, 69, 71, 101, 102, 103, 108, 109, 111], "grad": [1, 16, 23, 28, 32, 41, 71, 72, 80, 82, 92, 99, 101, 102, 103, 107, 108, 109, 111, 113, 114, 135], "lr": [1, 4, 10, 11, 21, 22, 23, 25, 26, 28, 34, 35, 36, 37, 39, 41, 43, 51, 52, 54, 55, 59, 65, 66, 70, 71, 74, 76, 79, 81, 86, 88, 99, 102, 107, 108, 109, 111, 112, 123, 125, 127, 129, 134, 135, 136], "minibatch": [1, 3, 4, 6, 10, 18, 23, 29, 31, 32, 35, 43, 58, 59, 60, 63, 64, 66, 70, 71, 73, 74, 75, 80, 82, 85, 86, 87, 91, 92, 93, 94, 99, 102, 103, 106, 107, 109, 110, 123, 125, 128, 129, 132, 133, 135, 142], "stochast": [1, 2, 34, 43, 45, 47, 52, 58, 59, 71, 74, 75, 77, 82, 93, 98, 102, 103, 104, 105, 106, 107, 109, 110, 113, 133, 135, 138, 142], "gradient": [1, 2, 3, 6, 8, 15, 16, 26, 34, 41, 43, 52, 58, 59, 63, 64, 70, 71, 74, 75, 76, 77, 78, 80, 81, 89, 93, 98, 100, 101, 102, 103, 104, 106, 107, 109, 111, 113, 116, 126, 127, 131, 133, 140, 142], "descent": [1, 2, 34, 43, 52, 58, 59, 71, 74, 75, 77, 82, 93, 98, 102, 103, 104, 106, 109, 110, 113, 133, 135, 140, 142], "load_data_fashion_mnist": [1, 107], "resiz": [1, 11, 22, 25, 26, 28, 30, 32, 34, 36, 37, 39, 62], "download": [1, 18, 22, 24, 28, 31, 62, 72, 78, 85, 86, 87, 91, 95, 97, 108, 113, 126, 132, 137], "fashion": [1, 11, 22, 23, 29, 34, 35, 37, 39, 43, 52, 60, 62, 65, 66, 76, 77, 80, 81, 90, 93, 102, 107, 111, 114, 131, 136], "mnist": [1, 11, 22, 23, 29, 34, 35, 37, 39, 43, 52, 58, 62, 65, 66, 76, 81, 102, 107, 111, 131], "dataset": [1, 6, 10, 11, 13, 19, 23, 24, 28, 30, 34, 35, 37, 39, 43, 46, 47, 48, 49, 52, 56, 58, 60, 61, 63, 64, 66, 68, 69, 70, 71, 72, 74, 76, 77, 78, 81, 83, 84, 92, 94, 95, 96, 99, 105, 106, 110, 112, 113, 116, 117, 121, 123, 125, 126, 127, 129, 131, 132, 134, 135, 136, 140, 142], "load": [1, 12, 13, 19, 20, 22, 25, 28, 29, 30, 31, 45, 63, 70, 72, 73, 86, 87, 91, 92, 94, 117, 120, 126, 127, 129, 134, 135, 137], "memori": [1, 3, 10, 17, 18, 26, 31, 34, 36, 37, 39, 40, 41, 44, 52, 58, 60, 62, 65, 67, 69, 73, 75, 81, 97, 102, 108, 114, 116, 117, 120, 125, 126, 130, 133, 137, 142], "mnist_train": 1, "load_fashion_mnist": 1, "root": [1, 10, 23, 25, 47, 54, 55, 62, 72, 74, 79, 89, 112, 115, 117, 121, 128, 137, 142], "train": [1, 2, 5, 6, 7, 8, 12, 15, 16, 17, 22, 24, 29, 30, 31, 38, 41, 42, 46, 47, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 68, 69, 73, 77, 78, 79, 80, 82, 83, 84, 85, 87, 90, 91, 92, 93, 94, 95, 96, 102, 103, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 120, 121, 122, 123, 126, 128, 130, 131, 132, 133, 137, 138, 142], "mnist_test": 1, "is_resize_en": 1, "mnist_train_it": 1, "shuffl": [1, 25, 26, 31, 62, 72, 73, 85, 91, 97], "image_resize_if": 1, "imag": [1, 2, 5, 6, 8, 9, 11, 12, 19, 20, 21, 22, 24, 27, 29, 30, 32, 33, 34, 35, 37, 40, 42, 43, 44, 45, 46, 47, 49, 58, 60, 61, 63, 64, 65, 66, 67, 73, 76, 77, 80, 81, 86, 88, 108, 113, 115, 117, 120, 131, 136, 142], "key_transform": [1, 29], "astyp": [1, 2, 3, 19, 21, 23, 25, 28, 29, 31, 32, 59, 66, 76, 79, 121, 128, 129, 135], "float32": [1, 2, 3, 9, 10, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 35, 40, 41, 44, 45, 59, 62, 66, 70, 71, 73, 76, 79, 82, 86, 88, 91, 92, 99, 105, 108, 114, 117, 118, 119, 120, 121, 129, 133, 135, 136], "255": [1, 21, 23, 25, 28, 29, 31, 65], "int64": [1, 4, 10, 62, 129, 135], "rename_kei": [1, 22], "mnist_test_it": 1, "evaluate_accuracy_gpu": [1, 23, 25, 107], "net": [1, 12, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 28, 32, 34, 35, 36, 37, 39, 43, 65, 70, 72, 76, 81, 86, 88, 92, 99, 107, 108, 130], "data_it": [1, 23, 25, 26, 29, 31, 71, 91, 97, 99, 101, 102, 103, 108, 109, 111], "comput": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74, 76, 77, 78, 80, 81, 82, 83, 86, 88, 89, 90, 92, 93, 94, 96, 97, 98, 99, 102, 103, 104, 105, 107, 108, 109, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 141, 142], "accuraci": [1, 6, 11, 19, 21, 22, 23, 25, 30, 32, 34, 35, 37, 38, 39, 43, 45, 52, 58, 60, 61, 62, 63, 64, 65, 66, 67, 73, 74, 80, 81, 86, 88, 102, 107, 115, 122, 123, 132, 136], "model": [1, 3, 5, 8, 9, 12, 13, 15, 16, 18, 19, 20, 23, 24, 27, 28, 29, 30, 31, 34, 35, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 60, 61, 62, 63, 68, 73, 75, 77, 78, 82, 83, 84, 85, 87, 89, 92, 94, 95, 97, 101, 102, 103, 104, 106, 107, 108, 110, 112, 113, 114, 115, 117, 120, 121, 122, 123, 124, 126, 128, 129, 130, 131, 137, 138, 139, 142], "gpu": [1, 3, 5, 13, 34, 36, 39, 42, 43, 46, 51, 54, 55, 57, 58, 62, 64, 71, 72, 75, 77, 81, 103, 108, 119, 142], "isinst": [1, 4, 11, 19, 23, 30, 32, 34, 35, 43, 72, 85, 91, 115, 129, 137], "modul": [1, 3, 4, 7, 9, 10, 11, 12, 13, 14, 16, 17, 26, 28, 32, 34, 35, 36, 37, 39, 41, 43, 56, 59, 62, 70, 71, 72, 82, 86, 88, 90, 113, 116, 123, 124, 125, 127, 129, 134, 135, 142], "metric": [1, 23, 25, 26, 32, 47, 52, 54, 55, 56, 77, 92, 99, 107, 121], "accumul": [1, 23, 25, 26, 32, 58, 92, 99, 102, 107, 108, 109, 111, 136], "sampl": [1, 6, 19, 20, 22, 23, 25, 26, 27, 31, 34, 35, 40, 41, 42, 46, 47, 48, 49, 51, 52, 54, 56, 58, 59, 60, 61, 66, 67, 69, 76, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 98, 99, 106, 107, 108, 118, 119, 121, 129, 132, 135, 136, 140, 141], "reset": [1, 23, 25, 26, 32, 56, 85, 86, 88, 99, 107, 108, 126, 127, 140], "train_ch6": [1, 107], "train_it": [1, 21, 22, 23, 25, 26, 29, 31, 32, 85, 86, 87, 88, 91, 92, 107], "test_it": [1, 21, 22, 23, 25, 26, 31, 85, 86, 87, 88, 107], "num_epoch": [1, 21, 22, 23, 25, 26, 28, 32, 86, 88, 99, 107, 108, 109], "chapter": [1, 3, 4, 5, 6, 13, 15, 18, 21, 22, 24, 30, 38, 42, 43, 46, 47, 50, 51, 52, 53, 57, 58, 61, 62, 66, 67, 68, 69, 71, 72, 75, 77, 78, 80, 83, 84, 87, 90, 94, 102, 106, 107, 108, 110, 112, 113, 115, 116, 126, 128, 130, 131, 132, 135, 136, 138, 140], "6": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 30, 32, 33, 34, 35, 37, 39, 40, 41, 43, 44, 45, 46, 47, 51, 52, 54, 55, 58, 61, 66, 67, 72, 74, 76, 77, 79, 80, 81, 82, 88, 90, 91, 92, 96, 97, 99, 102, 103, 107, 108, 109, 110, 111, 113, 114, 115, 117, 119, 121, 122, 128, 129, 132, 136, 137, 141], "get_num_batch": [1, 86, 88, 107, 108], "num_batch": [1, 23, 25, 26, 29, 31, 32, 86, 88, 91, 92, 97, 99, 107, 108], "init_weight": [1, 125, 127], "ndim": [1, 3, 43, 115, 129], "weight_fn": [1, 14, 43, 70, 108, 129], "init": [1, 14, 22, 23, 43, 57, 70, 72, 108, 113, 129], "glorot_uniform": [1, 14, 22, 23, 43, 129], "linear": [1, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 26, 28, 30, 34, 35, 36, 37, 39, 40, 43, 47, 49, 50, 52, 54, 58, 59, 60, 61, 62, 65, 66, 67, 72, 73, 76, 77, 79, 81, 82, 86, 88, 90, 102, 104, 105, 107, 108, 109, 113, 114, 115, 116, 119, 121, 129, 130, 131, 134, 136, 142], "conv2d": [1, 11, 21, 23, 32, 33, 34, 35, 36, 37, 39, 41, 43, 44, 107], "updat": [1, 4, 6, 9, 15, 22, 23, 28, 32, 34, 35, 41, 43, 51, 56, 57, 58, 59, 60, 63, 69, 71, 72, 73, 74, 75, 77, 80, 82, 92, 93, 98, 99, 101, 102, 103, 105, 106, 107, 108, 109, 113, 115, 119, 121, 126, 127, 129, 130, 135, 136, 140, 141], "tree_map": [1, 4, 34, 43, 129, 135], "optim": [1, 2, 3, 5, 6, 15, 21, 22, 23, 25, 26, 28, 32, 34, 35, 38, 39, 40, 41, 46, 47, 59, 60, 64, 65, 68, 69, 72, 74, 75, 77, 79, 80, 81, 82, 86, 88, 92, 99, 101, 102, 103, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 121, 122, 129, 130, 134, 135, 136, 138, 142], "learning_r": [1, 21, 22, 23, 25, 26, 28, 32, 51, 52, 54, 55, 56, 59, 70, 74, 86, 88, 92, 99, 101, 102, 103, 107, 108, 109, 111, 129], "loss": [1, 6, 16, 18, 21, 22, 23, 24, 25, 26, 30, 34, 37, 39, 41, 43, 47, 52, 55, 58, 59, 60, 61, 63, 65, 67, 68, 72, 74, 75, 77, 79, 80, 81, 83, 86, 88, 89, 90, 91, 92, 93, 97, 98, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 121, 126, 130, 132, 133, 135, 136], "cross_entropi": [1, 21, 22, 23, 25, 26, 32, 65, 66, 86, 88, 90, 92, 107], "anim": [1, 23, 25, 26, 28, 32, 34, 41, 58, 60, 72, 92, 99, 107, 108, 109], "epoch": [1, 22, 23, 25, 26, 28, 32, 34, 41, 43, 52, 54, 55, 56, 61, 65, 66, 70, 71, 72, 76, 77, 81, 92, 99, 101, 102, 103, 105, 107, 108, 109, 111, 112, 132, 135, 136], "acc": [1, 21, 22, 23, 25, 26, 59, 86, 88, 107], "test": [1, 4, 6, 7, 15, 17, 21, 22, 23, 24, 29, 31, 32, 35, 43, 47, 52, 57, 58, 60, 62, 63, 66, 67, 70, 73, 76, 77, 79, 81, 83, 85, 86, 87, 88, 95, 97, 104, 107, 108, 113, 118, 121, 122, 129, 131, 137, 138], "timer": [1, 23, 25, 26, 32, 92, 99, 108], "loss_fn": [1, 25, 26, 28, 32, 41, 72, 92, 99, 107, 108, 135], "y_hat": [1, 2, 23, 25, 26, 28, 41, 52, 59, 65, 66, 70, 71, 72, 74, 86, 107, 108, 129, 135], "reduct": [1, 12, 23, 25, 26, 28, 32, 37, 39, 40, 43, 44, 46, 65, 92, 99, 107, 108, 109, 116, 121], "loss_and_grad_fn": [1, 23, 28, 32, 99, 107, 108], "value_and_grad": [1, 23, 28, 32, 41, 72, 92, 99, 107, 108, 135], "eval": [1, 3, 10, 11, 17, 21, 23, 32, 52, 71, 86, 107, 108], "stop": [1, 4, 23, 25, 26, 32, 48, 52, 54, 55, 56, 60, 69, 78, 80, 92, 99, 105, 107, 108, 112, 119, 129, 137], "train_l": 1, "train_acc": [1, 107], "test_acc": [1, 23, 107], "print": [1, 4, 9, 10, 14, 16, 18, 19, 21, 22, 23, 25, 26, 28, 29, 31, 32, 35, 41, 43, 51, 52, 62, 70, 71, 72, 73, 74, 76, 79, 82, 85, 86, 87, 91, 92, 95, 96, 97, 99, 105, 107, 108, 115, 118, 119, 120, 121, 125, 128, 129, 132, 137], "f": [1, 2, 4, 7, 9, 10, 15, 22, 23, 25, 26, 29, 31, 32, 33, 36, 39, 41, 46, 47, 48, 49, 51, 52, 56, 60, 61, 62, 67, 69, 70, 71, 74, 75, 79, 80, 85, 86, 87, 90, 92, 93, 95, 96, 97, 99, 100, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 127, 128, 129, 130, 133, 135, 136, 137, 140, 141], "3f": [1, 4, 10, 23, 25, 26, 41, 92, 95, 99, 107, 108, 129], "1f": [1, 23, 25, 26, 32, 92, 99], "exampl": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 56, 57, 61, 62, 63, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 142], "sec": [1, 21, 22, 23, 25, 26, 32, 55, 62, 69, 86, 88, 92, 99, 101, 102, 103, 108, 109, 111], "evaluate_accuraci": 1, "correct": [1, 20, 21, 58, 59, 63, 64, 66, 69, 73, 103, 109, 117, 130, 135, 138, 141], "predict": [1, 4, 6, 7, 10, 15, 16, 17, 23, 24, 25, 26, 27, 30, 31, 36, 37, 44, 46, 48, 49, 50, 58, 59, 60, 61, 63, 64, 67, 68, 71, 74, 75, 76, 77, 78, 80, 83, 86, 88, 92, 93, 94, 98, 99, 113, 117, 120, 121, 122, 123, 124, 125, 126, 128, 131, 132, 133, 135, 138, 142], "show_imag": [1, 21, 22, 23, 29, 31, 62], "img": [1, 19, 20, 21, 23, 27, 28, 29, 31, 32, 62], "num_row": [1, 8, 23, 62], "num_col": [1, 8, 23, 62], "titl": [1, 8, 10, 58, 60, 62], "flatten": [1, 11, 32, 34, 35, 36, 37, 39, 42, 43, 65, 66, 75, 76, 81, 86, 90, 107, 137], "try": [1, 15, 18, 20, 21, 28, 34, 36, 37, 39, 41, 43, 47, 52, 56, 58, 60, 64, 66, 67, 69, 70, 71, 73, 74, 79, 80, 81, 82, 91, 99, 102, 103, 108, 109, 111, 114, 117, 120, 128, 130, 136, 140, 141], "numpi": [1, 2, 7, 8, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 47, 49, 52, 56, 58, 62, 66, 69, 70, 72, 73, 74, 79, 82, 91, 104, 105, 108, 110, 113, 115, 119, 120, 121, 134, 136, 140, 141], "except": [1, 3, 6, 10, 18, 21, 22, 32, 33, 35, 47, 51, 65, 69, 72, 73, 76, 83, 110, 125, 135, 137], "pass": [1, 5, 11, 15, 32, 34, 39, 43, 51, 52, 54, 56, 60, 63, 65, 66, 69, 71, 73, 75, 76, 92, 97, 103, 108, 112, 114, 117, 123, 127, 130, 131, 132, 135], "get_xaxi": 1, "set_vis": 1, "get_yaxi": 1, "tab": [1, 25, 26, 49, 57, 79, 113, 128], "pytorch": [1, 21, 49, 50, 58, 70, 72, 107, 113, 119], "mxnet": [1, 58, 70, 107, 108, 113, 119], "tensorflow": [1, 34, 58, 70, 113, 119], "linreg": [1, 108], "The": [1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 60, 63, 65, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 89, 90, 92, 94, 95, 100, 104, 105, 106, 107, 108, 110, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 141, 142], "regress": [1, 5, 6, 8, 15, 28, 30, 32, 43, 48, 50, 52, 59, 60, 61, 63, 67, 72, 77, 79, 80, 81, 82, 84, 108, 113, 131, 132, 133, 136, 142], "squared_loss": [1, 108], "squar": [1, 3, 6, 10, 25, 28, 32, 41, 46, 47, 58, 64, 67, 68, 70, 71, 74, 75, 79, 83, 93, 100, 101, 102, 103, 108, 111, 112, 115, 117, 121], "get_fashion_mnist_label": 1, "text_label": [1, 62, 66], "t": [1, 4, 8, 9, 28, 31, 32, 33, 39, 41, 43, 47, 49, 58, 60, 61, 62, 64, 69, 71, 85, 89, 96, 97, 98, 101, 102, 103, 107, 108, 109, 111, 112, 117, 121, 122, 123, 125, 127, 128, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "shirt": [1, 62], "trouser": [1, 62], "pullov": [1, 62], "dress": [1, 62], "coat": [1, 43, 62], "sandal": [1, 62], "sneaker": [1, 60, 62], "bag": [1, 34, 62, 77, 89, 94, 96, 137], "ankl": [1, 62], "boot": [1, 62], "int": [1, 19, 30, 32, 39, 46, 47, 54, 55, 56, 60, 61, 62, 67, 72, 85, 91, 95, 96, 100, 104, 118, 119, 121, 129, 135, 137], "__init__": [1, 3, 4, 7, 9, 10, 11, 12, 15, 17, 18, 26, 28, 31, 32, 34, 35, 36, 37, 39, 41, 43, 51, 56, 62, 65, 66, 70, 71, 72, 73, 74, 76, 79, 81, 85, 86, 88, 90, 91, 95, 97, 107, 108, 123, 124, 125, 127, 128, 129, 132, 134, 135, 136, 137], "fmt": [1, 105, 115], "m": [1, 2, 3, 4, 8, 10, 11, 19, 29, 35, 47, 48, 49, 58, 60, 75, 82, 86, 89, 93, 96, 98, 102, 104, 108, 110, 115, 117, 121, 129, 130, 132, 133, 137], "nrow": [1, 62], "ncol": [1, 28, 62], "increment": [1, 19, 69], "multipl": [1, 6, 7, 9, 10, 15, 16, 18, 20, 21, 22, 24, 27, 28, 30, 34, 35, 36, 37, 39, 41, 42, 43, 46, 51, 52, 54, 55, 61, 64, 65, 67, 69, 70, 72, 73, 75, 78, 79, 80, 81, 86, 88, 91, 93, 95, 98, 99, 107, 108, 109, 112, 115, 116, 119, 120, 123, 125, 126, 127, 128, 129, 130, 133, 140, 142], "captur": [1, 5, 7, 9, 20, 34, 36, 37, 39, 43, 44, 46, 47, 58, 64, 67, 69, 77, 88, 95, 113, 117, 121, 122, 125, 130, 131, 132, 133, 136, 137], "config_ax": 1, "set_ax": [1, 115], "__len__": [1, 31, 72, 73, 85, 91, 95, 115, 137], "cla": [1, 115], "variabl": [1, 3, 4, 8, 10, 14, 15, 17, 18, 19, 25, 26, 27, 28, 32, 35, 36, 40, 47, 48, 49, 52, 58, 61, 64, 66, 67, 69, 72, 74, 75, 76, 77, 79, 93, 96, 97, 99, 100, 101, 102, 103, 104, 105, 109, 111, 112, 115, 116, 117, 119, 120, 122, 123, 124, 127, 129, 130, 132, 133, 136, 138, 140], "arg": [1, 15, 118, 124, 129], "float": [1, 9, 12, 23, 28, 29, 30, 32, 34, 40, 51, 52, 54, 55, 56, 58, 64, 65, 74, 79, 95, 99, 105, 107, 108, 119, 120, 121], "__getitem__": [1, 31, 72, 85, 91, 95, 137], "idx": [1, 15, 31, 32, 79, 85, 91, 95, 97, 128, 132, 137], "argmax": [1, 19, 21, 23, 25, 26, 32, 59, 64, 66, 86, 122, 129, 135, 140, 141], "axi": [1, 3, 4, 6, 7, 10, 19, 20, 21, 23, 25, 26, 27, 30, 32, 35, 36, 37, 40, 41, 59, 61, 66, 69, 77, 86, 88, 92, 95, 99, 102, 108, 115, 117, 119, 121, 123, 133, 134, 135], "cmp": 1, "dtype": [1, 3, 4, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 30, 31, 32, 33, 35, 40, 41, 44, 45, 59, 62, 66, 70, 71, 73, 76, 79, 82, 86, 88, 91, 92, 97, 99, 105, 108, 114, 117, 118, 119, 120, 121, 128, 132, 133, 135, 136], "reduce_sum": 1, "hashlib": [1, 113], "o": [1, 2, 9, 13, 22, 25, 26, 29, 31, 39, 40, 47, 54, 55, 61, 62, 64, 65, 75, 80, 82, 85, 87, 89, 95, 96, 97, 98, 102, 105, 107, 109, 111, 112, 113, 120, 122, 123, 127, 128, 130, 133, 135, 142], "tarfil": [1, 113], "zipfil": [1, 113], "request": [1, 18, 58, 113], "url": [1, 79], "folder": [1, 22, 25, 26, 64, 79], "sha1_hash": [1, 79], "file": [1, 13, 22, 25, 26, 29, 31, 57, 58, 73, 79, 87, 95, 97, 120, 142], "local": [1, 2, 9, 11, 12, 20, 28, 39, 40, 41, 47, 52, 54, 79, 88, 107, 108, 112], "filepath": [1, 79], "back": [1, 13, 17, 18, 21, 31, 34, 35, 39, 46, 54, 58, 60, 61, 62, 64, 69, 80, 104, 105, 114, 115, 121, 135, 136, 137], "compat": [1, 8, 9, 35, 67, 77, 101], "data_hub": [1, 22, 25, 26, 29, 31, 85, 87, 91, 95, 97, 108], "makedir": [1, 25, 120], "exist_ok": [1, 25, 120], "fname": [1, 25, 31, 137], "path": [1, 6, 9, 10, 18, 22, 25, 26, 29, 31, 38, 39, 75, 85, 87, 89, 95, 97, 107, 112, 113, 114, 120, 133], "join": [1, 4, 10, 22, 25, 26, 29, 31, 85, 87, 95, 96, 97, 120, 128, 129, 135, 137], "split": [1, 4, 11, 25, 26, 31, 32, 58, 66, 67, 71, 72, 85, 91, 95, 96, 97, 118, 128, 129, 137], "check": [1, 3, 8, 12, 16, 20, 40, 44, 47, 51, 56, 57, 58, 62, 64, 71, 73, 77, 79, 104, 112, 117, 120, 121, 132, 135, 136], "hit": [1, 45, 52], "cach": [1, 28, 34, 37, 69, 79, 97, 106, 130], "exist": [1, 12, 18, 23, 34, 39, 52, 58, 60, 70, 71, 73, 79, 80, 82, 90, 94, 99, 104, 106, 110, 112, 115, 123, 125], "sha1": 1, "rb": [1, 87], "while": [1, 4, 5, 6, 8, 9, 13, 14, 15, 16, 19, 22, 23, 25, 26, 27, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 85, 86, 90, 91, 92, 96, 97, 98, 100, 102, 104, 105, 107, 108, 109, 110, 111, 113, 114, 115, 117, 119, 120, 121, 122, 127, 129, 130, 131, 132, 135, 136, 137, 138, 140], "read": [1, 13, 17, 18, 24, 27, 34, 40, 52, 54, 58, 60, 63, 64, 68, 78, 82, 83, 84, 94, 106, 116, 119, 121, 126, 131, 132, 136], "1048576": 1, "break": [1, 4, 10, 14, 19, 31, 34, 39, 60, 69, 71, 76, 85, 87, 91, 92, 96, 97, 101, 108, 128, 129, 130, 132, 141], "hexdigest": 1, "stream": [1, 34, 64, 67, 73, 118, 136], "verifi": [1, 12, 17, 20, 79, 89, 95, 104, 114], "wb": 1, "write": [1, 6, 12, 13, 15, 17, 18, 26, 34, 35, 47, 49, 58, 69, 73, 77, 82, 103, 104, 105, 111, 113, 114, 115, 117, 119, 120, 121, 134, 135, 136, 139, 140, 141], "content": [1, 6, 8, 24, 34, 46, 60, 64, 106, 116, 118, 126, 132, 136], "extract": [1, 11, 16, 21, 22, 24, 26, 30, 31, 32, 34, 35, 37, 73, 79, 85, 87, 88, 94, 96, 120, 128, 136], "filenam": [1, 25, 79], "tar": [1, 31, 79, 87], "base_dir": 1, "dirnam": 1, "ext": 1, "splitext": 1, "assert": [1, 35, 40, 72, 76, 100, 135], "gz": [1, 87], "fp": 1, "extractal": 1, "download_extract": [1, 21, 22, 25, 26, 29, 31, 85, 87, 95, 97], "data_dir": [1, 22, 25, 26, 29, 85, 87, 91, 95, 97], "can": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141], "token": [1, 3, 4, 5, 6, 8, 9, 10, 11, 25, 64, 84, 85, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 99, 122, 123, 124, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 142], "word": [1, 4, 5, 30, 34, 35, 39, 43, 46, 48, 58, 60, 61, 64, 66, 75, 76, 82, 83, 85, 86, 87, 89, 90, 91, 94, 96, 102, 104, 105, 108, 109, 113, 117, 121, 127, 128, 131, 133, 135, 136, 137, 141, 142], "charact": [1, 4, 58, 67, 96, 98, 127, 128, 130, 131, 132, 135, 137], "char": [1, 128], "unknown": [1, 25, 26, 58, 61, 77, 85, 95, 96, 97, 117, 121, 128, 137, 138, 140, 141], "evaluate_loss": [1, 26, 108], "evalu": [1, 2, 3, 23, 25, 34, 36, 37, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 65, 66, 67, 69, 71, 72, 73, 74, 77, 79, 84, 85, 90, 92, 100, 105, 106, 108, 112, 114, 115, 117, 119, 122, 126, 130, 131, 132, 135, 136, 138], "given": [1, 2, 3, 5, 6, 7, 8, 9, 14, 19, 21, 27, 28, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 50, 51, 52, 58, 59, 60, 61, 64, 66, 67, 69, 71, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 88, 89, 90, 92, 93, 94, 95, 98, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 130, 132, 133, 134, 135, 136, 139, 140, 141], "grad_clip": 1, "theta": [1, 47, 104, 135], "clip": [1, 6, 28, 29, 34, 104, 123, 126, 127, 130, 131], "clipped_grad": 1, "clip_grad_norm": 1, "max_norm": 1, "norm_squar": 1, "tree_reduc": 1, "total_norm": 1, "sqrt": [1, 3, 10, 19, 32, 35, 47, 49, 61, 69, 79, 82, 95, 97, 99, 101, 102, 103, 111, 112, 117, 121, 135], "1e": [1, 19, 21, 26, 35, 40, 51, 52, 54, 55, 56, 92, 95, 97, 99, 101, 102, 103, 107, 108, 111], "clipper": 1, "where": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 15, 16, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 64, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 139, 140, 141], "attent": [1, 6, 8, 10, 11, 43, 45, 47, 58, 61, 80, 83, 84, 90, 92, 110, 113, 120, 121, 127, 129, 136, 142], "fra": [1, 4, 10, 128, 129], "eng": [1, 4, 10, 128, 129], "data_url": [1, 22, 25, 26, 29, 31, 79, 87, 95, 97, 108, 128, 137], "94646ad1522d915e7b0f9296181140edcf86a4f5": [1, 128], "read_data_nmt": 1, "english": [1, 4, 6, 10, 58, 85, 90, 91, 95, 96, 98, 113, 124, 128, 129, 132], "french": [1, 4, 5, 6, 10, 58, 96, 124, 128, 129], "txt": [1, 31, 85, 95, 97, 128, 132, 137], "encod": [1, 2, 4, 5, 25, 29, 31, 43, 44, 47, 49, 64, 66, 77, 79, 83, 88, 91, 92, 94, 98, 117, 121, 122, 126, 127, 128, 132, 139, 142], "utf": [1, 87, 128], "8": [1, 3, 4, 6, 9, 10, 11, 12, 14, 16, 19, 20, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 48, 51, 52, 54, 55, 56, 58, 62, 64, 69, 76, 80, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 96, 97, 98, 101, 103, 105, 108, 110, 111, 112, 113, 114, 117, 119, 121, 123, 128, 129, 140, 141], "preprocess_nmt": 1, "preprocess": [1, 24, 26, 35, 58, 62, 67, 72, 78, 80, 84, 108, 116, 126, 137, 142], "no_spac": [1, 128], "prev_char": [1, 128], "replac": [1, 2, 3, 4, 6, 10, 11, 26, 28, 30, 32, 33, 35, 39, 41, 43, 45, 56, 58, 70, 72, 74, 76, 79, 80, 87, 88, 90, 91, 93, 96, 97, 102, 103, 108, 109, 112, 115, 119, 120, 123, 125, 126, 127, 128, 129, 130, 135, 140], "non": [1, 4, 8, 24, 25, 30, 32, 33, 34, 35, 39, 47, 49, 58, 60, 67, 77, 89, 90, 93, 97, 99, 109, 112, 116, 121, 128, 136, 139, 141], "space": [1, 3, 4, 8, 9, 21, 30, 32, 38, 39, 40, 41, 43, 47, 48, 50, 51, 54, 55, 56, 58, 64, 67, 74, 80, 82, 83, 84, 85, 91, 96, 97, 102, 104, 117, 121, 122, 128, 139, 140], "convert": [1, 3, 6, 18, 20, 23, 32, 59, 62, 85, 91, 117, 119, 120, 124, 128, 131, 136, 142], "uppercas": [1, 128], "letter": [1, 62, 100, 117, 128], "lowercas": [1, 96, 100, 117, 128], "ones": [1, 3, 4, 7, 9, 10, 11, 18, 19, 27, 35, 39, 40, 41, 51, 55, 56, 61, 62, 68, 69, 74, 76, 80, 85, 97, 99, 102, 104, 110, 111, 117, 118, 119, 121, 122, 128, 132, 135, 136, 139, 140], "u202f": [1, 128], "xa0": [1, 128], "lower": [1, 6, 9, 10, 19, 20, 29, 30, 34, 39, 41, 45, 46, 52, 58, 61, 64, 67, 69, 75, 76, 80, 91, 105, 107, 112, 115, 117, 121, 128, 129, 137], "insert": [1, 10, 35, 56, 81, 90, 91, 92, 96, 108, 128], "between": [1, 2, 3, 4, 5, 6, 8, 9, 10, 18, 19, 20, 22, 23, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 45, 46, 48, 51, 52, 54, 56, 58, 60, 61, 62, 64, 67, 69, 72, 74, 76, 77, 79, 80, 81, 85, 86, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 102, 103, 104, 107, 108, 109, 110, 112, 115, 117, 121, 122, 123, 127, 128, 129, 130, 132, 133, 136, 138, 140], "punctuat": [1, 91, 128, 137], "mark": [1, 6, 30, 37, 41, 79, 83, 90, 113, 115, 118, 128, 129], "tokenize_nmt": 1, "target": [1, 4, 5, 6, 10, 22, 23, 25, 29, 35, 47, 48, 58, 60, 62, 63, 65, 69, 72, 86, 99, 106, 107, 114, 119, 120, 121, 124, 128, 129, 130, 131, 132, 133, 136], "part": [1, 2, 4, 5, 7, 17, 25, 28, 30, 31, 34, 35, 39, 43, 52, 58, 60, 64, 65, 66, 67, 71, 72, 74, 75, 77, 80, 83, 85, 94, 103, 104, 105, 107, 111, 113, 123, 125, 128, 136, 140, 141], "truncate_pad": [1, 85, 87], "num_step": [1, 4, 9, 10, 11, 85, 86, 87, 92, 123, 125, 127, 128, 129, 132, 134, 135], "padding_token": 1, "truncat": [1, 30, 32, 87, 128, 132], "pad": [1, 3, 4, 9, 10, 21, 24, 29, 30, 32, 34, 36, 37, 39, 40, 41, 42, 43, 65, 85, 87, 91, 97, 99, 107, 124, 128, 129, 136, 142], "sequenc": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 18, 36, 42, 46, 52, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 98, 106, 112, 118, 121, 122, 123, 124, 125, 126, 127, 130, 131, 133, 135, 138, 139, 142], "build_array_nmt": 1, "vocab": [1, 85, 86, 87, 88, 91, 92, 97, 99, 123, 125, 127, 128, 132, 134, 135, 137], "transform": [1, 3, 4, 7, 8, 15, 16, 19, 21, 22, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 37, 38, 39, 40, 43, 58, 62, 64, 69, 71, 79, 80, 81, 82, 83, 87, 88, 92, 94, 97, 99, 113, 114, 117, 119, 124, 127, 129, 130, 131, 136, 137, 142], "machin": [1, 4, 5, 6, 8, 10, 11, 13, 18, 30, 34, 35, 43, 46, 47, 48, 49, 50, 52, 53, 54, 57, 61, 62, 63, 64, 67, 69, 71, 72, 73, 74, 77, 79, 83, 84, 85, 86, 87, 94, 103, 104, 111, 113, 114, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 130, 131, 133, 134, 135, 136, 137, 138, 142], "translat": [1, 2, 3, 4, 5, 6, 8, 10, 11, 35, 40, 45, 48, 49, 58, 60, 64, 69, 77, 79, 83, 84, 85, 86, 87, 94, 122, 124, 126, 131, 132, 136, 142], "eo": [1, 4, 6, 10, 122, 128, 129], "valid_len": [1, 3, 7, 9, 10, 11, 90, 91, 92, 128], "int32": [1, 17, 19, 21, 23, 25, 31, 91, 97, 99, 117, 119, 128, 129, 132, 135], "load_data_nmt": 1, "600": [1, 58, 136], "vocabulari": [1, 66, 85, 87, 89, 90, 91, 93, 95, 96, 97, 98, 99, 122, 128, 129, 131, 132, 133, 135, 136], "src_vocab": [1, 4, 10, 128, 129], "min_freq": [1, 85, 87, 91, 97, 128, 137], "reserved_token": [1, 85, 87, 91, 137], "bo": [1, 6, 128, 129], "tgt_vocab": [1, 4, 10, 128, 129], "src_arrai": [1, 128], "src_valid_len": [1, 72, 128, 129], "tgt_arrai": [1, 128], "tgt_valid_len": 1, "create_model": [1, 21, 22, 26, 28], "model_nam": 1, "weight": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 18, 21, 22, 23, 26, 28, 32, 33, 34, 35, 39, 40, 41, 43, 44, 46, 47, 48, 50, 51, 52, 60, 63, 64, 66, 67, 68, 69, 70, 71, 75, 76, 77, 79, 80, 81, 82, 86, 88, 90, 91, 93, 97, 99, 103, 104, 107, 108, 111, 117, 121, 123, 125, 126, 127, 129, 130, 133, 134, 135, 142], "bool": [1, 16, 17, 20, 33, 114, 117, 119], "num_class": [1, 11, 19, 21, 22, 25, 32, 34, 35, 36, 37, 39, 43, 51, 54, 55, 135], "1000": [1, 6, 9, 18, 21, 22, 25, 26, 29, 34, 46, 47, 51, 60, 62, 70, 71, 73, 87, 90, 112, 114, 121, 123, 130, 136, 139], "strict": [1, 41], "verbos": 1, "kwarg": [1, 3, 7, 28, 32, 37, 86, 88, 90], "an": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 141], "mlxim": [1, 21, 22, 26], "resnet": [1, 10, 11, 15, 21, 22, 23, 26, 32, 38, 43, 52, 58, 113, 142], "pretrain": [1, 5, 21, 22, 24, 28, 30, 58, 83, 84, 86, 96, 113, 142], "resnet18": [1, 21, 22, 23, 25, 39], "hf": [1, 26, 127], "custom": [1, 13, 25, 26, 29, 35, 58, 60, 64, 71, 72, 85, 90, 91, 105, 120, 121, 129, 136, 142], "npz": [1, 17], "If": [1, 3, 5, 8, 18, 19, 21, 22, 25, 26, 27, 28, 33, 34, 35, 39, 40, 41, 43, 44, 47, 48, 49, 54, 55, 56, 57, 58, 60, 61, 64, 65, 67, 69, 71, 72, 79, 80, 82, 93, 102, 104, 105, 106, 107, 108, 109, 110, 112, 113, 117, 118, 119, 121, 122, 127, 128, 129, 130, 131, 132, 133, 136, 137, 139, 140, 141], "start": [1, 2, 5, 10, 11, 12, 13, 15, 16, 17, 19, 21, 23, 25, 26, 28, 32, 34, 35, 38, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 61, 64, 66, 69, 70, 72, 75, 77, 79, 83, 84, 85, 91, 92, 96, 105, 107, 108, 110, 111, 112, 113, 114, 116, 117, 118, 121, 127, 129, 130, 132, 135, 139, 140, 141], "default": [1, 5, 12, 14, 15, 18, 19, 39, 43, 44, 45, 51, 52, 53, 58, 59, 60, 64, 66, 70, 79, 80, 107, 112, 114, 117, 118, 125, 131], "error": [1, 11, 32, 37, 38, 39, 41, 43, 47, 48, 51, 52, 53, 54, 55, 56, 58, 61, 62, 64, 68, 69, 70, 71, 74, 75, 77, 78, 80, 90, 92, 93, 105, 107, 108, 110, 113, 114, 120, 121, 133, 136], "some": [1, 2, 3, 4, 5, 6, 8, 12, 13, 15, 16, 17, 18, 19, 21, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 60, 61, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 90, 91, 93, 94, 98, 99, 100, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141], "ar": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "inform": [1, 4, 8, 18, 19, 20, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 42, 44, 45, 46, 48, 58, 60, 61, 63, 69, 73, 79, 80, 83, 85, 86, 93, 95, 96, 105, 117, 121, 123, 125, 126, 127, 128, 129, 131, 132, 133, 136, 137, 141], "dure": [1, 6, 10, 15, 16, 19, 22, 23, 25, 26, 28, 31, 32, 39, 41, 52, 54, 55, 58, 59, 60, 66, 69, 75, 76, 82, 83, 88, 90, 91, 92, 97, 102, 104, 105, 107, 108, 113, 125, 127, 129, 130, 133, 135, 140], "avail": [1, 2, 5, 6, 8, 12, 18, 23, 34, 37, 43, 51, 54, 55, 56, 58, 60, 61, 62, 67, 70, 77, 95, 109, 111, 112, 113, 121, 123, 131, 132, 136, 138], "vgg": [1, 28, 32, 37, 38, 39], "make_lay": 1, "cfg": 1, "vgg19": [1, 28], "weights_path": 1, "download_from_hf": 1, "repo_id": 1, "safetensor": [1, 26, 28], "load_weight": [1, 17], "hf_weights_split": 1, "invalid": 1, "18": [1, 21, 22, 23, 36, 39, 51, 52, 54, 55, 56, 76, 117], "in_channel": [1, 21, 32, 37], "super": [1, 3, 4, 7, 9, 10, 11, 12, 15, 17, 26, 28, 32, 34, 35, 36, 37, 39, 41, 43, 62, 65, 66, 70, 71, 72, 73, 74, 76, 79, 81, 82, 86, 88, 90, 123, 124, 125, 127, 128, 129, 132, 134, 135], "resnet_block": 1, "out_channel": [1, 21, 32], "num_residu": [1, 39], "first_block": [1, 39], "blk": [1, 10, 11, 32, 36, 39, 90], "residu": [1, 5, 11, 35, 36, 37, 38, 62, 127, 142], "use_1x1conv": [1, 39], "stride": [1, 11, 21, 24, 30, 32, 34, 35, 36, 37, 39, 40, 42, 43, 107, 142], "sequenti": [1, 8, 9, 11, 12, 13, 14, 16, 18, 21, 26, 28, 32, 34, 35, 36, 37, 39, 43, 51, 52, 54, 65, 75, 76, 81, 86, 90, 99, 107, 108, 113, 123, 131, 136, 138], "b1": [1, 36, 37, 39, 81], "64": [1, 10, 12, 15, 21, 25, 31, 32, 34, 36, 37, 39, 48, 55, 58, 62, 79, 87, 88, 91, 92, 108, 119, 123, 136], "kernel_s": [1, 11, 21, 32, 33, 34, 35, 36, 37, 39, 41, 43, 44, 88, 107], "7": [1, 2, 3, 4, 5, 6, 9, 10, 11, 19, 21, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 51, 52, 54, 55, 58, 60, 64, 66, 69, 76, 77, 79, 88, 89, 90, 93, 96, 97, 101, 102, 103, 104, 105, 107, 108, 110, 111, 113, 117, 119, 120, 121, 122, 129, 130, 131, 132, 137], "batchnorm": [1, 10, 21, 32, 35, 36, 39], "relu": [1, 5, 10, 11, 12, 14, 15, 16, 17, 21, 26, 32, 34, 36, 37, 39, 43, 45, 52, 76, 81, 82, 86, 88, 90, 107, 110, 135], "maxpool2d": [1, 32, 34, 36, 37, 39, 45, 107], "b2": [1, 37, 81], "b3": [1, 37], "128": [1, 4, 10, 11, 12, 22, 25, 26, 31, 32, 34, 35, 36, 37, 39, 40, 43, 51, 54, 55, 56, 85, 92, 108, 128, 129], "b4": [1, 37], "256": [1, 4, 10, 15, 17, 21, 22, 23, 26, 29, 31, 32, 34, 35, 37, 39, 40, 51, 52, 54, 55, 56, 65, 66, 69, 76, 81, 86, 92, 107, 108, 129, 137, 140], "b5": [1, 37], "512": [1, 11, 21, 22, 37, 39, 91, 92, 97, 99, 108, 128], "layer": [1, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 16, 17, 18, 22, 23, 24, 26, 27, 28, 30, 33, 34, 37, 38, 39, 42, 43, 44, 45, 49, 51, 52, 54, 55, 58, 63, 64, 65, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 81, 82, 83, 86, 88, 90, 92, 108, 110, 113, 117, 123, 125, 126, 127, 129, 130, 131, 133, 134, 135, 142], "avgpool2d": [1, 35, 36, 37, 39, 43], "adaptiveavgpool2d": [1, 21], "__call__": [1, 3, 4, 7, 9, 10, 11, 12, 15, 17, 26, 28, 32, 35, 36, 37, 39, 41, 65, 66, 70, 71, 72, 76, 81, 86, 88, 90, 107, 123, 124, 125, 127, 129, 134, 135], "input_channel": [1, 36, 39], "num_channel": [1, 28, 30, 36, 39, 88], "conv1": [1, 21, 39], "conv2": [1, 21, 39], "conv3": [1, 39], "bn1": [1, 21, 39], "bn2": [1, 21, 39], "appli": [1, 3, 4, 5, 8, 10, 11, 14, 15, 19, 20, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 52, 53, 58, 61, 63, 64, 65, 66, 67, 69, 71, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 88, 90, 94, 96, 102, 104, 105, 107, 108, 111, 113, 114, 115, 116, 117, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 136, 139], "averag": [1, 3, 6, 7, 8, 11, 21, 22, 35, 36, 37, 39, 42, 43, 48, 51, 54, 58, 59, 60, 61, 65, 67, 69, 70, 71, 72, 79, 86, 98, 99, 101, 103, 107, 108, 110, 111, 112, 117, 121, 129, 132, 141], "pool": [1, 3, 4, 5, 7, 8, 9, 10, 21, 22, 23, 30, 32, 33, 34, 36, 37, 39, 42, 43, 54, 83, 84, 142], "signal": [1, 15, 35, 44, 45, 58, 64, 80, 97, 136], "output": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 21, 22, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 58, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 75, 76, 80, 81, 82, 83, 85, 86, 88, 90, 91, 93, 95, 96, 99, 105, 110, 114, 115, 117, 118, 119, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 136, 142], "spatial": [1, 20, 21, 27, 30, 32, 33, 35, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 66, 81, 113, 117], "dimens": [1, 3, 4, 9, 10, 14, 15, 19, 20, 21, 26, 27, 30, 32, 33, 35, 36, 37, 40, 41, 43, 44, 45, 46, 49, 58, 59, 60, 61, 66, 67, 73, 76, 77, 81, 86, 88, 95, 99, 100, 105, 110, 117, 119, 127, 129, 133, 135], "output_s": [1, 30, 32], "standard": [1, 13, 14, 15, 16, 21, 22, 25, 26, 28, 31, 34, 35, 40, 41, 47, 48, 51, 52, 55, 57, 58, 61, 62, 65, 67, 69, 70, 71, 73, 74, 76, 79, 80, 82, 100, 107, 108, 109, 119, 121, 122, 123, 124, 125, 127, 131, 134, 135, 136, 137, 138], "dynam": [1, 4, 5, 12, 58, 65, 102, 106, 107, 113, 114, 131, 136, 138], "calcul": [1, 12, 14, 15, 18, 19, 21, 26, 28, 32, 34, 35, 40, 41, 44, 45, 58, 60, 61, 63, 64, 65, 67, 69, 70, 75, 76, 78, 79, 80, 89, 90, 93, 96, 97, 98, 99, 101, 108, 109, 114, 115, 117, 121, 123, 127, 129, 130, 131, 132, 133, 135, 141], "kernel": [1, 3, 5, 8, 9, 11, 21, 33, 34, 37, 39, 40, 42, 43, 44, 45, 46, 48, 50, 58, 67, 74, 77, 80, 88], "achiev": [1, 4, 6, 13, 21, 25, 26, 30, 33, 34, 36, 37, 39, 42, 43, 45, 46, 49, 58, 60, 61, 62, 64, 67, 77, 86, 102, 107, 108, 113, 121, 125, 130, 134, 139, 141], "It": [1, 2, 4, 5, 8, 16, 18, 19, 20, 21, 22, 23, 24, 28, 30, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 48, 49, 51, 52, 58, 59, 60, 61, 62, 64, 65, 66, 69, 70, 71, 72, 73, 75, 79, 80, 83, 84, 88, 93, 94, 98, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 121, 122, 130, 131, 132, 133, 135, 139, 140, 141], "primarili": [1, 5, 6, 39, 43, 58, 59, 75, 80, 107, 110, 112, 130, 131], "design": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 19, 21, 22, 27, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 52, 54, 58, 60, 62, 64, 65, 68, 69, 71, 73, 76, 79, 81, 82, 83, 84, 85, 86, 88, 90, 93, 96, 98, 103, 104, 105, 106, 107, 114, 117, 120, 121, 123, 124, 126, 127, 129, 132, 134, 135, 136, 137, 139, 142], "downsampl": [1, 21, 33, 40, 43, 44, 45], "form": [1, 2, 8, 15, 25, 29, 35, 38, 39, 43, 46, 47, 48, 49, 52, 58, 60, 63, 67, 69, 71, 76, 80, 83, 85, 88, 93, 95, 96, 97, 102, 103, 104, 105, 107, 109, 113, 114, 117, 119, 121, 124, 126, 127, 130, 132, 135, 136, 137, 138, 139], "singl": [1, 3, 5, 6, 7, 10, 11, 15, 18, 24, 30, 34, 35, 36, 40, 41, 45, 46, 47, 48, 54, 55, 56, 58, 61, 64, 65, 67, 69, 70, 74, 75, 76, 80, 81, 82, 84, 85, 86, 88, 90, 92, 96, 105, 108, 110, 113, 115, 118, 119, 120, 121, 122, 123, 129, 130, 131, 132, 133, 135, 136, 137, 142], "integ": [1, 19, 21, 25, 29, 51, 52, 64, 79, 97, 98, 100, 120], "two": [1, 3, 4, 6, 7, 9, 10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 55, 58, 60, 61, 64, 67, 69, 72, 73, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 96, 97, 98, 99, 101, 102, 104, 105, 107, 108, 109, 110, 113, 117, 118, 119, 120, 121, 122, 124, 125, 126, 128, 129, 132, 133, 135, 136, 137, 141], "output_h": 1, "output_w": 1, "must": [1, 6, 12, 15, 27, 32, 35, 39, 43, 58, 59, 60, 61, 62, 64, 67, 69, 71, 74, 75, 76, 77, 80, 81, 85, 93, 110, 113, 119, 120, 121, 128, 130, 131, 132, 135, 136, 137], "posit": [1, 4, 5, 10, 11, 19, 20, 21, 22, 23, 27, 29, 30, 32, 33, 34, 35, 40, 41, 44, 46, 47, 52, 58, 60, 64, 65, 69, 75, 80, 83, 87, 88, 89, 90, 91, 97, 98, 100, 104, 105, 109, 110, 112, 117, 119, 121, 132, 135, 142], "forward": [1, 5, 11, 12, 13, 16, 21, 27, 28, 30, 32, 33, 34, 36, 39, 40, 41, 45, 51, 52, 54, 62, 65, 66, 70, 71, 72, 76, 78, 81, 82, 90, 92, 107, 114, 115, 123, 124, 125, 127, 130, 135, 136, 139, 142], "tensor": [1, 3, 7, 8, 9, 10, 12, 13, 16, 19, 20, 25, 31, 32, 33, 37, 40, 41, 44, 45, 46, 59, 62, 66, 70, 71, 72, 73, 75, 76, 79, 81, 88, 90, 100, 114, 115, 116, 118, 119, 129, 135], "h_in": 1, "w_in": 1, "typic": [1, 6, 8, 9, 15, 18, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 55, 56, 58, 59, 60, 61, 62, 67, 69, 76, 77, 79, 81, 82, 97, 98, 102, 103, 104, 107, 108, 111, 112, 113, 115, 117, 121, 127, 129, 132, 136, 137, 138, 139, 140], "channel": [1, 9, 11, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 62, 88, 117, 142], "last": [1, 3, 4, 5, 8, 13, 18, 21, 22, 28, 32, 33, 34, 46, 47, 50, 51, 54, 55, 58, 59, 86, 87, 88, 97, 102, 103, 107, 108, 109, 112, 119, 127, 130, 132], "format": [1, 18, 19, 20, 21, 23, 25, 28, 31, 32, 33, 34, 41, 47, 64, 65, 91, 96, 97, 100, 115, 116, 128], "h_out": 1, "w_out": 1, "input_h": 1, "input_w": 1, "handl": [1, 12, 15, 19, 43, 44, 46, 58, 68, 72, 79, 80, 90, 104, 120, 124, 127, 129, 130, 131, 136, 140], "common": [1, 2, 3, 6, 8, 15, 19, 22, 24, 28, 35, 39, 47, 58, 59, 60, 64, 66, 67, 69, 70, 72, 74, 76, 77, 79, 80, 82, 83, 90, 94, 96, 102, 103, 104, 105, 106, 107, 109, 112, 113, 114, 115, 117, 119, 120, 121, 123, 129, 132, 133, 134, 135, 136, 137], "global": [1, 2, 6, 11, 18, 21, 22, 28, 32, 36, 37, 39, 45, 52, 69, 88, 94, 105, 110, 112, 142], "case": [1, 2, 3, 4, 8, 9, 10, 12, 14, 18, 22, 23, 32, 34, 35, 36, 39, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 58, 59, 60, 61, 64, 65, 67, 69, 70, 71, 74, 76, 77, 78, 80, 82, 84, 85, 88, 91, 93, 96, 98, 102, 103, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 125, 127, 128, 129, 131, 132, 133, 135, 136, 139, 140, 141], "effici": [1, 3, 4, 6, 9, 10, 11, 18, 29, 32, 33, 34, 36, 37, 38, 39, 41, 42, 44, 46, 51, 52, 53, 54, 55, 56, 58, 62, 64, 66, 69, 71, 73, 78, 79, 81, 88, 93, 96, 97, 99, 103, 104, 105, 106, 107, 108, 112, 113, 114, 119, 120, 122, 128, 129, 130, 132, 134, 136], "keepdim": [1, 35, 66, 117, 121], "reli": [1, 2, 3, 5, 8, 10, 13, 15, 16, 23, 34, 35, 39, 58, 60, 61, 62, 64, 67, 69, 70, 71, 74, 75, 76, 77, 81, 84, 98, 107, 113, 129, 134, 135], "suit": [1, 34, 63, 64, 113, 120, 132, 138], "smaller": [1, 6, 15, 22, 27, 28, 31, 32, 34, 36, 39, 40, 41, 44, 46, 62, 66, 69, 74, 75, 89, 91, 93, 102, 103, 105, 107, 108, 110, 112, 130, 132, 135, 137], "than": [1, 3, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 22, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 85, 86, 87, 90, 91, 92, 93, 97, 98, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 117, 118, 119, 120, 121, 122, 127, 128, 130, 132, 133, 135, 136, 137], "least": [1, 18, 25, 34, 35, 40, 43, 46, 47, 52, 53, 54, 55, 56, 58, 61, 64, 67, 72, 80, 82, 91, 97, 102, 104, 107, 108, 109, 110, 112, 121, 132, 136], "one": [1, 2, 3, 4, 5, 6, 8, 9, 12, 15, 16, 18, 19, 20, 21, 22, 28, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 117, 119, 120, 121, 122, 123, 124, 125, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141], "requir": [1, 2, 3, 6, 8, 10, 12, 15, 17, 18, 19, 21, 22, 23, 25, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 66, 67, 69, 70, 71, 72, 73, 75, 76, 77, 79, 80, 82, 83, 84, 89, 90, 93, 98, 101, 102, 103, 104, 105, 106, 108, 109, 112, 113, 114, 115, 119, 120, 121, 123, 124, 127, 129, 130, 131, 133, 136, 140, 141], "greater": [1, 15, 19, 22, 28, 34, 40, 41, 43, 44, 47, 48, 58, 61, 64, 67, 69, 76, 77, 80, 82, 97, 98, 112, 113, 121, 122, 129], "equal": [1, 5, 8, 9, 16, 19, 34, 35, 44, 52, 58, 59, 60, 64, 66, 67, 69, 74, 76, 80, 87, 89, 90, 97, 99, 100, 102, 107, 108, 111, 115, 117, 119, 121, 132, 135, 136, 140, 141], "stride_h": [1, 30, 32], "math": [1, 3, 7, 9, 10, 25, 34, 47, 52, 64, 69, 72, 87, 91, 97, 99, 102, 107, 111, 112, 129, 135], "floor": [1, 25], "implicit": [1, 44, 58, 67, 80], "stride_w": [1, 30, 32], "formula": [1, 67, 69, 105, 132], "ensur": [1, 3, 8, 10, 17, 23, 34, 35, 40, 44, 52, 54, 58, 61, 64, 66, 74, 76, 82, 85, 91, 102, 104, 105, 107, 109, 111, 115, 123, 127, 131, 135, 138, 140, 141], "oper": [1, 7, 8, 9, 10, 11, 15, 16, 18, 21, 23, 24, 25, 26, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 58, 59, 60, 64, 66, 67, 69, 70, 74, 75, 76, 80, 82, 83, 86, 88, 89, 96, 98, 102, 108, 113, 115, 116, 117, 123, 125, 127, 129, 130, 133], "produc": [1, 2, 5, 7, 25, 32, 33, 36, 41, 44, 58, 69, 70, 73, 77, 80, 82, 87, 88, 96, 107, 117, 119, 121, 122, 123, 124, 131, 132, 135, 136], "kernel_h": [1, 32], "kernel_w": [1, 32], "valid": [1, 2, 3, 4, 6, 8, 10, 24, 29, 32, 33, 34, 35, 39, 40, 41, 45, 51, 52, 53, 54, 56, 59, 60, 61, 64, 65, 66, 69, 71, 72, 73, 74, 77, 78, 80, 83, 88, 97, 117, 124, 136], "should": [1, 2, 5, 8, 10, 12, 17, 18, 19, 20, 25, 35, 37, 39, 40, 41, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 64, 66, 67, 69, 70, 71, 74, 76, 79, 80, 83, 86, 93, 101, 104, 105, 107, 112, 113, 114, 117, 118, 119, 120, 121, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 139, 140, 141], "etc": [1, 35, 37, 47, 48, 49, 60, 67, 69, 72, 79, 107, 113, 117, 136, 137, 138, 139], "ideal": [1, 2, 28, 42, 46, 51, 58, 64, 67, 86, 91, 111, 113, 122, 132, 140], "caught": 1, "runtimeerror": 1, "pool_lay": 1, "doe": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 16, 21, 22, 23, 26, 28, 31, 34, 35, 37, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 74, 75, 77, 79, 80, 81, 82, 84, 88, 89, 90, 97, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 115, 117, 121, 122, 127, 128, 129, 130, 132, 133, 135, 136, 138, 139, 140, 141], "involv": [1, 6, 46, 47, 48, 49, 51, 58, 60, 75, 76, 80, 89, 98, 110, 112, 114, 117, 121, 130, 132, 137], "explicit": [1, 8, 58, 103, 125, 127], "numref": [1, 135], "sec_softmax_concis": 1, "start_axi": [1, 11, 32, 34, 35, 36, 37, 39, 43, 65, 76, 81, 86, 90, 107], "end_axi": [1, 11, 65, 76, 81], "featur": [1, 2, 3, 4, 9, 10, 15, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 48, 54, 58, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 77, 79, 80, 81, 88, 90, 98, 99, 103, 106, 113, 119, 121, 125, 126, 129, 131, 133, 135, 136, 140], "dropout": [1, 3, 4, 5, 7, 9, 10, 11, 34, 35, 51, 52, 58, 77, 78, 79, 82, 86, 88, 90, 92, 123, 125, 129, 142], "avgpool": [1, 21], "classifi": [1, 11, 21, 24, 30, 32, 33, 34, 35, 36, 37, 39, 43, 46, 58, 60, 61, 62, 63, 65, 66, 67, 76, 80, 81, 83, 85, 90, 121, 124, 135, 136, 137], "4096": [1, 32, 34], "_initialize_weight": 1, "model_config": 1, "huggingfac": [1, 22, 26, 28, 91], "hub": [1, 28], "yet": [1, 6, 8, 12, 34, 35, 37, 43, 46, 51, 52, 55, 56, 57, 58, 60, 61, 67, 71, 72, 76, 77, 80, 90, 95, 101, 102, 107, 111, 113, 127], "hf_hub_download": [1, 113], "repo_typ": 1, "fail": [1, 4, 18, 35, 58, 60, 65, 67, 77, 80, 102, 103, 109, 112, 121, 135, 136], "quit": [1, 3, 4, 8, 19, 35, 36, 38, 39, 41, 46, 48, 52, 55, 59, 62, 64, 65, 72, 79, 80, 101, 102, 105, 107, 108, 109, 110, 114, 121, 122, 127, 130, 132, 135, 136, 137, 139, 141], "llm": 1, "whether": [1, 2, 3, 6, 16, 19, 24, 30, 34, 35, 40, 41, 42, 45, 46, 47, 48, 49, 54, 57, 58, 60, 61, 66, 69, 71, 73, 74, 79, 80, 83, 85, 90, 104, 105, 112, 117, 121, 127, 129, 135, 136, 137, 138], "strictli": [1, 39, 41, 47, 64, 69], "enforc": [1, 6, 104], "kei": [1, 2, 3, 4, 5, 7, 9, 10, 13, 15, 21, 22, 24, 25, 29, 34, 35, 36, 37, 41, 47, 55, 56, 60, 61, 62, 64, 69, 72, 76, 78, 80, 81, 82, 91, 96, 103, 105, 107, 109, 111, 113, 114, 115, 117, 118, 119, 125, 126, 127, 130, 131, 136, 137, 138, 140, 141, 142], "match": [1, 3, 6, 8, 9, 15, 34, 43, 44, 45, 46, 47, 58, 59, 64, 66, 73, 79, 85, 109, 114, 115, 119, 121, 125, 129], "torch_weight": 1, "pretrained_weight": 1, "feat": [1, 58, 113], "new_kei": 1, "transpos": [1, 3, 4, 7, 10, 24, 28, 32, 41, 86, 100, 117, 135, 142], "torch": [1, 18, 19, 49, 58, 62, 73, 74, 79, 90, 113], "like": [1, 6, 11, 12, 15, 18, 24, 27, 28, 32, 34, 35, 39, 45, 46, 47, 48, 49, 51, 52, 58, 60, 64, 65, 66, 67, 69, 70, 71, 73, 74, 77, 79, 80, 82, 84, 88, 91, 93, 102, 107, 109, 110, 112, 113, 117, 119, 120, 121, 122, 124, 125, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "layer_nam": 1, "model_weight": 1, "tree_flatten": [1, 17, 113, 129, 135], "have": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 90, 93, 96, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "extra": [1, 12, 44, 55, 83, 109, 124], "found": [1, 6, 34, 41, 47, 51, 54, 55, 57, 58, 67, 70, 77, 80, 107, 112, 113, 141], "warn": [1, 54, 55], "less": [1, 2, 6, 7, 10, 11, 22, 23, 26, 28, 35, 39, 43, 47, 48, 52, 55, 58, 60, 61, 71, 74, 79, 80, 82, 87, 90, 91, 97, 98, 99, 102, 104, 107, 108, 109, 110, 113, 114, 117, 121, 128, 132, 137, 139, 141], "miss": [1, 29, 48, 79, 117, 120, 132], "keyerror": 1, "continu": [1, 6, 9, 19, 23, 28, 32, 34, 35, 41, 44, 47, 49, 50, 54, 55, 56, 58, 60, 61, 62, 74, 75, 77, 79, 80, 82, 83, 86, 89, 91, 94, 96, 97, 102, 105, 106, 113, 117, 121, 122, 130, 132, 135, 136, 139], "pretrained_w": 1, "same": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 44, 45, 46, 47, 49, 51, 52, 54, 55, 56, 58, 59, 60, 61, 63, 64, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 83, 85, 88, 90, 92, 93, 94, 96, 98, 99, 100, 101, 102, 105, 107, 108, 109, 111, 114, 115, 117, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 139, 140, 141], "expect": [1, 2, 3, 8, 15, 18, 39, 41, 43, 45, 47, 48, 58, 59, 60, 61, 64, 67, 69, 72, 73, 74, 75, 76, 79, 80, 81, 87, 93, 97, 100, 103, 104, 107, 108, 109, 110, 112, 113, 114, 116, 119, 130, 135, 136, 140, 141], "got": [1, 58, 105, 110, 128], "tree_unflatten": [1, 47, 113], "count_corpu": [1, 97], "statist": [1, 2, 4, 35, 41, 44, 46, 47, 51, 53, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 74, 77, 80, 81, 94, 96, 101, 108, 110, 113, 114, 116, 128, 131, 132, 136, 142], "frequenc": [1, 9, 28, 34, 61, 96, 97, 121, 136, 137], "counter": [1, 25, 97, 102, 103, 137], "adaptiveavgpool1d": [1, 88], "sec_util": 1, "1d": [1, 3], "length": [1, 3, 4, 5, 6, 9, 10, 11, 27, 28, 29, 30, 33, 35, 43, 47, 48, 49, 58, 64, 66, 69, 73, 75, 81, 85, 86, 87, 89, 90, 91, 92, 96, 97, 98, 103, 104, 114, 117, 119, 121, 122, 123, 124, 126, 127, 129, 130, 131, 132, 135, 136, 137], "avgpool1d": 1, "determin": [1, 2, 5, 19, 20, 27, 30, 32, 41, 46, 47, 48, 56, 57, 58, 60, 61, 64, 69, 71, 73, 77, 79, 81, 82, 83, 85, 86, 102, 105, 109, 111, 115, 116, 121, 125, 126, 127, 133, 135, 137, 138], "first": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 99, 102, 103, 104, 105, 107, 108, 110, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141], "convent": [1, 35, 38, 44, 47, 58, 60, 62, 65, 74, 80, 100, 110, 115, 121, 122, 131], "But": [1, 18, 46, 47, 58, 60, 61, 65, 67, 70, 74, 77, 79, 80, 102, 117, 129, 131, 134, 135, 136, 137, 140], "ll": [1, 47], "both": [1, 3, 4, 6, 9, 10, 11, 15, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 58, 60, 61, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 92, 93, 94, 96, 98, 102, 103, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 119, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 133, 134, 137, 140, 141], "3d": [1, 3, 110], "assum": [1, 2, 3, 15, 17, 18, 19, 20, 21, 22, 27, 28, 35, 39, 40, 41, 44, 45, 46, 47, 48, 52, 55, 56, 58, 59, 60, 61, 64, 66, 67, 69, 71, 73, 74, 75, 79, 80, 82, 89, 98, 104, 105, 107, 110, 112, 113, 114, 121, 125, 130, 131, 132, 133, 135, 136, 140, 141], "need": [1, 2, 3, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 85, 86, 88, 91, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141], "befor": [1, 4, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 22, 23, 25, 26, 28, 30, 32, 35, 37, 39, 40, 42, 45, 46, 47, 49, 51, 52, 54, 55, 57, 58, 60, 61, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 85, 88, 91, 92, 97, 99, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 119, 120, 121, 123, 127, 128, 129, 130, 132, 133, 134, 136, 138, 140], "after": [1, 2, 3, 4, 6, 7, 10, 11, 16, 17, 19, 20, 22, 23, 25, 26, 31, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 54, 55, 56, 58, 60, 61, 65, 67, 69, 72, 73, 75, 76, 77, 79, 80, 82, 85, 87, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 112, 113, 114, 117, 119, 121, 122, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141], "input_length": 1, "note": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 16, 17, 19, 21, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 86, 88, 90, 91, 92, 93, 96, 97, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 112, 114, 115, 119, 121, 122, 124, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 139, 140, 141], "so": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 16, 17, 18, 19, 22, 25, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 54, 56, 57, 58, 60, 61, 62, 64, 66, 67, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 85, 88, 93, 96, 97, 101, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 128, 129, 130, 132, 133, 135, 136, 137, 139, 140], "x_transpos": 1, "result": [1, 2, 3, 5, 6, 7, 9, 10, 11, 15, 17, 18, 19, 21, 22, 23, 24, 28, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 54, 55, 58, 59, 60, 61, 65, 66, 67, 69, 71, 73, 76, 77, 79, 80, 81, 83, 85, 86, 88, 89, 90, 92, 93, 95, 96, 97, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 117, 119, 121, 122, 125, 127, 129, 130, 131, 132, 133, 135, 136, 137, 139, 140, 141], "now": [2, 3, 4, 5, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 21, 23, 25, 26, 27, 28, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 51, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 67, 69, 70, 71, 72, 74, 75, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 96, 97, 99, 102, 103, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 125, 127, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141], "introduc": [2, 3, 4, 5, 6, 8, 13, 15, 19, 20, 21, 22, 25, 27, 30, 32, 33, 35, 37, 39, 42, 43, 45, 47, 48, 49, 50, 52, 53, 56, 58, 60, 61, 64, 66, 67, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 86, 88, 89, 90, 98, 104, 105, 107, 108, 110, 113, 115, 117, 121, 122, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 139], "primari": [2, 5, 43, 58, 59, 61, 66, 69, 113, 116], "compon": [2, 8, 10, 12, 13, 15, 16, 24, 31, 36, 41, 51, 60, 62, 64, 65, 66, 69, 70, 71, 72, 74, 103, 113, 114, 117, 119, 121, 124, 131, 134, 139, 142], "mechan": [2, 3, 7, 8, 9, 10, 34, 45, 47, 48, 49, 58, 60, 63, 64, 66, 71, 74, 75, 80, 84, 86, 88, 103, 113, 117, 119, 121, 125, 126, 127, 129, 142], "let": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 54, 56, 59, 60, 61, 62, 64, 66, 69, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 85, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 139, 140, 141], "them": [2, 3, 6, 8, 10, 11, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 48, 49, 52, 55, 56, 58, 60, 61, 62, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 79, 80, 81, 82, 86, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 102, 103, 104, 105, 108, 110, 113, 114, 117, 119, 120, 121, 122, 128, 129, 132, 135, 136, 137, 140], "rather": [2, 3, 4, 5, 8, 16, 17, 18, 19, 22, 30, 31, 32, 34, 35, 36, 39, 40, 41, 45, 46, 47, 58, 60, 61, 62, 64, 67, 68, 69, 70, 71, 73, 74, 76, 77, 79, 80, 81, 85, 86, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 114, 117, 118, 120, 121, 127, 130, 132, 133, 135, 136], "classic": [2, 5, 8, 34, 52, 58, 60, 61, 67, 68, 69, 74, 76, 78], "classif": [2, 6, 11, 20, 21, 22, 24, 26, 29, 31, 32, 33, 34, 37, 41, 43, 47, 52, 60, 65, 66, 67, 68, 69, 77, 80, 81, 84, 86, 87, 88, 90, 91, 92, 113, 126, 133, 136, 142], "densiti": [2, 47, 48, 58, 61, 67, 71, 100, 121, 136], "estim": [2, 8, 34, 35, 37, 47, 48, 52, 56, 58, 59, 60, 61, 64, 67, 69, 70, 71, 73, 74, 76, 77, 79, 98, 101, 103, 112, 120, 121, 130, 132, 136, 137, 140, 141], "detour": [2, 36], "simpli": [2, 3, 4, 6, 8, 12, 15, 18, 26, 28, 32, 34, 35, 37, 39, 40, 41, 44, 46, 47, 48, 49, 52, 57, 58, 60, 61, 64, 67, 69, 71, 72, 74, 75, 76, 77, 79, 80, 82, 88, 101, 102, 104, 107, 108, 112, 115, 117, 120, 121, 122, 123, 125, 130, 132, 133, 135, 136, 139], "provid": [2, 5, 7, 8, 10, 12, 14, 15, 17, 21, 23, 25, 26, 30, 31, 32, 34, 35, 37, 39, 40, 42, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 69, 70, 71, 72, 73, 74, 75, 77, 79, 80, 97, 103, 105, 107, 108, 110, 113, 116, 118, 119, 121, 122, 124, 125, 132, 134, 135], "addit": [2, 4, 5, 6, 7, 9, 10, 18, 21, 22, 23, 27, 30, 31, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 49, 52, 54, 55, 56, 58, 60, 62, 65, 67, 69, 72, 73, 74, 76, 80, 82, 83, 90, 93, 102, 103, 107, 108, 109, 110, 112, 117, 118, 119, 121, 123, 124, 132, 135, 136, 141], "background": [2, 5, 19, 25, 29, 30, 31, 32, 34, 58, 113, 131], "entir": [2, 3, 5, 6, 8, 10, 15, 16, 17, 19, 22, 25, 26, 30, 34, 35, 37, 39, 45, 46, 47, 48, 49, 52, 56, 58, 60, 61, 64, 65, 67, 69, 71, 72, 73, 74, 83, 89, 90, 92, 93, 102, 105, 107, 108, 110, 113, 117, 121, 127, 129, 132, 133, 135, 136, 138], "skip": [2, 13, 25, 35, 39, 44, 47, 57, 58, 62, 64, 79, 89, 94, 95, 96, 97, 104, 117, 125, 127, 128], "At": [2, 4, 5, 9, 10, 19, 24, 27, 32, 34, 36, 37, 39, 40, 41, 43, 44, 45, 48, 53, 54, 55, 56, 57, 58, 60, 62, 66, 67, 69, 70, 71, 72, 76, 77, 78, 86, 87, 108, 112, 113, 114, 115, 117, 122, 123, 129, 132, 133, 135, 136, 139, 141], "alpha": [2, 3, 4, 8, 32, 35, 47, 49, 61, 64, 80, 86, 93, 104, 105, 107, 111, 112, 117, 121, 122, 135, 137, 140], "mathbf": [2, 3, 4, 7, 8, 9, 10, 15, 19, 28, 33, 35, 36, 39, 41, 46, 47, 52, 56, 60, 61, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 80, 82, 86, 89, 90, 93, 96, 98, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 114, 115, 117, 119, 121, 122, 123, 125, 127, 129, 130, 131, 132, 133, 135, 136], "relat": [2, 4, 9, 22, 24, 35, 41, 42, 47, 58, 60, 61, 67, 69, 71, 77, 78, 80, 81, 93, 102, 117, 120, 121, 125, 132, 136, 141], "queri": [2, 3, 4, 5, 7, 9, 10, 18, 45, 47, 49, 56, 58, 73, 83, 118, 142], "begin": [2, 4, 6, 7, 9, 10, 14, 15, 18, 20, 24, 32, 33, 37, 38, 39, 41, 46, 47, 48, 49, 52, 56, 58, 60, 61, 64, 66, 67, 69, 70, 71, 74, 76, 80, 81, 82, 85, 86, 89, 90, 91, 94, 96, 97, 98, 101, 102, 103, 104, 105, 107, 109, 111, 112, 115, 117, 119, 121, 122, 125, 127, 128, 129, 130, 132, 133, 134, 135, 136, 140, 141], "align": [2, 4, 6, 9, 14, 30, 45, 46, 47, 58, 60, 61, 64, 69, 74, 76, 80, 81, 82, 86, 89, 98, 101, 102, 103, 104, 108, 109, 111, 112, 115, 121, 122, 125, 127, 130, 132, 135, 136, 140], "exp": [2, 3, 8, 19, 47, 48, 49, 60, 61, 64, 65, 66, 69, 71, 79, 80, 82, 86, 89, 93, 98, 99, 100, 104, 105, 112, 119, 129, 132, 135], "frac": [2, 3, 8, 9, 14, 19, 34, 35, 36, 37, 41, 44, 47, 48, 49, 55, 56, 60, 61, 64, 65, 66, 67, 69, 70, 71, 74, 75, 76, 79, 80, 82, 86, 89, 93, 97, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 111, 112, 114, 115, 117, 121, 122, 129, 130, 132, 135, 137, 140], "textrm": [2, 3, 8, 9, 10, 14, 19, 32, 35, 39, 40, 41, 44, 45, 47, 48, 49, 52, 56, 58, 59, 60, 61, 64, 65, 67, 69, 70, 74, 75, 76, 79, 82, 89, 92, 93, 95, 97, 98, 99, 100, 102, 103, 104, 105, 108, 109, 110, 112, 115, 117, 119, 121, 123, 125, 127, 128, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "gaussian": [2, 3, 11, 14, 43, 52, 58, 66, 69, 74, 76, 80, 82, 90, 117, 119, 121, 125, 127, 142], "leq": [2, 3, 9, 32, 60, 65, 69, 79, 83, 89, 98, 102, 104, 105, 110, 112, 117, 121, 130, 135], "boxcar": 2, "mathop": [2, 8, 39, 60, 103, 104, 107], "mathrm": [2, 3, 39, 52, 55, 56, 60, 64, 66, 80, 104, 107, 133, 140, 141], "max": [2, 19, 21, 25, 28, 30, 32, 34, 36, 37, 39, 43, 45, 54, 55, 56, 64, 80, 84, 90, 91, 96, 97, 104, 105, 107, 140, 141], "epanechikov": 2, "end": [2, 3, 4, 6, 7, 9, 10, 13, 14, 24, 26, 27, 29, 30, 32, 33, 34, 36, 40, 45, 46, 47, 48, 53, 54, 55, 58, 59, 60, 64, 67, 69, 70, 71, 74, 76, 77, 78, 80, 82, 83, 84, 85, 89, 91, 96, 98, 101, 102, 103, 104, 105, 107, 109, 111, 112, 113, 115, 117, 118, 119, 121, 122, 123, 125, 127, 128, 129, 130, 132, 136, 140, 141], "There": [2, 3, 8, 16, 18, 19, 29, 31, 32, 34, 39, 44, 46, 47, 50, 52, 58, 64, 69, 72, 74, 80, 82, 86, 97, 104, 107, 108, 109, 110, 112, 115, 117, 119, 121, 123, 131, 132, 133, 136, 138, 140], "mani": [2, 4, 5, 6, 8, 15, 18, 19, 20, 22, 23, 24, 27, 28, 30, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 56, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 73, 76, 77, 79, 80, 82, 86, 89, 93, 94, 96, 97, 102, 103, 104, 105, 107, 108, 110, 112, 113, 115, 117, 121, 123, 126, 127, 128, 131, 132, 133, 135, 136, 137, 138, 140, 141], "choic": [2, 3, 11, 35, 37, 38, 39, 45, 46, 47, 51, 56, 58, 59, 60, 61, 63, 64, 69, 74, 76, 77, 79, 80, 81, 82, 88, 91, 93, 94, 97, 102, 103, 105, 107, 109, 111, 112, 113, 114, 121, 122, 132, 136, 137, 141], "could": [2, 5, 6, 9, 15, 32, 34, 35, 39, 40, 42, 45, 46, 47, 48, 52, 54, 55, 56, 58, 60, 61, 62, 64, 65, 67, 69, 71, 73, 74, 80, 81, 82, 98, 101, 102, 103, 105, 107, 108, 109, 110, 112, 113, 114, 117, 119, 120, 121, 122, 123, 130, 132, 133, 135, 136, 137, 141], "pick": [2, 3, 5, 8, 44, 45, 46, 51, 61, 64, 66, 67, 69, 79, 82, 93, 103, 104, 105, 107, 108, 109, 112, 120, 122, 123, 132, 133, 135, 137, 140, 141], "wikipedia": [2, 6, 90, 91, 95, 108, 132], "articl": [2, 6, 35, 58, 64, 83, 94, 97, 100, 108, 109, 137], "extens": [2, 6, 25, 36, 39, 44, 49, 51, 74, 94, 105, 117, 129, 132], "review": [2, 3, 6, 8, 34, 35, 39, 46, 58, 65, 69, 70, 74, 81, 87, 94, 99, 103, 105, 107, 109, 114, 117, 121, 131, 136], "sometim": [2, 5, 14, 15, 16, 28, 35, 40, 41, 44, 45, 46, 53, 58, 60, 64, 72, 74, 77, 79, 80, 102, 113, 114, 117, 119, 121, 129, 131, 135, 136], "also": [2, 5, 6, 8, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 64, 65, 67, 69, 71, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 88, 90, 92, 93, 95, 96, 97, 98, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 129, 130, 131, 133, 135, 136, 137, 138, 139, 140, 141], "call": [2, 5, 6, 7, 8, 9, 10, 13, 14, 15, 19, 22, 23, 27, 28, 31, 33, 34, 37, 39, 41, 42, 45, 46, 47, 48, 51, 56, 58, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 86, 93, 96, 98, 99, 102, 103, 104, 105, 108, 109, 113, 114, 115, 117, 118, 119, 120, 121, 126, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141], "parzen": 2, "window": [2, 30, 33, 34, 37, 38, 40, 41, 43, 44, 45, 46, 57, 58, 88, 89, 93, 97, 98, 118, 136], "all": [2, 3, 4, 5, 6, 8, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 88, 89, 92, 93, 94, 96, 98, 99, 100, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 139, 140, 141], "heurist": [2, 8, 34, 41, 58, 67, 74, 76, 77, 79, 82, 107, 120, 126, 135], "tune": [2, 5, 8, 21, 24, 25, 28, 34, 37, 39, 49, 50, 51, 52, 54, 55, 58, 60, 61, 69, 77, 79, 84, 88, 90, 92, 99, 106, 123, 142], "instanc": [2, 3, 4, 8, 10, 11, 12, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 29, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 52, 54, 55, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 90, 93, 94, 95, 96, 97, 102, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 123, 127, 128, 132, 136, 137], "adjust": [2, 3, 12, 19, 21, 22, 23, 28, 35, 36, 37, 39, 40, 43, 45, 52, 58, 60, 66, 71, 74, 79, 81, 101, 102, 103, 104, 105, 107, 111, 112, 116, 125, 127, 129, 132, 135], "width": [2, 11, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 49, 52, 62, 77, 81, 88, 117, 123], "basi": [2, 19, 35, 46, 48, 50, 67, 69, 76, 77, 80, 94, 102, 103, 104, 109, 111, 124, 132, 138], "even": [2, 3, 4, 6, 8, 11, 13, 15, 17, 18, 19, 28, 30, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 67, 69, 71, 72, 74, 75, 77, 79, 80, 81, 82, 91, 96, 97, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 119, 121, 127, 128, 132, 133, 135, 136, 137, 138, 139, 140], "per": [2, 3, 25, 34, 35, 37, 40, 43, 44, 51, 52, 55, 58, 64, 81, 87, 97, 102, 103, 104, 108, 111, 117, 119, 128, 130], "coordin": [2, 19, 20, 21, 27, 28, 29, 30, 38, 46, 64, 69, 80, 101, 102, 103, 105, 108, 109, 111, 112, 117, 121, 131], "regardless": [2, 3, 8, 40, 42, 45, 46, 49, 59, 61, 90], "lead": [2, 3, 6, 8, 11, 12, 19, 22, 26, 28, 30, 35, 36, 39, 40, 41, 46, 47, 49, 52, 53, 54, 55, 58, 60, 64, 65, 67, 69, 70, 71, 74, 75, 77, 79, 80, 86, 93, 96, 97, 102, 103, 104, 105, 107, 109, 112, 114, 117, 121, 125, 127, 130, 132, 134, 135, 136], "follow": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 84, 85, 86, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 112, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141], "equat": [2, 48, 49, 50, 58, 64, 73, 74, 75, 80, 103, 105, 107, 109, 111, 113, 117, 121, 125, 127, 129, 136], "alik": [2, 46], "sum_i": [2, 8, 64, 66, 69, 74, 104, 109], "_i": [2, 3, 7, 8, 9, 28, 60, 64, 66, 77, 79, 86, 93, 98, 100, 102, 104, 109, 112, 121, 130, 131], "sum_j": [2, 8, 64], "_j": [2, 3, 8, 28, 64, 65, 86, 93, 98, 117, 121], "In": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141], "scalar": [2, 7, 8, 15, 32, 35, 41, 64, 66, 71, 73, 75, 83, 88, 93, 100, 105, 108, 110, 115, 116, 119, 121, 130, 135], "y_i": [2, 60, 66, 79, 112, 117], "respect": [2, 3, 6, 9, 11, 12, 15, 16, 17, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 54, 58, 60, 62, 63, 64, 66, 67, 69, 71, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 96, 97, 98, 99, 100, 102, 104, 105, 108, 110, 112, 113, 114, 115, 117, 119, 120, 121, 122, 129, 130, 132, 133, 136, 141], "vector": [2, 3, 5, 7, 9, 10, 11, 15, 17, 28, 30, 33, 34, 35, 41, 42, 43, 45, 46, 47, 48, 49, 58, 60, 62, 65, 66, 68, 70, 71, 73, 74, 75, 76, 77, 79, 81, 82, 86, 89, 90, 94, 96, 99, 100, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 114, 115, 116, 119, 121, 129, 130, 131, 133, 135, 136, 142], "denot": [2, 8, 9, 10, 12, 19, 21, 28, 32, 35, 36, 39, 40, 41, 45, 46, 55, 58, 59, 60, 64, 69, 75, 79, 80, 86, 89, 93, 95, 96, 98, 100, 104, 105, 109, 112, 117, 119, 121, 122, 129, 130, 132, 133, 141], "new": [2, 4, 5, 12, 13, 15, 17, 19, 22, 26, 28, 30, 33, 34, 38, 39, 45, 47, 50, 51, 52, 54, 55, 56, 57, 58, 60, 61, 64, 65, 67, 69, 70, 73, 74, 76, 77, 79, 83, 85, 91, 94, 96, 98, 102, 104, 109, 113, 114, 118, 119, 121, 125, 127, 128, 133, 135, 136, 137, 138, 139, 140], "locat": [2, 8, 18, 19, 20, 31, 35, 40, 41, 44, 45, 46, 47, 48, 49, 57, 58, 60, 72, 80, 108, 110, 115, 117, 119, 120, 136, 139, 140, 141], "multiclass": [2, 58, 59, 61, 79], "hot": [2, 24, 64, 66, 79, 82, 94, 114], "obtain": [2, 4, 6, 11, 19, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 37, 39, 41, 45, 46, 49, 54, 58, 59, 60, 61, 64, 73, 75, 76, 82, 86, 88, 90, 93, 96, 98, 99, 101, 103, 105, 107, 108, 109, 110, 112, 115, 117, 121, 122, 129, 132, 133, 135, 138, 139, 140, 141], "One": [2, 3, 4, 8, 12, 15, 19, 22, 28, 30, 31, 34, 35, 36, 39, 40, 43, 44, 47, 56, 58, 60, 61, 62, 64, 67, 69, 72, 73, 74, 75, 76, 79, 80, 82, 84, 94, 103, 104, 106, 107, 109, 111, 114, 117, 121, 127, 129, 130, 131, 132, 136, 137], "conveni": [2, 5, 8, 15, 17, 18, 31, 33, 35, 47, 58, 59, 62, 64, 65, 69, 70, 72, 73, 74, 79, 103, 104, 107, 108, 109, 115, 123, 130, 132, 135, 137], "properti": [2, 3, 4, 8, 10, 34, 35, 47, 48, 49, 50, 58, 61, 73, 77, 79, 90, 105, 106, 108, 109, 110, 113, 115, 116, 118, 119, 120, 121, 130, 132, 135, 137, 138], "suitabl": [2, 3, 11, 12, 22, 30, 32, 35, 39, 41, 46, 58, 64, 74, 80, 82, 91, 105, 107, 110, 112, 124], "narrow": [2, 47, 48, 58, 109, 113], "increas": [2, 5, 6, 7, 18, 21, 22, 25, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 48, 56, 58, 64, 65, 67, 69, 70, 71, 74, 76, 77, 79, 80, 93, 102, 104, 105, 107, 108, 109, 112, 115, 121, 123, 129, 130, 132, 133, 136, 140, 141], "amount": [2, 6, 8, 22, 32, 34, 35, 37, 39, 40, 43, 46, 47, 48, 49, 52, 55, 56, 58, 60, 61, 64, 67, 69, 70, 73, 74, 77, 79, 94, 97, 101, 103, 104, 105, 107, 108, 109, 110, 113, 114, 115, 121, 123, 126, 132, 136, 139, 140], "approach": [2, 5, 8, 9, 26, 30, 35, 42, 43, 46, 47, 49, 50, 52, 53, 58, 60, 61, 64, 77, 79, 80, 82, 90, 96, 104, 105, 108, 110, 112, 113, 115, 124, 125, 128, 129, 132, 136], "consist": [2, 5, 6, 8, 11, 15, 19, 22, 25, 26, 28, 30, 32, 34, 35, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 52, 55, 58, 59, 60, 62, 64, 65, 66, 67, 69, 73, 76, 77, 78, 79, 81, 83, 86, 87, 90, 97, 98, 105, 112, 117, 120, 121, 123, 124, 128, 129, 130, 131, 135, 136, 137], "converg": [2, 34, 35, 47, 52, 61, 65, 69, 77, 82, 90, 101, 102, 103, 106, 107, 108, 109, 111, 115, 121, 123, 135, 140, 141], "solut": [2, 22, 36, 39, 44, 47, 48, 56, 58, 60, 61, 64, 65, 67, 70, 71, 77, 79, 90, 105, 107, 109, 110, 112, 113, 127, 132, 135, 138, 140], "rotat": [2, 6, 29, 102, 105, 109, 111, 117], "invari": [2, 11, 34, 35, 40, 42, 45, 48, 49, 62, 64, 131], "shift": [2, 5, 6, 35, 38, 39, 41, 44, 45, 46, 58, 63, 67, 69, 80, 82, 128, 129, 132, 133, 142], "manner": [2, 8, 46, 53, 58, 60, 72, 76, 84, 103, 106, 107, 108, 109, 112, 114, 125, 137], "remain": [2, 3, 5, 6, 11, 15, 19, 25, 29, 30, 32, 34, 35, 38, 41, 43, 46, 52, 55, 56, 58, 60, 61, 63, 64, 67, 76, 77, 82, 90, 91, 94, 103, 104, 107, 108, 113, 115, 118, 127, 128, 131, 135, 137], "unchang": [2, 30, 32, 33, 39, 41, 45, 60, 76, 90, 91, 104, 108, 111, 117, 127, 135], "simplic": [2, 19, 21, 32, 41, 47, 52, 56, 58, 60, 70, 72, 75, 76, 79, 80, 91, 105, 107, 108, 137], "thu": [2, 3, 5, 6, 7, 8, 10, 15, 16, 17, 19, 22, 28, 29, 32, 33, 34, 35, 37, 39, 40, 41, 43, 44, 46, 47, 51, 58, 60, 61, 64, 65, 66, 67, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 90, 91, 93, 94, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 114, 115, 117, 119, 121, 123, 124, 125, 127, 130, 131, 132, 133, 136, 140], "mathbb": [2, 3, 7, 8, 9, 10, 19, 28, 46, 52, 56, 60, 64, 69, 73, 75, 80, 86, 98, 100, 102, 104, 105, 108, 112, 115, 117, 119, 123, 125, 127, 130, 133, 136, 139, 140], "origin": [2, 4, 5, 6, 10, 11, 17, 19, 20, 21, 23, 25, 26, 28, 31, 32, 33, 34, 35, 37, 39, 43, 44, 46, 49, 52, 53, 58, 60, 61, 62, 67, 69, 72, 74, 76, 79, 80, 83, 85, 88, 89, 90, 91, 92, 97, 101, 104, 108, 109, 113, 114, 117, 121, 129, 131, 132, 133, 135, 137], "yield": [2, 3, 4, 33, 34, 37, 40, 41, 44, 45, 46, 58, 59, 60, 64, 67, 69, 72, 73, 75, 76, 77, 80, 85, 91, 97, 101, 103, 105, 109, 111, 112, 114, 119, 121, 129, 130], "ab": [2, 14, 15, 21, 28, 32, 40, 71, 105, 113, 117, 122], "constant": [2, 3, 14, 15, 19, 23, 31, 35, 46, 48, 54, 56, 58, 60, 61, 64, 66, 69, 70, 71, 74, 82, 93, 97, 102, 105, 107, 108, 111, 112, 114, 115, 117, 127, 132, 135, 136, 137], "maximum": [2, 9, 10, 24, 30, 32, 42, 52, 56, 60, 64, 67, 69, 80, 81, 88, 91, 92, 97, 98, 107, 110, 122], "zeros_lik": [2, 76, 81, 119], "sharei": [2, 8], "12": [2, 6, 28, 30, 33, 34, 37, 39, 45, 46, 52, 54, 55, 57, 64, 76, 92, 101, 102, 103, 104, 105, 107, 108, 109, 111, 112, 113, 114, 117, 119], "correspond": [2, 5, 8, 9, 15, 16, 19, 21, 22, 27, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 54, 55, 58, 60, 61, 62, 64, 66, 67, 69, 74, 75, 76, 79, 80, 85, 88, 89, 90, 97, 98, 102, 104, 105, 117, 119, 120, 121, 123, 128, 129, 130, 131, 132, 133, 135, 136, 137, 139, 140, 141], "notion": [2, 35, 39, 40, 47, 58, 61, 67, 74, 76, 95, 115, 117, 123, 130, 135, 139], "smooth": [2, 32, 37, 49, 72, 76, 80, 107, 109, 110, 112, 135], "attend": [2, 4, 5, 6, 7, 9, 10, 11], "within": [2, 3, 7, 9, 10, 14, 15, 35, 39, 41, 44, 46, 47, 48, 58, 61, 64, 74, 75, 93, 96, 104, 108, 109, 112, 121, 135, 138, 139], "distanc": [2, 3, 21, 39, 41, 48, 49, 58, 61, 62, 69, 74, 77, 80, 93, 97, 102, 104, 105, 109, 112, 117, 121, 125], "otherwis": [2, 18, 23, 32, 41, 43, 48, 51, 58, 67, 70, 71, 76, 89, 93, 97, 100, 104, 112, 119, 121, 128, 140], "indiscrimin": 2, "depend": [2, 3, 6, 7, 9, 10, 23, 30, 35, 36, 45, 46, 47, 48, 51, 52, 53, 54, 56, 58, 60, 61, 64, 67, 69, 71, 74, 75, 76, 77, 79, 80, 89, 90, 96, 102, 103, 105, 108, 112, 113, 114, 115, 117, 120, 121, 123, 125, 127, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "sin": [2, 9, 47, 49, 72, 105, 112, 114, 136], "x_i": [2, 12, 35, 47, 48, 49, 64, 69, 74, 93, 100, 104, 105, 109, 112, 115, 117, 121], "epsilon": [2, 19, 35, 41, 47, 48, 52, 61, 64, 69, 73, 74, 76, 77, 101, 102, 103, 104, 105, 111, 136, 140], "drawn": [2, 3, 48, 49, 51, 58, 60, 61, 64, 67, 69, 71, 73, 77, 82, 108, 110, 112, 119, 140], "distribut": [2, 6, 8, 14, 19, 27, 32, 35, 39, 46, 47, 48, 49, 50, 51, 52, 54, 55, 58, 59, 61, 63, 64, 67, 68, 71, 73, 74, 76, 77, 80, 82, 83, 89, 93, 97, 100, 104, 107, 110, 111, 112, 118, 119, 121, 125, 127, 129, 132, 133, 136, 137, 139, 141, 142], "unit": [2, 3, 10, 11, 12, 15, 27, 30, 32, 34, 35, 39, 43, 45, 46, 49, 50, 52, 58, 60, 64, 69, 76, 79, 80, 81, 82, 90, 92, 98, 104, 108, 117, 121, 123, 126, 127, 129, 133, 135, 137, 142], "varianc": [2, 3, 10, 28, 35, 47, 48, 49, 61, 64, 69, 71, 76, 79, 82, 100, 102, 103, 107, 108, 109, 112, 121, 130, 136], "40": [2, 6, 25, 30, 34, 47, 96, 108, 109, 111, 121, 122], "x_train": 2, "sort": [2, 19, 25, 26, 56, 58, 61, 62, 64, 70, 79, 91, 121, 123, 124, 136, 137], "uniform": [2, 3, 4, 12, 14, 15, 16, 18, 19, 23, 41, 44, 52, 60, 61, 66, 76, 82, 97, 118, 132, 140], "y_train": 2, "x_val": 2, "y_val": 2, "rel": [2, 5, 19, 21, 26, 27, 32, 34, 36, 37, 43, 45, 47, 48, 49, 58, 60, 61, 64, 66, 67, 75, 79, 80, 97, 100, 102, 107, 108, 109, 112, 113, 117, 119, 121, 129, 130, 131, 132, 136], "order": [2, 3, 6, 9, 15, 16, 17, 18, 19, 21, 22, 23, 25, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 41, 42, 43, 46, 47, 48, 50, 51, 52, 54, 55, 56, 57, 58, 61, 64, 67, 69, 73, 75, 77, 80, 85, 86, 89, 91, 95, 102, 105, 108, 112, 113, 114, 115, 116, 117, 119, 120, 121, 128, 130, 131, 132, 135, 138, 139], "perform": [2, 3, 5, 6, 7, 8, 10, 12, 15, 16, 17, 18, 19, 21, 22, 24, 25, 26, 28, 30, 32, 34, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 85, 88, 96, 101, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 117, 119, 123, 125, 129, 132, 133, 134, 135, 136, 141], "diagnost": [2, 16, 31, 58], "henc": [2, 3, 17, 33, 34, 35, 45, 51, 52, 54, 55, 58, 60, 62, 64, 69, 71, 79, 90, 102, 103, 104, 105, 108, 109, 111, 112, 121, 130, 132, 133, 135, 136], "covari": [2, 35, 47, 48, 49, 50, 58, 69, 100, 121], "matrix": [2, 8, 9, 18, 19, 24, 28, 34, 35, 39, 40, 41, 42, 43, 44, 47, 48, 49, 58, 59, 60, 64, 66, 69, 70, 71, 73, 75, 76, 80, 81, 82, 90, 99, 100, 102, 104, 105, 108, 109, 110, 114, 115, 116, 119, 121, 129, 130, 133, 135], "subsequ": [2, 6, 11, 15, 30, 32, 35, 39, 41, 43, 46, 51, 58, 60, 61, 62, 75, 76, 77, 78, 80, 98, 102, 108, 109, 113, 114, 119, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136], "when": [2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 51, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "multipli": [2, 3, 9, 10, 25, 26, 30, 33, 40, 41, 69, 75, 82, 88, 104, 108, 109, 115, 117, 121, 130, 133, 136], "recal": [2, 4, 5, 6, 12, 15, 21, 23, 26, 27, 31, 32, 35, 36, 41, 44, 61, 62, 65, 66, 67, 69, 70, 71, 74, 75, 76, 77, 79, 80, 81, 89, 90, 91, 92, 96, 99, 104, 105, 108, 109, 110, 111, 114, 117, 120, 121, 126, 128, 129, 130, 133, 135, 136, 140], "11": [2, 3, 4, 6, 7, 8, 9, 10, 11, 21, 30, 34, 37, 38, 41, 45, 54, 55, 58, 64, 74, 75, 77, 84, 88, 90, 99, 112, 113, 117, 119, 128, 129, 130, 131, 132], "pair": [2, 3, 4, 6, 7, 8, 9, 10, 19, 41, 47, 48, 58, 64, 69, 84, 85, 86, 90, 91, 92, 94, 97, 98, 112, 119, 128, 132, 133, 137, 140], "As": [2, 3, 6, 7, 8, 9, 10, 12, 18, 19, 21, 22, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 39, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 59, 60, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 94, 96, 97, 98, 99, 100, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 139, 140, 141], "attention_w": 2, "below": [2, 7, 9, 10, 11, 14, 15, 16, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 44, 45, 47, 48, 49, 51, 52, 54, 56, 58, 60, 62, 64, 66, 69, 70, 71, 73, 74, 76, 78, 80, 85, 86, 88, 95, 99, 105, 107, 109, 110, 114, 115, 117, 119, 120, 123, 127, 128, 129, 135, 137], "nadaraya_watson": 2, "dist": [2, 49], "column": [2, 3, 8, 9, 19, 25, 27, 28, 33, 41, 42, 43, 44, 46, 58, 60, 66, 69, 79, 99, 100, 108, 114, 117, 119, 120, 121, 129, 131, 133], "row": [2, 3, 8, 9, 10, 19, 21, 27, 28, 32, 33, 43, 44, 46, 58, 59, 60, 64, 66, 69, 73, 80, 85, 90, 95, 99, 100, 108, 117, 119, 120, 121, 129, 130, 131, 133], "look": [2, 9, 12, 14, 15, 21, 29, 31, 34, 35, 37, 39, 40, 41, 44, 46, 47, 48, 49, 51, 52, 54, 58, 60, 61, 62, 64, 66, 69, 72, 73, 74, 77, 79, 80, 82, 90, 91, 102, 104, 105, 107, 108, 109, 110, 112, 121, 122, 130, 131, 132, 133, 136, 137, 140], "kind": [2, 15, 39, 41, 51, 60, 63, 80, 119, 122, 132, 136, 140, 142], "pcm": [2, 8], "red": [2, 6, 8, 20, 22, 40, 46, 58, 62, 104, 117, 139], "colorbar": [2, 8], "shrink": [2, 8, 36, 74, 77, 115, 135], "thing": [2, 8, 34, 40, 46, 47, 58, 60, 61, 62, 64, 65, 67, 69, 71, 73, 74, 77, 79, 80, 90, 93, 102, 105, 107, 108, 109, 115, 117, 119, 120, 121, 123, 130, 132, 136, 137, 141], "stand": [2, 58, 107, 136], "three": [2, 3, 6, 10, 19, 22, 25, 26, 28, 31, 32, 35, 36, 37, 40, 43, 44, 46, 50, 58, 61, 62, 64, 66, 67, 71, 72, 80, 83, 85, 86, 90, 92, 93, 95, 104, 105, 113, 115, 117, 122, 125, 127, 130, 132, 133, 135, 137], "nontrivi": [2, 34, 58, 60, 64, 70, 107, 113, 121, 123, 127, 132], "fairli": [2, 34, 39, 55, 58, 69, 72, 79, 101, 103, 105, 107, 121, 130, 132], "workabl": 2, "too": [2, 4, 8, 16, 19, 27, 34, 36, 47, 52, 54, 55, 58, 60, 61, 62, 67, 73, 74, 75, 76, 77, 80, 82, 93, 96, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 117, 121, 130], "far": [2, 6, 8, 13, 17, 25, 33, 34, 37, 39, 40, 42, 43, 44, 46, 47, 48, 51, 52, 54, 58, 60, 61, 66, 67, 69, 70, 74, 75, 77, 78, 82, 101, 105, 107, 108, 109, 112, 113, 114, 115, 117, 120, 121, 122, 130, 132, 133, 135, 136, 139], "trivial": [2, 8, 40, 44, 47, 54, 55, 60, 83, 90], "unrealist": [2, 105], "bit": [2, 3, 9, 18, 19, 23, 34, 39, 40, 43, 62, 64, 65, 69, 80, 82, 104, 105, 107, 108, 112, 114, 130, 132], "close": [2, 6, 22, 24, 27, 28, 34, 35, 39, 41, 47, 48, 49, 50, 52, 57, 58, 60, 61, 67, 69, 70, 71, 76, 77, 79, 80, 82, 93, 110, 125, 127, 135, 141], "clearli": [2, 5, 8, 39, 48, 58, 61, 77, 103, 104, 112, 113, 132, 136], "why": [2, 6, 10, 15, 16, 18, 20, 23, 27, 33, 34, 35, 36, 37, 39, 40, 41, 45, 46, 48, 49, 51, 52, 58, 59, 61, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 81, 82, 90, 91, 92, 93, 98, 101, 102, 103, 105, 107, 109, 110, 111, 112, 113, 114, 115, 117, 121, 122, 123, 127, 128, 129, 133, 135, 136, 140], "veri": [2, 3, 4, 9, 10, 12, 17, 32, 34, 35, 39, 43, 46, 47, 48, 49, 52, 58, 60, 62, 64, 65, 66, 67, 69, 71, 72, 79, 80, 82, 92, 94, 97, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 120, 121, 123, 130, 132, 133, 135, 137, 139, 141], "thei": [2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 25, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 88, 90, 97, 98, 99, 103, 104, 105, 106, 107, 108, 109, 113, 114, 117, 119, 120, 121, 124, 125, 127, 128, 130, 131, 133, 135, 136, 137, 140], "deriv": [2, 6, 8, 35, 38, 39, 40, 41, 45, 46, 47, 48, 49, 60, 61, 64, 67, 69, 71, 74, 75, 80, 100, 102, 105, 109, 110, 114, 116, 121, 130], "despit": [2, 5, 10, 35, 46, 47, 48, 58, 60, 61, 69, 77, 80, 88, 113, 121, 123, 126], "question": [2, 6, 11, 34, 35, 38, 39, 45, 47, 54, 58, 60, 61, 64, 67, 76, 77, 79, 80, 84, 85, 90, 102, 107, 113, 118, 121, 128, 132], "alwai": [2, 5, 6, 10, 20, 34, 39, 40, 45, 46, 55, 58, 59, 61, 64, 66, 67, 74, 77, 79, 80, 81, 90, 105, 117, 119, 127, 132, 133, 135, 136], "That": [2, 3, 19, 34, 35, 36, 39, 41, 45, 46, 58, 59, 60, 64, 66, 69, 70, 74, 77, 80, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 115, 119, 121, 130, 136], "sigma": [2, 32, 35, 47, 48, 49, 52, 61, 64, 66, 69, 70, 71, 73, 74, 76, 79, 80, 81, 82, 89, 100, 121, 123, 125, 127, 135], "affect": [2, 10, 11, 19, 27, 28, 34, 37, 41, 48, 49, 58, 60, 62, 81, 82, 85, 97, 106, 107, 121, 122, 126, 128, 130, 138, 141], "outcom": [2, 3, 39, 43, 58, 64, 75, 80, 104, 112, 121, 130], "gaussian_with_width": 2, "better": [2, 5, 6, 11, 18, 22, 26, 34, 39, 43, 45, 47, 51, 52, 55, 56, 58, 60, 61, 64, 65, 66, 67, 69, 77, 79, 80, 82, 86, 96, 98, 102, 103, 105, 107, 108, 109, 112, 113, 118, 121, 125, 130, 132, 135, 136, 137], "variat": [2, 35, 47, 48, 49, 55, 58, 70, 80, 104, 110], "would": [2, 8, 10, 11, 15, 16, 17, 18, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 72, 73, 74, 76, 79, 80, 82, 102, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 120, 121, 122, 123, 125, 127, 130, 132, 133, 135, 136, 137, 139, 140], "larg": [2, 3, 5, 8, 11, 18, 19, 22, 23, 32, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 48, 49, 52, 54, 55, 58, 60, 61, 62, 64, 65, 66, 69, 71, 73, 74, 75, 77, 79, 80, 82, 83, 86, 87, 89, 92, 93, 94, 95, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 117, 120, 121, 125, 128, 130, 132, 135, 137, 139, 140, 142], "might": [2, 4, 5, 8, 11, 15, 17, 18, 26, 34, 35, 39, 41, 43, 44, 45, 46, 47, 48, 52, 54, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 125, 130, 131, 132, 135, 136, 137, 139], "fact": [2, 6, 8, 12, 19, 22, 23, 26, 32, 34, 35, 36, 37, 38, 39, 43, 45, 46, 47, 49, 58, 61, 64, 65, 67, 69, 71, 72, 73, 74, 77, 79, 80, 82, 84, 85, 89, 90, 101, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 121, 122, 130, 132, 136], "propos": [2, 4, 5, 6, 8, 10, 11, 30, 35, 39, 43, 58, 61, 80, 82, 83, 86, 90, 96, 98, 101, 103, 107, 109, 111, 121, 127, 129, 130, 132, 133], "trick": [2, 34, 37, 39, 58, 64, 65, 74, 77, 82, 86, 104, 121], "been": [2, 5, 6, 8, 10, 19, 20, 22, 23, 24, 25, 27, 28, 32, 34, 35, 36, 38, 39, 43, 47, 48, 52, 56, 58, 60, 61, 64, 67, 69, 72, 73, 75, 77, 80, 83, 85, 87, 90, 94, 96, 104, 107, 108, 109, 114, 115, 119, 120, 121, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 140], "nearest": [2, 77, 95], "neighbor": [2, 28, 72, 77, 95], "interpol": [2, 21, 30, 77, 136], "techniqu": [2, 13, 20, 21, 22, 23, 24, 32, 34, 35, 38, 42, 44, 47, 53, 58, 64, 67, 69, 70, 74, 75, 76, 77, 79, 91, 94, 98, 103, 105, 111, 112, 113, 114, 116, 122, 127, 128, 132, 136, 138], "cross": [2, 5, 6, 32, 36, 40, 42, 43, 44, 45, 46, 56, 58, 61, 63, 65, 78, 88, 90, 93, 96, 129, 132, 133, 139], "modal": [2, 6, 58, 131], "represent": [2, 4, 5, 6, 7, 8, 9, 10, 11, 15, 20, 24, 27, 28, 32, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 58, 64, 65, 80, 82, 83, 84, 86, 88, 92, 94, 96, 98, 99, 113, 114, 117, 120, 129, 136, 137, 142], "astut": [2, 74, 121, 136], "reader": [2, 35, 46, 47, 52, 54, 58, 60, 74, 79, 91, 102, 107, 109, 113, 121, 131, 136], "wonder": [2, 11, 64, 73, 74, 95, 121, 136], "method": [2, 5, 6, 7, 8, 9, 10, 13, 14, 19, 20, 22, 24, 25, 27, 30, 31, 32, 34, 35, 38, 41, 46, 47, 48, 50, 51, 52, 54, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 80, 81, 82, 86, 88, 89, 91, 93, 97, 98, 99, 102, 104, 106, 107, 111, 113, 114, 117, 118, 121, 122, 123, 124, 128, 130, 131, 132, 135, 136, 137, 138, 140], "half": [2, 12, 19, 27, 32, 34, 44, 90, 101, 104, 111, 114], "centuri": [2, 58, 69, 80, 114], "old": [2, 40, 45, 58, 60, 61, 80, 125, 127], "earliest": [2, 5, 46, 58, 80, 114], "precursor": [2, 34], "modern": [2, 3, 5, 8, 10, 34, 35, 37, 39, 42, 43, 58, 61, 62, 64, 70, 71, 77, 80, 82, 107, 113, 114, 117, 119, 128, 130, 131, 135, 136, 137, 142], "second": [2, 3, 9, 10, 11, 14, 16, 18, 19, 28, 32, 34, 35, 37, 39, 41, 43, 44, 45, 46, 51, 52, 58, 59, 60, 64, 66, 68, 69, 71, 72, 75, 76, 79, 81, 82, 83, 90, 96, 101, 102, 103, 105, 108, 110, 114, 115, 117, 119, 121, 122, 126, 129, 130, 132, 136, 137, 140, 141], "great": [2, 13, 18, 34, 49, 50, 58, 64, 79, 82, 87, 88, 90, 91, 104, 109, 110, 113, 127, 131, 132, 136], "third": [2, 9, 10, 16, 19, 28, 35, 37, 45, 46, 58, 66, 71, 85, 117, 119, 121, 130, 132, 135, 136, 137], "just": [2, 4, 6, 8, 11, 12, 13, 15, 16, 18, 19, 23, 25, 27, 28, 29, 32, 33, 34, 35, 37, 39, 40, 41, 43, 45, 46, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 67, 69, 70, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 86, 88, 89, 92, 102, 103, 104, 105, 107, 109, 110, 112, 113, 114, 115, 116, 117, 119, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 140], "importantli": [2, 41, 60, 121], "demonstr": [2, 6, 9, 11, 16, 22, 24, 25, 27, 30, 41, 45, 46, 47, 58, 77, 79, 82, 84, 86, 88, 90, 91, 92, 95, 113, 114, 119, 120, 121, 122, 129, 133, 137], "limit": [2, 3, 4, 6, 8, 18, 21, 22, 30, 32, 34, 39, 40, 46, 47, 49, 54, 55, 58, 61, 64, 65, 66, 69, 74, 77, 84, 90, 104, 107, 109, 111, 112, 113, 115, 117, 120, 121, 132, 135], "hand": [2, 19, 34, 37, 39, 47, 48, 52, 55, 56, 58, 60, 61, 67, 69, 75, 77, 79, 80, 83, 86, 90, 91, 93, 100, 102, 105, 106, 108, 112, 113, 114, 115, 117, 119, 121, 122, 138], "craft": [2, 19, 34, 60, 83, 84, 90], "much": [2, 3, 4, 6, 18, 22, 29, 30, 32, 34, 35, 37, 39, 40, 43, 46, 47, 49, 50, 52, 55, 58, 60, 61, 62, 64, 66, 67, 69, 70, 72, 74, 79, 80, 81, 85, 86, 93, 94, 101, 102, 103, 104, 105, 108, 109, 112, 113, 114, 115, 116, 117, 120, 121, 125, 127, 128, 130, 131, 132, 135, 136, 137], "strategi": [2, 4, 8, 11, 35, 37, 39, 40, 58, 60, 69, 77, 81, 102, 104, 105, 107, 108, 112, 122, 129, 132, 135, 136], "embark": 2, "earli": [2, 34, 43, 55, 56, 58, 60, 78, 82, 107, 127], "current": [2, 4, 10, 22, 24, 27, 32, 35, 38, 46, 51, 55, 56, 57, 58, 62, 67, 69, 70, 71, 74, 75, 77, 99, 107, 108, 112, 113, 117, 123, 124, 125, 127, 129, 130, 132, 133, 135, 138, 139, 140, 141], "directli": [2, 9, 12, 17, 25, 29, 30, 34, 35, 38, 39, 48, 49, 50, 52, 57, 58, 59, 60, 61, 64, 66, 68, 69, 70, 74, 77, 80, 81, 96, 98, 105, 106, 121, 125, 127, 129, 136], "littl": [2, 5, 6, 47, 61, 65, 67, 97, 104, 105, 108, 109, 121, 132, 136], "either": [2, 3, 9, 10, 22, 32, 33, 34, 39, 41, 44, 45, 46, 48, 52, 54, 55, 57, 58, 60, 64, 67, 69, 77, 79, 80, 82, 84, 87, 90, 102, 104, 108, 120, 121, 128, 135, 136], "assign": [2, 4, 5, 9, 15, 21, 32, 33, 37, 46, 52, 56, 58, 61, 64, 66, 67, 69, 74, 77, 79, 83, 90, 93, 100, 108, 111, 114, 117, 119, 121, 129, 132, 136, 137], "accord": [2, 8, 9, 14, 15, 19, 21, 25, 26, 27, 30, 37, 45, 46, 54, 58, 60, 61, 64, 67, 69, 75, 76, 77, 79, 82, 83, 91, 97, 98, 99, 104, 117, 119, 130, 136], "hat": [2, 35, 47, 60, 61, 64, 65, 66, 67, 69, 70, 79, 86, 103, 132, 136, 140], "prove": [2, 8, 11, 34, 35, 40, 45, 46, 58, 61, 64, 67, 68, 69, 71, 76, 79, 80, 102, 104, 109, 110, 112, 115, 117, 121, 130, 135, 136], "binari": [2, 9, 30, 58, 60, 61, 62, 64, 76, 80, 88, 89, 90, 91, 105, 119, 121], "equival": [2, 3, 15, 32, 40, 46, 49, 64, 69, 74, 76, 77, 80, 82, 83, 85, 88, 93, 98, 104, 107, 110, 112, 115, 117, 119, 132, 133, 135, 137, 141], "good": [2, 8, 10, 16, 34, 39, 43, 46, 47, 49, 53, 54, 58, 60, 61, 62, 65, 66, 67, 69, 70, 71, 73, 76, 79, 80, 86, 93, 98, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 121, 123, 128, 132, 135, 136, 140, 141], "happen": [2, 15, 34, 35, 39, 40, 41, 43, 46, 47, 48, 49, 58, 60, 61, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 79, 82, 101, 103, 105, 107, 108, 109, 110, 111, 113, 114, 115, 117, 119, 120, 121, 125, 133, 135, 136, 139, 140, 141], "abov": [2, 6, 7, 8, 9, 10, 15, 19, 22, 23, 25, 26, 31, 32, 33, 34, 35, 40, 41, 44, 46, 47, 48, 49, 52, 54, 58, 60, 61, 62, 64, 66, 67, 72, 73, 75, 76, 78, 80, 82, 83, 87, 88, 93, 97, 98, 99, 102, 104, 105, 109, 110, 112, 121, 125, 127, 128, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "minim": [2, 6, 16, 28, 39, 43, 47, 52, 53, 54, 58, 59, 60, 61, 64, 69, 74, 77, 80, 83, 84, 90, 93, 98, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 117, 130, 140], "hint": [2, 9, 10, 18, 28, 29, 46, 51, 52, 54, 59, 60, 64, 66, 67, 69, 70, 71, 73, 79, 80, 93, 96, 98, 105, 114, 115, 120, 121, 130, 136], "term": [2, 3, 8, 13, 15, 18, 27, 34, 35, 36, 37, 39, 41, 47, 51, 52, 58, 59, 60, 61, 64, 65, 66, 69, 72, 74, 75, 77, 80, 82, 93, 102, 103, 104, 105, 107, 108, 109, 111, 112, 114, 115, 117, 121, 122, 125, 126, 128, 129, 130, 132, 133, 136, 140, 142], "remov": [2, 3, 6, 19, 25, 30, 32, 33, 34, 35, 48, 58, 72, 74, 76, 79, 85, 88, 95, 97, 105, 108, 130], "do": [2, 3, 9, 10, 11, 15, 16, 17, 18, 19, 22, 23, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 81, 82, 86, 89, 91, 92, 95, 96, 100, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 114, 115, 117, 118, 119, 120, 121, 124, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139], "still": [2, 3, 6, 10, 12, 13, 15, 22, 32, 34, 37, 40, 43, 45, 46, 47, 48, 49, 52, 54, 55, 56, 58, 59, 61, 64, 65, 66, 69, 71, 72, 74, 77, 80, 82, 90, 91, 93, 102, 105, 108, 109, 110, 112, 113, 114, 119, 121, 123, 125, 128, 131, 132, 135, 136, 137, 139], "overfit": [2, 22, 23, 25, 34, 35, 49, 52, 58, 61, 68, 74, 76, 78, 79, 88, 107, 110, 113, 134], "lie": [2, 51, 58, 61, 80, 121, 125], "sphere": 2, "satisfi": [2, 15, 19, 46, 60, 61, 64, 66, 82, 102, 104, 105, 110, 117, 121, 130, 132, 136, 138], "simplifi": [2, 3, 4, 8, 11, 15, 19, 28, 34, 36, 37, 40, 43, 44, 46, 58, 59, 69, 72, 75, 78, 79, 83, 98, 102, 109, 117, 121, 125, 130, 133, 137], "exponenti": [2, 3, 8, 34, 64, 65, 66, 69, 79, 100, 103, 104, 109, 112, 117, 119, 122, 132, 133], "later": [2, 3, 4, 6, 8, 10, 12, 17, 18, 19, 34, 35, 37, 38, 39, 40, 41, 45, 47, 48, 49, 51, 56, 58, 60, 64, 66, 67, 69, 71, 72, 73, 75, 77, 80, 82, 91, 95, 102, 103, 105, 108, 109, 111, 112, 113, 115, 117, 123, 124, 127, 128, 129, 130, 132, 136, 137, 140], "dot": [2, 4, 5, 7, 9, 10, 28, 39, 41, 47, 48, 49, 56, 69, 89, 98, 99, 100, 108, 112, 116, 119, 131, 136], "product": [2, 4, 5, 6, 7, 9, 10, 28, 34, 38, 43, 48, 49, 52, 58, 60, 64, 69, 71, 74, 82, 83, 87, 89, 94, 98, 99, 100, 108, 112, 113, 114, 115, 116, 118, 119, 121, 125, 127, 130, 133, 134, 135, 136], "quickli": [2, 29, 47, 48, 49, 51, 52, 55, 58, 60, 71, 82, 102, 103, 104, 111, 112, 113, 115, 118, 121, 132, 136, 137], "reduc": [2, 6, 19, 21, 22, 23, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 39, 43, 44, 45, 46, 47, 48, 54, 55, 56, 58, 61, 62, 64, 67, 69, 71, 74, 77, 80, 85, 88, 89, 102, 103, 105, 107, 108, 109, 110, 112, 117, 119, 121, 125, 135, 136, 140], "intuit": [2, 5, 8, 15, 19, 27, 34, 35, 37, 38, 40, 46, 47, 48, 49, 50, 58, 64, 67, 73, 74, 76, 77, 79, 80, 93, 97, 102, 104, 105, 107, 109, 112, 113, 115, 117, 120, 121, 125, 126, 127, 130, 136, 141], "your": [2, 15, 18, 26, 34, 35, 38, 40, 47, 51, 53, 54, 57, 58, 60, 61, 62, 64, 65, 66, 67, 70, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 107, 108, 113, 115, 116, 117, 118, 120, 121, 122, 134, 138], "answer": [2, 6, 8, 47, 58, 64, 67, 74, 76, 80, 84, 85, 90, 113, 116, 117, 128], "dimension": [2, 3, 4, 9, 10, 15, 20, 21, 27, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 52, 58, 60, 61, 64, 65, 68, 69, 73, 75, 77, 80, 81, 84, 86, 95, 98, 100, 104, 106, 110, 115, 116, 117, 119, 133, 135], "base": [3, 4, 5, 6, 7, 9, 10, 11, 12, 14, 15, 19, 20, 21, 22, 23, 24, 27, 28, 34, 35, 36, 38, 41, 42, 43, 46, 47, 48, 51, 52, 54, 56, 57, 58, 60, 61, 63, 64, 66, 67, 69, 70, 72, 74, 77, 80, 82, 83, 84, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 108, 110, 113, 115, 117, 118, 119, 120, 121, 122, 123, 124, 129, 130, 131, 132, 134, 136, 137, 140, 141, 142], "includ": [3, 4, 5, 6, 9, 13, 15, 21, 25, 26, 29, 30, 32, 34, 35, 37, 38, 40, 41, 42, 44, 47, 48, 49, 50, 51, 52, 58, 60, 65, 66, 67, 68, 69, 71, 72, 74, 75, 77, 79, 80, 83, 85, 89, 90, 97, 99, 106, 113, 115, 117, 118, 119, 120, 121, 122, 123, 127, 128, 129, 133, 136], "turn": [3, 4, 15, 35, 37, 40, 41, 46, 58, 60, 61, 64, 66, 67, 69, 71, 75, 77, 78, 80, 82, 104, 110, 112, 115, 121, 122, 123, 125, 130, 132, 139, 141], "slightli": [3, 6, 11, 34, 35, 37, 41, 44, 45, 51, 61, 62, 64, 99, 102, 103, 105, 107, 108, 109, 121, 122, 132], "expens": [3, 34, 43, 47, 52, 54, 56, 58, 60, 67, 93, 94, 102, 105, 108, 112, 113, 114, 133], "nonneg": [3, 8, 64, 66, 69, 74, 103, 104, 117, 121], "work": [3, 5, 8, 11, 12, 13, 15, 16, 19, 27, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 48, 50, 51, 52, 58, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 88, 96, 99, 101, 102, 103, 104, 105, 107, 109, 112, 113, 114, 115, 117, 119, 120, 121, 123, 125, 128, 130, 131, 132, 134, 135, 137, 140, 142], "gone": 3, "simpler": [3, 16, 34, 35, 39, 60, 67, 77, 80, 86, 104, 107, 121, 127, 130], "mathit": [3, 8, 11, 39, 122], "without": [3, 4, 6, 8, 10, 11, 13, 15, 18, 21, 22, 23, 26, 30, 32, 34, 35, 39, 44, 46, 47, 49, 50, 52, 54, 58, 60, 61, 64, 65, 69, 70, 72, 73, 80, 82, 84, 86, 89, 90, 94, 96, 98, 101, 103, 105, 107, 108, 109, 111, 112, 113, 115, 117, 119, 121, 127, 129, 130, 131, 132, 135, 136, 139, 140], "moment": [3, 5, 41, 49, 58, 66, 77, 101, 103, 113, 132], "top": [3, 8, 15, 28, 32, 33, 39, 41, 44, 45, 46, 47, 49, 51, 52, 56, 57, 58, 69, 73, 74, 75, 80, 86, 89, 93, 95, 98, 100, 102, 104, 105, 109, 114, 115, 117, 121, 123, 130], "final": [3, 4, 7, 10, 11, 15, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 43, 44, 45, 47, 51, 56, 58, 60, 61, 64, 66, 67, 69, 71, 72, 74, 75, 79, 80, 81, 86, 88, 90, 92, 104, 108, 110, 112, 113, 114, 119, 120, 121, 122, 123, 125, 128, 129, 130, 131, 135, 138], "ident": [3, 8, 10, 15, 22, 34, 35, 39, 47, 49, 51, 58, 60, 67, 69, 73, 80, 100, 104, 107, 108, 110, 114, 118, 119, 121, 130, 133, 140, 141], "disappear": [3, 47, 48, 60, 121], "discuss": [3, 5, 8, 9, 10, 14, 17, 18, 21, 22, 23, 26, 27, 31, 32, 38, 42, 45, 47, 51, 52, 58, 60, 61, 62, 63, 66, 67, 69, 71, 72, 75, 76, 77, 78, 81, 82, 83, 84, 85, 87, 89, 91, 92, 93, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 116, 119, 122, 127, 129, 130, 131, 133, 135, 136, 137, 138, 140, 141], "activ": [3, 5, 6, 11, 12, 15, 35, 36, 37, 39, 43, 46, 49, 50, 52, 57, 58, 60, 62, 64, 69, 71, 75, 76, 78, 81, 82, 89, 90, 99, 104, 107, 110, 123, 125, 127, 130, 131, 133, 135], "well": [3, 5, 6, 8, 10, 19, 32, 33, 34, 35, 37, 39, 40, 41, 44, 45, 46, 47, 49, 50, 51, 52, 55, 56, 58, 60, 61, 62, 64, 67, 69, 70, 71, 76, 77, 79, 80, 81, 82, 85, 88, 90, 101, 104, 105, 106, 107, 109, 110, 112, 113, 114, 115, 121, 130, 132, 135, 136, 137, 140, 141], "bound": [3, 24, 27, 29, 30, 31, 35, 39, 47, 49, 52, 61, 64, 67, 77, 82, 104, 105, 107, 111, 112, 121, 132, 135, 142], "often": [3, 5, 6, 9, 10, 13, 14, 15, 16, 19, 20, 21, 25, 32, 34, 35, 37, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 58, 59, 60, 61, 62, 64, 67, 68, 69, 71, 73, 74, 75, 76, 77, 79, 80, 82, 89, 93, 97, 98, 99, 100, 102, 104, 107, 108, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 125, 128, 131, 134, 135, 136, 137, 138, 140, 141], "norm": [3, 10, 11, 15, 18, 32, 35, 60, 68, 75, 76, 77, 100, 104, 112, 114, 116, 135], "whenev": [3, 18, 39, 42, 46, 51, 57, 58, 59, 61, 62, 64, 65, 67, 69, 70, 77, 102, 103, 104, 105, 107, 108, 109, 112, 113, 114, 118, 119, 120, 121, 125, 127, 129, 130, 136, 137], "were": [3, 5, 6, 11, 15, 22, 34, 35, 37, 38, 39, 43, 46, 47, 48, 58, 59, 60, 61, 64, 67, 69, 71, 76, 77, 80, 81, 82, 88, 106, 113, 114, 115, 117, 121, 127, 128, 131, 132, 135, 136, 137, 138, 139, 140], "drop": [3, 19, 34, 41, 71, 74, 76, 79, 80, 97, 112, 119, 121, 136, 137], "definit": [3, 9, 23, 27, 37, 46, 47, 50, 54, 56, 60, 64, 66, 72, 75, 79, 80, 89, 91, 99, 100, 103, 106, 109, 111, 113, 115, 117, 121, 129, 130, 133, 138], "major": [3, 5, 6, 20, 24, 30, 34, 35, 39, 46, 51, 58, 61, 62, 86, 98, 113, 121, 124, 128, 136], "keep": [3, 4, 8, 15, 16, 18, 19, 22, 28, 33, 35, 36, 41, 45, 51, 54, 56, 58, 60, 61, 64, 65, 67, 69, 70, 72, 74, 76, 81, 82, 91, 97, 101, 102, 105, 107, 108, 109, 111, 117, 121, 123, 126, 127, 128, 130, 135, 136, 139, 140, 141], "magnitud": [3, 6, 34, 35, 46, 52, 58, 67, 69, 82, 102, 103, 105, 107, 117], "under": [3, 25, 35, 36, 49, 58, 60, 61, 67, 69, 71, 75, 77, 79, 90, 107, 109, 115, 116, 119, 121, 122, 128, 138, 140, 141], "control": [3, 5, 8, 15, 30, 32, 35, 36, 39, 44, 47, 48, 49, 50, 53, 58, 61, 67, 69, 74, 76, 79, 80, 82, 103, 109, 111, 112, 116, 125, 127, 131, 135, 138], "element": [3, 8, 9, 19, 28, 29, 30, 33, 34, 35, 38, 39, 40, 41, 44, 45, 56, 58, 60, 64, 66, 76, 80, 82, 88, 92, 93, 97, 98, 99, 100, 105, 108, 112, 116, 117, 118, 119, 121, 122, 135, 136, 137], "d": [3, 8, 9, 10, 30, 32, 41, 46, 47, 49, 52, 58, 60, 61, 64, 67, 69, 74, 75, 77, 80, 86, 88, 89, 95, 96, 98, 102, 104, 105, 110, 114, 115, 117, 119, 121, 122, 123, 125, 127, 129, 130, 132, 133, 136], "independ": [3, 7, 10, 30, 35, 39, 40, 46, 47, 48, 49, 52, 54, 58, 64, 67, 69, 73, 82, 83, 89, 94, 98, 100, 102, 108, 111, 112, 119, 121, 136], "rescal": [3, 10, 28, 31, 35, 76, 79, 101, 102, 103, 108], "arriv": [3, 9, 36, 37, 39, 60, 69, 74, 102, 104, 105, 108, 112, 117, 120, 121, 127, 130, 136, 138, 140], "commonli": [3, 14, 20, 21, 24, 28, 32, 35, 37, 39, 42, 44, 58, 62, 64, 67, 74, 75, 80, 93, 104, 110, 113, 114, 117, 130], "further": [3, 4, 6, 11, 16, 21, 22, 25, 26, 27, 30, 32, 34, 35, 37, 39, 44, 48, 49, 54, 55, 58, 61, 64, 67, 77, 80, 81, 82, 83, 88, 90, 93, 107, 109, 114, 120, 121, 124, 129, 130, 135, 136, 137, 140], "via": [3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 19, 21, 22, 23, 28, 29, 32, 33, 35, 36, 39, 41, 43, 45, 51, 54, 58, 60, 65, 69, 71, 72, 73, 74, 75, 79, 80, 81, 90, 91, 97, 99, 104, 105, 107, 109, 112, 113, 114, 115, 117, 119, 120, 121, 122, 127, 130, 131, 132, 133, 135, 138], "sum_": [3, 4, 8, 12, 28, 35, 46, 49, 60, 61, 64, 67, 69, 71, 74, 79, 82, 86, 89, 93, 96, 98, 102, 103, 104, 108, 109, 112, 117, 121, 122, 130, 132, 139, 140, 141], "j": [3, 4, 5, 8, 10, 12, 19, 28, 32, 33, 41, 44, 45, 46, 48, 49, 60, 64, 65, 69, 75, 79, 82, 83, 86, 89, 93, 96, 98, 100, 102, 108, 113, 117, 119, 121, 129, 130], "popular": [3, 15, 24, 34, 35, 38, 40, 42, 44, 45, 47, 49, 50, 51, 58, 60, 61, 67, 69, 74, 77, 79, 80, 82, 83, 84, 85, 90, 91, 96, 103, 107, 111, 112, 125, 126, 128, 129, 131, 135, 136, 137, 138], "ourselv": [3, 15, 35, 40, 58, 61, 65, 66, 69, 71, 73, 81, 112, 117, 121, 136], "remaind": [3, 19, 46, 58, 60, 76, 128, 140, 141], "deploi": [3, 17, 35, 38, 42, 58, 60], "tool": [3, 13, 34, 35, 37, 41, 43, 44, 46, 58, 60, 61, 68, 69, 70, 71, 74, 76, 77, 79, 98, 104, 106, 107, 110, 113, 114, 117, 120, 121, 131, 132, 136, 137, 142], "deal": [3, 12, 34, 46, 58, 59, 60, 61, 64, 69, 73, 74, 79, 81, 82, 104, 107, 108, 109, 113, 119, 120, 121, 130, 131, 132, 135, 136, 137], "string": [3, 4, 17, 57, 91, 120, 125, 128, 134, 137], "natur": [3, 5, 6, 8, 10, 11, 15, 17, 35, 39, 41, 46, 47, 54, 58, 60, 64, 69, 74, 77, 80, 83, 88, 89, 90, 92, 95, 96, 98, 100, 102, 104, 105, 110, 112, 113, 114, 117, 120, 121, 126, 128, 131, 132, 136, 139, 142], "languag": [3, 5, 8, 10, 11, 15, 39, 46, 58, 64, 77, 80, 83, 88, 92, 95, 96, 98, 102, 113, 114, 116, 117, 120, 121, 122, 124, 125, 126, 128, 129, 131, 134, 136, 142], "applic": [3, 5, 6, 8, 10, 11, 15, 22, 23, 24, 30, 31, 32, 35, 41, 46, 47, 48, 49, 50, 58, 59, 60, 66, 67, 69, 70, 80, 85, 86, 87, 88, 90, 91, 92, 94, 98, 99, 104, 113, 117, 120, 122, 123, 124, 126, 129, 130, 131, 133, 135, 137, 138, 142], "abl": [3, 16, 34, 35, 43, 46, 51, 53, 56, 57, 58, 64, 67, 72, 73, 75, 77, 82, 85, 90, 104, 105, 108, 110, 113, 121, 126, 127, 132, 136, 138], "mai": [3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 102, 103, 104, 105, 107, 110, 113, 117, 120, 121, 122, 124, 128, 129, 132, 133, 136, 138, 139], "necessit": [3, 35], "dummi": 3, "shorter": [3, 7, 9, 58, 85, 98, 108, 128, 129, 132], "These": [3, 5, 6, 9, 10, 13, 15, 19, 22, 28, 30, 32, 34, 35, 37, 39, 42, 43, 45, 47, 48, 50, 52, 58, 60, 70, 75, 79, 80, 83, 88, 90, 91, 99, 108, 109, 113, 117, 119, 120, 121, 123, 127, 131, 133, 134, 136, 137, 138], "special": [3, 6, 8, 11, 34, 37, 38, 39, 41, 45, 46, 50, 58, 60, 61, 64, 74, 79, 80, 82, 83, 85, 88, 90, 91, 92, 95, 96, 105, 115, 117, 118, 119, 120, 121, 122, 127, 128, 129, 130, 135, 136, 137, 141], "carri": [3, 8, 10, 12, 35, 37, 39, 46, 58, 75, 79, 93, 102, 105, 137], "sentenc": [3, 4, 5, 6, 10, 58, 83, 85, 86, 88, 92, 97, 128, 129, 132, 136, 137], "code": [3, 6, 8, 9, 10, 13, 14, 16, 17, 18, 22, 23, 25, 26, 33, 34, 35, 39, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 55, 56, 58, 59, 61, 64, 65, 66, 69, 70, 71, 72, 73, 74, 76, 79, 80, 81, 85, 90, 91, 97, 107, 108, 114, 115, 117, 118, 119, 123, 127, 128, 129, 133, 134, 135, 140, 141], "blank": [3, 58], "hello": 3, "world": [3, 6, 15, 29, 30, 40, 48, 58, 60, 67, 69, 77, 80, 94, 108, 113, 117, 120, 135, 138], "sinc": [3, 4, 6, 9, 10, 11, 16, 17, 18, 19, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 49, 52, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 80, 81, 82, 87, 89, 92, 93, 96, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 124, 125, 127, 128, 129, 130, 132, 133, 136, 137, 141], "our": [3, 5, 6, 7, 8, 11, 12, 14, 15, 16, 17, 19, 21, 23, 24, 26, 27, 29, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 89, 99, 102, 103, 104, 105, 108, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "howev": [3, 5, 6, 9, 10, 11, 14, 15, 16, 17, 20, 22, 25, 27, 28, 29, 31, 32, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 67, 69, 71, 72, 74, 75, 76, 77, 79, 80, 83, 84, 85, 89, 90, 93, 94, 96, 97, 102, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 133, 135, 136, 137, 140], "long": [3, 4, 5, 8, 9, 10, 17, 18, 34, 35, 38, 42, 47, 49, 51, 52, 54, 55, 58, 60, 62, 64, 69, 72, 75, 85, 90, 92, 104, 107, 109, 110, 111, 112, 114, 115, 121, 122, 125, 126, 130, 131, 132, 133, 136, 138, 139, 141, 142], "actual": [3, 8, 16, 19, 34, 35, 36, 37, 40, 41, 46, 47, 48, 49, 54, 58, 60, 61, 64, 66, 70, 77, 79, 80, 102, 105, 107, 108, 109, 113, 121, 130, 132, 136, 137, 140], "problem": [3, 6, 8, 15, 22, 26, 30, 31, 32, 34, 35, 36, 37, 39, 44, 45, 46, 47, 49, 51, 53, 59, 61, 62, 63, 64, 65, 66, 67, 69, 71, 73, 74, 77, 79, 80, 81, 82, 83, 84, 85, 87, 101, 102, 103, 104, 105, 106, 110, 111, 112, 113, 115, 117, 118, 120, 121, 122, 124, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 138, 139, 141, 142], "cheat": [3, 25, 90, 140], "ever": [3, 37, 39, 45, 49, 58, 60, 61, 65, 67, 80, 107, 110, 113, 139], "moreov": [3, 5, 6, 8, 15, 18, 20, 30, 34, 36, 37, 44, 45, 46, 49, 51, 54, 55, 58, 60, 61, 64, 65, 67, 69, 71, 72, 74, 77, 80, 81, 82, 97, 101, 103, 104, 105, 107, 110, 112, 113, 114, 120, 121, 123, 129, 130, 131, 134], "neg": [3, 19, 22, 32, 46, 58, 61, 64, 65, 66, 69, 80, 83, 87, 88, 94, 99, 105, 110, 119, 121, 135], "vanish": [3, 8, 35, 41, 52, 64, 76, 78, 80, 105, 112, 117, 126, 127, 130, 135], "practic": [3, 5, 7, 10, 15, 17, 19, 22, 23, 25, 26, 29, 30, 34, 35, 40, 41, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 58, 60, 61, 64, 66, 67, 69, 70, 71, 73, 74, 77, 78, 79, 81, 82, 83, 90, 93, 94, 95, 102, 103, 104, 105, 106, 107, 108, 111, 112, 113, 118, 122, 126, 127, 130, 131, 133, 137], "algebra": [3, 34, 47, 69, 70, 113, 115, 116, 119, 142], "heavili": [3, 13, 15, 58, 60, 67, 70, 108, 136, 139], "faster": [3, 24, 34, 35, 39, 40, 54, 55, 69, 70, 74, 95, 105, 108, 125, 127, 134], "wast": [3, 60, 112, 128, 134], "condit": [3, 6, 15, 41, 47, 48, 58, 60, 64, 69, 76, 77, 79, 80, 82, 89, 93, 94, 98, 100, 102, 103, 104, 105, 107, 114, 119, 121, 122, 124, 129, 130, 132, 133, 135, 136, 139, 141], "statement": [3, 32, 58, 61, 67, 72, 104, 113, 114, 115, 119, 121, 130, 132], "masked_softmax": 3, "_sequence_mask": 3, "maxlen": 3, "arithmet": [3, 15, 34, 116, 119], "repeat": [3, 4, 7, 15, 19, 30, 37, 38, 48, 51, 56, 58, 71, 90, 108, 112, 115, 121, 130, 135], "On": [3, 7, 19, 31, 34, 35, 39, 48, 51, 52, 55, 56, 57, 58, 60, 61, 67, 75, 77, 79, 82, 83, 90, 91, 93, 102, 106, 108, 112, 113, 121, 122, 131, 135], "whose": [3, 6, 9, 10, 11, 15, 19, 22, 25, 26, 30, 35, 37, 42, 43, 45, 57, 58, 61, 67, 75, 80, 82, 86, 89, 90, 91, 95, 97, 99, 113, 114, 117, 119, 120, 129, 130, 133, 135, 136, 140], "1e6": 3, "illustr": [3, 6, 15, 18, 19, 28, 30, 33, 34, 39, 41, 49, 51, 58, 60, 62, 66, 67, 71, 73, 74, 75, 79, 80, 82, 83, 84, 86, 88, 89, 90, 93, 96, 104, 105, 107, 108, 109, 110, 113, 114, 117, 119, 122, 123, 125, 127, 129, 130, 133, 136], "consid": [3, 6, 8, 9, 11, 19, 27, 30, 33, 34, 35, 37, 39, 41, 44, 46, 47, 48, 49, 51, 52, 54, 56, 58, 61, 62, 64, 66, 67, 69, 74, 77, 81, 82, 83, 87, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 110, 112, 114, 117, 120, 121, 122, 129, 130, 132, 133, 136, 139, 140], "beyond": [3, 5, 11, 34, 36, 38, 45, 46, 47, 51, 52, 58, 73, 75, 76, 77, 102, 103, 107, 108, 109, 113, 118, 120, 121, 122, 132, 136, 137, 140], "657478": 3, "342522": 3, "345029": 3, "654971": 3, "379866": 3, "297738": 3, "322396": 3, "376224": 3, "342722": 3, "281054": 3, "fine": [3, 5, 24, 31, 48, 58, 60, 74, 84, 90, 92, 113, 115, 121, 142], "grain": [3, 31, 48, 74], "everi": [3, 5, 9, 10, 12, 18, 19, 25, 26, 27, 32, 35, 39, 40, 45, 47, 48, 51, 52, 53, 54, 55, 56, 58, 60, 61, 64, 65, 69, 70, 71, 73, 77, 80, 81, 82, 83, 86, 90, 96, 107, 109, 113, 119, 121, 124, 128, 129, 131, 134, 136, 140], "284035": 3, "357395": 3, "35857": 3, "452218": 3, "547782": 3, "240856": 3, "28755": 3, "20002": 3, "271574": 3, "anoth": [3, 6, 7, 9, 16, 19, 20, 22, 23, 28, 33, 34, 35, 39, 44, 45, 46, 48, 52, 56, 58, 60, 64, 67, 69, 76, 77, 80, 81, 82, 83, 85, 93, 96, 101, 102, 105, 107, 110, 118, 120, 121, 122, 124, 127, 128, 130, 131, 135, 137, 139, 141], "matric": [3, 8, 9, 14, 18, 28, 33, 34, 39, 46, 64, 74, 75, 81, 82, 100, 104, 108, 109, 113, 114, 115, 116, 119, 130, 133, 135], "come": [3, 5, 8, 9, 10, 15, 19, 25, 33, 34, 35, 39, 40, 41, 46, 47, 52, 58, 60, 62, 64, 65, 69, 71, 76, 77, 80, 83, 84, 89, 96, 98, 105, 108, 109, 112, 113, 115, 121, 122, 127, 132, 136, 139], "handi": [3, 8, 39, 65, 71, 115, 117, 121, 132], "specif": [3, 4, 6, 7, 8, 9, 10, 11, 12, 16, 18, 19, 20, 30, 31, 32, 35, 37, 39, 47, 58, 59, 60, 62, 64, 66, 69, 76, 77, 80, 83, 84, 89, 91, 94, 95, 97, 98, 100, 102, 104, 108, 110, 112, 114, 116, 117, 121, 127, 128, 129, 130, 133, 136, 137, 140], "_1": [3, 8, 9, 28, 39, 60, 64, 86, 102, 112, 117, 121, 129, 130, 136], "_2": [3, 89, 102, 104, 115, 117, 121, 130], "ldot": [3, 7, 8, 9, 19, 28, 36, 60, 64, 69, 76, 86, 89, 93, 98, 104, 105, 109, 111, 112, 115, 117, 121, 122, 123, 129, 130, 132, 133, 135, 136, 139, 140, 141], "_n": [3, 9, 60, 86], "Then": [3, 4, 5, 7, 8, 11, 15, 18, 19, 21, 22, 23, 24, 26, 28, 29, 30, 32, 33, 36, 39, 47, 49, 55, 57, 58, 59, 60, 64, 67, 69, 71, 76, 77, 78, 79, 85, 86, 88, 90, 91, 95, 96, 98, 99, 104, 107, 112, 113, 115, 122, 125, 129, 130], "bmm": 3, "elementwis": [3, 19, 35, 41, 59, 69, 75, 80, 88, 100, 108, 117, 119, 121, 125, 127], "framework": [3, 8, 12, 14, 16, 17, 18, 23, 25, 26, 34, 35, 36, 37, 43, 45, 50, 51, 58, 59, 62, 64, 65, 66, 70, 71, 73, 74, 75, 80, 81, 82, 107, 108, 113, 114, 119, 123, 134, 135], "check_shap": [3, 4, 7, 9, 10, 11, 129, 135], "sai": [3, 6, 14, 15, 17, 19, 21, 27, 29, 30, 35, 41, 45, 46, 48, 56, 58, 60, 61, 64, 67, 74, 76, 77, 80, 83, 105, 108, 110, 114, 115, 117, 121, 122, 132, 133, 135, 136, 139], "though": [3, 8, 10, 32, 34, 35, 37, 39, 40, 41, 46, 52, 58, 61, 62, 64, 65, 69, 80, 81, 82, 84, 86, 88, 90, 93, 102, 103, 104, 107, 110, 113, 114, 117, 121, 129, 133, 135, 136], "address": [3, 8, 11, 15, 17, 21, 22, 25, 26, 35, 45, 46, 58, 60, 61, 64, 66, 67, 74, 79, 80, 81, 82, 84, 86, 96, 98, 102, 103, 104, 107, 109, 113, 115, 119, 120, 121, 127, 130, 135, 136], "easili": [3, 9, 18, 19, 30, 34, 39, 47, 48, 54, 58, 61, 66, 75, 80, 82, 96, 107, 108, 123, 130, 131, 132, 137, 140], "chosen": [3, 6, 16, 37, 54, 58, 61, 64, 67, 69, 104, 137, 140, 141], "think": [3, 6, 13, 15, 27, 31, 35, 36, 39, 40, 45, 46, 48, 58, 60, 62, 64, 66, 67, 69, 71, 76, 77, 80, 81, 88, 110, 113, 117, 120, 121, 124, 130, 132, 135, 136, 138, 139, 141], "written": [3, 18, 36, 49, 58, 94, 104, 105, 117, 127, 135, 141], "regular": [3, 4, 10, 11, 33, 34, 35, 37, 38, 39, 48, 52, 60, 67, 71, 75, 76, 78, 79, 82, 108, 109, 113, 125, 127, 130], "dotproductattent": [3, 7], "swap": [3, 75], "_attention_weight": [3, 4, 10], "attention_weight": [3, 4, 8, 10, 129], "earlier": [3, 6, 10, 20, 21, 22, 29, 32, 34, 35, 36, 41, 43, 45, 58, 61, 69, 70, 79, 84, 112, 113, 126, 133, 136], "toi": [3, 7, 52, 106, 112, 114], "purpos": [3, 8, 11, 15, 16, 34, 35, 41, 42, 43, 45, 47, 52, 56, 57, 58, 61, 66, 73, 74, 79, 101, 104, 105, 107, 114, 117, 121, 122, 125, 140], "total": [3, 19, 25, 32, 33, 34, 37, 39, 44, 46, 54, 55, 56, 60, 69, 97, 108, 117, 121, 130, 132, 136, 139], "lastli": [3, 35, 39, 41, 45, 59, 61, 62, 64, 107, 121], "anyth": [3, 16, 35, 37, 58, 60, 67, 69, 102, 113, 119, 121, 136], "sixth": 3, "becaus": [3, 6, 9, 10, 11, 12, 18, 19, 21, 22, 23, 26, 30, 32, 34, 35, 40, 41, 42, 43, 44, 46, 47, 48, 52, 54, 55, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77, 79, 80, 82, 85, 93, 99, 108, 112, 113, 115, 117, 119, 121, 122, 127, 130, 131, 133, 136, 137, 139, 140, 141], "show_heatmap": [3, 4, 8, 9, 10], "mismatch": [3, 72, 90, 105], "benefit": [3, 6, 8, 10, 12, 13, 15, 17, 34, 35, 37, 39, 43, 44, 58, 65, 69, 73, 74, 77, 80, 84, 99, 102, 108, 109, 114, 136], "its": [3, 4, 6, 8, 9, 10, 11, 12, 14, 15, 16, 19, 20, 21, 22, 25, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 93, 94, 96, 97, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 117, 119, 121, 123, 124, 128, 129, 131, 132, 136, 137, 139, 140, 141], "w_v": [3, 7], "tanh": [3, 52, 90, 110, 125, 127, 135], "w_q": [3, 7], "w_k": [3, 7, 89, 93], "learnabl": [3, 7, 9, 10, 11, 34, 35, 46, 58, 72, 90, 123, 135], "fed": [3, 5, 6, 7, 10, 11, 26, 58, 69, 72, 82, 83, 84, 90, 94, 108, 129, 133, 135], "interpret": [3, 5, 8, 18, 35, 40, 48, 50, 57, 58, 61, 64, 69, 74, 77, 80, 94, 108, 115, 118, 121], "concaten": [3, 4, 7, 10, 11, 15, 19, 28, 29, 30, 33, 36, 37, 40, 45, 79, 81, 86, 88, 90, 91, 97, 99, 100, 115, 119, 129, 130, 133, 135], "mlp": [3, 10, 11, 13, 15, 16, 17, 35, 36, 40, 42, 43, 51, 75, 76, 77, 80, 81, 82, 83, 84, 86, 90, 110, 123, 125, 130, 133], "hidden": [3, 4, 9, 10, 15, 16, 17, 34, 35, 40, 41, 45, 46, 49, 50, 51, 58, 75, 76, 78, 81, 82, 90, 92, 94, 110, 113, 123, 126, 129, 130, 131, 134, 135], "disabl": [3, 74, 76], "bia": [3, 7, 12, 14, 16, 17, 21, 22, 23, 33, 35, 39, 40, 41, 46, 49, 52, 58, 60, 61, 64, 67, 69, 70, 71, 74, 75, 77, 80, 81, 93, 103, 108, 123, 125, 127, 130, 133, 135], "additiveattent": [3, 4], "k_input": [3, 4], "q_input": [3, 4], "num_hidden": [3, 4, 7, 9, 10, 11, 81, 86, 90, 92, 123, 125, 127, 129, 134, 135], "expans": [3, 36, 69, 105, 111], "broadcast": [3, 33, 66, 69, 71, 116, 117, 127, 129, 133], "expand_dim": [3, 4, 9, 19, 21, 49, 92], "squeez": [3, 8, 19, 32, 44, 62, 88], "likewis": [3, 15, 33, 39, 58, 60, 64, 65, 69, 73, 80, 82, 86, 102, 105, 108, 114, 117, 119, 121, 125, 127, 132], "behavior": [3, 6, 7, 13, 35, 39, 58, 60, 61, 64, 69, 71, 73, 74, 77, 101, 102, 107, 108, 109, 111, 121], "qualit": [3, 5, 49, 58, 62, 76, 137], "similar": [3, 5, 6, 10, 11, 15, 19, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 51, 54, 58, 59, 60, 61, 62, 64, 70, 71, 74, 76, 80, 82, 83, 86, 87, 89, 90, 94, 96, 97, 98, 99, 108, 109, 111, 112, 123, 125, 127, 128, 129, 130, 132, 133, 135, 137, 140, 141, 142], "nonzero": [3, 12, 19, 41, 44, 60, 65, 77, 102, 105, 121, 132], "effect": [3, 6, 8, 10, 11, 22, 23, 24, 30, 32, 34, 35, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 58, 60, 64, 66, 69, 70, 74, 76, 80, 102, 103, 105, 107, 108, 110, 111, 121, 125, 130, 133, 135, 138], "aggreg": [3, 4, 6, 8, 35, 39, 42, 45, 46, 58, 69, 70, 102, 103, 109, 111, 121], "across": [3, 6, 8, 10, 16, 19, 29, 34, 35, 37, 38, 39, 40, 41, 42, 45, 49, 51, 52, 54, 55, 58, 60, 67, 69, 74, 76, 77, 80, 82, 83, 88, 90, 113, 120, 126, 127, 130, 131, 132], "particular": [3, 4, 5, 8, 12, 15, 34, 35, 39, 40, 46, 48, 49, 54, 56, 58, 60, 64, 65, 66, 67, 69, 70, 72, 74, 75, 76, 77, 81, 102, 103, 105, 107, 109, 112, 113, 115, 117, 121, 126, 131, 132, 135, 136, 139, 140, 141], "mainstai": [3, 34, 58, 77, 126], "architectur": [3, 4, 5, 6, 9, 11, 12, 13, 15, 16, 17, 37, 38, 39, 40, 41, 42, 43, 46, 51, 52, 57, 58, 61, 67, 68, 70, 76, 77, 80, 81, 82, 83, 84, 86, 88, 90, 94, 113, 122, 123, 125, 126, 127, 129, 130, 131, 135, 136, 142], "instead": [3, 4, 5, 7, 8, 11, 16, 17, 23, 31, 32, 34, 35, 39, 40, 41, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 59, 60, 61, 64, 65, 66, 69, 72, 74, 82, 84, 85, 92, 96, 101, 103, 105, 107, 109, 110, 112, 115, 119, 121, 136, 138, 139, 141], "area": [3, 10, 19, 21, 22, 23, 25, 26, 31, 34, 39, 41, 44, 45, 54, 58, 60, 64, 69, 82, 102, 113, 115, 131], "advanc": [3, 6, 13, 24, 38, 43, 47, 50, 52, 53, 54, 58, 61, 62, 64, 79, 105, 107, 112, 113, 114, 117, 120, 121, 128, 131, 135, 138], "recent": [3, 6, 10, 11, 24, 34, 38, 41, 42, 47, 52, 53, 58, 60, 61, 75, 77, 94, 98, 113, 117, 131, 136, 140], "year": [3, 5, 6, 24, 34, 35, 50, 58, 60, 61, 67, 69, 79, 98, 113, 121, 127, 136], "nvidia": [3, 18, 34, 54, 55, 57, 58, 65], "librari": [3, 12, 13, 47, 51, 57, 58, 69, 70, 72, 76, 103, 108, 113, 114, 115, 116, 117, 118, 119, 120, 134, 135], "megatron": [3, 6], "crucial": [3, 8, 47, 51, 58, 60, 61, 67, 71, 77, 82, 114, 115, 121, 131], "variant": [3, 6, 34, 35, 37, 39, 55, 58, 60, 80, 96, 101, 102, 104, 107, 108, 109, 127, 132], "detail": [3, 4, 6, 13, 15, 16, 17, 28, 30, 32, 34, 35, 37, 39, 40, 42, 43, 58, 61, 62, 64, 71, 72, 75, 79, 81, 82, 86, 97, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 120, 125, 127, 129, 131, 133, 139], "modifi": [3, 4, 6, 11, 19, 26, 28, 30, 34, 36, 39, 47, 51, 58, 73, 87, 89, 102, 107, 108, 113, 115, 135, 140], "allow": [3, 6, 7, 8, 9, 10, 12, 14, 15, 16, 18, 23, 28, 29, 34, 35, 36, 37, 39, 40, 44, 46, 51, 52, 56, 58, 60, 61, 62, 64, 65, 66, 67, 69, 70, 72, 73, 74, 79, 80, 88, 93, 96, 102, 103, 104, 105, 106, 109, 112, 113, 115, 117, 121, 125, 126, 127, 129, 132, 135, 136, 138, 140], "emploi": [3, 10, 34, 35, 45, 58, 60, 61, 67, 69, 71, 114, 117, 121, 128, 131, 136], "cost": [3, 7, 22, 26, 32, 34, 37, 39, 40, 45, 56, 58, 60, 64, 75, 84, 89, 93, 102, 105, 108, 109, 112, 122, 127, 133], "bandwidth": [3, 34, 37, 108], "encount": [4, 21, 22, 37, 39, 40, 43, 46, 50, 58, 60, 61, 64, 67, 69, 71, 73, 82, 92, 103, 104, 108, 109, 110, 111, 112, 121, 123, 126, 127, 131, 136, 137], "rnn": [4, 5, 8, 10, 83, 84, 88, 113, 123, 124, 125, 126, 127, 128, 129, 131, 134, 136, 137], "fix": [4, 5, 8, 9, 10, 15, 31, 35, 40, 43, 45, 48, 49, 52, 55, 56, 58, 60, 61, 65, 66, 67, 69, 71, 76, 80, 81, 82, 87, 88, 96, 98, 102, 103, 105, 107, 111, 117, 124, 126, 127, 129, 131, 132, 136, 141], "context": [4, 5, 6, 12, 16, 17, 35, 45, 56, 58, 59, 61, 68, 74, 77, 80, 89, 92, 93, 94, 98, 99, 102, 104, 106, 107, 109, 113, 117, 120, 121, 122, 124, 129, 132, 136], "convention": [4, 42], "relev": [4, 8, 19, 46, 50, 52, 57, 58, 59, 62, 67, 71, 79, 80, 83, 137], "intern": [4, 35, 58, 59, 76, 96, 105, 118, 125, 126], "complet": [4, 18, 21, 25, 35, 37, 47, 54, 55, 56, 58, 60, 66, 75, 90, 95, 97, 118, 122, 128, 129, 130, 132, 134, 136, 140, 141], "exclus": [4, 58, 117, 121, 126], "treat": [4, 11, 28, 39, 42, 46, 58, 60, 64, 66, 67, 72, 79, 87, 94, 97, 106, 115, 120, 122, 123, 128, 133, 135, 136], "intermedi": [4, 6, 15, 17, 21, 27, 28, 33, 35, 37, 39, 44, 45, 58, 69, 75, 76, 77, 90, 114, 127, 130, 141], "suffici": [4, 34, 58, 59, 60, 61, 62, 66, 67, 69, 77, 80, 83, 102, 104, 105, 107, 113, 130, 132, 133, 135, 136, 137], "whatev": [4, 46, 69, 133, 136], "serv": [4, 38, 39, 45, 51, 58, 60, 62, 74, 79, 101, 107, 112, 137], "piec": [4, 37, 64, 70, 71, 103, 135, 137], "share": [4, 6, 12, 15, 16, 30, 34, 39, 58, 69, 79, 82, 88, 96, 108, 111, 113, 121, 131], "reason": [4, 6, 15, 17, 34, 35, 37, 39, 40, 46, 47, 48, 49, 50, 58, 59, 60, 61, 64, 65, 67, 68, 69, 74, 75, 79, 80, 82, 85, 93, 98, 101, 104, 106, 107, 109, 110, 111, 112, 113, 115, 116, 119, 121, 122, 132, 135, 136], "short": [4, 18, 42, 45, 46, 47, 49, 58, 60, 61, 64, 67, 72, 74, 75, 102, 104, 107, 108, 110, 112, 116, 121, 123, 125, 126, 130, 136, 139, 141, 142], "infeas": [4, 30, 31, 32, 35, 46, 52, 58, 83, 102, 130], "enough": [4, 9, 15, 17, 34, 35, 41, 57, 58, 61, 62, 64, 67, 69, 77, 79, 80, 90, 102, 104, 105, 107, 108, 109, 116, 121, 132], "store": [4, 10, 15, 17, 18, 26, 31, 34, 52, 54, 58, 59, 62, 64, 69, 72, 73, 74, 75, 85, 88, 101, 103, 105, 109, 113, 116, 119, 120, 129, 130, 132, 133, 136], "consequ": [4, 8, 34, 35, 39, 42, 45, 46, 58, 60, 62, 66, 75, 76, 80, 82, 89, 102, 105, 109, 110, 121, 130, 136], "complex": [4, 6, 8, 9, 11, 12, 13, 15, 16, 19, 28, 32, 34, 35, 36, 37, 39, 40, 43, 46, 47, 52, 55, 56, 58, 60, 61, 69, 70, 72, 74, 77, 79, 80, 81, 86, 89, 90, 91, 96, 98, 106, 112, 113, 114, 123, 125, 126, 128, 131, 141], "wa": [4, 5, 6, 8, 10, 11, 15, 18, 22, 23, 34, 35, 37, 38, 42, 43, 45, 46, 47, 49, 51, 58, 59, 60, 61, 62, 64, 66, 67, 69, 74, 77, 79, 80, 82, 87, 90, 95, 96, 98, 99, 101, 102, 105, 107, 108, 109, 110, 112, 113, 114, 115, 117, 121, 124, 127, 128, 130, 131, 134, 136, 137, 139, 141], "who": [4, 58, 60, 64, 65, 67, 69, 70, 79, 83, 113, 121, 128, 139], "tri": [4, 35, 37, 58, 60, 96], "handwritten": [4, 43, 58, 62], "arbitrari": [4, 6, 12, 15, 17, 35, 37, 45, 47, 49, 58, 60, 61, 67, 75, 77, 96, 114, 117, 119, 120, 136, 141], "differenti": [4, 5, 8, 15, 58, 59, 67, 69, 70, 71, 75, 77, 78, 80, 82, 98, 104, 105, 113, 116, 119, 129, 130, 133, 136, 142], "longer": [4, 6, 7, 20, 34, 35, 37, 46, 55, 56, 58, 62, 69, 76, 79, 80, 81, 85, 96, 102, 103, 104, 105, 109, 114, 117, 122, 129, 132, 137], "pen": [4, 114], "trace": [4, 60, 105, 109, 114, 115], "move": [4, 12, 13, 16, 18, 19, 26, 27, 32, 35, 39, 43, 44, 45, 46, 47, 48, 49, 58, 69, 80, 82, 102, 103, 105, 107, 108, 111, 114, 115, 131, 132, 135, 138, 139, 140, 141], "direct": [4, 6, 20, 28, 35, 40, 41, 58, 69, 71, 75, 79, 80, 104, 105, 107, 109, 114, 115, 116, 121, 123, 130, 135, 136], "algorithm": [4, 6, 19, 21, 23, 25, 26, 32, 34, 35, 37, 40, 46, 50, 52, 53, 54, 56, 60, 62, 64, 65, 67, 68, 69, 72, 73, 74, 75, 77, 78, 80, 81, 82, 83, 91, 96, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 117, 120, 132, 136, 138, 139, 141, 142], "speech": [4, 5, 10, 15, 35, 39, 45, 58, 83, 113, 131, 132, 136], "recognit": [4, 5, 15, 20, 24, 34, 39, 45, 58, 60, 62, 67, 77, 90, 113, 126, 131, 132, 136], "markov": [4, 58, 121, 133, 138, 140, 141, 142], "inspir": [4, 6, 10, 39, 42, 46, 58, 67, 69, 72, 78, 82, 103, 135], "idea": [4, 5, 10, 16, 21, 24, 34, 35, 36, 38, 39, 45, 46, 49, 52, 55, 56, 58, 60, 61, 62, 64, 66, 67, 69, 70, 74, 76, 77, 79, 81, 82, 84, 89, 96, 97, 101, 102, 105, 113, 114, 115, 121, 123, 125, 126, 127, 128, 130, 137, 138, 140, 141], "unidirect": [4, 129], "deem": 4, "innocu": [4, 73], "descript": [4, 6, 31, 41, 58, 91, 99, 113, 118, 137], "arguabl": [4, 5, 37, 47, 58, 66, 67, 70, 103], "influenti": [4, 24, 67], "past": [4, 6, 8, 18, 35, 51, 58, 61, 67, 69, 70, 80, 95, 102, 103, 108, 109, 111, 113, 114, 117, 126, 130, 133, 135, 136, 138, 139], "decad": [4, 8, 18, 34, 43, 47, 58, 62, 67, 70, 80, 113, 114, 128], "give": [4, 9, 13, 15, 16, 19, 33, 37, 41, 43, 44, 46, 47, 48, 49, 52, 58, 60, 61, 64, 65, 67, 74, 78, 79, 80, 81, 82, 88, 90, 107, 108, 112, 113, 115, 117, 119, 120, 121, 122, 127, 130, 136, 137, 140, 141], "rise": [4, 42, 58, 60, 127, 136], "notat": [4, 43, 46, 47, 60, 64, 67, 69, 71, 74, 75, 80, 93, 101, 105, 109, 115, 119, 121, 122, 130, 131, 141, 142], "summar": [4, 6, 15, 34, 43, 58, 76, 86, 129, 132], "alreadi": [4, 5, 8, 10, 16, 21, 39, 45, 47, 48, 49, 50, 52, 55, 56, 57, 58, 60, 61, 67, 71, 74, 79, 80, 84, 102, 105, 106, 108, 109, 113, 114, 115, 117, 119, 121, 122, 123, 129, 130, 131, 135, 136, 137], "suppos": [4, 7, 8, 9, 19, 22, 28, 30, 31, 32, 33, 41, 46, 47, 48, 49, 57, 60, 61, 64, 69, 73, 82, 83, 86, 90, 93, 98, 104, 110, 112, 114, 115, 121, 122, 123, 124, 125, 127, 128, 129, 132, 136, 139], "score": [4, 5, 9, 10, 19, 32, 46, 55, 58, 59, 60, 61, 64, 79, 83, 121, 122, 129, 142], "depict": [4, 6, 11, 37, 39, 44, 46, 56, 58, 64, 69, 80, 83, 84, 86, 90, 129, 131], "proce": [4, 16, 18, 19, 46, 56, 69, 75, 79, 107, 108, 109, 128, 136], "redefin": 4, "omit": [4, 9, 32, 79, 93, 98, 103, 105, 112, 133], "symbol": [4, 6, 58, 69, 96, 100, 115, 117, 121, 125], "interfac": [4, 34, 51, 54, 58, 62, 108, 119, 124], "unsurprisingli": [4, 105], "attentiondecod": [4, 10], "notimplementederror": [4, 51, 62, 72, 124], "seq2seqattentiondecod": 4, "initi": [4, 5, 6, 10, 11, 12, 13, 15, 17, 19, 23, 24, 33, 34, 35, 37, 39, 41, 43, 44, 45, 47, 48, 51, 52, 55, 56, 57, 58, 61, 66, 69, 71, 75, 77, 78, 86, 88, 90, 93, 96, 101, 102, 103, 105, 107, 108, 109, 110, 111, 112, 114, 117, 119, 121, 123, 129, 130, 134, 135, 136, 141, 142], "ii": [4, 6, 15, 28, 32, 34, 35, 43, 49, 58, 64, 66, 69, 70, 71, 72, 77, 82, 83, 90, 91, 102, 113, 114, 115, 116, 119, 121, 122, 127, 133, 136, 137, 141], "iii": [4, 6, 15, 28, 32, 34, 58, 66, 71, 72, 90, 91, 113, 114, 115, 116, 122, 127, 136, 137], "exclud": [4, 6, 39, 69, 79, 91, 95, 97, 124, 128, 129], "previou": [4, 10, 15, 17, 22, 24, 25, 31, 32, 34, 36, 39, 40, 41, 43, 44, 51, 52, 54, 56, 58, 60, 67, 70, 73, 74, 76, 80, 82, 83, 99, 101, 108, 109, 112, 113, 117, 121, 122, 123, 124, 125, 126, 127, 129, 130, 132, 133, 135, 136, 137, 139, 140, 141], "embed": [4, 5, 6, 9, 10, 86, 88, 89, 90, 91, 94, 95, 129, 135, 142], "num_input": [4, 11, 32, 43, 51, 52, 54, 55, 65, 66, 70, 71, 74, 76, 79, 81, 86, 90, 123, 125, 127, 129, 134, 135, 136], "vocab_s": [4, 10, 88, 90, 92, 123, 125, 127, 129, 134, 135], "embed_s": [4, 86, 88, 99, 129], "num_lay": [4, 123, 129], "gru": [4, 123, 126, 127, 129, 142], "dens": [4, 10, 38, 39, 43, 83, 129, 142], "init_seq2seq": [4, 129], "init_st": [4, 10, 124, 129], "enc_output": [4, 10, 129], "enc_valid_len": [4, 10], "hidden_st": [4, 129], "fulli": [4, 6, 7, 10, 11, 12, 13, 15, 16, 22, 24, 26, 30, 32, 34, 36, 37, 39, 40, 41, 42, 43, 47, 58, 60, 64, 65, 69, 70, 71, 72, 76, 77, 78, 80, 81, 82, 83, 88, 90, 113, 123, 125, 127, 129, 133, 134, 135, 142], "connect": [4, 5, 6, 7, 9, 11, 12, 15, 16, 21, 22, 24, 26, 30, 32, 34, 37, 38, 39, 40, 41, 42, 43, 49, 50, 64, 65, 67, 68, 69, 70, 76, 77, 78, 80, 81, 82, 83, 88, 90, 104, 107, 125, 127, 129, 131, 133, 134, 135, 142], "four": [4, 8, 9, 19, 21, 22, 23, 29, 30, 32, 33, 34, 36, 37, 39, 41, 43, 45, 46, 55, 58, 61, 64, 79, 80, 108, 117, 122, 132, 135, 136, 139, 141], "seven": 4, "16": [4, 11, 15, 21, 27, 30, 32, 33, 34, 35, 37, 39, 43, 45, 51, 52, 54, 55, 58, 76, 92, 107, 108, 113, 117, 119, 129, 132, 135, 136, 137, 139, 141], "seq2seqencod": [4, 129], "analog": [4, 39, 58, 61, 64, 117, 121, 133, 141], "instanti": [4, 5, 10, 15, 17, 43, 69, 70, 90, 111, 125, 127, 129, 133], "mtfraeng": [4, 10, 128, 129], "seq2seq": [4, 10, 128, 129], "tgt_pad": [4, 10, 129], "001": [4, 9, 21, 22, 23, 86, 88, 108, 129], "max_epoch": [4, 10, 11, 18, 34, 35, 36, 37, 39, 43, 51, 52, 54, 55, 56, 65, 66, 70, 71, 72, 74, 76, 79, 81, 123, 125, 127, 129, 134, 135, 136], "30": [4, 5, 10, 30, 43, 44, 54, 55, 56, 58, 90, 107, 121, 129, 136, 137], "gradient_clip_v": [4, 10, 18, 71, 72, 123, 125, 127, 129, 134, 135], "num_gpu": [4, 10, 11, 18, 34, 35, 36, 37, 39, 43, 51, 55, 56, 72, 123, 125, 127, 129, 134, 135], "fit": [4, 6, 10, 11, 19, 31, 34, 35, 36, 37, 39, 41, 42, 43, 46, 47, 48, 49, 51, 52, 54, 55, 58, 60, 61, 65, 66, 69, 70, 71, 72, 74, 76, 77, 79, 81, 91, 93, 108, 113, 115, 123, 125, 127, 129, 131, 132, 134, 135, 136], "bleu": [4, 10, 129], "go": [4, 10, 15, 17, 26, 29, 34, 37, 40, 43, 44, 45, 46, 48, 58, 60, 61, 64, 66, 67, 69, 70, 72, 75, 77, 80, 81, 82, 94, 95, 99, 102, 103, 105, 107, 108, 110, 112, 113, 117, 121, 123, 128, 129, 130, 135, 136, 137, 138, 139, 141], "lost": [4, 10, 35, 46, 121, 129, 137], "he": [4, 10, 58, 64, 76, 86, 92, 113, 129], "calm": [4, 10, 129], "home": [4, 10, 58, 60, 69, 120, 121, 129], "ai": [4, 5, 6, 10, 57, 58, 113, 129, 140, 141], "perdu": [4, 10, 129], "il": [4, 10, 124, 129], "est": [4, 10, 129], "je": [4, 10, 129], "sui": [4, 10, 129], "chez": [4, 10, 129], "moi": [4, 10, 129], "pred": [4, 10, 21, 25, 26, 32, 49, 59, 66, 79, 99, 129, 136], "predict_step": [4, 10, 129], "build": [4, 9, 10, 12, 15, 17, 31, 34, 39, 41, 42, 49, 58, 60, 61, 65, 73, 77, 79, 80, 97, 107, 113, 114, 115, 117, 121, 123, 128, 129, 132, 133, 135, 136, 137, 138], "try_gpu": [4, 10, 18, 123, 125, 127, 129, 134, 135], "en": [4, 10, 54, 55, 95, 129], "fr": [4, 10, 129], "to_token": [4, 10, 97, 99, 128, 129, 137], "000": [4, 9, 10, 34, 47, 58, 61, 62, 69, 70, 79, 80, 82, 83, 121, 129, 132, 137], "nou": 4, "unk": [4, 95, 96, 97, 128, 137], "select": [4, 5, 8, 19, 23, 25, 26, 28, 30, 35, 37, 47, 51, 52, 58, 59, 61, 66, 68, 71, 74, 78, 84, 90, 104, 105, 113, 119, 120, 122, 123, 139, 140], "dec_attention_weight": [4, 10], "plu": [4, 34, 40, 47, 48, 58, 60, 62, 66], "lstm": [4, 5, 90, 123, 125, 126, 129, 142], "experi": [4, 6, 7, 10, 21, 22, 23, 25, 26, 27, 28, 31, 32, 34, 35, 37, 41, 43, 45, 51, 54, 55, 58, 62, 66, 67, 70, 71, 72, 74, 76, 85, 90, 92, 97, 102, 105, 106, 107, 108, 111, 112, 115, 121, 125, 127, 129, 130, 135, 136, 137, 138, 140], "influenc": [4, 39, 58, 66, 67, 69, 78, 80, 113, 114, 121, 123, 125, 126, 127, 129, 130, 135, 136], "boom": [5, 34], "driven": [5, 113, 131, 136], "multilay": [5, 11, 34, 58, 77, 113, 123, 129, 131, 142], "perceptron": [5, 35, 52, 58, 77, 113, 131, 142], "convolut": [5, 8, 9, 10, 11, 15, 23, 24, 27, 28, 30, 32, 36, 37, 39, 44, 45, 53, 58, 65, 66, 70, 84, 86, 107, 113, 126, 130, 131, 142], "network": [5, 8, 11, 12, 13, 15, 16, 17, 22, 23, 24, 26, 27, 28, 30, 40, 41, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 58, 60, 61, 62, 64, 65, 66, 67, 70, 71, 72, 74, 76, 78, 79, 80, 81, 82, 84, 90, 98, 102, 105, 107, 108, 111, 112, 113, 114, 115, 117, 119, 124, 127, 128, 130, 132, 136, 138, 140, 142], "recurr": [5, 9, 10, 39, 42, 80, 86, 88, 113, 127, 129, 130, 142], "remark": [5, 8, 39, 41, 43, 58, 61, 71, 77, 117], "underpin": [5, 58, 67], "breakthrough": [5, 34, 58, 128, 131], "2010": [5, 25, 38, 58, 79, 125, 131], "had": [5, 6, 18, 34, 37, 39, 43, 44, 48, 58, 60, 62, 64, 72, 75, 82, 109, 113, 121, 127, 128, 135, 136, 137], "anteced": 5, "laps": 5, "nearli": [5, 34, 35, 48, 58, 59, 61, 69, 70, 71, 77, 115], "plenti": [5, 58, 113, 118], "methodolog": 5, "innov": [5, 58, 69, 77, 80, 105, 126, 127], "made": [5, 11, 34, 35, 36, 39, 43, 46, 50, 58, 60, 61, 64, 65, 82, 113, 120, 125, 127, 135, 138], "wai": [5, 8, 11, 12, 15, 16, 18, 19, 22, 23, 26, 27, 30, 32, 33, 34, 35, 37, 39, 44, 45, 46, 48, 51, 52, 53, 55, 56, 58, 60, 61, 64, 65, 66, 67, 69, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 86, 88, 94, 95, 98, 99, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 119, 120, 121, 128, 129, 130, 131, 132, 133, 135, 136, 138, 139, 140], "practition": [5, 34, 35, 42, 53, 61, 64, 69, 77, 80, 82, 113, 114, 119, 120, 122], "toolkit": [5, 72, 80], "rate": [5, 22, 25, 26, 34, 35, 36, 39, 41, 43, 47, 48, 49, 51, 52, 58, 60, 61, 62, 65, 66, 67, 69, 70, 71, 81, 82, 97, 101, 103, 106, 108, 109, 111, 115, 121, 123, 135, 140, 142], "schedul": [5, 25, 26, 28, 53, 56, 106, 108, 111, 112, 142], "mind": [5, 9, 13, 58, 61, 67, 73, 88, 108, 139], "underli": [5, 16, 35, 37, 39, 44, 47, 53, 58, 61, 67, 69, 71, 74, 77, 82, 105, 108, 115, 121, 122, 131, 136, 138], "recogniz": [5, 35], "thousand": [5, 22, 30, 34, 35, 46, 47, 58, 61, 67, 77, 89, 130, 135, 136, 137], "paper": [5, 10, 21, 28, 32, 34, 35, 36, 39, 47, 58, 61, 64, 75, 76, 82, 93, 94, 96, 97, 98, 114, 126, 129], "altern": [5, 6, 9, 23, 33, 35, 36, 39, 40, 44, 47, 49, 52, 54, 57, 58, 61, 69, 75, 89, 103, 104, 105, 107, 108, 111, 112, 120, 122, 127, 129, 130, 135], "resembl": [5, 34, 35, 58, 77, 82, 109, 119, 125, 127], "neural": [5, 8, 13, 15, 16, 21, 22, 23, 24, 27, 32, 35, 39, 40, 41, 46, 47, 48, 50, 52, 53, 54, 56, 58, 61, 64, 66, 67, 70, 71, 72, 74, 76, 77, 78, 80, 81, 82, 84, 98, 105, 107, 113, 115, 117, 119, 124, 127, 128, 130, 132, 136, 137, 140, 142], "retain": [5, 13, 15, 28, 31, 43, 71, 75, 76, 80, 91, 119, 123, 125, 127, 133], "art": [5, 6, 11, 47, 49, 50, 52, 53, 58, 62, 66, 81, 83, 90, 128, 132], "statu": [5, 54, 55, 108, 121, 136], "vision": [5, 6, 10, 15, 20, 22, 23, 25, 26, 31, 34, 38, 39, 40, 41, 42, 43, 46, 58, 60, 77, 88, 107, 113, 120, 142], "sepp": 5, "hochreit": [5, 127], "domin": [5, 9, 11, 34, 38, 43, 52, 58, 64, 113, 127], "rapid": [5, 13, 18, 39, 58, 105, 113, 116], "emerg": [5, 6, 11, 42, 60, 61, 77, 82, 113, 132], "appear": [5, 23, 27, 35, 46, 48, 58, 60, 61, 77, 87, 90, 91, 93, 97, 127, 128, 129, 130, 136, 137], "resourc": [5, 51, 52, 54, 55, 56, 58, 74, 83, 113, 117], "thank": [5, 38, 58, 96, 113], "parallel": [5, 7, 9, 10, 15, 18, 34, 37, 42, 52, 54, 55, 56, 58, 72, 103, 108, 114], "massiv": [5, 30, 58, 67, 77, 79, 94, 114, 130, 135, 136], "cheap": [5, 53, 56, 58, 67, 69, 71, 102, 107, 108, 122], "storag": [5, 34, 47, 52, 58, 64, 67, 70, 75, 127, 133], "internet": [5, 22, 29, 58, 67, 79, 113, 121], "servic": [5, 64, 113, 132], "factor": [5, 6, 12, 18, 21, 23, 35, 39, 40, 43, 47, 58, 60, 61, 64, 69, 70, 77, 108, 113, 117, 129, 130, 136, 138, 140, 141], "inde": [5, 8, 35, 41, 47, 50, 58, 59, 60, 61, 64, 71, 72, 74, 79, 82, 90, 106, 109, 112, 115, 121], "driver": [5, 18, 69, 90, 92], "behind": [5, 12, 15, 50, 58, 107, 108, 113, 114, 126, 140, 141], "technologi": [5, 43, 58, 60, 113], "power": [5, 6, 9, 13, 17, 24, 34, 35, 39, 41, 42, 46, 47, 50, 57, 58, 61, 67, 69, 70, 72, 73, 74, 77, 79, 80, 81, 82, 90, 97, 108, 113, 114, 115, 130, 133, 136, 137, 141], "wit": [5, 70], "sea": [5, 47], "landscap": [5, 11, 28, 35, 58, 109], "present": [5, 6, 10, 20, 35, 36, 38, 53, 58, 61, 69, 72, 77, 95, 113, 115, 123, 128, 132], "task": [5, 6, 10, 11, 12, 15, 18, 20, 24, 26, 28, 29, 31, 32, 34, 36, 38, 39, 40, 41, 42, 43, 45, 51, 52, 58, 60, 61, 63, 67, 69, 73, 77, 80, 83, 84, 85, 86, 87, 92, 94, 95, 109, 113, 115, 121, 126, 128, 129, 131, 132, 136, 139], "grab": [5, 58, 71, 73], "bert": [5, 84, 94, 142], "electra": [5, 6], "roberta": [5, 6, 96], "longform": 5, "necessari": [5, 15, 37, 39, 41, 42, 46, 47, 58, 70, 75, 104, 110, 113, 136, 137], "downstream": [5, 6, 58, 83, 84, 86, 88, 90, 92, 94, 95], "pai": [5, 8, 39, 58, 72, 75, 110, 120, 121, 127], "breathless": 5, "coverag": [5, 118], "openai": [5, 58], "track": [5, 8, 16, 35, 37, 38, 41, 51, 58, 80, 81, 102, 112, 114], "convers": [5, 6, 20, 40, 58, 60, 79, 102, 104, 105, 107, 108, 109, 112, 115, 116, 121, 136], "gpt": [5, 90, 96], "meanwhil": 5, "divers": [5, 6, 39, 40, 58, 60, 77, 87, 90, 113, 131, 132, 140], "object": [5, 6, 15, 16, 17, 19, 21, 22, 23, 24, 28, 30, 31, 32, 34, 38, 42, 45, 46, 47, 49, 51, 53, 56, 59, 60, 64, 67, 68, 69, 71, 73, 74, 75, 79, 83, 89, 102, 104, 105, 106, 107, 108, 109, 110, 116, 117, 118, 121, 122, 130, 135, 136, 137, 140, 141, 142], "detect": [5, 6, 15, 19, 21, 24, 25, 30, 31, 34, 35, 37, 38, 40, 42, 45, 46, 54, 55, 58, 60, 121, 142], "semant": [5, 21, 24, 30, 33, 45, 83, 85, 86, 90, 93, 95, 98, 99, 132, 142], "segment": [5, 21, 24, 33, 37, 38, 46, 58, 79, 83, 90, 91, 92, 96, 104, 121, 128, 130, 142], "superresolut": 5, "competit": [5, 6, 15, 25, 26, 34, 38, 52, 58, 79, 85, 127], "reinforc": [5, 6, 8, 10, 39, 113, 121, 139, 140, 141, 142], "graph": [5, 36, 39, 42, 52, 58, 78, 108, 110, 114, 115, 121, 130, 142], "envis": 5, "enhanc": [5, 58, 82], "compress": [5, 8, 35, 43, 64, 65, 96, 129, 132], "revisit": [5, 15, 35, 37, 38, 61, 63, 67, 78, 93, 109, 133], "imagin": [5, 9, 15, 30, 46, 48, 49, 58, 60, 64, 67, 81, 82, 102, 104, 121, 137, 140, 141], "focu": [5, 8, 10, 11, 15, 20, 24, 30, 32, 39, 46, 48, 50, 52, 58, 61, 62, 64, 68, 69, 70, 74, 75, 81, 84, 94, 110, 112, 113, 114, 115, 117, 128, 131, 132, 136], "bahdanau": [5, 10, 142], "simpl": [5, 6, 7, 8, 9, 12, 15, 24, 28, 29, 32, 34, 36, 38, 39, 41, 43, 45, 47, 48, 50, 51, 52, 54, 55, 56, 58, 60, 62, 64, 67, 69, 74, 75, 76, 79, 80, 81, 82, 88, 90, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 120, 122, 123, 125, 127, 128, 129, 130, 133, 135, 136, 139, 140, 141], "high": [5, 6, 10, 13, 14, 19, 25, 26, 28, 30, 31, 33, 34, 35, 36, 39, 43, 45, 46, 47, 48, 49, 55, 58, 60, 61, 62, 64, 65, 67, 68, 69, 70, 72, 76, 77, 78, 80, 81, 86, 97, 98, 101, 103, 105, 110, 113, 116, 117, 118, 123, 125, 127, 129, 130, 132, 134], "level": [5, 6, 10, 13, 21, 24, 25, 26, 27, 30, 31, 33, 34, 35, 37, 41, 43, 45, 46, 47, 48, 49, 54, 55, 56, 58, 60, 61, 62, 64, 65, 69, 70, 72, 76, 77, 80, 81, 84, 86, 96, 101, 113, 117, 121, 123, 125, 127, 128, 131, 132, 134, 135, 137, 142], "receiv": [5, 8, 18, 46, 58, 60, 61, 69, 73, 78, 83, 102, 115, 121, 136, 140, 141], "extent": [5, 36, 37, 58, 60, 125, 136], "focus": [5, 6, 15, 16, 31, 58, 61, 79, 80, 84, 94, 107, 113, 117, 123, 130, 131, 136], "along": [5, 6, 9, 30, 32, 35, 37, 41, 52, 58, 61, 66, 69, 75, 77, 80, 88, 104, 117, 119, 126, 133, 135, 138, 139], "success": [5, 6, 12, 23, 35, 37, 41, 44, 53, 60, 67, 71, 77, 113, 114, 121, 126, 127, 129, 140, 142], "furthermor": [5, 34, 36, 41, 52, 58, 79, 82, 103, 104, 105, 107, 109, 110, 113, 117, 121, 128, 129, 132, 137], "research": [5, 6, 8, 11, 12, 13, 18, 22, 34, 35, 38, 43, 46, 47, 49, 58, 60, 61, 64, 69, 70, 76, 77, 79, 80, 82, 87, 90, 94, 105, 113, 125, 128, 131], "nice": [5, 35, 60, 64, 69, 73, 74, 104, 109, 121, 132], "insight": [5, 13, 34, 38, 49, 75, 102, 112, 113, 121, 131, 134, 138, 140], "pattern": [5, 6, 11, 15, 35, 36, 37, 40, 45, 46, 58, 60, 61, 67, 69, 73, 76, 77, 113, 121, 123, 127], "lingual": 5, "synonym": [5, 117], "my": [5, 121, 137], "feet": [5, 58, 64, 69], "hurt": [5, 52, 55, 67, 77], "mal": 5, "au": 5, "spur": 5, "claim": [5, 35, 76], "confer": [5, 35, 45, 58], "although": [5, 6, 10, 19, 22, 29, 30, 32, 34, 36, 39, 47, 58, 59, 69, 74, 78, 80, 90, 98, 105, 108, 110, 127, 129, 136], "precis": [5, 34, 35, 41, 42, 44, 46, 47, 48, 49, 58, 61, 63, 64, 65, 67, 69, 71, 74, 77, 80, 113, 117, 121, 123, 129, 130, 131, 136, 137], "hazi": 5, "topic": [5, 37, 47, 58, 60, 61, 64, 69, 77, 82, 85, 113, 115, 136], "soon": [5, 11, 47, 54, 55, 60, 61, 69, 127], "signific": [5, 7, 8, 11, 18, 19, 23, 34, 35, 38, 39, 40, 41, 42, 43, 44, 46, 58, 60, 61, 67, 71, 77, 80, 81, 82, 103, 105, 107, 108, 113, 117, 134], "concern": [5, 15, 32, 46, 58, 60, 71, 80, 81, 110, 113, 114, 115, 117, 121, 127, 137, 140], "put": [5, 18, 35, 43, 46, 47, 58, 61, 62, 64, 72, 73, 79, 80, 84, 88, 91, 93, 94, 104, 115, 121, 122, 126, 129, 131, 138], "salient": [5, 127], "dispens": 5, "altogeth": [5, 60, 61, 65, 69, 79, 121], "cleverli": [5, 58], "arrang": [5, 15, 37, 43, 58, 117, 131], "relationship": [5, 6, 46, 58, 61, 67, 69, 74, 80, 84, 85, 86, 90, 93, 96, 98, 110, 121, 123, 133], "among": [5, 12, 19, 26, 28, 30, 32, 37, 40, 43, 46, 58, 59, 60, 61, 64, 67, 69, 71, 74, 77, 79, 80, 81, 82, 83, 88, 90, 93, 94, 95, 96, 97, 98, 108, 113, 114, 119, 121, 122, 126, 128, 130, 132, 137], "2018": [5, 90], "began": [5, 60, 69, 125, 137], "system": [5, 6, 15, 20, 24, 34, 38, 42, 46, 47, 55, 57, 60, 62, 64, 69, 71, 73, 77, 80, 83, 98, 102, 113, 115, 119, 132, 136, 138, 139], "becam": [5, 58, 127], "enorm": [5, 35, 46, 58, 121, 122], "corpora": [5, 6, 58, 90, 91, 94, 95, 97, 98, 137], "supervis": [5, 6, 38, 43, 64, 67, 83, 90, 94, 120, 121, 129, 140], "gap": [5, 39, 61, 67, 76, 77, 107], "tradit": [5, 8, 34, 35, 49, 58, 69, 77, 110, 126], "grew": [5, 58], "especi": [5, 16, 31, 33, 34, 49, 52, 58, 67, 70, 74, 82, 90, 93, 109, 113, 121, 127, 130, 136], "wide": [5, 10, 12, 20, 22, 23, 26, 30, 32, 34, 35, 40, 43, 47, 58, 60, 62, 68, 74, 77, 79, 80, 82, 83, 84, 85, 87, 88, 90, 108, 112, 113, 117, 127, 135], "paradigm": [5, 6, 34, 58], "ascend": 5, "coincid": [5, 60, 64], "foundat": [5, 50, 58, 61, 113, 121, 141], "basic": [5, 12, 13, 15, 20, 21, 24, 37, 38, 39, 42, 43, 47, 51, 53, 56, 61, 63, 68, 70, 74, 75, 79, 80, 81, 84, 94, 98, 105, 106, 107, 112, 113, 114, 116, 119, 125, 131, 132, 136, 137], "simplest": [5, 8, 23, 47, 56, 57, 58, 69, 72, 73, 74, 77, 78, 112], "summari": [5, 13, 24, 38, 42, 50, 53, 63, 68, 78, 84, 94, 106, 116, 126, 131, 138, 142], "exercis": [5, 13, 24, 38, 42, 50, 53, 63, 68, 78, 84, 94, 106, 116, 126, 131, 138, 142], "nadaraya": [5, 8], "watson": [5, 8], "multi": [5, 6, 9, 10, 11, 18, 38, 39, 40, 45, 52, 53, 58, 64, 88, 103, 132, 142], "head": [5, 6, 9, 10, 11, 37, 38, 58, 92, 121, 142], "compar": [5, 6, 8, 10, 18, 20, 22, 23, 30, 31, 32, 34, 35, 36, 37, 39, 41, 42, 43, 47, 52, 53, 54, 55, 56, 58, 59, 61, 62, 64, 65, 66, 67, 69, 70, 71, 76, 77, 79, 80, 81, 83, 88, 89, 91, 96, 99, 101, 102, 108, 109, 112, 117, 121, 122, 123, 125, 127, 129, 132, 133, 134, 135, 136, 137, 140, 141], "cnn": [5, 8, 10, 11, 21, 24, 27, 28, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 83, 84, 88, 113, 123, 131, 142], "positionwis": [5, 11, 90], "feed": [5, 6, 9, 11, 12, 33, 34, 42, 43, 51, 58, 79, 80, 86, 88, 90, 117, 119, 120, 127, 129, 133, 135], "patch": [5, 6, 38, 46, 58, 128], "togeth": [5, 15, 19, 35, 36, 38, 39, 40, 43, 46, 48, 58, 60, 64, 71, 77, 82, 84, 88, 91, 93, 94, 113, 117, 121, 123, 126, 128, 129, 131, 133, 135, 139, 140, 141], "scalabl": [5, 11, 47, 50, 51, 58, 78, 109, 113], "scratch": [6, 13, 15, 22, 38, 50, 54, 55, 58, 59, 60, 62, 63, 64, 68, 70, 78, 80, 82, 83, 90, 103, 106, 113, 115, 121, 126, 131, 134, 136, 142], "becom": [6, 8, 11, 18, 28, 34, 35, 36, 39, 40, 46, 47, 48, 49, 51, 52, 54, 56, 58, 60, 61, 67, 69, 74, 76, 77, 80, 85, 90, 94, 98, 103, 105, 109, 110, 113, 114, 117, 118, 120, 121, 126, 129, 135, 136], "expert": [6, 52, 83, 113, 138], "sensit": [6, 23, 35, 45, 47, 58, 59, 60, 69, 76, 92, 94, 107, 111, 117], "slight": [6, 51, 56, 91, 102, 103, 109, 121, 130], "compet": [6, 37, 50, 61, 67, 79, 113], "generalist": 6, "increasingli": [6, 13, 36, 42, 48, 50], "larger": [6, 11, 15, 18, 21, 22, 25, 26, 27, 28, 32, 33, 34, 35, 39, 40, 41, 44, 45, 46, 47, 48, 49, 54, 56, 57, 61, 64, 65, 67, 69, 74, 75, 77, 79, 81, 91, 93, 96, 102, 103, 109, 112, 119, 121, 128, 130, 137, 140], "superior": [6, 11, 58], "law": [6, 58, 71, 113, 121, 137, 139], "evidenc": 6, "significantli": [6, 22, 34, 35, 36, 37, 43, 47, 56, 58, 60, 67, 69, 75, 78, 80, 89, 90, 92, 97, 102, 108, 109, 112, 121, 127, 128, 136, 137], "boost": [6, 43], "stori": [6, 34, 60, 77, 131, 142], "gato": 6, "plai": [6, 13, 35, 38, 39, 47, 52, 58, 60, 82, 104, 107, 112, 113, 127, 138, 140], "atari": [6, 58, 139], "caption": [6, 41, 58, 131, 136], "chat": [6, 58, 94], "act": [6, 15, 35, 58, 60, 80, 121, 124, 136, 140], "robot": [6, 20, 58, 131, 139, 140, 141], "joint": [6, 47, 48, 49, 58, 89, 121, 132, 136], "torqu": [6, 58], "button": [6, 25, 26, 58, 79], "press": [6, 58, 60, 113, 122], "notabl": [6, 10, 11, 67, 77, 92, 137, 140], "multimod": 6, "serial": [6, 12, 17], "flat": [6, 43, 81, 109], "akin": [6, 8, 45, 103], "prior": [6, 11, 28, 35, 37, 39, 42, 47, 48, 50, 52, 54, 58, 74, 107, 110, 121, 142], "compel": [6, 49, 58], "wealth": 6, "repres": [6, 8, 9, 10, 12, 15, 16, 20, 24, 27, 28, 29, 31, 32, 34, 41, 42, 43, 46, 47, 48, 49, 52, 54, 55, 56, 58, 60, 61, 62, 64, 66, 69, 70, 76, 77, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 93, 94, 96, 97, 98, 100, 109, 113, 114, 117, 119, 120, 121, 122, 128, 130, 131, 133, 135, 136, 137], "mode": [6, 10, 21, 35, 45, 54, 55, 58, 64, 73, 76, 107], "conclud": [6, 24, 37, 42, 60, 61, 67], "explain": [6, 8, 9, 10, 21, 23, 24, 28, 32, 33, 41, 47, 58, 60, 61, 64, 67, 72, 77, 83, 84, 90, 93, 104, 105, 107, 112, 113, 121, 122, 124, 126, 128, 129, 130, 133], "project": [6, 7, 9, 11, 35, 38, 72, 85, 95, 110, 113, 117, 128, 132, 135, 136], "cl": [6, 11, 32, 83, 90, 91, 92], "bidirect": [6, 88, 94, 126, 129, 142], "mask": [6, 10, 19, 21, 24, 31, 32, 58, 76, 83, 92, 97, 99, 126], "love": [6, 95, 98, 113], "vertic": [6, 41, 44, 48, 104, 115, 117], "horizont": [6, 25, 40, 41, 44, 48, 109, 117], "randomli": [6, 15, 17, 22, 23, 25, 26, 31, 41, 51, 52, 56, 58, 61, 62, 64, 67, 69, 71, 76, 77, 90, 93, 97, 98, 119, 132, 135, 136, 140], "9": [6, 9, 19, 21, 25, 26, 30, 31, 32, 33, 35, 37, 40, 45, 46, 48, 54, 55, 57, 58, 61, 66, 76, 82, 84, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101, 103, 104, 107, 108, 109, 111, 112, 113, 117, 119, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 140], "car": [6, 25, 31, 43, 58, 83, 113], "prepend": 6, "entropi": [6, 32, 43, 58, 60, 61, 63, 65, 90, 93, 100, 129, 132, 133], "constraint": [6, 11, 83, 102, 106, 108, 140, 141], "manual": [6, 25, 34, 37, 39, 41, 45, 52, 58, 90, 120], "ad": [6, 9, 10, 15, 20, 34, 35, 36, 37, 38, 39, 40, 44, 46, 47, 59, 60, 64, 69, 71, 72, 73, 76, 77, 79, 80, 81, 90, 101, 103, 104, 112, 117, 119, 127, 133], "those": [6, 8, 10, 11, 13, 15, 16, 19, 21, 22, 26, 28, 29, 30, 32, 34, 35, 36, 39, 43, 44, 46, 48, 49, 58, 60, 64, 66, 67, 69, 71, 75, 76, 77, 78, 80, 83, 84, 89, 91, 92, 97, 100, 107, 110, 111, 113, 114, 120, 121, 123, 132, 133], "sentiment": [6, 83, 84, 85, 90, 136, 142], "analysi": [6, 40, 42, 54, 58, 61, 69, 74, 77, 80, 83, 84, 85, 90, 96, 102, 104, 106, 113, 131, 142], "take": [6, 8, 11, 12, 15, 18, 19, 20, 22, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 97, 98, 100, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 119, 120, 121, 124, 125, 127, 128, 129, 130, 132, 133, 135, 136, 138, 139, 140, 141], "350": [6, 58], "million": [6, 11, 22, 27, 34, 46, 47, 58, 61, 67, 77, 79, 80, 83, 89, 90, 92], "250": [6, 19, 58, 140], "billion": [6, 34, 40, 46, 90, 97, 108], "tag": [6, 64, 84, 90, 136], "understand": [6, 16, 31, 35, 36, 38, 39, 40, 41, 43, 48, 49, 50, 51, 58, 62, 64, 65, 67, 68, 71, 75, 77, 85, 90, 94, 103, 104, 105, 106, 109, 113, 117, 125, 132], "immedi": [6, 10, 34, 46, 47, 54, 55, 58, 61, 114, 121, 136, 139], "2000": [6, 18, 22, 30, 34, 43, 58, 70, 127], "improv": [6, 10, 11, 21, 22, 23, 24, 25, 26, 30, 32, 34, 35, 37, 38, 39, 42, 43, 45, 47, 51, 53, 58, 60, 61, 62, 64, 67, 69, 70, 77, 79, 83, 88, 90, 96, 99, 103, 105, 106, 107, 109, 112, 113, 121, 122, 129, 135, 136], "albert": [6, 120], "spanbert": 6, "span": [6, 8, 50, 58, 77, 83, 128, 131], "distilbert": 6, "lightweight": [6, 72, 105, 113], "knowledg": [6, 7, 15, 22, 25, 32, 34, 42, 46, 52, 58, 60, 61, 77, 79, 80, 98, 106, 113, 116, 121, 127, 138], "distil": [6, 109, 113], "swin": [6, 11, 38], "mae": [6, 32], "autoencod": [6, 58], "cannot": [6, 9, 17, 18, 22, 31, 34, 35, 40, 44, 45, 47, 52, 55, 56, 58, 60, 61, 64, 67, 69, 70, 71, 73, 76, 77, 79, 82, 96, 97, 98, 104, 105, 107, 108, 121, 131, 135, 136, 138], "outfit": [6, 46], "autoregress": [6, 10, 50, 90, 127, 131, 134], "causal": [6, 58, 60, 136], "literatur": [6, 35, 41, 58, 61, 69, 104], "mislead": [6, 61], "proper": [6, 7, 14, 35, 51, 57, 58, 67, 83, 102, 103, 109, 120, 121, 123, 127], "studi": [6, 8, 24, 31, 43, 54, 58, 60, 67, 69, 80, 83, 85, 87, 94, 96, 109, 110, 117, 118, 121, 138], "human": [6, 39, 46, 58, 62, 77, 94, 113], "bart": 6, "concurr": [6, 54, 55], "attempt": [6, 35, 58, 60, 61, 67, 107, 110, 113, 121, 132], "reconstruct": [6, 60], "former": [6, 10, 19, 30, 35, 36, 43, 73, 90, 92, 103, 110, 115], "emphas": [6, 47, 65, 93, 112, 118], "delet": [6, 120], "permut": [6, 42, 62, 64, 73, 82, 85, 91, 108, 118], "latter": [6, 19, 35, 36, 37, 39, 40, 43, 55, 60, 73, 90, 92, 104, 108, 110, 112, 120, 127], "highlight": [6, 69, 72, 86, 94], "multitask": 6, "unif": 6, "comprehens": [6, 77, 83, 84, 112, 113, 131], "ablat": 6, "transfer": [6, 18, 22, 24, 49, 52, 142], "unifi": [6, 35, 58, 113], "consecut": [6, 85, 90, 96, 132, 137], "z": [6, 10, 18, 33, 41, 45, 46, 49, 60, 75, 96, 100, 102, 104, 109, 110, 114, 115, 117, 119, 121, 125, 136, 137], "upper": [6, 19, 20, 21, 25, 29, 30, 39, 41, 44, 45, 52, 54, 55, 61, 75, 112, 121, 132, 135], "rectangl": [6, 20, 61], "triangl": [6, 115, 117], "shown": [6, 10, 11, 18, 19, 21, 22, 23, 25, 26, 30, 32, 36, 37, 40, 41, 49, 58, 60, 64, 83, 88, 98, 104, 127, 130, 139, 141], "prevent": [6, 9, 35, 65, 77, 107, 109, 120, 127, 130], "itself": [6, 8, 9, 15, 46, 47, 51, 57, 58, 64, 70, 73, 74, 76, 80, 101, 102, 103, 108, 117, 121, 130], "futur": [6, 16, 24, 35, 47, 58, 59, 60, 72, 101, 113, 121, 126, 136, 138, 139, 140], "refer": [6, 8, 9, 10, 16, 19, 20, 23, 28, 30, 36, 39, 40, 41, 44, 45, 46, 47, 51, 52, 58, 62, 64, 69, 71, 75, 90, 96, 100, 101, 102, 108, 110, 114, 117, 119, 121, 128, 130, 132, 133], "corrupt": [6, 58, 64, 73, 74, 136], "With": [6, 10, 31, 39, 46, 48, 51, 56, 58, 61, 66, 76, 77, 79, 80, 81, 82, 86, 87, 90, 92, 108, 113, 115, 119, 126, 128, 133, 136], "c4": [6, 37], "coloss": 6, "clean": [6, 34, 35, 58, 62, 113], "crawl": 6, "corpu": [6, 83, 85, 90, 91, 94, 97, 99, 132, 135, 137], "web": [6, 25, 26, 57, 58, 60, 70, 113, 132], "11b": 6, "benchmark": [6, 24, 34, 51, 54, 58, 59, 60, 61, 62, 67, 69, 83, 85, 108], "releas": [6, 13, 34, 58, 62], "switch": [6, 46, 58, 76, 82, 93, 98, 103, 125], "subset": [6, 26, 52, 56, 58, 67, 76, 83, 95, 117, 121], "imagen": [6, 58], "frozen": [6, 90, 140, 141], "xxl": 6, "photorealist": [6, 58], "suggest": [6, 18, 40, 51, 52, 56, 61, 69, 70, 76, 79, 80, 82, 93, 97, 102, 108, 109, 128, 132], "alon": [6, 45, 52, 58, 67, 69, 74, 113], "taken": [6, 11, 18, 22, 28, 41, 43, 46, 48, 58, 60, 64, 67, 69, 74, 76, 80, 93, 113, 121, 139, 141], "sublay": [6, 10], "nowadai": [6, 34, 43, 58], "de": 6, "facto": [6, 73], "leverag": [6, 13, 15, 22, 24, 26, 27, 28, 30, 42, 58, 60, 66, 69, 80, 83, 90, 93, 94, 113, 114, 119, 134, 135], "abund": [6, 34, 58, 67, 90], "unlabel": [6, 19, 58, 60, 61, 67], "pre": [6, 11, 18, 26, 61, 73, 80, 82, 90, 125], "choos": [6, 7, 19, 26, 28, 30, 40, 44, 49, 51, 53, 58, 59, 61, 64, 66, 67, 69, 74, 77, 81, 82, 84, 90, 98, 101, 102, 105, 107, 108, 109, 112, 113, 121, 122, 123, 140, 141], "backbon": [6, 11, 42, 58, 113, 121], "describ": [6, 7, 8, 9, 10, 15, 19, 20, 21, 22, 24, 26, 28, 30, 32, 35, 37, 38, 39, 40, 41, 44, 45, 46, 48, 58, 60, 64, 69, 70, 73, 75, 76, 77, 80, 81, 83, 84, 86, 88, 89, 91, 99, 104, 109, 110, 112, 113, 117, 121, 127, 130, 131, 133, 136, 139, 141], "100": [6, 7, 9, 10, 11, 16, 18, 22, 23, 25, 34, 35, 39, 40, 56, 58, 62, 66, 67, 74, 79, 82, 86, 88, 93, 95, 99, 108, 114, 117, 121, 123, 132, 134, 135, 136], "individu": [6, 10, 13, 15, 17, 30, 34, 35, 41, 58, 60, 70, 76, 80, 85, 88, 91, 94, 97, 102, 114, 117, 121, 136, 137], "adopt": [6, 19, 32, 35, 39, 58, 70, 74, 77, 131, 135], "gb": [6, 31, 58, 108], "promis": [6, 25, 51, 56, 77], "potenti": [6, 19, 47, 51, 58, 60, 65, 69, 71, 77, 80, 87, 109, 113, 130, 133, 141], "computation": [6, 18, 34, 37, 42, 46, 58, 65, 81, 93, 103, 108, 122, 125, 130], "shot": [6, 24, 30, 142], "prefix": [6, 96, 122, 125, 134, 135, 136], "prompt": [6, 18, 57, 82, 128], "categor": [6, 52, 58, 59, 64, 79, 87, 118, 120, 135, 141], "42": [6, 14, 81], "denomin": [6, 65, 66, 122], "largest": [6, 19, 29, 30, 34, 37, 58, 59, 61, 64, 65, 66, 67, 102, 122, 139, 141], "version": [6, 10, 11, 12, 34, 35, 36, 37, 39, 45, 57, 58, 62, 64, 65, 70, 74, 80, 83, 92, 95, 104, 105, 107, 112, 113, 121, 122, 125, 126, 138, 140, 141], "predecessor": [6, 37, 113], "sparser": [6, 38], "300": [6, 11, 28, 31, 34, 95], "rapidli": [6, 13, 48, 67, 74, 77, 80, 105, 107, 109, 112, 115, 121, 125, 136], "did": [6, 15, 18, 26, 34, 35, 45, 46, 48, 51, 55, 58, 59, 60, 70, 71, 79, 95, 102, 112, 113, 121, 136, 137], "disclos": 6, "technic": [6, 28, 32, 35, 58, 60, 97, 101, 109, 113, 116, 133], "report": [6, 18, 34, 46, 51, 54, 55, 58, 59, 61, 66, 67, 72, 79, 83, 121, 136], "By": [6, 8, 14, 15, 18, 27, 28, 29, 31, 34, 35, 39, 40, 41, 43, 44, 45, 46, 47, 49, 58, 59, 61, 62, 65, 66, 67, 70, 74, 75, 76, 85, 86, 91, 104, 105, 109, 110, 113, 117, 118, 119, 121, 125, 130, 135], "contrast": [6, 10, 11, 22, 23, 26, 30, 33, 34, 35, 36, 43, 48, 58, 61, 67, 70, 74, 86, 90, 97, 113, 117, 121, 125, 126, 129, 130], "empir": [6, 10, 11, 35, 36, 47, 58, 59, 61, 67, 69, 84, 90, 107, 110, 121, 132], "led": [6, 35, 38, 39, 58, 102], "smoothli": 6, "tandem": 6, "bottleneck": [6, 30, 34, 39, 47, 62, 120], "petaflop": 6, "dai": [6, 17, 34, 43, 46, 52, 54, 58, 59, 60, 61, 64, 69, 70, 77, 106, 117, 131, 134, 136], "matter": [6, 9, 34, 35, 37, 41, 43, 52, 58, 67, 69, 74, 78, 80, 81, 94, 105, 107, 108, 109, 111, 117, 121, 130, 133], "debat": [6, 35, 69, 76], "enjoi": [6, 9, 10, 43, 58, 85, 87, 109, 121], "small": [6, 11, 12, 18, 22, 25, 26, 27, 29, 32, 34, 35, 36, 41, 44, 46, 47, 48, 49, 52, 58, 61, 64, 66, 67, 69, 71, 74, 75, 76, 77, 79, 82, 83, 92, 95, 101, 102, 104, 105, 107, 108, 109, 112, 113, 115, 121, 122, 132, 135, 139], "fewer": [6, 27, 29, 32, 42, 43, 46, 47, 48, 56, 61, 64, 65, 67, 70, 77, 86, 90, 128, 132, 140], "trend": [6, 35, 58, 61], "deviat": [6, 14, 21, 22, 26, 34, 35, 47, 48, 51, 61, 69, 71, 73, 74, 79, 100, 103, 108, 119, 121, 125, 127], "curv": [6, 48, 54, 55, 56, 65, 71, 107, 115, 121], "count": [6, 19, 40, 69, 85, 87, 91, 92, 93, 97, 102, 108, 121, 128, 132, 136, 137], "hypothesi": [6, 61, 67, 77, 85, 86], "seri": [6, 19, 23, 30, 37, 41, 42, 49, 50, 58, 61, 77, 113, 115, 127, 131], "530": 6, "ture": [6, 58], "nlg": 6, "270": 6, "280": 6, "gopher": 6, "inherit": [6, 12, 15, 31, 72, 85, 124, 134], "budget": [6, 34, 52, 56, 58], "chinchilla": 6, "substanti": [6, 54, 55, 60, 67, 74], "70": [6, 79], "trillion": [6, 61], "outperform": [6, 11, 34, 51, 52, 61, 67, 76, 108], "emphasi": [6, 58], "palm": 6, "pathwai": 6, "540": [6, 99], "780": 6, "big": [6, 18, 58, 61, 65, 67, 77, 94, 95, 113, 117, 140, 141], "bench": 6, "Its": [6, 22, 27, 30, 39, 51, 91, 97, 110, 125, 127], "roughli": [6, 44, 49, 51, 52, 58, 61, 75, 113, 122, 136, 137, 140], "multilingu": 6, "capabl": [6, 34, 37, 49, 58, 67, 73, 77, 80, 83, 108, 122, 136, 139], "minerva": 6, "galactica": 6, "quantit": [6, 76, 79], "scientif": [6, 16, 35, 61, 67, 77, 119], "opt": [6, 54, 55], "bloom": 6, "falcon": 6, "democrat": [6, 43], "infer": [6, 34, 35, 37, 48, 49, 50, 52, 58, 67, 69, 83, 84, 90, 108, 110, 113, 119, 121, 127, 142], "llama": 6, "abil": [6, 13, 22, 23, 35, 39, 40, 49, 58, 64, 67, 71, 114, 116, 121, 123, 136, 140], "inher": [6, 34, 35, 58, 82, 102, 103, 107], "instruct": [6, 34, 38, 57, 70, 106, 118, 132, 135], "held": [6, 38, 48, 58, 73, 77], "feedback": [6, 58, 60, 113], "instructgpt": 6, "intent": [6, 58, 65, 121], "chatgpt": [6, 58], "respons": [6, 34, 41, 58, 60, 64, 107, 121, 127, 140], "debug": [6, 16, 58, 73, 113], "creativ": [6, 12, 15, 46, 58, 113, 115], "partial": [6, 58, 60, 75, 98, 100, 104, 105, 113, 114, 116, 121, 130], "autom": [6, 39, 52, 58, 60, 62, 70, 71, 113], "known": [6, 10, 19, 34, 35, 39, 45, 46, 47, 48, 50, 52, 58, 60, 64, 67, 69, 73, 74, 77, 85, 103, 109, 112, 114, 117, 121, 127, 137, 140, 141], "offer": [6, 8, 13, 18, 34, 35, 38, 39, 40, 44, 58, 70, 74, 76, 79, 82, 94, 103, 108, 113, 114, 117, 118, 121, 125], "excit": [6, 8, 38, 58, 64, 69, 104, 137], "prospect": 6, "formul": [6, 46, 49, 58, 59, 60, 69, 113, 121, 128, 139, 141], "induc": [6, 49], "desir": [6, 8, 35, 39, 43, 45, 58, 61, 74, 86, 105, 107, 108, 109, 111, 113, 114, 117, 122, 130, 132, 135, 136], "chain": [6, 15, 33, 36, 43, 58, 75, 114, 116, 121, 125, 130, 135, 136], "thought": [6, 27, 28, 35, 39, 47, 58, 69, 90, 113, 117, 131, 137], "elicit": 6, "solv": [6, 37, 39, 47, 58, 60, 61, 64, 66, 67, 69, 71, 80, 102, 103, 104, 109, 113, 117, 121, 133, 138], "mathemat": [6, 7, 9, 15, 35, 36, 38, 39, 46, 58, 61, 64, 65, 66, 69, 74, 75, 76, 77, 80, 82, 93, 104, 109, 110, 113, 115, 117, 119, 121, 122, 125, 127, 130, 133, 139, 141], "commonsens": 6, "diversifi": 6, "sub": [6, 16, 30, 52, 54, 85, 121, 137], "decent": 6, "higher": [6, 9, 11, 19, 26, 34, 36, 46, 49, 55, 58, 61, 64, 67, 75, 79, 80, 92, 96, 97, 105, 107, 109, 110, 112, 114, 117, 121, 129, 132], "lean": 6, "toward": [6, 11, 47, 49, 55, 61, 62, 63, 64, 69, 71, 74, 75, 77, 87, 90, 103, 107, 121, 130, 135, 136], "nonetheless": [6, 8, 34, 35, 40, 46, 58, 62, 64, 65, 67, 69, 73, 80, 81, 106, 107, 109, 110, 132], "extend": [6, 11, 25, 26, 44, 52, 58, 61, 64, 65, 68, 72, 81, 91, 96, 113, 136], "flamingo": 6, "dall": [6, 58], "systemat": [6, 46, 53], "parti": 6, "fidel": [6, 53, 103, 142], "rich": [6, 42, 46, 58, 69, 80, 93, 94, 104, 114], "350m": 6, "750m": 6, "3b": 6, "20b": 6, "possibl": [6, 9, 10, 11, 19, 22, 27, 29, 34, 35, 41, 42, 43, 44, 46, 47, 48, 52, 55, 58, 60, 61, 62, 64, 66, 67, 69, 71, 77, 80, 82, 84, 86, 91, 93, 96, 102, 103, 108, 112, 113, 118, 119, 121, 122, 129, 132, 133, 135, 136, 139, 141], "ask": [6, 35, 45, 58, 60, 70, 74, 79, 80, 113, 117, 121, 132], "throughout": [6, 15, 17, 19, 20, 34, 35, 38, 43, 57, 58, 60, 67, 69, 72, 73, 74, 76, 77, 78, 79, 82, 100, 108, 112, 113, 115, 120, 130, 131, 136, 137], "combin": [7, 8, 9, 15, 19, 25, 28, 36, 37, 40, 41, 45, 46, 47, 48, 50, 52, 58, 64, 65, 69, 70, 71, 72, 74, 77, 84, 86, 94, 103, 109, 121, 123, 125, 126, 132, 137], "variou": [7, 11, 14, 15, 16, 17, 20, 23, 24, 27, 28, 34, 35, 36, 37, 48, 51, 58, 60, 62, 67, 72, 76, 79, 83, 84, 90, 94, 111, 113, 117, 118, 119, 121, 127, 139], "benefici": [7, 35, 82, 107, 109, 110], "jointli": [7, 30, 34, 40, 58, 64, 76, 80, 81, 86, 121], "subspac": [7, 10, 58, 104], "linearli": [7, 9, 11, 69, 70, 71, 80, 89, 102, 111, 112], "formal": [7, 46, 56, 58, 60, 67, 69, 76, 80, 90, 102, 104, 113, 115, 116, 117, 122, 123, 130, 135], "d_q": 7, "d_k": 7, "d_v": 7, "w_i": [7, 49, 67, 69, 74, 93, 97, 117], "p_v": 7, "p_q": 7, "p_k": 7, "w_o": [7, 89, 98], "p_o": 7, "bmatrix": [7, 9, 47, 48, 109, 117], "h_1": [7, 30, 76], "vdot": [7, 48, 117, 136], "h_h": 7, "sophist": [7, 34, 51, 52, 54, 58, 80, 117, 129, 130], "express": [7, 16, 28, 30, 35, 39, 40, 41, 45, 46, 48, 49, 58, 59, 61, 64, 67, 69, 70, 74, 77, 80, 82, 93, 98, 104, 109, 115, 117, 119, 121, 122, 123, 129, 130, 133, 140], "avoid": [7, 13, 28, 31, 39, 44, 52, 54, 55, 60, 62, 64, 65, 66, 69, 71, 75, 76, 79, 90, 105, 113, 117, 126, 128, 130, 134, 139], "growth": [7, 18, 36, 58], "parametr": [7, 32, 36, 39, 46, 58, 60, 63, 64, 68, 69, 74, 77, 80, 82, 105, 121, 133], "multiheadattent": [7, 9, 10, 11], "num_head": [7, 9, 10, 11, 90, 92], "transpose_qkv": 7, "copi": [7, 21, 22, 25, 79, 91, 108, 113, 119, 125], "output_concat": 7, "transpose_output": 7, "transposit": [7, 24, 75, 117], "revers": [7, 25, 33, 58, 75, 121, 136, 137], "num_queri": [7, 9], "num_kvpair": 7, "manipul": [7, 10, 16, 19, 46, 48, 58, 60, 64, 73, 74, 113, 114, 115, 116, 117, 137, 142], "prune": 7, "speed": [7, 10, 18, 34, 37, 43, 52, 54, 56, 60, 68, 71, 81, 97, 108, 109, 112, 113, 117, 122, 123, 125, 135], "measur": [7, 18, 19, 25, 26, 28, 43, 46, 47, 58, 59, 60, 61, 64, 67, 69, 71, 72, 74, 76, 77, 78, 80, 81, 83, 85, 93, 108, 117, 120, 121, 129, 131, 132], "being": [8, 10, 19, 33, 38, 39, 47, 49, 51, 58, 60, 61, 64, 69, 73, 79, 80, 82, 83, 89, 90, 93, 96, 97, 98, 107, 108, 109, 119, 121, 125, 127, 130, 138], "imagenet": [8, 11, 15, 21, 22, 24, 28, 34, 37, 38, 39, 58, 62, 67, 107, 142], "224": [8, 21, 22, 26, 28, 31, 34, 36, 37, 40, 54], "pixel": [8, 19, 21, 22, 23, 25, 27, 28, 30, 31, 33, 34, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 58, 62, 64, 66, 76, 80, 81, 88, 131], "truli": [8, 37, 43, 46, 64, 67, 69, 77, 78, 80, 122], "vari": [8, 19, 21, 22, 26, 27, 29, 32, 35, 38, 47, 48, 49, 58, 61, 67, 70, 74, 87, 97, 104, 121, 124, 129, 130, 131, 136, 137], "difficult": [8, 18, 27, 32, 35, 46, 52, 54, 58, 59, 60, 61, 64, 65, 67, 69, 71, 80, 81, 102, 104, 112, 113, 115, 129, 132, 136], "everyth": [8, 18, 45, 46, 50, 58, 61, 66, 81, 113, 137], "databas": [8, 58, 113, 120], "mathcal": [8, 9, 19, 35, 39, 40, 47, 48, 49, 52, 56, 61, 64, 69, 71, 74, 76, 89, 93, 96, 98, 100, 102, 104, 105, 107, 108, 109, 111, 112, 121, 122, 133, 135, 139, 140, 141], "zhang": [8, 113], "aston": [8, 58, 64], "lipton": 8, "zachari": 8, "li": [8, 30, 32, 35, 51, 65, 77, 83, 88, 101, 112, 113], "mu": [8, 35, 47, 48, 49, 58, 60, 61, 69, 73, 79, 121], "smola": 8, "alex": [8, 34, 58], "hu": [8, 113], "rachel": 8, "wer": 8, "brent": 8, "exact": [8, 16, 35, 47, 48, 58, 61, 69, 102, 104, 105, 119, 121], "record": [8, 48, 51, 58, 69, 77, 79, 108, 114, 117, 120, 121, 128, 131, 140, 141], "approxim": [8, 30, 35, 41, 47, 49, 52, 56, 58, 60, 61, 64, 65, 69, 77, 94, 97, 102, 104, 105, 108, 110, 130, 132, 133, 136, 139, 140, 142], "retriev": [8, 55, 58, 85, 131], "teach": [8, 58, 71, 113], "u": [8, 12, 14, 15, 18, 23, 28, 29, 36, 37, 39, 40, 41, 43, 46, 47, 48, 49, 50, 51, 52, 54, 56, 58, 60, 61, 64, 66, 67, 69, 70, 72, 73, 74, 75, 76, 79, 80, 81, 82, 85, 89, 93, 96, 98, 99, 102, 103, 104, 105, 106, 108, 109, 112, 113, 114, 115, 117, 119, 121, 122, 125, 129, 130, 132, 135, 136, 137, 138, 139, 140, 141], "execut": [8, 13, 16, 34, 51, 52, 54, 57, 58, 64, 67, 71, 108, 113, 114, 137], "here": [8, 9, 10, 11, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 39, 40, 41, 44, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 60, 61, 62, 64, 65, 66, 67, 69, 71, 74, 75, 77, 79, 80, 82, 85, 91, 93, 95, 97, 101, 102, 103, 104, 105, 107, 109, 110, 112, 114, 115, 117, 119, 120, 121, 122, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 141], "wasn": 8, "concept": [8, 13, 15, 35, 39, 48, 51, 56, 58, 74, 78, 105, 113, 115, 117, 119, 121, 131, 133, 138, 139], "cover": [8, 16, 19, 21, 24, 25, 31, 34, 35, 38, 45, 46, 47, 64, 65, 69, 71, 77, 79, 84, 94, 95, 107, 109, 113, 117, 128, 129, 131, 136], "stackrel": [8, 35, 39, 60, 64, 65, 82, 93, 100, 102, 104, 105, 108, 109, 112, 121, 140], "_m": [8, 60, 86, 117], "convex": [8, 34, 35, 47, 64, 102, 103, 105, 106, 107, 110, 111, 125, 142], "cone": [8, 35], "geq": [8, 19, 61, 64, 104, 112, 121, 130], "exactli": [8, 11, 40, 45, 47, 52, 58, 60, 67, 69, 71, 74, 77, 80, 81, 102, 112, 121, 125, 139], "resort": [8, 58], "softmax": [8, 15, 21, 26, 30, 32, 43, 45, 52, 60, 61, 63, 68, 80, 81, 82, 83, 86, 94, 98, 104, 129, 132, 133, 140, 142], "multinomi": [8, 118, 121], "readili": [8, 58], "never": [8, 15, 34, 35, 58, 60, 61, 64, 65, 67, 69, 80, 82, 90, 104, 110, 121, 130, 135, 136], "bulk": 8, "outlin": [8, 20, 35, 58, 105, 135], "exposit": [8, 75, 113, 131], "famili": [8, 42, 46, 58, 62, 64], "concis": [8, 19, 32, 38, 39, 59, 63, 64, 68, 71, 72, 78, 101, 103, 106, 126, 131, 142], "arbitrarili": [8, 31, 58, 67, 77, 85, 91, 121, 136, 140], "particularli": [8, 28, 44, 48, 64, 80, 102, 104, 107, 108, 112, 121, 125, 132, 136, 137], "rememb": [8, 35, 57, 58, 60, 111, 114, 117, 125, 141], "varieti": [8, 12, 34, 37, 47, 49, 50, 58, 59, 60, 72, 79, 80, 82, 94, 107, 112, 113, 116, 119, 138], "heatmap": 8, "sharex": 8, "row_ax": 8, "row_matric": 8, "quick": [8, 59, 72, 105, 109, 112, 118, 127], "saniti": [8, 12, 62, 79], "ey": [8, 31, 34, 47], "abstract": [8, 13, 15, 27, 49, 58, 73, 81, 104, 139], "mysteri": [8, 77, 115], "aris": [8, 35, 36, 40, 53, 58, 60, 66, 67, 69, 71, 103, 106, 108, 120, 122, 130, 131, 140, 141], "help": [8, 22, 28, 44, 47, 48, 50, 51, 58, 60, 68, 71, 73, 74, 75, 77, 79, 80, 83, 90, 96, 102, 104, 105, 110, 113, 118, 120, 121, 125, 126, 127, 132, 134], "themselv": [8, 17, 34, 40, 41, 42, 58, 113, 114, 115, 136], "associ": [8, 9, 15, 34, 41, 47, 48, 49, 58, 60, 61, 62, 64, 69, 75, 80, 82, 86, 100, 102, 110, 112, 113, 115, 117, 121, 133, 137, 141], "reimplement": [8, 15, 113, 134], "nabla_": [8, 33, 100, 115, 140], "cov": [8, 47, 48, 49, 100, 121], "search": [8, 30, 34, 38, 51, 53, 55, 56, 57, 60, 69, 83, 95, 126, 129, 135, 136, 142], "engin": [8, 18, 34, 41, 43, 44, 58, 60, 64, 65, 80, 83, 108, 113, 118, 135], "own": [9, 12, 15, 35, 38, 39, 53, 58, 59, 61, 64, 65, 70, 71, 72, 73, 76, 82, 104, 107, 108, 113, 117, 121, 123, 131, 132, 136, 140], "full": [9, 19, 25, 26, 35, 37, 39, 42, 47, 54, 55, 56, 58, 69, 71, 72, 105, 108, 110, 111, 112, 113, 114, 136, 138, 140], "appropri": [9, 18, 37, 43, 46, 57, 58, 60, 61, 67, 69, 70, 75, 80, 101, 102, 107, 108, 111, 117, 121, 129, 130, 137, 138], "unlik": [9, 10, 16, 21, 26, 34, 45, 46, 47, 58, 60, 61, 69, 77, 93, 98, 103, 122, 128, 132, 133], "elsewher": [9, 115], "intra": 9, "snippet": [9, 10, 15, 33, 43, 58, 73, 90, 97, 113, 114, 117, 119, 128, 133], "map": [9, 17, 21, 25, 27, 30, 31, 32, 33, 36, 37, 39, 40, 42, 43, 45, 46, 51, 52, 58, 64, 66, 80, 88, 96, 97, 98, 99, 104, 105, 108, 115, 117, 119, 121, 124, 127, 128, 130, 132, 137], "easier": [9, 19, 23, 25, 26, 27, 28, 34, 39, 44, 47, 58, 62, 65, 70, 74, 102, 104, 117, 121, 127, 136], "regard": [9, 35, 41, 46, 60, 66, 104, 105, 112, 113, 124, 129, 130], "similarli": [9, 11, 18, 23, 26, 35, 43, 46, 49, 58, 61, 64, 65, 74, 77, 82, 88, 92, 100, 101, 113, 115, 119, 135, 140], "gram": [9, 28, 85, 88, 89, 94, 96, 97, 129, 133, 137], "knd": 9, "hierarch": [9, 27, 28, 34, 45, 58, 94, 131], "_5": 9, "recept": [9, 27, 32, 42, 45], "field": [9, 11, 20, 24, 27, 29, 31, 32, 34, 38, 42, 45, 52, 58, 69, 80, 87, 113, 120, 121, 128, 136], "nd": [9, 117], "therefor": [9, 10, 15, 22, 26, 27, 30, 32, 33, 34, 39, 47, 49, 67, 72, 75, 93, 104, 105, 112, 122, 130, 132, 133, 139, 140], "shortest": [9, 10, 58], "quadrat": [9, 11, 34, 39, 64, 69, 74, 86, 102, 105, 111, 117, 121], "prohibit": [9, 47, 64, 105, 114, 122], "slow": [9, 18, 30, 37, 47, 62, 69, 97, 103, 105, 107, 108, 109, 121, 130, 135], "ditch": 9, "favor": [9, 64, 108], "preserv": [9, 10, 28, 30, 36, 42, 44, 61, 64, 80, 86], "realli": [9, 36, 39, 40, 48, 49, 58, 60, 61, 67, 71, 74, 85, 101, 105, 107, 110, 112, 121, 132, 136, 140], "know": [9, 12, 14, 16, 18, 19, 20, 21, 32, 35, 39, 41, 44, 46, 48, 49, 58, 60, 61, 62, 64, 65, 66, 67, 70, 71, 74, 75, 79, 80, 81, 82, 85, 97, 104, 105, 114, 117, 118, 119, 120, 121, 132, 133, 136, 138, 139, 140, 141], "priori": [9, 35, 46, 49, 61, 73, 79, 114], "scheme": [9, 11, 19, 60, 61, 82], "sine": 9, "cosin": [9, 95, 98, 99, 104, 105, 117], "th": [9, 10, 19, 52, 60, 69, 79, 89, 97, 99, 100, 105, 115, 117, 119, 123, 128, 129, 135, 136, 137, 141], "2j": 9, "p_": [9, 40, 44, 45, 60, 93, 110], "10000": [9, 25, 52, 62, 69, 71, 85, 90, 97, 115, 121, 122, 132], "co": [9, 22, 26, 72, 76, 91, 94, 95, 97, 99, 104, 105, 107, 110, 114, 136], "glanc": [9, 136], "trigonometr": [9, 136], "weird": [9, 60, 77], "explan": [9, 35, 47, 64, 72, 113, 126], "positionalencod": [9, 10], "max_len": [9, 90, 91, 92, 97, 99], "offset": [9, 27, 30, 32, 35, 46, 69, 71, 104], "due": [9, 12, 15, 21, 22, 30, 32, 34, 35, 37, 38, 43, 45, 46, 52, 55, 58, 60, 61, 65, 69, 70, 80, 81, 86, 89, 90, 97, 102, 103, 104, 105, 107, 108, 109, 111, 112, 121, 127, 130, 134], "encoding_dim": 9, "32": [9, 15, 21, 23, 25, 26, 29, 32, 34, 36, 37, 39, 43, 51, 52, 54, 55, 56, 58, 62, 64, 69, 73, 88, 108, 117, 123, 125, 127, 134, 135], "60": [9, 20, 34, 54, 55, 58, 62, 79, 87, 97, 137], "pos_encod": [9, 10], "col": 9, "monoton": [9, 64, 77, 80, 104], "decreas": [9, 39, 48, 56, 64, 65, 67, 74, 77, 80, 101, 102, 105, 107, 108, 109, 111, 112, 115, 116], "lowest": [9, 34, 52, 55, 64, 104], "03b": 9, "010": [9, 102, 109, 111], "011": [9, 101, 103, 111], "101": [9, 55, 110], "110": [9, 83, 92], "111": [9, 110, 128], "heat": [9, 60], "blue": [9, 19, 20, 22, 40, 46, 47, 48, 58, 62, 113, 117], "besid": [9, 20, 22, 30, 31, 32, 48, 60, 74, 75, 82, 83, 88, 93, 95, 96, 107, 110, 124, 130], "delta": [9, 40, 46, 49, 61, 79, 101, 102], "omega_j": 9, "place": [9, 11, 25, 29, 35, 45, 58, 60, 61, 64, 69, 70, 71, 74, 77, 79, 80, 91, 103, 104, 108, 113, 114, 119, 121, 130, 136, 138], "inject": [9, 35, 58, 76, 108, 112], "stack": [9, 10, 11, 16, 19, 20, 26, 30, 37, 38, 39, 40, 43, 46, 80, 85, 91, 117, 119, 123, 126, 134, 135, 136], "issu": [9, 17, 21, 31, 35, 39, 44, 46, 47, 52, 58, 60, 65, 74, 78, 82, 96, 98, 102, 103, 109, 111, 114, 119], "appeal": [10, 61, 64, 82, 104, 130], "sole": [10, 58, 67], "pervas": [10, 39, 58], "panda": [10, 25, 29, 79, 91, 113, 120], "pd": [10, 25, 29, 79, 91, 113, 120], "overal": [10, 53, 54, 56, 77, 82, 103, 109, 121, 123], "compos": [10, 12, 22, 23, 25, 26, 28, 34, 36, 58, 62, 69, 71, 73, 90, 108, 115, 117, 121, 136, 137], "overview": [10, 32, 44, 58, 64, 77, 107, 113], "around": [10, 32, 34, 39, 41, 44, 46, 52, 58, 60, 107, 119, 136], "feasibl": [10, 34, 39, 52, 84, 105, 109], "rest": [10, 19, 22, 30, 31, 41, 56, 58, 61, 72, 76, 79, 90, 96, 108, 119, 127, 132], "ffn_num_output": 10, "positionwiseffn": 10, "ffn_num_input": [10, 90, 92], "ffn_num_hidden": [10, 90, 92], "dense1": [10, 11], "dense2": [10, 11], "innermost": [10, 19, 20, 32], "ffn": [10, 11], "0411104": 10, "229808": 10, "378752": 10, "421943": 10, "244533": 10, "239171": 10, "usual": [10, 19, 20, 22, 23, 28, 29, 30, 31, 35, 46, 52, 55, 58, 60, 61, 65, 67, 69, 71, 85, 90, 98, 102, 104, 110, 112, 113, 117, 118, 121, 122, 137], "ln": [10, 35, 115], "layernorm": [10, 11, 90], "bn": [10, 35], "nbatch": 10, "99998": 10, "addnorm": 10, "norm_shap": [10, 11], "add_norm": 10, "essenti": [10, 21, 27, 40, 45, 47, 48, 49, 58, 77, 102, 107, 108, 111, 117, 130], "assembl": [10, 15, 37, 43, 58, 113], "transformerencoderblock": [10, 90], "block": [10, 11, 13, 14, 15, 18, 28, 35, 38, 40, 43, 47, 57, 61, 72, 92, 108, 113, 115], "use_bia": [10, 11], "addnorm1": 10, "addnorm2": 10, "24": [10, 11, 37, 39, 47, 54, 55, 58, 64, 82, 92, 117, 136, 137], "encoder_blk": [10, 11], "48": [10, 11, 37], "num_blk": [10, 11, 90, 92], "transformerencod": [10, 90], "200": [10, 22, 23, 31, 44, 58, 74, 86, 108, 117], "transformerdecoderblock": 10, "dec_valid_len": 10, "attention1": 10, "attention2": 10, "addnorm3": 10, "key_valu": 10, "tile": [10, 19, 129], "x2": [10, 17, 20, 49, 102, 105, 109, 111, 112], "y2": [10, 17, 20, 32, 40], "facilit": [10, 25, 61, 72, 79, 91, 108, 113], "decoder_blk": 10, "transformerdecod": 10, "0003": [10, 121], "mouill\u00e9": 10, "658": 10, "enc_attention_weight": 10, "separ": [10, 17, 21, 34, 35, 39, 40, 45, 58, 69, 72, 76, 77, 79, 81, 83, 86, 88, 90, 92, 97, 108, 111, 113, 114, 120, 128, 129, 134, 135], "fill": [10, 20, 44, 48, 56, 58, 60, 87, 113, 136], "possibli": [10, 34, 35, 58, 60, 61, 69, 70, 73, 77, 80, 82, 97, 105, 107, 119, 121, 136], "dec_attention_weights_2d": 10, "attn": 10, "dec_attention_weights_fil": 10, "datafram": [10, 25, 79], "fillna": [10, 79, 120], "dec_self_attention_weight": 10, "dec_inter_attention_weight": 10, "discov": [10, 43, 49, 58, 60, 64, 67, 69, 77, 96, 117], "deeper": [10, 13, 26, 34, 35, 36, 37, 39, 40, 41, 45, 46, 61, 67, 69, 75, 80, 94, 106, 109], "challeng": [10, 34, 37, 38, 39, 43, 51, 52, 58, 60, 61, 62, 64, 69, 72, 76, 77, 80, 81, 106, 113, 131, 136], "face": [10, 52, 58, 60, 61, 65, 67, 82, 87, 102, 109, 115, 117, 120, 126, 127, 131], "survei": [10, 28, 80, 112, 113], "spark": 11, "immens": 11, "interest": [11, 15, 19, 20, 23, 28, 30, 32, 34, 35, 44, 49, 51, 52, 54, 58, 61, 64, 66, 67, 69, 75, 77, 80, 82, 102, 109, 112, 113, 114, 117, 121, 128, 131, 135, 136, 141], "commun": [11, 34, 46, 58, 64, 94, 113, 131], "hard": [11, 25, 52, 58, 59, 61, 64, 69, 77, 80, 86, 90, 91, 110, 112, 122, 132, 135], "hardwar": [11, 13, 41, 58, 72, 81, 113], "acceler": [11, 34, 35, 37, 39, 45, 55, 64, 69, 79, 82, 87, 103, 109, 119, 132, 139], "theoret": [11, 35, 47, 58, 60, 61, 67, 77, 82, 102, 106, 112, 113, 121], "behav": [11, 12, 35, 58, 64, 69, 72, 73, 77, 80, 82, 102, 105, 109, 110, 112, 117, 121, 129, 137, 138], "low": [11, 13, 14, 34, 35, 37, 58, 60, 67, 69, 73, 77, 79, 80, 97, 117, 121, 123, 135], "resolut": [11, 34, 37, 39, 40, 44, 45, 46, 58, 62, 67, 80, 82, 90, 131], "vit": 11, "margin": [11, 34, 35, 47, 48, 60, 121], "game": [11, 34, 46, 58, 60, 77, 113, 139, 140], "changer": [11, 34], "stem": [11, 37, 104, 126, 130], "patchifi": 11, "bodi": [11, 31, 37, 58, 71, 77, 80, 104], "nine": [11, 41, 90, 136, 137], "ten": [11, 15, 22, 27, 29, 34, 35, 44, 46, 52, 56, 58, 61, 113, 121, 122, 137], "height": [11, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 49, 61, 62, 88, 105, 115, 117, 121], "hw": [11, 27, 28], "cp": 11, "patchembed": 11, "img_siz": 11, "96": [11, 34, 36, 37, 39, 40, 54, 55, 93], "patch_siz": 11, "_make_tupl": 11, "num_patch": 11, "conv": [11, 33, 88], "patch_emb": 11, "gelu": [11, 80, 90], "smoother": [11, 32, 35, 102], "vitmlp": 11, "mlp_num_input": 11, "mlp_num_hidden": 11, "mlp_num_output": 11, "dropout1": 11, "dropout2": 11, "post": [11, 19, 58, 61, 73, 109, 113, 132], "vitblock": 11, "ln1": 11, "ln2": 11, "straightforward": [11, 41, 44, 55, 61, 66, 75, 77, 83, 90, 95, 101, 103, 105, 107, 109, 111, 114, 117, 122, 129, 130, 131, 136], "emb_dropout": 11, "blk_dropout": 11, "patch_embed": 11, "cls_token": 11, "pos_embed": [11, 90], "temp_cl": 11, "broadcast_to": 11, "2048": 11, "fashionmnist": [11, 34, 35, 36, 37, 39, 43, 51, 52, 54, 55, 62, 65, 66, 76, 81], "notic": [11, 15, 26, 40, 48, 58, 59, 70, 72, 75, 79, 98, 109, 119, 120, 121, 136, 137, 141], "lack": [11, 34, 46, 48, 56, 58, 65, 111, 113, 115, 136], "principl": [11, 32, 35, 46, 52, 58, 60, 61, 67, 69, 77, 106, 112, 113, 115, 129, 130, 136, 138], "pictur": [11, 43, 58, 60, 61, 67, 69, 77, 94, 141], "intrins": [11, 51, 73, 77, 121], "introduct": [11, 12, 20, 23, 34, 47, 50, 61, 67, 72, 110, 113, 116, 117, 142], "deit": 11, "reinstat": [11, 17], "invent": [12, 13, 35, 41, 46, 58, 64, 65, 69, 70, 76, 77, 82], "loop": [12, 15, 16, 28, 34, 41, 52, 54, 58, 60, 62, 66, 69, 70, 71, 74, 81, 92, 114, 130, 135], "program": [12, 15, 18, 34, 58, 69, 70, 72, 80, 113, 114, 117, 121, 136, 138], "sooner": 12, "familiar": [12, 17, 28, 29, 49, 65, 72, 77, 117, 130, 136], "centeredlay": 12, "subtract": [12, 22, 35, 65, 69, 100, 119, 135], "propag": [12, 13, 16, 21, 27, 28, 30, 32, 33, 36, 39, 40, 41, 45, 52, 76, 78, 82, 114, 124, 130, 131, 142], "intend": [12, 47, 65, 84, 121], "incorpor": [12, 15, 17, 46, 48, 58, 60, 67, 69, 79, 121, 125, 129, 133, 136], "send": [12, 108, 138], "quantiz": 12, "39698e": 12, "09": 12, "built": [12, 13, 17, 38, 41, 45, 58, 62, 65, 66, 69, 70, 71, 72, 73, 77, 81, 90, 107, 109, 117, 119, 127], "housekeep": [12, 15], "govern": [12, 35, 47, 58, 69, 109, 121, 127], "access": [12, 13, 14, 15, 19, 31, 32, 43, 54, 56, 57, 58, 60, 61, 65, 67, 69, 70, 72, 73, 78, 85, 91, 102, 108, 113, 114, 117, 119, 121, 129, 140], "routin": [12, 35, 47, 58, 74, 102, 115, 119, 120], "bake": [12, 73], "in_unit": 12, "mylinear": 12, "161859": 12, "68987": 12, "18379": 12, "14518": 12, "412968": 12, "185595": 12, "550684": 12, "01255": 12, "641095": 12, "333075": 12, "41537": 12, "06249": 12, "552186": 12, "21545": 12, "221213": 12, "99846": 12, "1563": 12, "25294": 12, "33314": 12, "onc": [12, 15, 18, 35, 48, 51, 54, 55, 56, 58, 60, 61, 65, 67, 70, 71, 72, 74, 75, 77, 105, 108, 110, 112, 113, 114, 117, 119, 121, 122, 129, 135], "92416": 12, "flexibl": [12, 13, 15, 35, 39, 40, 47, 49, 51, 58, 61, 122, 127, 136], "invok": [12, 15, 17, 19, 25, 28, 32, 37, 46, 51, 60, 62, 65, 69, 70, 72, 75, 81, 85, 91, 92, 102, 107, 115, 117, 118, 119, 121, 135], "y_k": 12, "w_": [12, 64, 69, 82, 98, 130], "ijk": [12, 117], "x_j": [12, 47, 48, 49, 69, 82, 131], "fourier": [12, 49, 50, 64], "coeffici": [12, 35, 46, 79, 100, 111, 115, 129], "alongsid": [13, 48, 70], "giant": [13, 58, 135], "softwar": [13, 16, 58, 113, 117], "indispens": [13, 23, 35], "role": [13, 38, 39, 47, 52, 58, 60, 82, 83, 90, 104, 106, 113, 137], "pathbreak": 13, "theano": [13, 34, 58, 70], "2007": 13, "enabl": [13, 32, 34, 35, 43, 47, 48, 58, 69, 81, 94, 106, 115, 140, 141], "prototyp": [13, 58, 60, 105, 127], "repetit": [13, 51, 54, 70, 113, 121], "recycl": [13, 67], "maintain": [13, 35, 56, 58, 61, 67, 72, 82, 101, 102, 109, 113, 136, 141], "modif": [13, 37, 54, 58, 73, 91, 137], "evolv": [13, 39, 54, 61, 76, 77, 107, 121, 136, 139, 140], "coars": 13, "semiconductor": 13, "went": [13, 37, 90, 95, 105, 121], "transistor": 13, "logic": [13, 34, 36, 58, 85, 86, 90, 113, 119, 132, 133], "circuit": [13, 58], "artifici": [13, 29, 34, 58, 69, 73, 80, 82, 90, 97], "neuron": [13, 15, 58, 69, 76, 78, 80, 81, 82, 127], "conceiv": [13, 58, 67], "whole": [13, 34, 35, 38, 45, 46, 49, 58, 69, 119, 132], "coarser": [13, 45, 121], "ramp": [13, 112, 117], "api": [13, 25, 26, 31, 33, 35, 53, 54, 58, 62, 64, 65, 70, 71, 72, 73, 76, 80, 81, 101, 113, 123, 125, 127, 134, 142], "roll": [13, 104, 109, 121], "effortlessli": [13, 58], "fast": [13, 18, 24, 32, 34, 40, 41, 60, 62, 69, 77, 96, 108, 112, 119], "upon": [13, 15, 34, 35, 38, 46, 51, 58, 64, 69, 72, 74, 80, 120, 121, 129, 131, 139, 140, 141], "peel": 13, "curtain": 13, "dig": 13, "disk": [13, 16, 17, 73, 77], "dramat": [13, 34, 46, 69, 74, 102, 121, 136], "speedup": [13, 69, 97], "user": [13, 16, 18, 22, 28, 51, 52, 54, 55, 56, 57, 58, 60, 64, 65, 69, 79, 113, 122, 135, 139, 140], "reap": [13, 135], "matur": [13, 113], "yourself": [13, 39, 52, 58, 66, 77], "manag": [13, 58, 67, 77, 87, 107, 113, 121, 142], "ti": [13, 40, 82, 140], "devic": [13, 17, 26, 34, 35, 43, 60, 67, 106, 108, 118, 129, 135], "properli": [14, 34, 41, 46, 70, 93, 104, 105, 132], "protocol": [14, 60], "uniformli": [14, 19, 27, 51, 97, 108, 112, 132, 140], "preset": 14, "std": [14, 21, 25, 28, 31, 69, 70, 79, 108], "bias_fn": [14, 70, 108], "00366156": 14, "00131906": 14, "00550299": 14, "00708594": 14, "certain": [14, 18, 19, 23, 27, 28, 41, 46, 48, 54, 56, 58, 65, 77, 88, 105, 107, 109, 113, 117, 119, 121, 132, 135, 137], "xavier": [14, 21, 43], "uniform_fn": 14, "const_fn": 14, "42661": 14, "115258": 14, "213216": 14, "670142": 14, "strang": [14, 61, 77], "sim": [14, 23, 47, 48, 49, 52, 60, 61, 64, 67, 69, 74, 76, 89, 95, 99, 100, 104, 121, 132, 141], "named_modul": [14, 16, 23], "68279": 14, "98607": 14, "97283": 14, "onlin": [14, 22, 23, 57, 58, 62, 87, 113, 117, 138], "document": [14, 23, 62, 70, 80, 108, 113, 116, 120, 131, 132, 135, 136, 142], "character": [15, 35, 36, 46, 58, 61, 69, 74, 76, 113, 121, 122, 136, 137], "tunabl": [15, 26, 69, 135], "structur": [15, 26, 34, 36, 37, 39, 41, 42, 43, 46, 49, 51, 52, 53, 58, 64, 66, 71, 72, 79, 81, 89, 96, 102, 108, 117, 121, 125, 128, 131, 132, 133, 136, 137, 138], "interestingli": [15, 34, 60, 114, 121], "constitu": [15, 31], "raw": [15, 25, 26, 34, 58, 66, 91, 121, 128, 131, 142], "possess": [15, 46, 60, 61, 75, 77, 83, 121], "ingest": [15, 37, 39, 58, 116, 131, 135], "suppli": [15, 17, 108, 119, 134, 135], "flow": [15, 18, 34, 39, 43, 58, 60, 69, 75, 80, 116, 125, 127], "backward": [15, 28, 40, 78, 115, 116, 121, 130, 135, 142], "busi": [15, 52, 54, 56, 58, 61, 64, 67, 121], "find": [15, 16, 18, 19, 20, 21, 25, 26, 31, 39, 41, 44, 46, 47, 48, 49, 51, 52, 56, 58, 60, 61, 62, 65, 67, 69, 71, 72, 74, 77, 79, 80, 82, 95, 99, 101, 102, 105, 107, 110, 113, 115, 116, 121, 122, 130, 132, 136, 137, 138, 139, 140, 141], "speak": [15, 28, 41, 64, 69, 133, 135], "152": [15, 39], "wildli": [15, 38, 67], "hundr": [15, 17, 34, 46, 47, 56, 58, 61, 67, 89, 113, 119, 137], "group": [15, 17, 21, 26, 34, 35, 37, 39, 42, 58, 113, 121], "grow": [15, 16, 34, 46, 47, 48, 55, 58, 60, 61, 67, 70, 72, 74, 77, 79, 102, 104, 108, 111, 112, 113, 114, 117, 121, 129, 133, 140], "tediou": [15, 16, 17, 49, 75, 114], "hypothet": 15, "mention": [15, 19, 23, 26, 28, 32, 35, 36, 58, 93, 122, 130, 133, 135, 136], "won": [15, 34, 37, 39, 58, 87], "2015": [15, 39, 58, 112], "coco": 15, "ubiquit": [15, 41, 42, 58, 74, 120, 135], "domain": [15, 48, 51, 58, 60, 66, 67, 69, 77, 80, 85, 91, 110, 112, 113, 131, 137], "artifact": [15, 44, 121], "recurs": [15, 16, 25, 109, 130], "demand": [15, 18, 52, 61, 69, 72, 113, 131], "surprisingli": [15, 39, 46, 61, 64, 69, 75, 79], "compact": [15, 34, 35, 64, 69, 101], "standpoint": [15, 130], "subclass": [15, 51, 56, 71, 72, 73, 74], "backpropag": [15, 28, 33, 34, 40, 43, 58, 65, 76, 78, 82, 105, 114, 115, 127, 131, 133, 135, 142], "fortun": [15, 34, 47, 48, 49, 58, 60, 61, 64, 65, 69, 71, 81, 89, 105, 110, 114, 115, 117, 119, 120, 126], "scene": [15, 46, 58], "magic": [15, 35, 71], "auto": [15, 50, 58, 136], "worri": [15, 19, 35, 57, 58, 60, 61, 68, 69, 70, 73, 75, 113, 136], "perhap": [15, 16, 17, 34, 38, 47, 49, 58, 61, 64, 67, 74, 77, 82], "easiest": [15, 80], "develop": [15, 34, 35, 38, 43, 48, 57, 58, 60, 61, 62, 67, 68, 69, 70, 76, 77, 90, 108, 113, 114, 115, 120, 121, 123, 130, 131, 135, 136, 138, 141], "briefli": [15, 31, 38, 46, 58, 76, 80, 83, 115], "automat": [15, 18, 22, 28, 34, 35, 36, 37, 38, 41, 47, 48, 52, 57, 58, 60, 64, 69, 70, 71, 75, 78, 79, 102, 105, 107, 113, 115, 116, 119, 128, 133, 141, 142], "parent": [15, 113], "constructor": [15, 34, 37, 41, 72, 76, 85], "python": [15, 16, 18, 35, 54, 55, 57, 58, 66, 69, 70, 71, 72, 73, 108, 113, 116, 117, 118, 120, 121, 127], "logit": [15, 64, 65], "net1": 15, "net2": 15, "spare": 15, "pain": 15, "restat": 15, "boilerpl": [15, 35, 71], "unless": [15, 18, 23, 44, 46, 60, 61, 67, 81, 82, 104, 132], "virtu": [15, 104], "versatil": [15, 47], "exploit": [15, 46, 51, 53, 54, 56, 58, 60, 62, 66, 108, 110, 112, 113, 114], "closer": [15, 27, 28, 32, 35, 39, 46, 48, 58, 61, 67, 76, 82, 107, 130, 136], "daisi": 15, "mysequenti": 15, "deliv": [15, 58, 138], "previous": [15, 34, 39, 40, 45, 46, 52, 58, 60, 61, 64, 67, 69, 76, 80, 81, 102, 107, 111, 114, 115, 119, 127, 132, 133, 135, 136, 137], "wrote": [15, 43], "easi": [15, 42, 48, 49, 50, 54, 58, 60, 61, 64, 69, 72, 74, 76, 86, 98, 102, 104, 105, 110, 113, 119, 121, 130, 136, 140], "predefin": [15, 19, 52, 70, 85, 86, 89, 90, 96, 97, 111, 130, 132], "until": [15, 19, 29, 34, 39, 40, 44, 48, 52, 54, 55, 56, 58, 67, 69, 71, 73, 75, 77, 80, 82, 85, 97, 105, 107, 109, 111, 122, 123, 127, 128, 131, 136], "neither": [15, 34, 61, 64, 82, 85, 96, 104, 110], "nor": [15, 34, 47, 61, 64, 69, 82, 85, 96, 104, 110], "cdot": [15, 35, 36, 39, 40, 56, 67, 69, 71, 80, 82, 86, 89, 98, 100, 102, 104, 105, 107, 108, 110, 112, 114, 115, 117, 121, 130, 136, 139], "fixedhiddenmlp": 15, "rand_weight": 15, "reus": [15, 16, 17, 26, 32, 36, 56, 63, 66, 72, 75, 81, 119, 130], "thereaft": [15, 43, 60, 141], "someth": [15, 18, 35, 52, 58, 61, 65, 79, 80, 83, 102, 104, 108, 121], "unusu": [15, 130, 132], "ran": [15, 55], "ell_1": [15, 32, 74, 77, 104, 117], "divid": [15, 19, 22, 25, 26, 27, 28, 30, 31, 35, 58, 64, 71, 73, 74, 76, 102, 105, 108, 113, 117, 121, 132], "real": [15, 21, 29, 30, 35, 46, 48, 49, 58, 60, 61, 67, 69, 73, 77, 78, 79, 80, 98, 100, 101, 104, 105, 110, 111, 113, 117, 119, 120, 121, 122, 132, 136, 137, 138, 139, 140], "integr": [15, 35, 46, 47, 50, 60, 67, 74, 100, 104, 109, 113, 115, 121, 125], "042019": 15, "mix": [15, 40, 60, 61, 79, 109, 113], "nest": [15, 16, 39, 41, 53, 115, 119], "nestmlp": [15, 16], "chimera": 15, "210023": 15, "compris": [15, 36, 37, 40, 42, 46, 47, 58, 61, 68, 137], "care": [15, 18, 19, 35, 42, 43, 46, 47, 58, 59, 60, 61, 64, 66, 67, 69, 73, 79, 82, 102, 108, 115, 119, 121, 123, 129], "lot": [15, 18, 22, 28, 30, 33, 34, 38, 46, 47, 58, 60, 64, 69, 73, 87, 102, 105, 107, 109, 114, 117, 130, 132, 136, 137], "occur": [15, 35, 40, 44, 45, 58, 60, 64, 65, 93, 97, 102, 108, 109, 112, 121, 122, 128, 129, 130, 132, 136, 137], "factori": 15, "goal": [16, 32, 45, 46, 51, 52, 54, 58, 61, 64, 67, 69, 71, 77, 83, 105, 106, 112, 113, 115, 122, 131, 132, 136, 139, 140, 141], "addition": [16, 17, 30, 35, 48, 56, 60, 76, 121, 127], "wish": [16, 18, 44, 47, 49, 58, 60, 61, 64, 69, 70, 72, 77, 79, 86, 114, 115, 117, 119, 121, 123, 136], "examin": [16, 83, 113], "hope": [16, 31, 43, 58, 60, 61, 77, 79, 102, 104, 113, 121, 125, 135, 137], "gain": [16, 34, 37, 49, 55, 72, 77, 79, 80, 121, 125, 134, 135, 136], "nitti": [16, 42], "gritti": [16, 42], "declar": [16, 41, 72], "heavi": [16, 32, 36, 64, 109, 120], "lift": [16, 64, 119, 120], "awai": [16, 39, 46, 47, 48, 49, 58, 67, 80, 98, 109, 112, 113, 121, 136], "weed": 16, "126733": 16, "33087": 16, "276235": 16, "178032": 16, "0230466": 16, "285598": 16, "0876096": 16, "bias": [16, 39, 46, 64, 66, 67, 69, 74, 77, 80, 90, 125, 127, 130], "numer": [16, 34, 35, 40, 42, 47, 48, 50, 58, 61, 62, 64, 65, 66, 69, 75, 77, 78, 79, 95, 99, 101, 103, 110, 113, 115, 119, 120, 126, 130, 131, 135, 137, 138, 142], "sever": [16, 17, 18, 20, 24, 31, 32, 34, 39, 48, 51, 52, 54, 58, 61, 65, 67, 77, 81, 90, 93, 102, 113, 115, 120, 126, 128, 136], "decoupl": [16, 103, 111, 121], "situat": [16, 34, 39, 58, 60, 67, 70, 74, 77, 79, 82, 102, 103, 105, 110, 121, 132, 139, 140], "unwieldi": [16, 44, 46, 47, 132], "tree": [16, 28, 58, 60, 67, 80, 89, 97, 132], "elegantli": 16, "alloc": [16, 18, 35, 37, 44, 51, 56, 60, 70, 75, 81, 119], "sure": [16, 18, 40, 51, 54, 56, 58, 61, 67, 71, 81, 87], "ty": [16, 130], "hopefulli": [17, 64, 130], "happi": [17, 121, 131, 136], "deploy": [17, 60, 121], "best": [17, 34, 35, 37, 39, 40, 43, 46, 51, 52, 54, 55, 56, 58, 61, 67, 69, 71, 79, 81, 86, 94, 102, 104, 107, 108, 110, 113, 121, 125, 132, 139, 141], "period": [17, 48, 49, 67, 79, 91, 107, 135, 136, 140], "checkpoint": [17, 54, 55], "lose": [17, 18, 40, 44, 58, 121], "worth": [17, 30, 35, 43, 49, 52, 58, 59, 64, 67, 69, 72, 80, 121, 133], "trip": 17, "cord": 17, "server": [17, 18, 34, 57, 61, 108, 120], "npy": 17, "dictionari": [17, 25, 54, 89, 96, 97, 98, 99, 103, 108, 122, 137], "mydict": 17, "savez": 17, "mydict2": 17, "sprinkl": 17, "flat_param": 17, "recov": [17, 35, 71, 73, 74, 96, 109, 117, 121, 122, 125], "clone": [17, 117], "input_dim": [17, 21, 22, 70, 99], "output_dim": [17, 21, 22, 70, 99], "y_clone": 17, "restrict": [17, 46, 60, 61, 67, 69, 74, 77, 121, 139], "impos": [17, 46, 58, 69, 76, 104], "tab_intro_decad": 18, "nutshel": [18, 19, 27, 32, 46, 47, 49, 58, 64, 101, 132], "opportun": [18, 60, 71], "har": 18, "instal": [18, 60, 91, 113, 142], "cuda": [18, 34, 35, 57], "prepar": [18, 58, 61, 67, 72, 113, 116, 129], "smi": [18, 54, 55], "command": [18, 54, 55, 57, 58, 80, 108, 113, 139], "graphic": [18, 34, 58, 115, 127], "card": [18, 58], "extravag": 18, "desktop": 18, "cloud": [18, 52, 54, 58, 120], "aw": [18, 58], "ec2": [18, 52], "almost": [18, 24, 34, 45, 47, 56, 60, 67, 69, 71, 91, 98, 106, 107, 118, 130, 132, 136], "cpu": [18, 34, 54, 55, 57, 69, 72, 81, 108, 119], "main": [18, 20, 28, 30, 34, 36, 39, 52, 54, 55, 58, 69, 71, 89, 91, 98, 101, 102, 104, 108, 119, 136, 141], "set_default_devic": 18, "default_devic": 18, "try_all_gpu": 18, "tpu": 18, "live": [18, 24, 47, 58, 60, 70, 120], "decid": [18, 46, 51, 55, 58, 60, 77, 80, 85, 102, 105, 113, 121, 132, 136], "consum": [18, 34, 52, 54, 58, 74, 77, 108, 114], "usag": [18, 60, 118], "exce": [18, 19, 34, 58, 61, 64, 65, 79, 80, 97, 108, 135], "496423": 18, "112784": 18, "439": 18, "530845": 18, "19399": 18, "156726": 18, "runtim": [18, 47, 51, 56, 57, 108, 125], "peopl": [18, 34, 47, 58, 60, 87, 102, 117, 121], "slower": [18, 34, 102, 109], "crash": [18, 113, 117, 120], "realiz": [18, 27, 34, 50, 77, 80, 82, 109, 113, 114, 117, 121], "sent": [18, 58, 69], "rule": [18, 33, 34, 52, 55, 58, 59, 61, 67, 75, 100, 103, 105, 114, 116, 121, 130, 132, 136], "thumb": [18, 52, 58, 67, 100], "wors": [18, 39, 52, 55, 69, 76, 77, 108, 109, 112, 132, 136], "interspers": [18, 72], "coffe": [18, 58, 60], "queue": [18, 56], "phone": [18, 34, 58], "readi": [18, 32, 41, 60, 62, 63, 66, 71, 78, 79, 91, 103, 120, 125, 135, 140], "transmiss": 18, "overhead": [18, 54, 74, 75, 102, 108, 119], "subject": [18, 39, 57, 58, 60, 64, 69, 104, 109, 112, 114, 117, 121], "dread": [18, 65], "lock": 18, "somewhat": [18, 34, 35, 45, 48, 52, 102, 104, 109, 132], "intens": [18, 46, 52, 58, 61, 80, 117], "706855": 18, "confirm": [18, 34, 35, 73, 112, 118], "0196834": 18, "295838": 18, "549062": 18, "min": [18, 19, 21, 30, 54, 55, 56, 60, 80, 85, 91, 97, 104, 105, 107, 110, 129, 135], "prepare_batch": [18, 52, 71], "prepare_model": [18, 72], "board": [18, 51, 58, 72, 74, 77, 79, 113], "mistak": [18, 58, 62], "log": [18, 19, 25, 26, 32, 47, 49, 52, 54, 55, 56, 61, 65, 66, 69, 74, 79, 82, 83, 87, 89, 93, 98, 99, 100, 104, 105, 108, 114, 115, 122, 132, 137], "ndarrai": [18, 22, 119], "trigger": [18, 49, 58, 127], "stall": [18, 107, 108, 109, 110, 112], "insid": [18, 20, 25, 35, 43, 54, 56, 60, 65, 104, 112, 115, 119, 141], "frobeniu": [18, 74, 75, 117], "region": [19, 23, 24, 27, 31, 34, 42, 45, 46, 47, 48, 58, 105, 142], "boundari": [19, 41, 44, 46, 58, 62, 67, 80, 96, 104, 128], "accur": [19, 20, 30, 34, 39, 41, 42, 58, 60, 65, 67, 69, 71, 77, 79, 98, 102, 121, 130, 132, 136], "aspect": [19, 22, 23, 27, 28, 30, 32, 34, 35, 46, 58, 60, 64, 65, 66, 69, 71, 90, 107, 109, 121, 141], "ratio": [19, 21, 22, 23, 25, 26, 27, 30, 32, 37, 45, 60, 94, 97, 102, 107, 115, 121, 129], "13": [19, 21, 22, 25, 26, 27, 28, 30, 31, 32, 33, 45, 54, 55, 64, 76, 80, 92, 112, 113, 117, 121, 130, 132, 137], "matplotlib": [19, 20, 21, 22, 23, 27, 28, 29, 31, 32, 47, 55, 62, 69, 71, 73, 74, 79, 80, 82, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 115, 120, 121, 135, 136, 140, 141], "inlin": [19, 21, 22, 23, 27, 28, 29, 31, 32, 62, 69, 71, 73, 74, 79, 80, 82, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 115, 121, 135, 136, 140, 141], "gluon": [58, 85, 102, 103, 108, 109, 113], "npx": 113, "set_printopt": [], "set_np": [], "s_1": [19, 139, 141], "s_n": 19, "r_1": [19, 139, 141], "r_m": 19, "whnm": 19, "r_2": [19, 139], "s_2": [19, 139], "s_3": 19, "wh": [19, 96], "multibox_prior": [19, 27, 32], "in_height": 19, "in_width": 19, "num_siz": 19, "num_ratio": 19, "ctx": [], "boxes_per_pixel": 19, "size_tensor": [], "ratio_tensor": [], "offset_h": 19, "offset_w": 19, "steps_h": 19, "steps_w": 19, "center_h": 19, "center_w": 19, "shift_x": 19, "shift_i": 19, "meshgrid": [19, 105, 110], "corner": [19, 20, 21, 25, 29, 30, 41, 44, 58, 65, 75], "xmin": 19, "xmax": 19, "ymin": 19, "ymax": 19, "rectangular": [19, 20, 21, 31, 45], "anchor_manipul": 19, "out_grid": 19, "ij": [19, 28, 47, 48, 49, 60, 66, 69, 82, 86, 93, 100, 102, 105, 108, 110, 117], "cat": [19, 20, 23, 25, 31, 43, 45, 46, 58, 60, 64, 77, 80, 96, 132], "repeat_interleav": [], "unsqueez": 32, "size_arrai": 19, "ratio_arrai": 19, "imread": [19, 20, 27], "catdog": [19, 20, 21, 27], "jpg": [19, 20, 21, 23, 26, 27, 28, 31, 32], "asnumpi": [], "75": [19, 47, 93, 97, 122, 128], "rand": [], "561": [19, 21, 27], "728": [19, 21, 27], "2042040": 19, "0551168": 19, "0715241": 19, "63307": 19, "821524": 19, "show_bbox": [19, 27, 29, 32], "bbox": [19, 20, 32], "make_list": [], "obj": [19, 72], "default_valu": 19, "rect": 19, "bbox_to_rect": [19, 20], "add_patch": [19, 20], "text_color": 19, "xy": [19, 20, 110], "facecolor": 19, "lw": 19, "_make_list": 19, "saw": [19, 41, 46, 49, 64, 76, 80, 102, 103, 107, 109, 110, 121, 128, 132, 137], "restor": [19, 28], "bbox_scal": [19, 27], "surround": [19, 58, 80, 94, 98], "dog": [19, 20, 24, 25, 31, 34, 46, 58, 60, 64, 77, 80, 96, 132, 142], "set_figs": [19, 20, 21, 23, 27, 28, 32, 47, 49, 54, 55, 56, 87, 104, 105, 108, 109, 110, 111, 115, 121, 128], "quantifi": [19, 51, 58, 61, 64, 69, 77, 121, 122], "jaccard": 19, "cap": [19, 58, 100, 104, 121], "cup": [19, 100, 104, 121], "overlap": [19, 27, 30, 46, 67, 83, 121], "box_iou": 19, "pairwis": 19, "boxes1": 19, "boxes2": 19, "box_area": 19, "areas1": 19, "areas2": 19, "inter_upperleft": 19, "inter_lowerright": 19, "inter": 19, "minimum": [19, 37, 40, 41, 45, 54, 56, 60, 69, 102, 104, 105, 107, 109, 110, 112], "inter_area": 19, "union_area": 19, "clamp": 19, "inters_diff": 19, "criteria": [19, 60], "closest": [19, 21, 28, 75, 104, 138], "a_1": [19, 61, 139, 141], "a_2": [19, 139], "a_": [19, 47, 96, 117, 130], "n_a": 19, "b_1": [19, 64], "b_2": [19, 64], "b_": [19, 117, 130], "n_b": 19, "x_": [19, 28, 41, 47, 48, 69, 93, 100, 109, 115, 117, 130, 132, 133, 135, 136], "a_i": 19, "b_j": 19, "i_1": 19, "j_1": 19, "discard": [19, 56, 58, 67, 80, 97, 120, 122, 128, 132], "i_2": 19, "j_2": 19, "travers": [19, 44, 45, 75, 89, 108, 112, 115, 130], "threshold": [19, 32, 58, 60, 80, 82], "concret": [19, 22, 25, 27, 28, 30, 32, 46, 49, 60, 69, 84, 88, 98, 104, 112, 129, 132, 139], "23": [19, 36, 54, 55, 64, 82, 117], "b_3": [19, 64], "71": [19, 32], "shade": [19, 33, 40, 41, 44, 45, 48, 88, 130], "a_7": 19, "middl": [19, 23, 37, 41, 58], "54": [19, 32, 34, 54, 121], "b_4": 19, "a_5": 19, "92": 19, "a_9": 19, "a_3": 19, "a_4": 19, "a_6": 19, "a_8": 19, "assign_anchor_to_bbox": 19, "ground_truth": 19, "iou_threshold": 19, "num_anchor": [19, 32], "num_gt_box": 19, "x_ij": 19, "hold": [21, 32, 33, 41, 46, 48, 52, 58, 60, 61, 64, 67, 73, 74, 89, 93, 102, 104, 105, 109, 112, 115, 117, 120, 121, 136, 141], "anchors_bbox_map": 19, "max_iou": 19, "anc_i": [], "box_j": [], "col_discard": 19, "row_discard": 19, "max_idx": 19, "box_idx": 19, "anc_idx": 19, "condition_mx": 19, "condition_np": 19, "indices_np": 19, "anc_i_np": 19, "box_j_np": 19, "central": [19, 22, 49, 54, 59, 61, 64, 67, 85, 121, 140], "x_a": 19, "y_a": 19, "x_b": 19, "y_b": 19, "w_a": 19, "w_b": 19, "h_a": 19, "h_b": 19, "mu_x": 19, "sigma_x": [19, 100], "mu_i": [19, 47, 49, 121], "sigma_i": [19, 100], "mu_w": 19, "sigma_w": 19, "mu_h": 19, "sigma_h": 19, "offset_box": 19, "assigned_bb": 19, "ep": [19, 21, 35, 101, 102, 103, 111], "c_anc": 19, "box_corner_to_cent": [19, 20], "c_assigned_bb": 19, "offset_xi": 19, "offset_wh": 19, "multibox_target": [19, 32], "batch_offset": 19, "batch_mask": 19, "batch_class_label": 19, "bbox_mask": [19, 32], "class_label": 19, "indices_tru": 19, "bb_idx": 19, "bbox_offset": 19, "five": [19, 27, 30, 31, 32, 34, 37, 58, 67, 76, 80, 91, 122, 132, 135], "a_0": [19, 139, 141], "08": [19, 26, 48, 54, 55, 119], "52": [19, 48, 55, 110], "55": [19, 32, 54], "88": [19, 32, 54, 55], "63": [19, 55, 112], "05": [19, 21, 32, 74, 80, 105, 108, 110], "98": [19, 80, 121], "66": [19, 119, 140, 141], "45": [19, 20, 48, 97, 102, 105, 135], "57": [19, 33, 121, 128], "analyz": [19, 34, 35, 58, 82, 84, 94, 102, 103, 104, 105, 107, 109, 114, 117, 121, 125, 127, 130, 140, 141], "filter": [19, 24, 28, 31, 32, 34, 35, 37, 41, 46, 52, 54, 55, 58, 60, 73, 87, 91, 102, 129, 137], "0000000e": 19, "00": 19, "3999999e": 19, "9999990e": 19, "5939715e": 19, "1754241e": 19, "1999989e": 19, "6881757e": 19, "6823640e": 19, "5654519e": 19, "7142800e": 19, "0000001e": 19, "1723233e": 19, "06": [19, 55, 121], "2582040e": 19, "offset_invers": 19, "invers": [19, 58, 76, 100, 112, 115], "offset_pr": 19, "anc": 19, "pred_bbox_xi": 19, "pred_bbox_wh": 19, "pred_bbox": 19, "predicted_bbox": 19, "box_center_to_corn": [19, 20], "merg": [19, 96], "belong": [19, 31, 34, 58, 64, 73, 83, 100, 117], "nm": 19, "likelihood": [19, 46, 47, 48, 58, 60, 61, 66, 69, 74, 77, 80, 83, 98, 104, 110, 121, 132, 136], "confid": [19, 32, 41, 47, 48, 58, 61, 64, 67, 69, 76, 121], "descend": 19, "highest": [19, 46, 56, 59, 61, 64, 83, 88, 122, 129], "argsort": [19, 95, 99], "kept": [19, 58, 97, 112, 120], "ind": 19, "numel": [], "multibox_detect": [19, 32], "complic": [19, 22, 29, 37, 40, 44, 58, 64, 67, 68, 69, 75, 77, 79, 104, 105, 110, 117, 121, 130], "cls_prob": [19, 32], "nms_threshold": 19, "pos_threshold": 19, "009999999": 19, "conf": 19, "class_id": 19, "predicted_bb": 19, "all_idx": 19, "concat": [79, 86, 88, 129], "uniqu": [19, 54, 55, 61, 69, 71, 113, 120, 121, 131, 132, 137], "return_count": 19, "non_keep": 19, "all_id_sort": 19, "below_min_idx": 19, "pred_info": 19, "prob": [19, 140], "56": [19, 40], "95": [19, 25, 47, 48, 51, 61, 62, 109, 110, 111, 140, 141], "62": 19, "91": [19, 54], "six": [19, 41, 58, 83, 90, 92, 122], "therebi": [19, 23, 33, 44, 58, 61, 140], "greedi": [19, 96, 126, 140], "softli": [19, 86], "soft": [19, 60, 64, 86], "recogn": [20, 22, 26, 31, 37, 40, 43, 45, 46, 49, 58, 67, 80, 85, 131, 132], "categori": [20, 22, 25, 26, 34, 46, 58, 60, 62, 64, 69, 80, 85, 87, 88, 90, 110, 120, 133], "drive": [20, 24, 52, 58, 67, 105, 108, 109, 113], "plan": [20, 34, 58, 60, 72, 121], "travel": [20, 117, 123, 137, 139, 141], "rout": [20, 46, 58], "vehicl": [20, 24, 31, 58], "pedestrian": 20, "road": [20, 65, 142], "obstacl": [20, 34, 67], "video": [20, 58, 62, 77, 79, 131, 136, 140], "navig": [20, 57, 58, 60, 113, 139, 141], "secur": [20, 136], "abnorm": 20, "intrud": 20, "bomb": 20, "tf": [58, 113], "side": [20, 33, 35, 44, 48, 64, 77, 80, 93, 100, 104, 105, 109, 113, 115, 119, 121, 135], "vice": [20, 28, 86, 93, 95, 121], "versa": [20, 28, 86, 93, 95, 121], "x1": [20, 49, 85, 102, 105, 109, 111, 112], "y1": [20, 32, 40], "cx": [20, 105], "cy": 20, "abbrevi": [20, 80], "dog_bbox": 20, "cat_bbox": 20, "378": 20, "516": 20, "400": [20, 23, 43, 86], "112": [20, 32, 37, 137], "655": 20, "493": 20, "twice": [20, 61, 70, 91, 93, 104, 108, 121, 128], "helper": [20, 44, 92, 94, 105], "packag": [20, 47, 54, 55, 79, 113, 114, 115, 119, 137, 138], "edgecolor": 20, "fcn": 21, "torchvis": [62, 113], "albument": [21, 22, 23, 25, 26, 28, 31], "pretrained_net": [21, 22, 28], "model_zoo": [], "resnet18_v2": [], "children": [21, 46, 99], "layer4": 21, "fc": [21, 22], "basicblock": 21, "dilat": 21, "momentum": [21, 25, 26, 35, 52, 101, 102, 103, 105, 106, 111, 142], "affin": [21, 35, 64, 69, 80], "track_running_stat": 21, "hybridsequenti": [], "pretrained_net_lay": 21, "320": [21, 31, 37], "480": [21, 31, 34, 37, 41], "21": [21, 54, 55, 64, 117, 132, 137, 140, 141], "pascal": [21, 24], "voc2012": [21, 24], "times2": [21, 32, 40, 41, 43, 44, 64, 88, 119], "conv2dtranspos": [], "add_modul": [], "final_conv": [], "transpose_conv": [], "convtranspose2d": [21, 33], "upsampl": [21, 33, 34], "scale_factor": 21, "align_corn": 21, "bilinear": [21, 30], "bilinear_kernel": 21, "og": 21, "filt": 21, "doubl": [21, 32, 39, 40, 64, 65, 69, 77], "conv_tran": 21, "copy_": [], "out_img": 21, "totensor": [23, 62], "detach": [116, 130], "asarrai": 21, "00220588": 21, "1122": 21, "1456": 21, "000244141": 21, "000732422": 21, "0012207": 21, "00219727": 21, "00366211": 21, "00610352": 21, "crop": [21, 22, 25, 26, 29, 31, 58, 73, 82], "divis": [21, 35, 39, 44, 58, 66, 71, 81, 111, 117, 119], "crop_siz": [21, 31], "load_data_voc": [21, 31], "num_train_batch": [21, 22, 23, 25, 26, 31, 72], "num_test_batch": [21, 25, 26, 31], "1114": [21, 31], "1078": [21, 31], "wd": [21, 25, 26, 74, 79], "softmaxcrossentropyloss": [], "collect_param": [], "reset_ctx": [], "train_ch13": [21, 22, 23, 86, 88, 92], "weight_decai": [21, 22, 25, 26, 32, 74], "nan": [21, 65, 79, 120], "111812": [], "876": [], "729": [], "_dataset": [], "normalize_imag": 31, "as_in_ctx": [], "485": [21, 22, 26, 28, 31], "456": [21, 22, 26, 28, 31], "406": [21, 22, 26, 28, 31], "229": [21, 22, 26, 28, 31], "225": [21, 22, 26, 28, 31], "label2imag": 21, "colormap": [21, 31], "voc_colormap": [21, 31], "uint8": [22, 28], "indivis": [21, 137], "times480": 21, "ground": [21, 27, 29, 30, 32, 47, 48, 58, 59, 60, 71, 73, 83, 85, 90, 117, 129, 138], "truth": [21, 27, 29, 30, 32, 34, 39, 47, 48, 58, 59, 60, 71, 73, 83, 85, 90, 117, 129], "voc_dir": [21, 31], "vocdevkit": [21, 31], "test_imag": 21, "test_label": 21, "read_voc_imag": [21, 31], "crop_rect": 21, "fixed_crop": [], "x_min": 21, "y_min": 21, "x_max": 21, "y_max": 21, "366": 21, "500": [21, 23, 28, 47, 87, 108], "335": 21, "333": 21, "375": 21, "60000": [22, 52, 62], "academia": [22, 24], "chair": [22, 31], "recommend": [22, 35, 42, 60, 72, 77, 107, 113, 117, 136, 138], "purchas": [22, 58, 120, 138], "link": [22, 76, 79, 113, 131], "identifi": [22, 34, 37, 51, 52, 56, 58, 74, 77, 79, 85, 122], "angl": [22, 98, 117], "tenth": [22, 108], "meet": [22, 25, 80], "obviou": [22, 60, 64, 65, 80, 90, 102, 132], "monei": [22, 60, 94, 121], "spent": [22, 52, 56, 58, 70], "dollar": [22, 58, 64, 69, 77, 121], "fund": 22, "noth": [22, 35, 58, 61, 80, 82, 89, 136], "edg": [22, 34, 40, 42, 45, 46, 58, 65, 69, 70, 126, 127, 131], "textur": [22, 28, 34, 46, 60], "composit": [22, 69, 77, 115, 127], "1400": 22, "food": 22, "unzip": [22, 25, 26, 57], "hotdog": 22, "subfold": [22, 26], "fba480ffa8aa7e0febbb511d181409f899b9baa5": 22, "s3": [79, 132], "amazonaw": [79, 132], "train_img": [], "imagefolderdataset": [], "test_img": [], "imagefold": [], "train_dataset": 22, "load_images_from_fold": 22, "test_dataset": 22, "\u8bad\u7ec3\u6837\u672c\u6570\u91cf": 22, "\u6d4b\u8bd5\u6837\u672c\u6570\u91cf": 22, "first_train_sampl": 22, "\u7b2c\u4e00\u4e2a\u8bad\u7ec3\u6837\u672c\u952e": 22, "\u56fe\u50cf": 22, "\u7c7b\u578b": 22, "\u5f62\u72b6": 22, "\u6570\u636e\u7c7b\u578b": 22, "\u6807\u7b7e": 22, "\u503c": 22, "800": [22, 90, 95], "dict_kei": 22, "146": 22, "313": 22, "not_hotdog": 22, "rgb": [22, 25, 26, 28, 29, 31, 40], "green": [22, 40, 46, 58, 62, 117, 139], "train_aug": [22, 23], "randomresizedcrop": [22, 23, 25, 26], "randomflipleftright": [], "test_aug": [22, 23], "centercrop": [22, 26], "randomhorizontalflip": [], "horizontalflip": [22, 23, 25, 26], "finetune_net": [22, 26], "eta": [22, 55, 56, 69, 71, 74, 102, 103, 105, 107, 109, 111, 112, 135], "lr_mult": [], "in_featur": [], "xavier_uniform_": [], "init_fn": 22, "0640211": [], "0963696": [], "0691823": [], "10138": [], "0660146": [], "10369": [], "0541353": [], "0181194": [], "0959341": [], "10743": [], "105315": [], "0906907": [], "train_fine_tun": 22, "dataload": [62, 71, 72, 73, 85], "transform_first": [], "hybrid": 107, "param_group": 22, "crossentropyloss": [], "params_1x": 22, "named_paramet": [], "process_train_sampl": 22, "process_test_sampl": 22, "sample_transform": [22, 23, 25], "trainable_paramet": 22, "5e": [22, 25, 32, 115], "222": 22, "917": [], "924": [], "187": [], "comparison": [22, 34, 51, 58, 67, 79, 86, 90], "scratch_net": 22, "356": [], "848": [], "797": [], "198": [], "tend": [22, 34, 35, 42, 44, 47, 60, 61, 64, 67, 70, 72, 74, 77, 79, 101, 121, 122, 125, 129, 136, 137], "grad_req": [], "null": [], "requires_grad": [], "hotdog_w": [], "713": [], "934": [], "prerequisit": [23, 60, 113, 115], "distinct": [23, 34, 37, 39, 46, 48, 49, 58, 60, 64, 67, 73, 83, 117, 120, 121, 122, 123, 127, 137, 138], "expand": [23, 56, 109, 111, 119, 121, 130], "motiv": [23, 35, 39, 41, 42, 44, 46, 61, 69, 74, 77, 90, 104, 113, 121, 131, 137, 142], "tweak": [23, 25, 58, 74, 113], "bright": [23, 26, 28, 58, 77, 80, 135], "alexnet": [23, 37, 38, 39, 113, 142], "autograd": [81, 113, 114], "investig": [23, 24, 49, 61, 71, 85, 88, 114, 121], "cat1": 23, "degre": [23, 35, 45, 58, 67, 72, 74, 102, 105, 110, 113, 117, 121, 132, 135], "auxiliari": [23, 102, 109, 114], "aug": 23, "randomfliptopbottom": [], "randomverticalflip": [], "verticalflip": 23, "interv": [23, 32, 34, 47, 48, 58, 61, 65, 80, 93, 104, 105, 115, 121, 125, 127], "shape_aug": 23, "satur": [23, 26], "hue": 23, "50": [23, 25, 28, 35, 47, 49, 51, 58, 70, 80, 85, 86, 87, 92, 95, 107, 112, 121, 125, 127], "150": 23, "randombright": [], "colorjitt": [23, 26], "randomhu": [], "randomcolorjitt": 23, "color_aug": 23, "cifar": [23, 24, 26, 34, 52, 142], "cifar10": 25, "all_imag": 23, "load_cifar10": 23, "toronto": [], "edu": [85, 95], "kriz": [], "162": 55, "6mib": [], "3mib": [], "hash": [], "4mib": [], "num_work": [], "get_dataloader_work": [], "process_sampl": [23, 25], "sec_multi_gpu_concis": 23, "train_batch_ch13": [23, 25, 26], "split_f": [], "split_batch": 86, "x_shard": [], "y_shard": [], "pred_shard": [], "flag": [], "stale": 119, "ignore_stale_grad": [], "train_loss_sum": 23, "train_acc_sum": 23, "zero_grad": [], "train_step": [23, 25, 26], "mini": [23, 47, 51, 52, 140], "dataparallel": [], "device_id": [], "lo": [23, 25, 26, 79], "train_with_data_aug": 23, "adam": [23, 28, 35, 47, 86, 88, 92, 99, 106, 113, 129, 142], "init_cnn": [34, 43, 51], "init_model_weight": 23, "new_weight": 23, "new_bia": 23, "492": [], "830": 95, "716": [], "5998": [], "simultan": [23, 31, 35, 37, 60, 61, 64, 69, 77, 82, 104, 113, 121, 131], "mitig": [23, 45, 52, 58, 60, 74, 77, 80, 82, 102, 126, 128, 135, 140], "medic": [24, 31, 58, 66, 67, 131, 137], "diagnosi": [24, 66, 121], "camera": [24, 45, 60], "monitor": [24, 31, 58, 60, 71, 77, 79], "smart": [24, 34, 58, 60, 65], "said": [24, 41, 45, 47, 58, 61, 67, 69, 115, 121, 133, 135], "insepar": 24, "industri": [24, 34, 58, 83, 113], "augment": [24, 29, 31, 34, 38, 90, 142], "layerwis": [24, 27, 28, 32, 82], "successfulli": [24, 42, 43, 78, 113, 126], "style": [24, 38, 43, 60, 72, 113, 127, 142], "materi": [24, 35, 60, 103, 113, 131], "box": [24, 29, 30, 31, 39, 79, 104, 106, 123, 130, 138, 142], "anchor": [24, 30, 32, 142], "intersect": [24, 100, 104, 121], "iou": 24, "suppress": [24, 30, 32], "multiscal": [24, 32, 142], "multibox": [24, 30, 142], "postprocess": [24, 69, 73, 80], "synthes": [24, 71], "kaggl": [24, 78, 142], "organ": [24, 58, 121], "submit": [24, 78], "breed": [24, 142], "identif": [24, 142], "webpag": [25, 26, 58, 113], "regist": [25, 71, 72, 73, 79, 108, 113], "account": [25, 26, 58, 61, 63, 69, 77, 79, 80, 113, 127, 132], "click": [25, 26, 57, 58, 60, 79], "glob": 25, "shutil": [25, 113], "50000": 25, "300000": 25, "290000": 25, "png": [25, 31], "airplan": [25, 31, 34, 69, 85], "bird": [25, 31, 69], "deer": 25, "frog": 25, "hors": [25, 31, 85], "boat": [25, 31], "truck": [25, 138], "7z": 25, "trainlabel": 25, "csv": [25, 26, 29, 79, 120], "samplesubmiss": 25, "directori": [25, 79], "sample_submiss": [25, 26], "submiss": [25, 26, 79], "demo": [25, 26], "cifar10_tini": 25, "kaggle_cifar10_tini": 25, "2068874e4b9a9f0fb07ebe0ad2b29754449ccacd": 25, "read_csv_label": [25, 26], "header": [25, 95], "readlin": [25, 85], "rstrip": [25, 95], "reorg_train_valid": [25, 26], "valid_ratio": [25, 26], "lfloor": [25, 44, 132], "nr": 25, "rfloor": [25, 44, 132], "45000": 25, "train_valid_test": [25, 26], "5000": [25, 132], "copyfil": 25, "target_dir": 25, "fewest": 25, "most_common": 25, "n_valid_per_label": 25, "label_count": 25, "train_fil": 25, "listdir": [25, 26, 87], "train_valid": [25, 26], "reorg_test": [25, 26], "test_fil": 25, "reorg_cifar10_data": 25, "flip": [25, 34, 41, 46, 58, 60, 110, 117, 121, 127], "transform_train": [25, 26], "4914": 25, "4822": 25, "4465": 25, "2023": 25, "1994": [25, 34, 49], "transform_test": [25, 26], "\u6807\u51c6\u5316\u56fe\u50cf\u7684\u6bcf\u4e2a\u901a\u9053": [], "files_and_class": 25, "suffix": [25, 26, 96], "class_to_idx": 25, "idx_to_class": 25, "ascii": [25, 29, 31, 137], "create_dataset": [25, 26], "load_imag": [25, 29, 31], "train_d": [25, 26], "train_ds_class": [25, 26], "train_valid_d": [25, 26], "train_valid_ds_class": [25, 26], "valid_d": [25, 26], "valid_ds_class": [25, 26], "test_d": [25, 26], "test_ds_class": [25, 26], "create_data_it": [25, 26], "drop_last": [25, 26, 31, 72, 85, 91], "len_dataset": 25, "ceil": [25, 72, 87, 91, 97], "train_valid_it": [25, 26], "num_train_valid_batch": [25, 26], "valid_it": [25, 26, 101, 102, 103, 108, 109, 111], "num_valid_batch": [25, 26], "get_net": [25, 26], "lr_period": [25, 26], "lr_decai": [25, 26], "step_decai": [25, 26, 28], "valid_acc": 25, "eas": [25, 34, 43, 65, 86, 92], "2e": [25, 32], "515": [], "847": [], "362": [], "2065": [], "retrain": [25, 26], "sorted_id": 25, "df": [25, 47, 54, 55, 91, 114, 115], "id": [25, 26, 54, 55, 58, 60, 79, 90, 113, 119], "to_csv": [25, 79], "528": 37, "835": [], "2001": 58, "rank": [25, 35, 55, 58, 64, 69, 79, 83, 137], "120": [26, 35, 40, 43, 107], "wider": [26, 27, 34, 67, 69, 80, 108, 113], "14": [26, 30, 43, 45, 48, 54, 55, 64, 76, 83, 84, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 113, 117, 120, 128, 129, 130, 132, 137], "websit": [26, 57, 79, 95, 137], "10222": 26, "10357": 26, "jpeg": 26, "labrador": 26, "poodl": [26, 58], "dachshund": 26, "samoi": 26, "huski": 26, "chihuahua": 26, "yorkshir": 26, "terrier": 26, "train_valid_test_tini": 26, "dog_tini": 26, "kaggle_dog_tini": 26, "0cb91d09b814ecdc07b50f31f8dcad3e81d6a86d": 26, "reorg_dog_data": 26, "randomlight": [], "\u4ece\u56fe\u50cf\u4e2d\u5fc3\u88c1\u5207224x224\u5927\u5c0f\u7684\u56fe\u7247": 26, "last_batch": [], "again": [26, 34, 36, 39, 47, 48, 56, 58, 60, 61, 64, 65, 69, 79, 80, 81, 104, 107, 112, 114, 121, 127, 140, 141], "34": [26, 54, 55, 64], "resnet34_v2": [], "output_new": 26, "resnet34": 26, "freez": [26, 28, 67, 88, 90], "unfreez": 26, "l_sum": 26, "output_featur": [], "set_learning_r": [107, 108], "valid_loss": 26, "lr_schedul": 107, "steplr": [], "391": 87, "455": [], "484": [], "synset": [], "num": 26, "363": [], "496": 26, "portion": [27, 29, 33, 39, 40, 41, 44, 45, 58, 74, 80, 88, 122], "display_anchor": 27, "fmap": 27, "spread": [27, 49, 69, 120], "fmap_w": 27, "fmap_h": 27, "distinguish": [27, 31, 34, 35, 46, 54, 56, 58, 60, 62, 77, 90, 96, 97, 110, 117, 125, 130, 140], "essenc": [27, 110, 142], "photographi": 28, "enthusiast": 28, "photo": [28, 29, 58, 60, 117], "sharper": 28, "portrait": 28, "whiten": [28, 108], "skin": [28, 58], "mount": 28, "rainier": 28, "nation": [28, 58, 69], "park": 28, "suburb": 28, "seattl": 28, "oil": [28, 69, 83], "paint": 28, "theme": [28, 35, 77], "autumn": 28, "oak": 28, "brush": 28, "stroke": [28, 58], "vivid": 28, "solid": [28, 39, 51, 87, 93, 113, 121], "dash": [28, 51, 79, 121], "tell": [28, 34, 47, 48, 58, 61, 67, 82, 102, 108, 113, 115, 117, 119, 121, 136], "content_img": 28, "style_img": 28, "rgb_mean": 28, "rgb_std": 28, "image_shap": 28, "max_pixel_valu": 28, "fromarrai": 28, "19": [28, 41, 54, 55, 72, 109, 117, 121, 132], "fangkeqiu": [28, 54, 55], "snapshot": 28, "c795ba47163d06ce5c6c89f6062abe763c9e03ea": 28, "excess": [28, 34, 36, 62, 69, 82, 105, 128, 135], "sec_vgg": 28, "fourth": [28, 32, 37, 46], "style_lay": 28, "content_lay": 28, "28": [28, 34, 37, 43, 47, 54, 55, 58, 62, 66, 81, 105, 114, 128, 131, 137], "feature_list": 28, "extract_featur": 28, "net_lay": 28, "get_cont": 28, "get_styl": 28, "content_x": 28, "contents_i": 28, "style_x": 28, "styles_i": 28, "content_loss": 28, "_c": [28, 89, 98], "correl": [28, 31, 40, 42, 44, 45, 46, 48, 58, 88, 100, 121, 132], "chw": 28, "obvious": [28, 31, 40, 107], "gram_i": 28, "precomput": [28, 93], "style_loss": 28, "dark": [28, 141], "denois": [28, 58], "tv_loss": 28, "balanc": [28, 32, 85, 104, 110], "retent": 28, "content_weight": 28, "style_weight": 28, "tv_weight": 28, "1e3": 28, "compute_loss": 28, "contents_y_hat": 28, "styles_y_hat": 28, "styles_y_gram": 28, "contents_l": 28, "styles_l": 28, "tv_l": 28, "synthesizedimag": 28, "img_shap": 28, "get_init": 28, "synthesized_net": 28, "gen_img": 28, "lr_decay_epoch": 28, "tv": [28, 31], "450": 28, "sceneri": 28, "subtl": [28, 60, 80, 108, 121, 130], "took": [29, 34, 58, 60, 61, 64, 65, 71, 82, 108, 115, 121, 138, 139], "free": [29, 47, 48, 51, 54, 55, 56, 58, 61, 70, 77, 101, 102, 109, 111, 121], "banana": [29, 32, 132], "offic": [29, 60], "5de26c8fce5ccdea9f91267273464dc968d20d72": 29, "read_data_banana": 29, "csv_fname": 29, "bananas_train": 29, "bananas_v": 29, "csv_data": 29, "read_csv": [29, 79, 120], "set_index": 29, "img_nam": 29, "iterrow": 29, "io": [], "read_imag": [], "image_path": [29, 31], "bananasdataset": 29, "create_banana_data_it": 29, "load_data_banana": [29, 32], "val_it": 29, "train_len": 29, "val_len": 29, "illeg": [29, 32], "reach": [29, 34, 39, 54, 55, 56, 58, 62, 64, 66, 69, 77, 80, 81, 97, 105, 107, 108, 113, 122, 123, 128, 136, 139, 140, 141], "edge_s": 29, "Of": [29, 38, 45, 59, 61, 89, 108, 121, 141], "cours": [29, 35, 38, 45, 46, 58, 61, 89, 108, 113, 117, 120, 121, 135, 136], "pioneer": [30, 58, 80], "qualiti": [30, 39, 58, 60, 69, 71, 74, 79, 96, 107, 109, 112, 113, 118, 120, 121, 129, 131, 132, 136], "trainabl": [30, 35, 80, 88], "w_1": [30, 49, 69, 112], "h_2": [30, 76], "w_2": [30, 112], "roi": 30, "indirectli": 30, "subwindow": 30, "shall": [30, 43, 86], "round": [30, 39, 55, 56, 61, 65, 67, 91], "spatial_scal": 30, "roi_pool": 30, "pooled_s": [], "op": [], "num_roi": 30, "out_h": [30, 32], "out_w": [30, 32], "pooled_featur": 30, "roi_idx": 30, "batch_idx": [30, 90], "roi_start_w": 30, "roi_start_h": 30, "roi_end_w": 30, "roi_end_h": 30, "roi_width": 30, "roi_height": 30, "roi_featur": 30, "curr_featur": 30, "start_h": 30, "end_h": 30, "start_w": 30, "end_w": 30, "pool_result": 30, "stai": [30, 58, 60, 69, 136, 139], "yolo": 30, "border": [31, 44], "guarante": [31, 35, 39, 47, 58, 60, 61, 64, 67, 77, 102, 105, 107, 110, 112, 121, 122], "mouth": 31, "mainli": [31, 32, 58, 60], "black": [31, 41, 45, 47, 49, 58, 60, 62, 69, 71, 104, 106, 121], "yellow": [31, 104], "voctrainval_11": 31, "2012": [31, 34], "4e443f8a2eca6b1dac8a6c57641b67dd40621a49": 31, "enter": [31, 34, 58, 60, 113], "imageset": 31, "jpegimag": 31, "segmentationclass": 31, "voc": 31, "txt_fname": 31, "val": [31, 52, 62, 79], "train_featur": [31, 87], "train_label": 31, "imagereadmod": [], "white": [31, 41, 45, 60, 62, 123], "192": [31, 37, 40, 128], "voc_class": 31, "aeroplan": 31, "bicycl": 31, "bottl": [31, 58], "bu": [31, 81], "cow": 31, "diningt": 31, "motorbik": 31, "person": [31, 58, 61, 85, 102, 113, 117, 121, 139], "pot": 31, "plant": [31, 117, 121], "sheep": 31, "sofa": 31, "voc_colormap2label": 31, "voc_label_indic": 31, "colormap2label": 31, "front": [31, 77], "105": [31, 128], "115": [31, 55], "130": [31, 137], "140": 31, "Such": [31, 58, 69, 77, 82, 83, 84, 85, 86, 108, 136, 137, 138, 140], "inaccur": [31, 47], "voc_rand_crop": 31, "random_crop": [], "randomcrop": 31, "get_param": [], "cropped_featur": 31, "cropped_label": 31, "vocsegdataset": 31, "vocsegdatas": 31, "voc_train": 31, "voc_test": 31, "create_voc_data_it": 31, "voc_dataset": 31, "autonom": [31, 60], "ssd": 32, "vast": [32, 61, 77, 94, 97], "hwa": 32, "sec_nin": 32, "alter": [32, 46, 81, 119], "times3": [32, 34, 40, 41, 44, 58, 88], "pil": [32, 113], "c_in": 32, "c_out": 32, "cls_predictor": 32, "bbox_predictor": 32, "33": [21, 32, 54, 55, 64], "flatten_pr": 32, "concat_pr": 32, "25300": 32, "down_sample_blk": 32, "halv": [32, 36, 39, 43, 44, 53, 64, 107, 108, 109, 142], "subsec_vgg": 32, "times6": 32, "enlarg": 32, "times256": 32, "base_net": 32, "num_filt": 32, "fifth": [32, 34, 37, 61], "adapativemaxpool2d": 32, "adaptivemaxpool2d": 32, "get_blk": 32, "blk_forward": 32, "cls_pred": 32, "bbox_pr": 32, "evenli": [32, 74], "37": [32, 33, 41, 54, 55, 80, 112], "272": 32, "447": 32, "619": 32, "79": [32, 79, 121], "961": 32, "tinyssd": 32, "idx_to_in_channel": 32, "blk_i": 32, "blk_": 32, "cls_": 32, "bbox_": 32, "getattr": 32, "5444": 32, "1024": [32, 37, 46, 51, 52, 81, 90, 92, 123, 125, 127, 134, 135], "21776": 32, "absolut": [32, 71, 79, 105, 117, 121], "cls_loss": 32, "bbox_loss": 32, "l1_loss": 32, "calc_loss": 32, "cls_label": 32, "bbox_label": 32, "cls_eval": 32, "bbox_ev": 32, "cls_err": 32, "bbox_ma": 32, "err": [32, 58, 79, 113], "21e": 32, "03": [32, 54, 70, 71, 108, 121], "18e": [], "don": 32, "uint64": 32, "2f": [32, 62, 104, 105, 107, 109, 111], "smooth_l1": 32, "p_j": 32, "focal": [32, 35], "gamma": [32, 35, 82, 111, 139, 140, 141], "misclassifi": [32, 58, 60], "focal_loss": 32, "bigger": [32, 34, 69, 77, 80], "seen": [33, 41, 47, 48, 52, 54, 55, 56, 58, 60, 62, 67, 80, 84, 90, 93, 104, 105, 107, 108, 112, 127, 130, 132, 136, 137, 138], "fraction": [33, 45, 56, 58, 59, 60, 61, 76, 120, 121], "n_h": 33, "n_w": 33, "k_h": 33, "k_w": 33, "slide": [33, 41, 44, 45, 88], "trans_conv": 33, "tconv": 33, "nhwc": 33, "c_i": [33, 40, 49, 93, 104, 119], "mathsf": [33, 46, 75, 100, 117], "corr2d": [33, 40, 41, 45], "27": [33, 54, 55], "67": 33, "rewrit": [33, 46, 89, 102, 103, 109], "spars": [33, 34, 103, 104, 106], "kernel2matrix": 33, "exchang": [33, 39, 58, 80, 117], "lenet": [34, 37, 38, 40, 42, 51, 54, 55, 62, 80, 107, 113, 142], "realist": [34, 51, 62, 69], "establish": [34, 35, 46, 77], "interven": 34, "1990": [34, 43, 58, 62, 80, 113], "watersh": 34, "surpass": [34, 70], "ensembl": [34, 64, 66], "lightli": 34, "pipelin": [34, 52, 58, 60, 73, 120, 137], "sift": [34, 58], "surf": 34, "came": [34, 58, 60, 75, 90, 92, 115, 121, 122, 127], "clever": [34, 42, 76, 80, 82, 115], "geometri": [34, 58, 117], "afterthought": 34, "multichannel": 34, "geforc": 34, "1999": 34, "mflop": [34, 62], "meaning": [34, 43, 79, 81, 89, 98, 102, 109, 112, 132, 139], "todai": [34, 46, 58, 62, 69, 113, 128, 136, 138], "tflop": 34, "ocr": [34, 43], "highli": [34, 41, 48, 50, 65, 71, 108, 111, 121, 134, 135], "squash": [34, 80], "sensor": [34, 35, 41, 58, 62, 69, 120, 136], "appl": [34, 58, 64, 69], "quicktak": 34, "sport": [34, 64], "whop": [34, 62], "megapixel": [34, 46, 67], "vga": 34, "price": [34, 35, 36, 40, 46, 58, 60, 64, 65, 67, 69, 78, 120, 135, 136, 142], "optic": [34, 58, 67], "analyt": [34, 61, 77, 82, 110, 135], "occasion": [34, 90, 130], "serendipit": [34, 35], "discoveri": [34, 61], "lucki": [34, 39, 60, 67, 105], "graduat": [34, 113], "student": [34, 58, 60, 67, 113, 121], "extractor": [34, 58], "robust": [34, 35, 47, 48, 54, 60, 66, 70, 74, 103, 104, 110, 130, 135], "opencv": 34, "dump": [34, 58], "favorit": 34, "spoke": [34, 121], "repli": [34, 58, 128], "beauti": [34, 58, 95, 109], "eleg": [34, 39, 52, 58, 65, 113], "theori": [34, 41, 42, 58, 60, 63, 67, 74, 76, 77, 102, 107, 113, 121, 130, 132], "thrive": 34, "rigor": [34, 35, 80, 113, 115, 117], "emin": 34, "hear": [34, 58], "dirti": [34, 59, 117, 119], "novel": [34, 58, 127, 132], "drove": [34, 60], "justifi": [34, 58, 67, 68, 112], "believ": [34, 35, 46, 47, 48, 60, 66, 67, 69, 113, 117, 121, 136], "cleaner": [34, 48], "cast": [34, 53, 64, 66, 67, 113], "affair": 34, "And": [34, 45, 46, 58, 60, 61, 64, 67, 77, 79, 80, 113, 117, 121, 127, 138], "mostli": [34, 35, 46, 48, 51, 58, 76, 112], "promin": [34, 58, 127, 131], "hog": 34, "histogram": [34, 87, 97, 128], "orient": [34, 58, 68, 71, 73, 142], "roost": 34, "yann": [34, 43], "lecun": [34, 43], "geoff": 34, "hinton": 34, "yoshua": 34, "bengio": [34, 127], "andrew": [34, 50, 113], "ng": [34, 58], "shun": 34, "ichi": 34, "amari": 34, "juergen": 34, "schmidhub": 34, "ought": [34, 66, 71, 75], "analogi": [34, 76, 94, 98, 142], "advent": [34, 58], "traction": 34, "inventor": [34, 35, 80], "krizhevski": 34, "evolutionari": 34, "excel": [34, 58, 67, 105, 112, 113, 117], "reproduct": [34, 43, 76], "courtesi": [34, 46], "descriptor": 34, "nose": 34, "blade": 34, "grass": 34, "frisbe": 34, "ultim": [34, 45, 49, 60, 65, 66, 67, 69, 115, 136, 137], "1995": [34, 58, 62], "beg": [34, 54], "regim": [34, 35, 58, 77], "tighter": 34, "tini": [34, 35, 135], "uci": [34, 120], "2009": [34, 58], "noun": [34, 58, 83, 96], "node": [34, 45, 52, 76, 77, 80, 89, 126, 131, 135], "wordnet": 34, "team": [34, 43, 64], "prefilt": 34, "candid": [34, 40, 51, 58, 97, 122, 126, 127, 136], "amazon": [34, 50, 52, 53, 58, 87, 113, 138], "turk": 34, "crowdsourc": 34, "unpreced": 34, "exceed": [34, 58], "80": [34, 54, 55, 58, 79, 90, 91, 121, 128], "tinyimag": 34, "thumbnail": 34, "dub": 34, "push": [34, 39, 56, 58, 69, 104, 135], "academ": [34, 58, 75, 113], "laion": 34, "5b": 34, "metadata": 34, "voraci": 34, "cycl": [34, 58, 60, 131], "prefer": [34, 35, 40, 45, 58, 64, 69, 77, 112, 113, 128, 132, 133, 136], "chip": [34, 37, 41, 95, 97, 99], "throughput": 34, "strikingli": [34, 123], "ati": [34, 113], "begun": [34, 38, 61], "market": [34, 58, 60, 87, 131], "gpgpu": 34, "microprocessor": [34, 99], "clock": [34, 51, 54, 55, 56, 102, 108], "megabyt": [34, 43, 119], "l3": [34, 108], "branch": [34, 38, 39, 74, 142], "predictor": [34, 47, 48, 60, 77, 80], "specul": [34, 35], "bell": [34, 43, 62, 71], "whistl": [34, 71], "appar": [34, 80], "strength": [34, 37, 77], "achil": 34, "heel": 34, "alu": 34, "aforement": [34, 39, 75, 82, 89, 90, 91, 92, 96, 110, 114, 129], "interconnect": 34, "bad": [34, 58, 60, 67, 77, 81, 86, 88, 94, 95, 122, 135, 140], "dedic": [34, 117, 127], "laptop": [34, 57, 120], "rare": [34, 43, 60, 65, 67, 93, 96, 97, 102, 105, 130, 132, 135, 137], "socket": [34, 108], "nivida": 34, "latest": [34, 82], "amper": 34, "6912": 34, "warp": 34, "amd": 34, "arm": [34, 58, 60, 103, 133], "vendor": 34, "weak": 34, "1ghz": 34, "a100": 34, "bfloat16": [34, 65], "fp32": [34, 65], "graviton": 34, "peak": [34, 46, 58, 69], "m1": [34, 117], "processor": [34, 58, 69, 108], "flop": 34, "consumpt": [34, 36, 60], "energi": [34, 64, 71], "shine": 34, "buse": 34, "ilya": 34, "sutskev": 34, "gtx": 34, "580": 34, "3gb": 34, "convnet": [34, 42, 64], "coupl": [34, 60, 121], "transcend": 34, "streamlin": [34, 72, 125], "quirk": 34, "eight": [34, 77], "sigmoid": [34, 35, 43, 82, 89, 99, 107, 125, 127], "delv": [34, 60, 82, 109, 113], "times11": 34, "taller": [34, 96], "occupi": [34, 55], "times5": 34, "huge": [34, 58, 61, 73, 83, 84, 89, 90, 91, 98, 99], "1gb": 34, "dual": [34, 45], "decai": [34, 35, 52, 61, 67, 68, 75, 76, 77, 79, 102, 104, 107, 108, 112, 136, 137, 142], "depth": [34, 36, 40, 47, 58, 64, 77, 106, 108, 109, 113, 123, 135], "apply_init_cnn": [34, 35, 36, 37, 39], "384": [34, 37, 51, 108], "6400": 34, "layer_summari": [34, 37, 39, 43], "26": [34, 54, 55, 88, 105], "hour": [34, 52, 54, 58, 106, 136], "faith": 34, "costli": [34, 37, 39, 69, 74, 105, 127], "bear": [34, 42, 60, 67, 87, 88], "strike": [34, 41, 58, 113, 122], "critic": [34, 35, 36, 60, 69, 113, 140], "month": [34, 43, 58, 70], "accomplish": [34, 39, 43, 44, 45, 58, 64, 73, 75, 86, 105, 107, 109, 110, 113, 132], "dozen": [34, 47, 82], "164": 34, "mb": [34, 58], "81": [34, 47, 79, 121, 128], "outlai": 34, "mobil": [34, 58], "shallow": [34, 58, 68, 75], "hardli": [34, 44, 45, 64, 82, 131], "virtual": [34, 35, 47, 54], "seem": [34, 35, 40, 46, 47, 48, 49, 58, 61, 69, 75, 77, 82, 105, 109, 113, 122, 131, 137, 139], "embrac": [34, 46], "conceptu": [34, 58, 81, 90], "advantag": [34, 35, 36, 41, 44, 45, 47, 49, 58, 60, 62, 70, 71, 75, 80, 113, 125, 135], "experiment": [34, 37, 38, 42, 43, 44, 58, 103, 109, 111], "distbelief": [34, 70], "caff": [34, 58, 70], "footprint": [34, 40, 75, 117, 120], "latenc": [34, 108], "trade": [34, 37, 39, 40, 60, 61, 64, 69, 74, 103, 108, 122, 136], "off": [34, 37, 38, 39, 40, 44, 46, 48, 58, 60, 61, 64, 74, 77, 79, 82, 83, 91, 100, 103, 108, 114, 117, 121, 122], "pin": [34, 58, 107], "tricki": [35, 44, 60, 71, 105, 110, 130, 132], "secondari": [35, 52, 80], "hous": [35, 36, 57, 58, 64, 69, 78, 121, 138, 139, 142], "boldsymbol": [35, 64, 73, 86, 102, 105, 109, 112, 121], "frequent": [35, 44, 52, 57, 58, 60, 69, 72, 80, 82, 93, 96, 102, 108, 113, 132, 136, 137], "diagon": [35, 39, 40, 41, 47, 48, 100, 102, 105, 109, 117, 121], "uniti": 35, "sigma_": 35, "constrain": [35, 42, 48, 52, 62, 74, 77, 80, 104, 121], "celebr": [35, 58, 69], "radiu": [35, 104, 115, 135], "theorem": [35, 49, 61, 64, 77, 102, 104, 109, 113, 121], "cousin": 35, "postul": 35, "drift": 35, "hamper": 35, "conjectur": 35, "compensatori": 35, "solver": [35, 109, 112, 121], "adagrad": [35, 101, 105, 106, 111, 142], "yogi": [35, 106], "shampoo": 35, "aim": [35, 46, 52, 60, 61, 76, 78, 85, 121, 125, 133], "viewpoint": [35, 115], "liabl": 35, "convei": [35, 38, 58, 75, 112, 114, 121], "stabil": [35, 37, 65, 78, 95, 99, 101, 103, 130, 142], "freedom": [35, 114], "guess": [35, 47, 58, 61, 67, 79, 102, 104, 118, 121, 136], "devot": [35, 58, 74, 121], "stabl": [35, 64, 65, 82, 109, 130], "takeawai": [35, 76], "calibr": [35, 101], "odot": [35, 75, 100, 101, 103, 111, 117, 125, 127], "beta": [35, 80, 86, 103, 104, 109, 112], "diverg": [35, 80, 82, 100, 103, 105, 107, 109, 130, 135, 136], "allud": 35, "aggress": [35, 46, 61, 102, 112], "counteract": [35, 130], "noisi": [35, 47, 52, 56, 69, 77, 109, 112], "contrari": [35, 82, 85], "recur": [35, 136], "bayesian": [35, 47, 48, 49, 50, 51, 54, 56, 64, 69, 74, 121], "penalti": [35, 39, 58, 59, 69, 77, 129], "shed": [35, 58, 83, 112], "light": [35, 58, 61, 71, 83, 112, 121, 141], "puzzl": 35, "moder": [35, 48, 56, 82, 109], "wherea": [35, 56, 58, 61, 73, 74, 102, 104, 105, 108, 109, 110, 114, 117, 119, 121, 127, 132, 136, 140], "destroi": [35, 58, 82], "explor": [35, 37, 38, 41, 44, 47, 52, 58, 62, 64, 67, 76, 80, 82, 84, 96, 106, 109, 114, 118, 126, 131, 138, 139], "resid": 35, "nonlinear": [35, 36, 39, 40, 46, 58, 69, 74, 82, 112], "phi": [35, 49, 75, 77, 80, 130, 133], "assumpt": [35, 38, 46, 47, 48, 49, 58, 60, 61, 67, 69, 77, 80, 82, 121, 138, 141], "consider": [35, 39, 44, 58, 60, 61, 64, 67, 69, 70, 73, 74, 77, 79, 81, 102, 105, 108, 117, 121, 123, 131, 132], "rightarrow": [35, 52, 104, 105, 115, 119, 121, 129, 140, 141], "wise": [35, 38, 40, 60, 69, 102, 108, 109, 111, 127], "approx": [35, 47, 64, 93, 112, 129, 133], "neq": [35, 60, 61, 64, 89, 98, 102, 105, 115, 117, 121], "infti": [35, 49, 58, 61, 64, 104, 109, 121, 139, 140, 141], "determinist": [35, 45, 58, 60, 69, 140, 141], "consult": [35, 61, 109], "luxuri": 35, "exhibit": [35, 37, 46, 54, 58, 79, 80, 82, 104, 130, 136], "characterist": [35, 46, 58, 60, 102, 115, 121], "batch_norm": 35, "moving_mean": 35, "moving_var": 35, "var": [35, 82, 100, 121], "x_hat": 35, "asid": [35, 43, 47, 61, 64, 74, 105, 113, 122], "bookkeep": [35, 53, 54, 56], "sake": [35, 41, 60, 75], "num_featur": 35, "num_dim": 35, "misnom": [35, 41, 69], "whatsoev": 35, "defer": [35, 72], "bnlenetscratch": 35, "84": [35, 43, 55, 107], "39026": 35, "37369": 35, "35802": 35, "4576": 35, "49847": 35, "38626": 35, "0650986": 35, "0108574": 35, "0253824": 35, "0769677": 35, "0154659": 35, "0418726": 35, "992138": 35, "03883": 35, "04084": 35, "999702": 35, "15719": 35, "01737": 35, "0301728": 35, "0303096": 35, "0288679": 35, "0360559": 35, "0356934": 35, "00168506": 35, "32831": 35, "16009": 35, "58963": 35, "44081": 35, "12681": 35, "09346": 35, "245147": 35, "0438392": 35, "257939": 35, "0622285": 35, "105919": 35, "25507": 35, "0244": 35, "37976": 35, "19781": 35, "62279": 35, "77749": 35, "97949": 35, "887637": 35, "43999": 35, "49573": 35, "88754": 35, "931088": 35, "385643": 35, "bnlenet": 35, "compil": [35, 60, 114, 127], "phenomena": [35, 136], "unseen": [35, 46, 58, 61, 67, 69, 76, 77, 113, 115], "refin": [35, 45, 103, 107], "presum": 35, "meant": 35, "render": [35, 60, 64, 82, 113], "leav": [35, 45, 47, 51, 67, 74, 79, 82, 91, 104, 112, 113, 126], "guid": [35, 46, 52, 64, 79, 136, 142], "eventu": [35, 43, 46, 58, 77, 105, 117, 135, 138], "master": [35, 58, 61, 80, 114, 127], "delin": [35, 45], "hunch": 35, "repeatedli": [35, 46, 49, 58, 61, 104, 115], "surfac": [35, 47, 49, 58, 64, 69, 82, 115, 121, 136], "broader": [35, 41, 63, 113, 121], "discours": [35, 113], "memor": [35, 58, 61, 67, 77], "accept": [35, 41, 58, 72, 83], "award": 35, "2017": [35, 58, 62, 127], "neurip": [35, 49], "ali": [35, 113], "rahimi": [35, 113], "liken": [35, 58], "alchemi": 35, "troubl": [35, 58, 60, 65, 67, 69, 73, 80, 112, 121], "author": [35, 39, 58, 60, 76, 82, 101, 103, 113, 123, 135], "opposit": [35, 58, 82, 89, 130], "worthi": [35, 58, 60], "vagu": [35, 58], "reson": 35, "ow": [35, 42, 58, 67, 71, 79, 93, 113, 127, 128, 131, 135], "broad": [35, 58, 67, 77, 90], "audienc": [35, 65], "proven": [35, 41, 104, 106, 114, 126, 133], "earn": [35, 58, 121, 139], "citat": [35, 113], "perturb": [35, 58, 60, 71, 76, 102, 109, 115, 127, 136], "lite": 35, "displac": [35, 38, 113], "monarch": 35, "sparsif": 35, "symmetri": [35, 64, 80, 121], "preced": [36, 56, 91, 126, 129], "taylor": [36, 105], "decompos": [36, 40, 86, 109, 117, 130, 136], "vein": [36, 115], "necessarili": [36, 58, 60, 64, 67, 136, 137, 138, 140], "f_1": [36, 61, 82], "f_2": [36, 61], "f_3": 36, "conv_block": 36, "lazi": [36, 70], "denseblock": 36, "num_conv": 36, "\u8fde\u63a5\u901a\u9053\u7ef4\u5ea6\u4e0a\u6bcf\u4e2a\u5757\u7684\u8f93\u5165\u548c\u8f93\u51fa": 36, "transition_block": 36, "growth_rat": 36, "arch": [36, 39], "unfortun": [36, 39, 47, 52, 58, 60, 61, 62, 69, 74, 82, 89, 102, 107, 108, 111, 112, 121, 122, 130, 132, 136], "tabl": [36, 39, 58, 73, 93, 117, 120, 121, 131], "2014": [37, 58], "nin": [37, 38], "cocktail": 37, "persist": [37, 61, 114, 120, 121], "ingeni": [37, 102], "meme": 37, "movi": [37, 58, 64, 87, 88, 90, 113, 136, 138], "capac": [37, 39, 52, 58, 74, 78, 136], "c1": [37, 72], "c4\u662f\u6bcf\u6761\u8def\u5f84\u7684\u8f93\u51fa\u901a\u9053\u6570": 37, "c2": [37, 72], "c3": [37, 72], "\u7ebf\u8def1": 37, "\u53551x1\u5377\u79ef\u5c42": 37, "p1_1": 37, "\u7ebf\u8def2": 37, "1x1\u5377\u79ef\u5c42\u540e\u63a53x3\u5377\u79ef\u5c42": 37, "p2_1": 37, "p2_2": 37, "\u7ebf\u8def3": 37, "1x1\u5377\u79ef\u5c42\u540e\u63a55x5\u5377\u79ef\u5c42": 37, "p3_1": 37, "p3_2": 37, "\u7ebf\u8def4": 37, "3x3\u6700\u5927\u6c47\u805a\u5c42\u540e\u63a51x1\u5377\u79ef\u5c42": 37, "p4_1": 37, "p4_2": 37, "p3": 37, "p4": 37, "\u5728\u901a\u9053\u7ef4\u5ea6\u4e0a\u8fde\u7ed3\u8f93\u51fa": 37, "tripl": [37, 125, 127, 130, 137], "suffic": [37, 41, 102, 108, 133], "208": 37, "160": 37, "288": 37, "832": 37, "144": 37, "partit": [37, 58, 64, 66, 75, 79, 115, 120, 130, 131], "grant": [37, 58, 60, 71, 82, 108, 115], "configur": [37, 39, 51, 54, 55, 56, 71, 92, 103, 125, 127], "explicitli": [37, 47, 58, 67, 69, 70, 73, 80, 90, 107, 109, 130], "flux": 37, "brute": [37, 38], "forc": [37, 38, 58, 60, 103, 104, 108, 109, 125, 126, 135], "genet": [37, 58], "procedur": [37, 47, 48, 49, 58, 60, 69, 71, 77, 79, 92, 102, 106, 108, 109, 111, 112, 114, 115, 119, 130, 131], "cheaper": [37, 52, 102], "deliber": [37, 58], "sec_cnn": [37, 39], "proud": 37, "nativ": [37, 113], "wire": [38, 64, 69], "tour": 38, "necess": 38, "incomplet": 38, "plethora": [38, 87], "Their": [38, 72, 76, 103, 113], "winner": 38, "runner": 38, "baromet": 38, "trial": [38, 51, 52, 53, 54, 55, 56, 113, 121, 140, 141], "chronolog": 38, "partli": [38, 40, 58, 71], "sens": [38, 39, 40, 47, 48, 58, 60, 61, 64, 66, 74, 77, 79, 80, 104, 107, 114, 121, 123, 135], "histori": [38, 51, 58, 103, 111, 114, 131, 135, 136], "beat": [38, 58, 67, 113, 132], "convolv": 38, "googlenet": [38, 39, 142], "shelf": [38, 58, 60, 91], "resnext": [38, 40, 142], "densenet": [38, 142], "shiftnet": [38, 39], "culmin": [38, 43, 126], "mobilenet": 38, "v3": 38, "semi": 38, "regnetx": [38, 39], "insofar": [38, 43, 58, 67, 77, 111], "marri": [38, 113], "ingenu": [38, 39, 58], "pivot": [38, 63, 68], "incept": [38, 39], "imper": [39, 58], "bet": 39, "argmin": [39, 52, 69, 104], "_f": [39, 60], "subseteq": [39, 121], "_3": [39, 130, 133], "_6": 39, "newli": [39, 69, 119], "heart": [39, 58, 61, 69, 108, 117, 121], "profound": [39, 58, 61, 121], "predat": [39, 69], "highwai": 39, "albeit": [39, 44, 58, 65, 82, 102, 105, 108, 109, 112, 137], "shortcut": 39, "widespread": [39, 70, 128], "c_": [39, 40, 49, 60, 117, 130], "emit": [39, 43, 58, 135], "proport": [39, 41, 60, 64, 75, 139], "smorgasbord": 39, "fittingli": 39, "proportion": 39, "amend": [39, 103], "sandwich": 39, "duti": 39, "date": [39, 58, 64, 69, 113, 114, 136], "ill": [39, 60], "resnextblock": 39, "bot_channel": 39, "bot_mul": 39, "bn3": 39, "conv4": 39, "bn4": 39, "resnetblock": 39, "subtli": [39, 64], "induct": [39, 46, 52, 67, 77], "bypass": 39, "gate": [39, 113, 123, 126, 142], "frugal": 39, "against": [39, 51, 55, 62, 66, 71, 73, 79, 83], "mimick": 39, "k_": [40, 41, 44, 47, 48, 49], "times1": [40, 41, 44, 88, 119], "times4": [40, 88], "times0": [40, 41, 44, 122], "corr2d_multi_in": 40, "0th": [40, 88], "72": [40, 54, 55, 117], "104": 40, "respond": [40, 41, 46, 58, 60], "realiti": [40, 45, 46, 58, 60, 64, 79], "naiv": [40, 47, 58, 61, 69, 102, 108], "detector": [40, 41, 46, 58, 60], "corr2d_multi_in_out": 40, "76": 40, "148": [40, 128], "172": 40, "adjac": [40, 41, 42, 45, 88, 131, 132, 133, 136], "constitut": [40, 58, 66, 67, 74, 117, 121, 123, 137], "fold": [40, 56, 67, 77, 78], "corr2d_multi_in_out_1x1": 40, "c_o": 40, "drastic": [40, 44, 46, 107, 135], "53": [40, 121], "cut": [40, 77, 82, 134], "k_1": [40, 49], "k_2": [40, 49], "s_": [40, 44, 45, 47, 139, 140, 141], "scan": [40, 43, 58], "strip": [40, 44, 85, 91], "broken": [40, 82, 85, 108, 121, 140], "downsid": [40, 77, 135], "stick": [41, 58, 60, 69, 74, 135], "subtensor": [41, 45, 88], "43": [41, 54, 55, 81, 121], "wholli": 41, "n_": [41, 44, 82, 121], "minu": 41, "pars": [41, 58], "finit": [41, 49, 60, 61, 64, 67, 69, 70, 77, 104, 106, 110, 121], "discret": [41, 46, 50, 58, 64, 79, 83, 87, 112, 121, 132, 136], "partial_i": [41, 102, 115], "lim_": [41, 49, 104, 115, 141], "neat": 41, "imposs": [41, 58, 60, 74, 82, 114, 121], "3e": 41, "\u8fed\u4ee3\u5377\u79ef\u6838": 41, "442": 41, "529": 41, "251": [41, 54], "191": 41, "943922": 41, "03332": 41, "noteworthi": [41, 85, 90, 133], "unaffect": 41, "terminologi": [41, 69, 90, 122], "neurophysiologi": 41, "stimuli": 41, "cortex": 41, "reprint": 41, "diagram": [41, 64, 69, 109, 121, 127], "symmetr": [41, 44, 46, 47, 93, 110, 117, 130], "incredibli": [41, 132], "biologi": [41, 42, 58], "surpris": [41, 60, 61, 67, 76, 77, 80, 105, 113, 132, 136], "hindsight": [41, 55], "herald": 41, "afford": [41, 67, 70, 103], "invest": [41, 60, 121], "door": 41, "blur": [41, 64], "sharpen": [41, 121], "statistician": [41, 60, 61, 64, 69, 121, 136], "evid": [41, 69, 121], "delightfulli": 41, "brain": [41, 58, 80, 131], "v_1": 41, "v_2": 41, "orthogon": [41, 81, 102, 109], "strongli": [41, 47, 48, 52, 58, 65, 72, 121], "messag": [41, 60], "monochromat": 42, "accordingli": [42, 46, 60, 102, 104, 117], "irrespect": [42, 140, 141], "deepli": [42, 115], "unsatisfi": [42, 61], "nearbi": 42, "imagnet": 42, "colloqui": [42, 64], "healthi": [42, 60, 121], "dose": 42, "tinker": 42, "credibl": [42, 47, 48], "competitor": 42, "audio": [42, 44, 46, 58, 79, 120], "brought": 42, "walk": [42, 47, 50, 58, 72, 79, 97, 105, 121], "ingredi": [43, 52, 58, 80], "cloth": [43, 58, 62, 80, 138], "amen": [43, 58, 80], "times28": 43, "784": [43, 52, 65, 66, 76, 81], "parsimoni": 43, "publish": [43, 49, 61, 113, 127], "AT": [43, 62], "digit": [43, 58, 62, 67], "outstand": 43, "deposit": [43, 58, 90, 94], "atm": 43, "hi": [43, 46, 58, 85, 98, 113, 127, 128], "colleagu": [43, 113], "leon": 43, "bottou": 43, "remind": [43, 58], "convinc": [43, 52], "liberti": 43, "greatli": [43, 47, 58, 72], "x_shape": 43, "__class__": 43, "__name__": [43, 72, 113, 118], "compens": [43, 60, 102], "trim": [43, 58, 85], "forgo": [43, 61], "fare": [43, 61], "particip": [43, 79, 133], "1980": [43, 58, 81, 114], "assembli": 43, "sn": 43, "lisp": [43, 70, 80], "minut": [43, 54, 55, 58, 60, 117, 122], "incred": 43, "tremend": [43, 58, 79, 126], "journei": [43, 117], "rabbit": 43, "hole": [43, 140, 141], "sweater": 43, "wind": [44, 58, 67], "240": [44, 54], "slice": [44, 67, 73, 74, 79, 104, 116, 117, 128, 132, 136], "obliter": 44, "perimet": 44, "filler": 44, "odd": [44, 121], "lceil": 44, "rceil": 44, "cleric": 44, "elev": 44, "comp_conv2d": 44, "006795": 44, "160262": 44, "254271": 44, "445965": 44, "00831387": 44, "151705": 44, "214373": 44, "169669": 44, "578095": 44, "201815": 44, "107239": 44, "355678": 44, "113741": 44, "165136": 44, "562286": 44, "309312": 44, "223754": 44, "108913": 44, "0777335": 44, "308797": 44, "0596657": 44, "303517": 44, "226628": 44, "13654": 44, "168673": 44, "499139": 44, "0353719": 44, "426747": 44, "0521719": 44, "094441": 44, "0134493": 44, "212274": 44, "108251": 44, "233703": 44, "056797": 44, "0818383": 44, "undesir": [44, 58, 109, 119, 130], "shrinkag": 44, "implicitli": [44, 47, 58, 72, 140], "whitespac": [44, 85], "mirror": [44, 58], "gradual": [45, 58, 60, 98, 105], "sharp": [45, 65, 90], "vastli": 45, "tripod": 45, "stationari": [45, 49, 60, 69, 107, 136], "vibrat": 45, "movement": 45, "shutter": 45, "slid": 45, "cognit": [45, 58, 115, 131], "neurosci": [45, 58, 69], "pool2d": 45, "pool_siz": 45, "p_h": 45, "p_w": 45, "avg": [45, 108], "needless": 45, "overrid": 45, "exceedingli": [45, 105], "indiffer": 45, "quarter": 45, "tabular": [46, 120, 131], "anticip": [46, 58, 136], "seek": [46, 58, 61, 62, 69, 113], "fancier": [46, 68, 79], "perceptu": [46, 58], "structureless": 46, "thorough": [46, 102, 113], "job": [46, 47, 51, 54, 55, 56, 58, 60, 79], "annot": [46, 58, 60, 110], "photograph": [46, 58, 60, 67, 121], "talent": [46, 58], "extraordinari": [46, 50, 67], "patienc": [46, 77], "grossli": [46, 61], "underestim": [46, 61], "seemingli": [46, 73, 77, 136], "contradict": [46, 85, 86, 104], "overli": [46, 47, 61, 76, 105, 111], "pig": 46, "fly": [46, 60, 73, 90, 92], "plane": [46, 83], "swim": 46, "waldo": 46, "life": [46, 50, 62, 65, 67, 101, 111], "imit": [46, 58, 138], "chaotic": 46, "burst": [46, 108], "somewher": 46, "lurk": 46, "him": [46, 67], "distract": [46, 68], "sweep": 46, "william": [46, 47], "murphi": 46, "infomatiqu": 46, "desiderata": 46, "equivari": 46, "distant": [46, 58], "sink": 46, "sum_k": [46, 65, 66], "sum_l": 46, "sum_a": [46, 117, 121, 141], "sum_b": 46, "cosmet": [46, 103], "re": [46, 47, 49, 51, 52, 58, 64, 73, 85, 96, 103, 113, 137], "subscript": [46, 64, 69, 117], "impli": [46, 55, 67, 80, 98, 104, 110], "vicin": [46, 110], "delai": [46, 138], "tdnn": 46, "glean": 46, "assess": [46, 58, 59, 61, 64, 67, 69, 80, 121, 131], "outsid": [46, 60, 65, 74, 104, 112, 114, 132], "paid": 46, "agre": [46, 61, 69, 76], "struggl": [46, 58, 69], "bring": [46, 60, 105, 113, 130], "desideratum": 46, "interleav": [46, 113], "summabl": 46, "infinit": [46, 48, 49, 50, 61, 64, 67, 77, 80, 105, 121, 139, 140], "weigh": [46, 60], "wherev": [46, 93], "blissfulli": 46, "multidimension": [46, 104, 119], "sum_c": 46, "anywher": 46, "unclear": [46, 102], "neighborhood": [46, 60], "neocognitron": 46, "tractabl": 46, "satellit": [46, 58], "agricultur": 46, "meteorologi": 46, "hyperspectr": [46, 62], "wavelength": [46, 71], "spectrogram": 46, "land": [47, 138], "temperatur": [47, 60, 64, 71, 80, 117, 135, 140], "co_2": 47, "concentr": [47, 48, 74], "latent": [47, 48, 125, 127, 133, 136], "x_1": [47, 48, 49, 64, 69, 74, 97, 102, 105, 109, 111, 112, 115, 117, 129, 130, 131, 132, 133, 135, 136], "x_n": [47, 48, 49, 69, 112, 115, 117], "textbf": 47, "multivari": [47, 48, 49, 74, 106, 115], "rbf": [47, 48, 50, 80], "ell": [47, 48, 49, 140], "17": [47, 48, 49, 54, 55, 80, 88, 117, 119], "aka": 47, "iid": [47, 48, 67], "2i": [47, 117], "bishop": [47, 76], "m_": [47, 110], "uncertainti": [47, 48, 58, 76, 112, 116, 121], "amplitud": [47, 48, 49, 58], "lengthscal": [47, 48, 49], "compartment": 47, "occam": 47, "razor": 47, "mackai": 47, "ch": 47, "rasmussen": 47, "pyplot": [47, 55, 113, 115], "scipi": [47, 49, 51, 52, 56, 113], "distance_matrix": [47, 49, 113], "maxim": [47, 54, 64, 69, 77, 83, 89, 98, 104, 110, 117, 121, 122, 138, 140, 141], "y_": [47, 122, 129, 136], "v_": [47, 109, 141], "incur": [47, 58, 60, 61, 64, 69, 108], "choleski": 47, "decomposit": [47, 64, 86, 117, 141], "histor": [47, 58, 61, 69, 82, 132, 133, 136], "reput": 47, "singular": [47, 58, 83], "caus": [47, 55, 58, 60, 61, 64, 66, 80, 82, 105, 110, 119, 121, 132, 135], "jitter": 47, "4x": [47, 115], "data_maker1": 47, "sig": 47, "randn": 47, "train_x": 47, "test_x": 47, "linspac": [47, 49, 110], "train_i": 47, "test_i": 47, "scatter": [47, 56, 77, 113], "circl": [47, 74, 75, 102, 104, 115, 130], "rbfkernel": [47, 49], "chanc": [47, 79, 82, 121], "prior_sampl": [47, 49], "multivariate_norm": [47, 49, 118], "fill_between": [47, 49], "diag": [47, 102, 105], "f_": [47, 60, 61, 115], "ell_est": 47, "post_sig_est": 47, "neg_mll": 47, "par": 47, "kernel_term": 47, "linalg": [47, 114, 117], "inv": 47, "logdet": 47, "det": 47, "const": 47, "learned_hyp": 47, "x0": [47, 85], "299": 47, "extrem": [47, 58, 60, 64, 65, 67, 69, 77, 95, 108, 121, 125, 136], "immun": 47, "poor": [47, 52, 58, 67, 82, 103, 105, 140], "script": [47, 54, 57], "hyper": [47, 140], "k_x_xstar": 47, "k_x_x": 47, "k_xstar_xstar": 47, "post_mean": 47, "post_cov": 47, "lw_bd": [47, 49], "up_bd": [47, 49], "func": [47, 104], "orang": [47, 48, 64], "perfectli": [47, 48, 49, 58, 60, 61, 64, 65, 67, 71, 77, 102, 105, 121, 132], "lw_bd_observ": 47, "up_bd_observ": 47, "epistem": [47, 48, 121], "aleator": [47, 121], "irreduc": 47, "belief": [47, 121], "careless": 47, "undefin": 47, "confus": [47, 58, 60, 69, 117], "meaningless": [47, 89, 107], "spirit": [47, 58], "quantiti": [47, 58, 59, 61, 76, 79, 117, 121, 130, 132, 139, 141], "posteriori": 47, "post_sampl": 47, "grai": 47, "mont": [47, 58], "carlo": [47, 58], "acquisit": [47, 121], "pretti": [47, 58, 103, 121, 136], "cumbersom": [47, 105, 141], "ski": [47, 113], "kiss": 47, "feel": [47, 48, 51, 54, 58, 61], "reproduc": [47, 48, 49, 74, 80, 141], "matern_kernel": 47, "gpyotrch": 47, "spectral_mixture_kernel": 47, "bfg": 47, "inclin": [47, 60, 117], "codeblock": 47, "283": 47, "datapoint": [47, 48], "reliabl": [47, 58, 70, 77, 108, 140, 141], "autocorrel": 47, "covariogram": 47, "biggest": [47, 95, 120, 135], "lkelihood": 47, "plausibl": [47, 58, 80, 82, 121, 128, 132], "optima": [47, 52, 110], "slowli": [47, 48, 60, 66, 69, 102, 103, 105, 107, 111, 112, 127], "plausibli": 47, "room": [47, 58, 120], "fundament": [47, 58, 60, 61, 64, 66, 67, 74, 79, 80, 82, 110, 113, 117, 121, 131, 135, 138, 140], "matern": 47, "spectral": [47, 71, 117], "mixtur": 47, "valuabl": [47, 113], "versu": [47, 48, 55, 61, 120, 121], "uninterpret": [48, 49], "carbon": 48, "dioxid": 48, "forecast": [48, 60, 69, 136], "posterior": [48, 49, 50, 74, 121], "thick": 48, "acquir": [48, 58, 119], "radial": [48, 50, 80], "wiggli": 48, "pronounc": [48, 74, 117], "gp": [48, 49, 50], "uncorrel": 48, "strong": [48, 49, 58, 62, 67, 80, 121], "ddot": [48, 117], "pm": [48, 61, 67], "chose": [48, 139], "contour": [48, 105], "ellips": 48, "stronger": [48, 58, 60, 136], "83": [48, 55], "righli": 48, "x_2": [48, 64, 69, 74, 97, 102, 105, 109, 111, 112, 115, 117, 132], "introductori": [48, 50, 113], "delta_": [48, 112], "wiggili": 48, "Will": 48, "everywher": 49, "inaccess": 49, "langl": [49, 100, 112, 117], "rangl": [49, 100, 112, 117], "acquaint": 49, "appreci": 49, "w_0": [49, 67], "inner": [49, 100, 117, 119], "straight": [49, 54, 137], "slope": [49, 115], "intercept": [49, 69], "lin_func": 49, "n_sampl": 49, "x_point": 49, "w_1x": 49, "w_0w_1x": 49, "w_1w_0x": 49, "2xx": 49, "xx": 49, "phi_i": 49, "centr": 49, "w_j": [49, 93, 98], "infin": [49, 60, 61, 64, 89, 132], "c_j": [49, 93], "c_1": [49, 104], "riemann": 49, "int_": 49, "c_0": 49, "phi_c": 49, "dc": 49, "apart": [49, 51, 52, 61, 117], "propto": [49, 64, 74, 121, 135, 137], "absorb": 49, "univers": [49, 50, 58, 60, 108, 113, 138], "collaps": [49, 80, 121], "mass": [49, 58, 83, 136], "fuss": 49, "overparametr": 49, "misplac": 49, "meanvec": 49, "covmat": 49, "radford": 49, "neal": 49, "pursu": 49, "1996": 49, "infam": 49, "reject": [49, 132], "tangent": [49, 62, 77, 80, 115], "v_i": [49, 102, 119], "u_i": [49, 102, 115, 119], "sigma_b": 49, "sigma_v": 49, "h_i": 49, "erf": 49, "u_0": 49, "u_j": 49, "dt": 49, "tild": [49, 102, 125, 127], "tau": [49, 109, 130, 136, 139, 141], "stationar": [49, 136], "polynomi": [49, 50, 61, 74, 107, 112], "ornstein": 49, "uhlenbeck": 49, "ou": 49, "2g": 49, "m_1": 49, "m_2": 49, "gordon": 50, "wilson": 50, "york": [50, 58, 98], "ubitiqu": 50, "joke": 50, "perspect": [50, 62, 77, 93, 131, 136], "ml": [50, 52], "spatiotempor": 50, "harmon": 50, "gpytorch": 50, "complementari": 50, "broadli": [50, 61, 64, 69, 110, 121, 128, 131], "tradiat": 50, "upcom": [50, 58], "methodologi": 51, "decis": [51, 54, 55, 58, 60, 67, 80, 87, 94, 108, 113, 121, 123, 129, 138, 140, 141, 142], "primit": [51, 132], "hposearch": [51, 56], "hposchedul": [51, 56], "hpotun": [51, 56], "syne": [51, 54, 55], "rai": 51, "optuna": 51, "stat": [51, 52, 56], "sample_configur": [51, 56], "config": [51, 52, 54, 55, 56], "additional_info": [51, 56], "prescrib": 51, "initial_config": [51, 54, 55, 56], "randomsearch": [51, 54, 56], "config_spac": [51, 52, 54, 55, 56], "rv": [51, 52], "deleg": 51, "info": [51, 54, 55, 56], "basicschedul": [51, 54], "callabl": 51, "bookeep": 51, "incumb": [51, 54], "incumbent_error": 51, "incumbent_trajectori": 51, "cumulative_runtim": 51, "current_runtim": 51, "number_of_tri": [51, 56], "start_tim": 51, "wall": [51, 54, 55, 56, 97, 104], "sequel": 51, "trajectori": [51, 54, 58, 102, 105, 109, 111, 112, 136, 139, 140, 141], "hpo_objective_lenet": [51, 56], "hpotrain": [51, 52, 54, 55], "apply_init": 51, "get_dataload": [51, 62, 72, 73, 74, 79, 128, 132, 136], "validation_error": [51, 52, 54, 55], "loguniform": [51, 52, 54, 55, 56], "randint": [51, 54, 55, 56, 90, 97, 118], "5066198515892029": 51, "35": [51, 54, 55], "7679648399353": 51, "time_stamp": 51, "median": [51, 79], "popul": [51, 58, 60, 61, 67, 77, 97, 110, 121], "afterward": [51, 55, 56], "laid": [51, 58, 113, 119], "pitfal": [51, 113], "awar": [51, 58, 129], "dropoutmlp": [51, 54, 76], "sensibl": [51, 52, 132], "num_hiddens_1": [51, 76], "num_hiddens_2": [51, 76], "dropout_1": [51, 76], "dropout_2": [51, 76], "probab_loc": 51, "num_init_random": 51, "attain": [51, 61, 104], "smallest": [51, 56, 61, 64, 65, 69, 102, 121], "localsearch": [51, 54], "member": [51, 67, 72], "optimum": [52, 110], "workflow": [52, 113], "elast": 52, "g4dn": 52, "xlarg": 52, "hpo": [52, 53, 54, 55, 56], "tackl": [52, 58, 61, 69, 77, 136], "effort": [52, 58, 77, 90, 94, 104], "automl": 52, "logist": [52, 58, 60, 64, 80, 131], "softmaxregress": [52, 65], "criterion": [52, 54, 67, 69, 77], "star": [52, 58], "hypergradi": 52, "burden": 52, "week": [52, 58, 106], "accuracy_sum": 52, "val_batch_idx": [52, 71, 72], "val_dataload": [52, 62, 66, 71, 72], "hpo_objective_softmax_classif": 52, "num_output": [52, 65, 66, 76, 81, 86], "logarithm": [52, 64, 66, 69, 70, 79, 80, 89, 93, 100, 121, 122], "ye": [52, 58, 113], "99": [52, 61, 121, 137, 139], "mat": 52, "scope": [52, 60, 72, 102, 107, 121], "exhaust": [52, 58, 73, 113, 126], "num_iter": 52, "2146": 52, "best_idx": 52, "004499880970120725": 52, "shortcom": 52, "poorli": [52, 56, 74, 104, 132], "overcom": [52, 80, 126, 136], "phrase": [52, 96, 98, 132, 136], "curs": [52, 65], "disjoint": [52, 104, 108, 121], "loader": [52, 62, 68, 71, 72, 81, 132], "problemat": [52, 60, 67], "sketch": [52, 58], "rough": 52, "sheer": [52, 70], "explod": [52, 78, 126, 127, 130, 135], "unpract": 52, "baselin": [52, 54, 55, 64, 68, 79, 121, 132], "equi": 52, "combinatori": 52, "cartesian": 52, "sizabl": 52, "aaron": 53, "klein": 53, "matthia": [53, 113], "seeger": 53, "cedric": 53, "archambeau": 53, "suboptim": [53, 55, 56, 58, 107], "proxi": [53, 56, 102, 107], "searcher": [53, 54, 56], "tuner": [53, 54, 55, 56], "asynchron": [53, 142], "synchron": [54, 55, 131], "finish": [54, 55, 56], "synchronis": [54, 55], "grei": 54, "idl": [54, 55, 56], "worker": [54, 55, 56], "straggler": [54, 55], "invit": 54, "basicconfig": [54, 55], "syne_tun": [54, 55], "stoppingcriterion": [54, 55], "backend": [54, 55], "pythonbackend": [54, 55], "load_experi": [54, 55], "callback": [54, 55], "hpo_objective_lenet_synetun": [54, 55], "fit_epoch": [54, 55, 70, 71, 72, 135], "val_err": 54, "n_worker": [54, 55], "max_wallclock_tim": [54, 55], "cluster": [54, 58, 104], "trial_backend": [54, 55], "tune_funct": [54, 55], "behaviour": 54, "do_minim": [54, 55], "points_to_evalu": [54, 55], "mediat": [54, 60], "stop_criterion": [54, 55], "print_update_interv": [54, 55], "entrypoint": [54, 55], "2025": [54, 55], "07": 54, "47": [54, 121], "51": 54, "677": 54, "launch": [54, 55, 58, 60, 80, 113], "usr": [54, 55], "bin": [54, 55, 57, 87], "local_backend": [54, 55], "num_gpus_per_tri": [54, 55], "subprocess": [54, 55], "anaconda3": [54, 55], "d2lbook": [54, 55], "python3": [54, 55], "lib": [54, 55], "python_backend": [54, 55], "python_entrypoint": [54, 55], "py": [54, 55], "tune_function_root": [54, 55], "tune_function_hash": [54, 55], "2403b5305c7599b48033ce9ca0bc5baa": 54, "st_checkpoint_dir": [54, 55], "785419139652293": 54, "253": 54, "trial_id": [54, 55], "015451559930309012": 54, "314703831688577": 54, "132": 54, "02832486312228176": 54, "86": 54, "3114746598543795": 54, "220": 54, "14734507957489268": 54, "37475164983438675": 54, "159": [54, 55], "4994060435597754": 54, "87": 54, "06238492357004281": 54, "14754101174871392": 54, "153": 54, "42188880580044036": 54, "2993200275939439": 54, "19147449863618432": 54, "26059001016457334": 54, "964713800900415": 54, "10696632399613491": 54, "248": [54, 55], "5917570853739808": 54, "65": [54, 79], "04447784402047958": 54, "20403568510229048": 54, "108": 54, "100000": 54, "269680": 54, "29": [54, 55, 62], "100968": 54, "785419": 54, "211973": 54, "808257": 54, "015452": 54, "746909": 54, "373880": 54, "314704": 54, "198006": 54, "31": [54, 55, 64], "834912": 54, "028325": 54, "469100": 54, "693813": 54, "311475": 54, "238202": 54, "783766": 54, "147345": 54, "287549": 54, "384183": 54, "374752": 54, "233063": 54, "162082": 54, "499406": 54, "155126": 54, "493749": 54, "062385": 54, "278216": 54, "484688": 54, "147541": 54, "262952": 54, "690224": 54, "421889": 54, "152469": 54, "553498": 54, "299320": 54, "178825": 54, "563370": 54, "191474": 54, "226708": 54, "486506": 54, "260590": 54, "189823": 54, "39": [54, 55], "855617": 54, "964714": 54, "121458": 54, "46": [54, 55, 121, 135], "087984": 54, "106966": 54, "350325": 54, "626774": 54, "591757": 54, "262156": 54, "41": [54, 121], "274113": 54, "inprogress": [54, 55], "044478": 54, "335800": 54, "564189": 54, "204036": 54, "436": [25, 54, 107], "wallclock": [54, 55], "7649756579068647": 54, "212": [54, 55], "0988395141460621": 54, "701409313060209": 54, "90": [54, 58, 65, 67], "22": [54, 55, 64, 82, 108, 117], "7311914189829157": 54, "014936836616036158": 54, "13976762587971506": 54, "6377240017626923": 54, "165": 54, "01286225998599121": 54, "02014490729340573": 54, "124": 54, "1333083293327977": 54, "68": [54, 79], "2879408868000836": 54, "102": [54, 55, 137], "011605333152295885": 54, "01484052260681797": 54, "163": 54, "stopping_criterion": [54, 55], "720": [54, 55], "330900": 54, "36": [54, 93, 121], "690488": 54, "207319": 54, "098498": 54, "764976": 54, "331466": 54, "470002": 54, "098840": 54, "358084": 54, "490762": 54, "701409": 54, "145933": 54, "306699": 54, "731191": 54, "170778": 54, "191342": 54, "014937": 54, "900000": 54, "009057": 54, "139768": 54, "223214": 54, "841101": 54, "637724": 54, "171714": 54, "903314": 54, "012862": 54, "899822": 54, "627085": 54, "020145": 54, "899781": 54, "135524": 54, "133308": 54, "214130": 54, "098702": 54, "287941": 54, "205189": 54, "413799": 54, "011605": 54, "900636": 54, "102841": 54, "014841": 54, "899761": 54, "691636": 54, "721": [54, 55], "94": 54, "12145810759683173": 54, "tuning_experi": 54, "st_tuner_tim": [54, 55], "marker": [54, 55], "hpo_objective_dropoutmlp_synetun": 54, "setup": [54, 58, 60, 69, 140, 141], "sagemak": 54, "facil": 54, "bayesianoptim": 54, "tutori": [54, 113, 120], "sh": [55, 57], "rung": [55, 56], "r_": [55, 56, 61, 67], "promot": [55, 56, 58], "slot": 55, "sit": [55, 61, 90, 94], "idel": 55, "implementaiton": 55, "asha": 55, "scenario": [55, 61, 112, 132], "favour": 55, "rid": [55, 105], "modest": [55, 113], "impact": [55, 58, 60, 67, 113, 127, 137], "reflect": [55, 58, 60, 61, 77, 83, 98, 132], "pend": 55, "min_number_of_epoch": [55, 56], "max_number_of_epoch": [55, 56], "resource_attr": 55, "time_attr": 55, "max_t": 55, "max_resource_attr": 55, "grace_period": 55, "reduction_factor": 55, "190": [55, 128], "3890338391272654": 55, "8d938717fd641d43907cdb9888ac1aaa": 55, "011335521846740686": 55, "3472413436671253": 55, "213": 55, "016820573610021133": 55, "028005751626881802": 55, "04981619915828577": 55, "212063712661875": 55, "103": 55, "0001": [55, 61], "38809559103096963": 55, "010988948291006459": 55, "235": 55, "05600839449203463": 55, "166": 55, "01176482331903498": 55, "016564846045842005": 55, "28001134495568514": 55, "118": 55, "3011893656031137": 55, "08928561211360032": 55, "2583974707015322": 55, "216": 55, "02994522036707356": 55, "389034": 55, "174823": 55, "390648": 55, "011336": 55, "899918": 55, "746251": 55, "347241": 55, "199671": 55, "409475": 55, "016821": 55, "810999": 55, "634836": 55, "028006": 55, "329817": 55, "44": [55, 58, 64], "935998": 55, "049816": 55, "172483": 55, "607070": 55, "212064": 55, "157916": 55, "433653": 55, "388096": 55, "131109": 55, "157970": 55, "010989": 55, "900160": 55, "473000": 55, "056008": 55, "473938": 55, "698198": 55, "011765": 55, "900002": 55, "082558": 55, "016565": 55, "898847": 55, "910791": 55, "280011": 55, "170069": 55, "088011": 55, "301189": 55, "216004": 55, "259483": 55, "089286": 55, "261735": 55, "068030": 55, "258397": 55, "029945": 55, "435": 55, "89": 55, "014524661982273063": 55, "175": 55, "09615916813911475": 55, "06691128419125478": 55, "197": 55, "20248813907299865": 55, "129": 55, "011114022771092129": 55, "226": 55, "1846580541163797": 55, "08169016239095044": 55, "04385133919593825": 55, "038617876339801765": 55, "209": 55, "41776684604758285": 55, "177": 55, "016830288384432443": 55, "205": 55, "12345124308220282": 55, "03716318260525985": 55, "08300129677257653": 55, "97": [55, 121], "34819874766327785": 55, "249": [55, 108], "268789": 55, "619754": 55, "899793": 55, "221629": 55, "014525": 55, "899113": 55, "563362": 55, "096159": 55, "234850": 55, "190157": 55, "066911": 55, "466594": 55, "127466": 55, "202488": 55, "237821": 55, "175115": 55, "011114": 55, "900478": 55, "078950": 55, "184658": 55, "238133": 55, "205698": 55, "081690": 55, "247822": 55, "514397": 55, "043851": 55, "278472": 55, "559851": 55, "038618": 55, "899923": 55, "638117": 55, "417767": 55, "155831": 55, "305785": 55, "016830": 55, "899888": 55, "042010": 55, "123451": 55, "262178": 55, "001491": 55, "037163": 55, "414087": 55, "973114": 55, "083001": 55, "348199": 55, "13110899872947157": 55, "underperform": 55, "paus": [55, 60, 137], "resum": [55, 58], "wrong": [55, 58, 60, 66, 69, 81, 105, 123, 130, 135, 136], "sped": 56, "willing": [56, 58, 64, 81], "spend": [56, 58, 64, 132], "defaultdict": [56, 96, 113, 129], "worst": [56, 61, 67, 95, 105, 132, 135], "surviv": [56, 58, 64, 116], "r_i": 56, "jump": [56, 85], "successivehalvingschedul": 56, "r_min": 56, "r_max": 56, "prefact": 56, "rung_level": 56, "observed_error_at_rung": 56, "all_observed_error_at_rung": 56, "empti": [56, 58, 120, 128], "n0": 56, "pop": [56, 58, 69, 113, 131], "ri": 56, "ki": 56, "ni": [56, 58], "kiplus1": 56, "niplus1": 56, "best_performing_configur": 56, "get_top_n_configur": 56, "riplus1": 56, "sorted_rung": 56, "1574882117184726": 56, "07677412033081": 56, "vanilla": [56, 123, 125, 127], "rung_index": 56, "xi": [56, 104, 105, 112, 127], "xtick": [56, 110], "jupyt": [57, 72, 113, 115, 118], "conda": 57, "visit": [57, 58, 79, 136, 140], "maco": 57, "bash": 57, "macosx": 57, "intel": [57, 58, 95, 97, 99], "mac": 57, "miniconda3": 57, "py39_4": 57, "x86_64": 57, "linux": [57, 58], "cmd": 57, "shell": 57, "reopen": 57, "pleas": [57, 58], "horsepow": 57, "encapsul": [57, 125, 127], "pip": [57, 91], "html": 57, "page": [57, 58, 60, 75, 79, 102, 113], "fetch": [57, 129], "sudo": 57, "apt": 57, "localhost": 57, "8888": 57, "browser": [57, 58, 118], "exit": [57, 58], "deactiv": 57, "ordinari": [58, 64, 117, 121, 127], "rigid": [58, 61], "commerc": [58, 120], "platform": [58, 72, 79, 87, 113], "huddl": 58, "whiteboard": 58, "ponder": 58, "settl": [58, 64, 113], "commerci": [58, 113], "grade": [58, 71], "transact": [58, 121], "spell": [58, 60, 117, 127, 132], "circumst": [58, 60, 67], "event": [58, 64, 69, 89, 93, 100, 121, 131, 135, 136, 138], "shop": 58, "cart": 58, "kink": 58, "devis": 58, "scientist": [58, 60, 67, 79, 80, 113, 118, 131, 132, 136], "bend": 58, "smartest": 58, "tomorrow": [58, 60, 67], "weather": [58, 113, 136], "geograph": [58, 60], "trail": 58, "factoid": 58, "correctli": [58, 66], "brows": 58, "elit": 58, "programm": 58, "gracefulli": 58, "consciou": 58, "subconsci": 58, "accru": [58, 127], "healthcar": [58, 121], "genom": 58, "caffein": 58, "hop": 58, "iphon": 58, "hei": 58, "siri": 58, "awaken": 58, "voic": 58, "transcript": 58, "app": [58, 94], "fulfil": 58, "fabric": 58, "pedagog": [58, 113], "everydai": [58, 94, 117], "engag": [58, 113, 131, 136], "wake": [58, 61, 121], "alexa": 58, "ok": 58, "editor": [58, 113], "microphon": 58, "sound": [58, 60, 104, 132], "wave": 58, "stuck": [58, 104, 105, 109, 110, 116], "knob": 58, "meta": 58, "ahead": [58, 117, 136], "goe": [58, 61, 107, 121, 136], "fire": [58, 80, 82], "apricot": 58, "chines": [58, 113, 128], "coerc": [58, 80], "awesom": 58, "bare": [58, 65, 82, 109, 136], "gave": [58, 60], "wavi": 58, "badli": [58, 61, 67, 74, 104], "scienc": [58, 67, 69, 77, 113, 120], "usefulli": 58, "times200": 58, "120000": 58, "electron": [58, 64, 77, 95], "health": [58, 77, 80], "patient": [58, 60, 64, 67, 69, 77, 117, 121, 136], "ag": [58, 60, 69, 121], "vital": [58, 94, 104, 114, 117, 130], "sign": [58, 64, 103, 105, 110, 117, 139], "comorbid": 58, "microscop": 58, "equip": [58, 62, 127], "mine": 58, "risk": [58, 61, 67, 78, 80, 82, 108, 110, 112, 117], "resist": [58, 71], "stubbornli": 58, "imdb": [58, 87], "tripadvisor": 58, "stink": 58, "rambl": 58, "grace": 58, "preconceiv": 58, "contributor": [58, 113], "clich\u00e9": [58, 121], "garbag": 58, "polic": [58, 60], "screen": [58, 65], "lend": 58, "alert": 58, "failur": [58, 60], "unrepres": 58, "cancer": [58, 60, 69, 121], "societ": [58, 60], "prejudic": 58, "hire": 58, "inadvert": [58, 119], "injustic": 58, "conspir": 58, "smilei": 58, "ness": 58, "anomal": [58, 69, 121], "machineri": 58, "spit": 58, "stretch": [58, 109], "princip": 58, "disagre": [58, 61], "mere": [58, 60, 61, 69, 77, 80, 130], "surrog": [58, 115], "exam": [58, 67], "encourag": [58, 69, 90, 112, 113, 118, 139], "falter": 58, "brief": [58, 107, 108, 126], "supervisor": 58, "probabilist": [58, 61, 64, 69, 121, 136], "crispli": 58, "tomographi": 58, "stock": [58, 60, 67, 69, 79, 121, 136], "financi": [58, 121, 136], "ton": 58, "die": [58, 121], "wrap": [58, 87, 117], "harvest": 58, "sale": [58, 69], "footag": 58, "bedroom": [58, 64], "bathroom": 58, "town": 58, "san": [58, 132], "francisco": [58, 132], "ceo": 58, "microsoft": 58, "facebook": [58, 60], "sq": 58, "pittsburgh": 58, "3000": 58, "fair": [58, 63, 109, 121], "netflix": [58, 138], "prize": [58, 79, 121], "hospit": [58, 64, 69, 121, 136], "surgeri": 58, "rainfal": 58, "drain": 58, "repair": 58, "contractor": 58, "gunk": 58, "sewag": 58, "pipe": 58, "bill": [58, 131], "friend": 58, "someon": [58, 61, 64, 121, 136], "invoic": 58, "charg": 58, "comfort": [58, 77], "templat": 58, "bank": [58, 90, 94, 97, 121], "snap": 58, "sought": 58, "regressor": 58, "firm": [58, 78], "attack": [58, 77, 117, 121], "demystifi": [58, 64], "mushroom": 58, "backyard": 58, "death": [58, 136], "eat": [58, 83, 121, 132], "poison": 58, "fool": 58, "delici": 58, "dinner": 58, "uncertain": [58, 121], "outweigh": [58, 112], "detriment": [58, 108], "harm": 58, "caution": [58, 66, 108, 117], "mycologist": 58, "linnaeu": 58, "fauna": 58, "hierarchi": [58, 108], "schnauzer": 58, "dinosaur": 58, "rattlesnak": 58, "garter": 58, "snake": 58, "phylogenet": 58, "rattler": 58, "fatal": [58, 105], "neatli": [58, 86], "musician": [58, 85], "bremen": 58, "german": [58, 127], "fairi": 58, "tale": 58, "donkei": [58, 64], "rooster": [58, 64], "mutual": [58, 89, 121, 126], "blog": [58, 70, 87, 113], "gadget": 58, "medicin": [58, 64, 91, 113, 136], "profession": [58, 71, 113], "pubm": 58, "mesh": 58, "ontologi": 58, "conduct": [58, 61, 121, 135], "lag": 58, "archiv": 58, "provision": 58, "bioasq": 58, "host": [58, 64, 79, 119], "pagerank": 58, "secret": 58, "sauc": 58, "weirdli": 58, "priorit": [58, 113], "authorit": 58, "fiction": 58, "fan": 58, "connoisseur": 58, "peter": [58, 113], "seller": 58, "comedi": 58, "retail": [58, 69, 138], "music": [58, 131], "goodread": 58, "playlist": 58, "dissatisfact": 58, "mayb": 58, "song": 58, "inappropri": 58, "econom": 58, "suffer": [58, 104, 111, 121, 135, 136], "seriou": [58, 66, 67, 82, 113], "flaw": [58, 105], "censor": 58, "preferenti": 58, "conspicu": 58, "habit": 58, "incent": 58, "downtown": [58, 117], "forgotten": [58, 113], "succeed": 58, "throw": [58, 136], "po": [58, 83, 87], "contigu": 58, "entiti": [58, 90, 139], "cartoonishli": 58, "ent": 58, "tom": 58, "washington": 58, "salli": 58, "speaker": 58, "8khz": 58, "16khz": 58, "spoken": 58, "formid": [58, 61, 62, 69, 113], "ea": 58, "unalign": [58, 124, 128, 129, 136], "pose": [58, 62, 80, 81, 82, 121, 130], "peculiar": [58, 103], "tendenc": 58, "verb": [58, 83, 96], "haben": 58, "sie": 58, "sich": 58, "schon": 58, "dies": 58, "grossartig": 58, "lehrwerk": 58, "angeschaut": 58, "textbook": [58, 74, 113], "layout": 58, "dialogu": [58, 113, 131, 132], "tempor": [58, 60, 113, 136], "learner": [58, 77], "dictatori": 58, "boss": [58, 75], "shoulder": 58, "lame": 58, "frustrat": [58, 61], "whet": [58, 64], "appetit": [58, 64], "babi": [58, 64, 95, 137], "mountain": 58, "ball": [58, 104, 109, 110, 135], "veloc": [58, 109, 139], "diamet": 58, "tailor": 58, "euclidean": [58, 74, 117], "rome": 58, "itali": 58, "franc": 58, "pari": 58, "demograph": 58, "pollut": 58, "crime": [58, 60], "educ": 58, "salari": 58, "synthet": [58, 60, 68, 71, 74, 120, 121, 136, 142], "adversari": [58, 60], "diffus": 58, "occlud": 58, "pile": 58, "upfront": 58, "motion": [58, 139], "disconnect": 58, "offlin": 58, "charm": 58, "upsid": 58, "isol": 58, "asimov": 58, "intellig": [58, 113, 121], "agent": [58, 113, 121], "spammer": [58, 60], "email": [58, 59, 64, 94, 135, 136], "evad": 58, "spam": [58, 59, 60, 64], "met": [58, 69, 77], "lectur": [58, 112], "homework": 58, "assist": [58, 70, 94, 135], "surg": 58, "alphago": 58, "dethron": 58, "champion": 58, "transmit": [58, 64, 74], "actuat": [58, 69], "overst": 58, "recast": 58, "chess": [58, 60], "win": [58, 60, 64, 79, 121, 138], "credit": [58, 60], "blame": 58, "employe": 58, "octob": 58, "trap": [58, 139], "closet": [58, 104], "rescu": [58, 121], "constantli": 58, "contextu": 58, "bandit": 58, "bernoulli": [58, 61, 76, 118], "jacob": [58, 113], "1655": 58, "1705": 58, "carl": 58, "friedrich": 58, "gauss": [58, 69], "1777": 58, "1855": 58, "multitud": 58, "insur": 58, "ohm": [58, 71], "voltag": [58, 71], "resistor": 58, "mathematician": [58, 80, 115], "keen": 58, "k\u00f6bel": 58, "1460": [58, 79], "1533": 58, "adult": [58, 64], "men": [58, 60], "foot": 58, "church": 58, "misshapen": 58, "longest": [58, 96, 129], "ronald": 58, "fisher": 58, "1890": 58, "1962": 58, "discrimin": [58, 60], "iri": 58, "1936": 58, "propon": 58, "eugen": 58, "moral": 58, "dubiou": 58, "endur": [58, 76], "claud": [58, 64], "shannon": [58, 64], "1916": 58, "alan": [58, 60], "1912": 58, "1954": 58, "famou": [58, 77, 79, 85, 87, 121], "pure": 58, "textual": [58, 83, 85], "psychologi": [58, 69], "scholar": [58, 121], "biolog": [58, 69, 80, 82], "donald": 58, "hebb": 58, "1904": 58, "1985": 58, "groundbreak": 58, "hebbian": 58, "rosenblatt": 58, "diminish": [58, 76, 102, 136], "alexand": 58, "bain": 58, "1873": 58, "jame": [58, 75], "sherrington": 58, "liter": [58, 76, 119], "languish": 58, "2005": 58, "scarc": [58, 67], "efficaci": [58, 77, 83, 109, 113, 121, 126], "scarciti": 58, "compani": [58, 60, 67, 113, 121], "dissemin": [58, 60], "inexpens": 58, "kryder": 58, "moor": 58, "revolution": [58, 90, 113], "suddenli": [58, 60, 61, 127], "1970": [58, 66], "kb": 58, "kf": 58, "8080": 58, "boston": [58, 79], "mf": 58, "80186": 58, "80486": 58, "gf": 58, "advertis": [58, 60, 102], "c2050": 58, "2020": 58, "social": [58, 59, 87, 94], "pf": 58, "dgx": 58, "pace": [58, 77], "outpac": 58, "sweet": 58, "spot": [58, 60, 62], "rediscov": 58, "ly": [58, 104, 121, 122, 136], "dormant": [58, 112], "cambrian": [58, 70], "explos": [58, 70, 130], "evolut": 58, "speci": 58, "plagu": [58, 61, 80, 82, 120], "pointer": 58, "commenc": 58, "unlock": 58, "stage": [58, 102, 111, 138, 141], "permit": [58, 60, 67, 74], "tradition": [58, 101], "sampler": 58, "fake": 58, "gallop": 58, "zebra": 58, "testimoni": 58, "amateur": 58, "doodler": 58, "insuffici": [58, 67, 73, 77, 85, 105], "workhors": 58, "024": 58, "superhuman": 58, "starcraft": [58, 60], "physic": [58, 60, 64, 66, 104, 113, 120], "simul": [58, 112, 121, 141], "mujoco": 58, "avenu": [58, 77, 117], "semin": [58, 61, 70], "supersed": 58, "kera": 58, "cntk": 58, "apach": 58, "ignit": 58, "chainer": 58, "syntax": [58, 95], "jax": [58, 70, 113], "labor": 58, "ph": 58, "carnegi": 58, "mellon": 58, "firmli": 58, "mail": 58, "creditworthi": 58, "fraud": 58, "payment": 58, "paypal": 58, "stripe": 58, "alipai": 58, "wechat": 58, "visa": 58, "mastercard": 58, "sight": [58, 94, 121], "limelight": 58, "intract": 58, "menial": [58, 114], "barber": 58, "appoint": 58, "dialog": [58, 128, 132], "pariti": 58, "nec": 58, "illinoi": 58, "urbana": 58, "champaign": 58, "stun": 58, "birdsong": 58, "diagnos": [58, 60, 67, 113, 121, 131], "prowess": 58, "td": 58, "gammon": 58, "backgammon": [58, 60], "deepblu": 58, "garri": 58, "kasparov": 58, "poker": 58, "oppon": [58, 138], "libratu": 58, "autonomi": [58, 113], "tesla": 58, "waymo": 58, "ship": [58, 60], "perceiv": [58, 60], "particl": 58, "astronomi": 58, "impress": [58, 82], "apocalyps": 58, "fear": 58, "somehow": [58, 74, 77], "sentient": 58, "livelihood": 58, "autopilot": 58, "bail": 58, "frivol": 58, "creator": [58, 82], "illus": 58, "daili": [58, 113, 138], "farm": 58, "farmer": 58, "phase": [58, 69, 77, 107], "revolut": [58, 131], "swath": 58, "societi": [58, 113], "employ": [58, 77, 117], "countri": [58, 95], "racial": [58, 60], "gender": 58, "consequenti": 58, "malevol": 58, "superintellig": 58, "dizzi": 58, "counterpart": [58, 70, 75, 117], "foreign": 58, "canni": 58, "reign": 58, "suprem": 58, "bygon": 58, "elimin": [58, 85, 102], "informat": [58, 113], "experienc": [58, 64], "nonparametr": [58, 78, 80], "nonconvex": [58, 102, 104, 105, 106, 111, 112], "empiric": 58, "influx": 58, "pride": 58, "corpor": 58, "freeli": [58, 113], "barrier": 58, "anyon": [58, 80, 89, 106], "prime": [58, 61, 129], "validation_step": [59, 71, 72, 129, 135], "configure_optim": [59, 70, 71, 72, 74, 129], "gmail": 59, "forum": [59, 79, 87], "warrant": 59, "l_": 59, "unbias": [59, 61, 76, 112], "probabilti": 59, "mid": [59, 60, 64, 69, 74, 89, 93, 98, 100, 104, 121, 122, 127, 129, 132, 133, 135, 136, 139, 140, 141], "contempl": 60, "rush": 60, "marvel": [60, 113], "catastroph": 60, "insidi": [60, 110], "catalyst": 60, "repai": [60, 80], "loan": [60, 80, 117], "footwear": 60, "oxford": 60, "repay": [60, 80], "wear": 60, "deni": 60, "leap": [60, 67], "disastr": 60, "starter": 60, "catch": 60, "digest": 60, "abound": 60, "treatment": [60, 102, 116], "expos": 60, "stimul": 60, "damag": [60, 135], "responsibli": 60, "realm": 60, "grappl": 60, "philosoph": [60, 67, 121], "ethic": 60, "passiv": 60, "salvag": 60, "p_t": 60, "confront": [60, 77, 120], "sober": 60, "absent": [60, 61, 67, 76, 77, 136], "patholog": 60, "god": 60, "lafeez": 60, "hossain": 60, "500px": 60, "getti": 60, "ilkermetinkursova": 60, "istock": 60, "globalp": 60, "musthafa": 60, "aboobakuru": 60, "sibas_minich": 60, "ghrzuzudu": 60, "digitalvis": 60, "yime": [60, 113], "cartoon": 60, "coher": [60, 77, 132], "symptom": [60, 121], "manifest": [60, 130], "preval": [60, 64, 121], "diseas": [60, 67, 113, 121], "degener": 60, "oppos": [60, 64], "mental": 60, "geographi": 60, "drink": [60, 77, 90], "cc": [60, 95], "BY": 60, "mcconchi": 60, "popvssoda": 60, "sick": 60, "career": [60, 79, 82, 113, 120, 121], "Not": [60, 65, 69, 79, 115], "wild": [60, 77, 120], "startup": [60, 103, 113], "ago": [60, 64, 113], "blood": 60, "predominantli": [60, 131], "older": [60, 136], "solicit": 60, "donat": 60, "campu": 60, "cohort": 60, "perfect": [60, 61, 69, 113], "hormon": 60, "diet": 60, "alcohol": 60, "unrel": [60, 93, 121], "roadsid": 60, "ala": [60, 80, 102, 105, 108], "disast": 60, "simplist": 60, "armi": 60, "tank": 60, "forest": 60, "aerial": 60, "shadow": 60, "morn": 60, "noon": 60, "adequ": [60, 102], "forget": [60, 70, 103, 115, 116], "obscur": 60, "ipad": 60, "winter": [60, 132], "santa": 60, "christma": 60, "offend": 60, "uk": 60, "decidedli": 60, "cope": [60, 130], "impati": 60, "y_1": [60, 112, 122, 129, 130, 136], "y_n": [60, 112], "e_": [60, 61, 67, 86, 104, 112, 121, 141], "reweigh": 60, "beta_i": 60, "plug": [60, 61, 64, 82, 105, 112, 115, 136], "fanci": 60, "recalibr": 60, "overweight": [60, 130], "underweight": 60, "ambient": 60, "mild": [60, 77], "strongest": 60, "y_j": [60, 64, 65], "invert": [60, 69, 80, 105, 115], "harder": 60, "unreason": [60, 79, 105], "traffic": 60, "lens": 60, "degrad": [60, 136], "environment": [60, 69], "catdoor": 60, "fall": [60, 61, 85, 110, 121], "profit": 60, "f_t": 60, "longrightarrow": 60, "_t": [60, 69, 101, 102, 103, 108, 109, 111, 112, 123, 125, 127, 129, 130, 133, 136, 139], "ervat": 60, "y_t": [60, 102, 130, 136], "pull": 60, "confusingli": 60, "boiler": 60, "pid": 60, "disentangl": 60, "cooper": 60, "accid": 60, "arbitrag": 60, "trader": [60, 136], "instantan": [60, 109, 112, 115, 141], "infrequ": [60, 61, 91, 102, 128, 132, 137], "aspir": [60, 70], "slew": [60, 130], "carefulli": [60, 82], "overlook": 60, "forese": [60, 122], "welfar": 60, "subpopul": 60, "administ": [60, 67, 121], "inferior": 60, "reconsid": 60, "seldom": [60, 61, 67, 69, 77, 121, 131, 136], "er": [60, 96], "sleight": 60, "misclassif": 60, "harmless": [60, 76], "patrol": 60, "unaccount": [60, 121], "runawai": 60, "outsiz": [60, 74], "dilemma": [60, 82, 107], "unavail": 60, "entangl": 60, "unanticip": 60, "corrector": 60, "guidanc": [61, 77, 113, 121], "burn": 61, "intellectu": 61, "absurd": [61, 67, 80], "certifi": [61, 67, 113], "hoc": 61, "sprung": 61, "gold": 61, "fresh": [61, 67], "epsilon_": 61, "a_n": 61, "asymptot": [61, 104], "zoom": 61, "reveal": [61, 77, 117, 131], "2500": 61, "peski": 61, "inequ": [61, 112, 117, 121], "hoeffd": 61, "1963": 61, "2n": [61, 117], "conserv": [61, 77], "ballpark": 61, "court": [61, 129], "succe": 61, "lesson": 61, "sanctiti": 61, "preliminari": [61, 113, 142], "night": 61, "3am": 61, "brilliant": [61, 77], "thrill": 61, "fade": 61, "f_k": 61, "distrust": 61, "contact": 61, "leak": [61, 119], "strictest": 61, "theorist": [61, 77], "holdout": [61, 67, 77], "bleak": 61, "analys": [61, 132], "dial": 61, "vigil": 61, "stake": 61, "demot": 61, "ostens": 61, "dib": 61, "gnaw": 61, "trust": [61, 113], "misgiv": 61, "subfield": [61, 64, 117], "elucid": 61, "hairi": [61, 120], "ambiti": 61, "misestim": 61, "useless": [61, 136], "underfit": [61, 68], "spectrum": [61, 122], "vapnik": 61, "chervonenki": 61, "vc": [61, 67, 77], "emp": [61, 67], "violat": [61, 80, 82, 104], "pessimist": 61, "bedrock": 61, "nevertheless": [61, 67, 73, 131], "curat": 61, "vladimir": 61, "alexei": 61, "chernovenki": 61, "revolutionari": 61, "powerless": [61, 77], "straightforwardli": 61, "somebodi": 61, "sun": [62, 113], "sparcstat": 62, "64mb": 62, "ram": 62, "blister": [62, 77], "laboratori": 62, "usp": 62, "unsuit": [62, 132, 137], "weaker": [62, 80], "skew": 62, "substitut": [62, 67, 85, 120, 130], "mlx_reshap": 62, "datamodul": [62, 72, 73, 74, 79, 128, 136, 137], "tran": 62, "train_data": [62, 85, 87], "train_target": 62, "val_data": 62, "val_target": 62, "6000": 62, "grayscal": [62, 64, 81], "upscal": 62, "hymap": 62, "126": 62, "train_dataload": [62, 71, 72, 73, 128, 132], "blazingli": 62, "tic": 62, "odditi": 62, "safeguard": 62, "apparel": 62, "palett": 62, "visibl": [62, 103], "decompress": 62, "transcod": 62, "profil": 62, "skill": [63, 67, 113, 116, 120, 121], "plumb": 63, "taxonomi": 63, "transpar": 63, "hammer": 64, "sold": [64, 69], "basebal": 64, "discharg": 64, "dealt": [64, 126], "overwhelm": 64, "inbox": 64, "watch": [64, 67, 121, 124, 138], "overload": [64, 69, 117], "entertain": 64, "flight": 64, "wet": 64, "x_3": [64, 74, 132], "x_4": [64, 132], "chicken": 64, "impuls": 64, "toddler": 64, "adolesc": 64, "young": 64, "geriatr": 64, "ordin": [64, 83], "redund": [64, 69, 79, 85, 103, 119], "o_1": [64, 69, 98], "o_2": 64, "o_3": 64, "gather": 64, "unsatisfactori": 64, "o_i": [64, 82, 98], "brittl": 64, "outlier": [64, 69, 117, 120], "bui": [64, 136], "mansion": 64, "squish": 64, "epsilon_i": 64, "probit": 64, "quad": [64, 86, 117], "o_j": [64, 65], "operatornam": [64, 69, 80, 122], "boltzmann": [64, 71], "father": 64, "ga": [64, 93], "molecul": 64, "thermodynam": [64, 66], "kt": 64, "gibb": 64, "rowwis": [64, 80], "overflow": [64, 65], "underflow": [64, 65, 82], "justif": [64, 76, 108], "prod_": [64, 69, 89, 98, 122, 129, 130, 132, 136], "awkward": 64, "certainti": [64, 121], "o_k": [64, 65], "partial_": [64, 69, 71, 82, 102, 108, 109, 112, 115], "nat": 64, "bore": 64, "dq": 64, "fri": 64, "quaternion": 64, "strive": 64, "pam": 64, "ternari": 64, "bradlei": 64, "terri": 64, "o_": [64, 82, 98, 130], "realsoftmax": 64, "softmin": 64, "riski": [65, 121], "38": [65, 140, 141], "max_k": 65, "escap": [65, 80], "logsumexp": 65, "hide": [65, 75, 102, 121], "danger": 65, "bless": 65, "disincent": 65, "muscl": [65, 69], "protect": [65, 66], "urg": 65, "fp64": 65, "fp16": 65, "unstabl": [65, 82, 107, 130, 135], "tf32": 65, "int8": 65, "refresh": [66, 107, 113], "ik": [66, 86, 93], "x_exp": 66, "verbatim": 66, "x_prob": 66, "128638": 66, "202501": 66, "329175": 66, "141182": 66, "198504": 66, "290871": 66, "164617": 66, "288431": 66, "139319": 66, "116763": 66, "softmaxregressionscratch": 66, "outnumb": 66, "49787": 66, "vi": [66, 116, 122], "\u00e0": 66, "incorrectli": [66, 77], "1960": 66, "instabl": [66, 126, 130, 135], "colleg": 67, "dilig": 67, "elli": 67, "endow": 67, "she": 67, "iren": 67, "knack": 67, "handili": 67, "her": [67, 96], "yesterdai": 67, "undiagnos": 67, "ailment": 67, "grander": 67, "engulf": 67, "public": [67, 82, 87, 101, 109, 113, 137], "flickr": 67, "yfc100m": 67, "infinitesim": [67, 115], "generaliz": 67, "phenomenon": [67, 77, 105, 107, 121, 136, 137], "combat": 67, "dead": 67, "water": [67, 93], "nobodi": [67, 108], "withheld": 67, "karl": 67, "popper": 67, "falsifi": 67, "told": [67, 108], "stress": 67, "unabl": 67, "economi": 67, "aptli": 67, "touch": [67, 72, 74, 80, 104], "honest": 67, "tightli": 67, "muddier": 67, "murki": 67, "worryingli": 67, "ambigu": [67, 115, 131, 132], "rightli": 67, "counterintuit": [67, 77, 121, 131], "predic": 67, "relax": 67, "milder": 67, "inadvis": 67, "subsum": [68, 69], "narrowli": 68, "repertoir": 68, "membership": [69, 80, 100, 117], "dawn": 69, "19th": 69, "superscript": 69, "disciplin": [69, 77, 113, 131], "w_d": 69, "x_d": [69, 105, 131, 132], "compactli": [69, 80], "summat": [69, 89, 100, 117, 122, 127, 133, 140, 141], "instrument": [69, 74], "unfit": 69, "notation": 69, "cancel": [69, 74, 76, 109], "sword": 69, "admit": 69, "drawback": [69, 86, 108], "predetermin": [69, 136], "leftarrow": [69, 71, 74, 79, 103, 104, 105, 107, 108, 109, 111, 112, 135, 140, 141], "partial_b": 69, "noiseless": 69, "saddl": [69, 104, 109], "minima": [69, 112], "conclus": [69, 121], "unnecessari": [69, 113], "workload": [69, 108], "5f": [69, 115], "13479": 69, "reload": 69, "00002": 69, "portabl": 69, "legendr": 69, "parentag": 69, "anachronist": 69, "cyberneticist": 69, "neurophysiologist": 69, "warren": 69, "mcculloch": [69, 80], "walter": 69, "pitt": [69, 80], "cartoonish": 69, "dendrit": 69, "termin": [69, 77, 130, 140], "nucleu": 69, "axon": 69, "synaps": 69, "anatomi": 69, "physiologi": 69, "institut": [69, 121], "surveil": 69, "epidemiologi": 69, "seer": 69, "synapt": 69, "inhibit": 69, "destin": 69, "certainli": [69, 76, 122], "ornithologi": 69, "aeronaut": 69, "linguist": [69, 83, 96], "maximimum": 69, "solvabl": 69, "fluctuat": 69, "pennystock": 69, "schole": 69, "groceri": 69, "sell": 69, "poisson": 69, "fortuit": 70, "sn2": 70, "simulateur": 70, "neuristiqu": 70, "modular": [70, 72, 81], "glad": 70, "lousi": 70, "reinvent": 70, "wheel": [70, 139, 140, 141], "inconveni": 70, "linearregress": [70, 74, 79, 136], "mseloss": 70, "fn": 70, "mse_loss": [70, 108], "syntheticregressiondata": [70, 71, 73], "get_w_b": 70, "00405765": 70, "0094018": 70, "0103469": 70, "tap": 70, "huber": 70, "iv": [71, 90, 113, 114, 115, 116, 122], "stitch": [71, 117], "hood": [71, 75], "linearregressionscratch": [71, 74], "training_step": [71, 72, 135], "clip_gradi": [71, 135], "train_batch_idx": [71, 72], "reserv": [71, 117], "elid": 71, "revis": 71, "14811": 71, "118367": 71, "217464": 71, "georg": [71, 113], "simon": [71, 113], "planck": 71, "radiat": 71, "eman": 71, "hc": [71, 127], "y_5": 71, "reshuffl": [71, 73], "malici": 71, "lightn": 72, "readabl": 72, "fragment": [72, 132], "incompat": 72, "wrapper": 72, "decor": 72, "signatur": [72, 108, 119], "notimpl": 72, "tensorboard": 72, "c0": 72, "reusabl": 72, "plot_train_per_epoch": 72, "plot_valid_per_epoch": 72, "num_val_batch": 72, "train_": 72, "val_": 72, "current_index": 72, "__iter__": [72, 85, 91], "__next__": 72, "stopiter": 72, "end_index": 72, "batch_indic": [72, 73, 85, 91, 97], "collate_fn": 72, "decoder_input": 72, "prepare_data": 72, "enrich": 72, "dividend": 72, "didact": 73, "succinct": [73, 113], "num_train": [73, 74, 128, 132, 136], "num_val": [73, 74, 128, 132], "nlabel": 73, "27212": 73, "345343": 73, "55914": 73, "ny": [73, 132], "invoc": [73, 101], "ex": 73, "ineffici": 73, "get_tensorload": [73, 74, 79, 128, 132, 136], "underdetermin": 73, "pseudorandom": 73, "dispos": 74, "toss": [74, 116], "blunt": [74, 126], "monomi": [74, 76], "x_5": 74, "blow": [74, 82, 103, 130], "banach": 74, "ell_p": [74, 100, 117], "reviv": 74, "penal": [74, 77, 79, 122, 129], "ridg": [74, 77], "popularli": 74, "lasso": [74, 77], "l2_penalti": 74, "weightdecayscratch": 74, "lambd": 74, "train_scratch": 74, "l2": [74, 108], "00873405858874321": 74, "0012009039055556059": 74, "anywai": 74, "weightdecai": 74, "hilbert": [74, 80], "rkh": 74, "wherebi": 74, "profoundli": 75, "recalcul": 75, "ell_2": [75, 76, 77, 100, 104, 112, 117], "etern": 75, "funk": 75, "virtuoso": 75, "brown": 75, "signifi": [75, 117, 137], "rightward": 75, "upward": 75, "calculu": [75, 105, 113, 116, 142], "prod": [75, 100, 130], "duplic": [75, 130], "plain": [75, 80, 121], "interdepend": 75, "disadvantag": 75, "peform": 76, "tikhonov": 76, "drew": [76, 121], "resili": [76, 79, 103], "narr": 76, "sexual": 76, "argu": [76, 80, 112], "gene": 76, "debias": 76, "h_5": 76, "dropout_lay": [76, 125], "survivor": 76, "dropout_p": 76, "dropoutmlpscratch": 76, "lin1": 76, "lin2": 76, "lin3": 76, "h1": 76, "h2": 76, "quest": 77, "myriad": [77, 120, 126], "protein": [77, 121], "pour": 77, "west": 77, "arsen": 77, "folk": 77, "fascin": 77, "pithi": 77, "justic": 77, "resolv": [77, 80, 91, 107, 112, 132, 140], "lunch": 77, "stranger": 77, "rademach": 77, "tempt": [77, 135], "riddl": 77, "isomorph": 77, "fruit": 77, "underscor": 77, "cleanli": 77, "mislabel": 77, "mortal": 77, "meaningfulli": 77, "rational": 77, "radic": 77, "paradox": 77, "intervent": 77, "concert": 77, "grasp": [78, 113], "punt": 78, "exot": 79, "am": [79, 86], "iowa": 79, "2006": 79, "harrison": 79, "rubinfeld": 79, "1978": 79, "boast": [79, 82], "sponsor": 79, "stakehold": 79, "foster": 79, "collabor": [79, 102], "leaderboard": 79, "chase": [79, 113], "spiral": 79, "myopic": 79, "everyon": [79, 113], "street": [79, 97, 117], "roof": [79, 120], "basement": 79, "offici": [79, 116, 118, 129], "upload": 79, "sha": 79, "clog": 79, "kagglehous": 79, "raw_train": 79, "kaggle_house_pred_train": 79, "585e9cc93e70b39160e7921475f9bcd7d31219c": 79, "raw_val": 79, "kaggle_house_pred_test": 79, "fa19780a7b011d9b009e8bff8e99922a8ee2eb90": 79, "1459": 79, "salepric": 79, "iloc": [79, 120], "mssubclass": 79, "mszone": 79, "lotfrontag": 79, "saletyp": 79, "salecondit": 79, "208500": 79, "181500": 79, "223500": 79, "abnorml": 79, "140000": [79, 120], "rm": [79, 101], "mszoning_rl": 79, "mszoning_rm": 79, "numeric_featur": 79, "get_dummi": [79, 120], "dummy_na": [79, 120], "331": 79, "bug": [79, 120], "rural": 79, "ohio": 79, "125": 79, "horribl": 79, "alto": [79, 117], "hill": 79, "california": 79, "stunningli": 79, "discrep": [79, 130], "get_tensor": 79, "smarter": 79, "obfusc": 79, "unnecessarili": [79, 119], "safe": [79, 102], "k_fold_data": 79, "ret": 79, "fold_siz": 79, "k_fold": 79, "val_loss": 79, "data_fold": 79, "330": 79, "mse": 79, "untun": 79, "17722380250692366": 79, "ensemble_pr": 79, "late": [79, 81, 114], "wrangl": 80, "incom": [80, 117], "relianc": 80, "doom": 80, "spline": 80, "rectifi": 80, "abus": [80, 121], "sigma_1": 80, "sigma_2": 80, "atop": 80, "absurdli": 80, "piecewis": [80, 107, 112, 114], "nondifferenti": 80, "adag": 80, "wisdom": 80, "grad_relu": 80, "vmap": [80, 82, 113], "prelu": 80, "inf": 80, "plateau": [80, 107], "grad_sigmoid": [80, 82], "hyperbol": [80, 105], "2x": [80, 105, 115], "nears": 80, "grad_tanh": 80, "circa": 80, "fortran": 80, "resurg": [80, 140], "cumul": [80, 102, 117], "swish": 80, "disregard": 81, "mlpscratch": 81, "w1": 81, "w2": 81, "messi": [81, 120], "42b": [81, 95], "renam": 81, "misalign": 81, "1025": 81, "1026": 81, "1028": 81, "1032": 81, "gloss": 82, "gotten": [82, 114, 117, 121], "f_l": 82, "circ": 82, "underbrac": [82, 140], "suscept": 82, "pressur": 82, "mantissa": 82, "expon": [82, 107, 137], "eigenvalu": [82, 102, 109, 110, 130], "unpredict": 82, "threaten": 82, "culprit": 82, "goldilock": 82, "zone": 82, "vex": [82, 110], "\u4e00\u4e2a\u77e9\u9635": 82, "\u4e58\u4ee5100\u4e2a\u77e9\u9635\u540e": 82, "58351": 82, "22097": 82, "760812": 82, "759199": 82, "114575": 82, "57469": 82, "02252": 82, "65959": 82, "838213": 82, "134918": 82, "3001": 82, "57311": 82, "25461": 82, "203396": 82, "31702": 82, "23945": 82, "34086e": 82, "09613e": 82, "21129e": 82, "09278e": 82, "90823e": 82, "40436e": 82, "48148e": 82, "74202e": 82, "03371e": 82, "99174e": 82, "26585e": 82, "74634e": 82, "95319e": 82, "87474e": 82, "03262e": 82, "61295e": 82, "nuisanc": 82, "2_": 82, "2_j": 82, "nonexist": 82, "stumbl": [82, 121], "340": [83, 92], "cola": 83, "judg": 83, "grammat": [83, 128, 132], "unambigu": [83, 90, 121, 131], "sep": [83, 90, 91, 92], "air": [83, 138], "woman": [83, 95], "meat": 83, "danc": 83, "man": [83, 85, 95, 96, 98, 132, 137], "adject": [83, 95], "penn": [83, 97], "treebank": 83, "john": [83, 113], "smith": 83, "nnp": 83, "vb": 83, "jj": [83, 102], "stanford": [83, 84, 87, 95], "squad": 83, "passag": [83, 131], "inconclus": 83, "maker": 83, "insist": 83, "n95": 83, "respir": 83, "guard": 83, "viru": 83, "pack": [83, 138], "s_i": [83, 121], "p_i": 83, "e_i": 83, "e_j": 83, "coronaviru": 83, "outbreak": 83, "novella": [84, 132], "textcnn": 84, "snli": [84, 86], "polar": [85, 87], "premis": [85, 86], "entail": [85, 86], "negat": 85, "neutral": [85, 86], "hug": 85, "women": 85, "sleep": [85, 86, 121], "500000": 85, "snli_1": 85, "nlp": [85, 95], "9fcde07509c7e87ec61c640c1b2753d9041758e4": 85, "richer": 85, "read_snli": 85, "hypothes": [85, 86, 121], "extract_text": 85, "label_set": 85, "file_nam": 85, "0_train": 85, "0_test": 85, "diner": 85, "omelett": 85, "outdoor": 85, "550000": 85, "test_data": [85, 87], "183416": 85, "183187": 85, "182764": 85, "3368": 85, "3237": 85, "3219": 85, "snlidataset": 85, "all_premise_token": 85, "all_hypothesis_token": 85, "_pad": 85, "mlxdataloadersnli": 85, "total_sampl": [85, 91], "batch_data": [85, 91, 97], "batch_x": 85, "batch_x0": 85, "batch_x1": 85, "batch_i": 85, "load_data_snli": [85, 86], "train_set": [85, 91], "test_set": 85, "549367": [85, 86], "9824": [85, 86], "18678": 85, "superfici": 85, "glove": [86, 88, 90, 94, 95, 96, 142], "tire": 86, "mn": [86, 117], "kj": 86, "f_a": 86, "f_b": 86, "v_a": 86, "v_b": [86, 103, 109], "_a": [86, 90], "_b": [86, 90, 104], "decomposableattent": 86, "num_inputs_attend": 86, "num_inputs_compar": 86, "num_inputs_agg": 86, "glove_embed": [86, 88], "tokenembed": [86, 88, 95], "6b": [86, 88, 95], "100d": [86, 88, 95], "emb": [86, 88, 95, 99, 129, 135], "idx_to_token": [86, 88, 91, 95, 135, 137], "sec_multi_gpu": 86, "split_batch_multi_input": 86, "521": 99, "793": [], "820": [], "8937": [], "predict_snli": 86, "17206": [], "90324": [], "53246": [], "prolifer": 87, "media": [87, 94], "opinion": 87, "comment": [87, 115], "polit": 87, "financ": 87, "brand": 87, "25000": 87, "aclimdb": 87, "aclimdb_v1": 87, "01ada507287d82875905620988597833ad4e0903": 87, "read_imdb": 87, "folder_nam": 87, "mem": 87, "bizarr": 87, "horror": 87, "stolen": 87, "unremark": 87, "film": 87, "matthau": 87, "einstein": [87, 120], "train_token": 87, "hist": [87, 128], "load_data_imdb": [87, 88], "test_token": 87, "test_featur": 87, "fig_nlp": 88, "sa": 88, "corr1d": 88, "corr1d_multi_in": 88, "sec_sentiment_rnn": 88, "constant_embed": 88, "conv1d": 88, "nums_channel": 88, "49346": 88, "054": 122, "983": [], "850": [], "2164": [], "predict_senti": 88, "w_c": [89, 98], "_o": [89, 98], "n_k": 89, "n_1": 89, "i_t": 89, "h_k": 89, "i_": 89, "leaf": 89, "w_3": 89, "leftchild": 89, "child": 89, "word2vec": [90, 91, 93, 94, 95, 96, 97, 142], "polysemi": [90, 92], "crane": [90, 92], "taglm": 90, "tagger": 90, "cove": 90, "elmo": 90, "corefer": 90, "hing": 90, "twelv": 90, "cash": 90, "bidirection": 90, "eleven": 90, "get_tokens_and_seg": [90, 91, 92], "tokens_a": [90, 91, 92], "tokens_b": [90, 91, 92], "bertencod": 90, "token_embed": 90, "segment_embed": 90, "768": [90, 92], "encoded_x": [90, 92], "seq": [90, 128], "masklm": 90, "pred_posit": [90, 91, 92], "num_pred_posit": 90, "masked_x": 90, "mlm_y_hat": [90, 92], "mlm": [90, 92], "mlm_posit": 90, "mlm_y": [90, 92], "mlm_l": [90, 92], "nextsentencepr": 90, "input_shap": 90, "nsp": [90, 92], "nsp_y_hat": [90, 92], "nsp_y": [90, 92], "nsp_l": [90, 92], "bookcorpu": [90, 91], "bertmodel": [90, 92], "hid_in_featur": [90, 92], "mlm_in_featur": [90, 92], "nsp_in_featur": [90, 92], "wikitext": [91, 92], "ptb": [91, 97, 99], "paragraph": [91, 128, 137], "delimit": [91, 96, 108, 128], "metamind": [], "3c914d17d80b1459be871a5039ac23e752a53cb": [], "_read_wiki": 91, "wiki": 95, "salesforc": 91, "00000": 91, "00001": [91, 115], "parquet": 91, "98ee727e59fcc34fddaadae93e15b1f8ed5561a4": 91, "read_parquet": 91, "_get_next_sent": 91, "next_sent": 91, "is_next": 91, "_get_nsp_data_from_paragraph": 91, "nsp_data_from_paragraph": 91, "_replace_mlm_token": 91, "candidate_pred_posit": 91, "num_mlm_pr": 91, "mlm_input_token": 91, "pred_positions_and_label": 91, "mlm_pred_posit": 91, "masked_token": 91, "_get_mlm_data_from_token": 91, "mlm_pred_label": 91, "_pad_bert_input": 91, "max_num_mlm_pr": 91, "all_token_id": 91, "all_seg": 91, "all_pred_posit": 91, "all_mlm_weight": 91, "all_mlm_label": 91, "nsp_label": [91, 92], "token_id": [91, 92], "mlm_pred_label_id": 91, "_wikitextdataset": 91, "wordpiec": 91, "30000": [91, 115], "byte": [91, 94, 108], "load_data_wiki": [91, 92], "mlxdataload": 91, "batch_item": 91, "key_list": 91, "mlm_weight": [91, 92], "mlm_label": [91, 92], "tokens_x": 92, "segments_x": 92, "valid_lens_x": 92, "pred_positions_x": 92, "mlm_weights_x": 92, "20256": 91, "dateset": 91, "spaci": 91, "nltk": 91, "punkt": 91, "sent_token": 91, "softmaxceloss": [], "_get_batch_loss_bert": 92, "shard": 92, "tokens_x_shard": [], "segments_x_shard": [], "valid_lens_x_shard": [], "pred_positions_x_shard": [], "mlm_weights_x_shard": [], "mlm_y_shard": [], "nsp_y_shard": [], "waital": [], "train_bert": 92, "num_steps_reach": 92, "split_and_load": [], "elem": 95, "even_split": [], "mlm_l_mean": [], "nsp_l_mean": [], "value_and_grads_fn": 92, "082": [], "700": [], "5600": [], "get_bert_encod": 92, "encoded_text": 92, "encoded_text_cl": 92, "encoded_text_cran": 92, "750546": [], "732056": [], "08622": [], "encoded_pair": 92, "encoded_pair_cl": 92, "encoded_pair_cran": 92, "705484": [], "668324": [], "06351": [], "ic": 93, "steam": 93, "q_": [93, 140, 141], "_k": 93, "multiset": 93, "rewritten": [93, 98], "b_i": [93, 127], "ji": [93, 110, 117], "asymmetr": 93, "p_1": [93, 129], "00019": 93, "000066": 93, "003": 93, "000017": 93, "p_2": [93, 129], "000022": 93, "00078": 93, "0022": 93, "000018": 93, "085": 93, "redesign": [93, 113], "subword": [94, 142], "upstream": 94, "cbow": 94, "subsampl": 94, "occurr": [94, 96, 97, 121, 132], "fasttext": [94, 95], "agnost": 94, "50d": 95, "0b8703943ccdb6eb788e6f091b8946e82231bc4d": 95, "cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a": 95, "300d": 95, "b5116e234e9eb9076672cfeabf5469f3eec904fa": 95, "c1816da3821ae9f43899be655002f6c723e91b88": 95, "embedding_nam": 95, "idx_to_vec": 95, "_load_embed": 95, "unknown_idx": 95, "token_to_idx": [95, 137], "vec": 95, "glove_6b50d": 95, "400000": 95, "400001": 95, "3367": 95, "knn": 95, "topk": [95, 99], "ret_typ": [], "mv": [], "get_similar_token": [95, 99], "query_token": [95, 99], "856": [95, 107], "749": 95, "839": [95, 107], "boi": [95, 96], "792": 95, "girl": [95, 96], "921": 95, "893": 95, "gorgeou": 95, "son": [95, 98], "daughter": 95, "get_analogi": 95, "token_a": 95, "token_b": 95, "token_c": 95, "male": 95, "femal": 95, "capit": [95, 117, 137], "beij": 95, "china": 95, "tokyo": 95, "japan": 95, "superl": 95, "syntact": [95, 137], "tens": 95, "inflect": 96, "boyfriend": 96, "girlfriend": 96, "spanish": 96, "finnish": 96, "morphologi": 96, "morpholog": 96, "whe": 96, "_w": 96, "_g": 96, "bpe": 96, "raw_token_freq": 96, "tall": [96, 121], "er_": 96, "token_freq": [96, 137], "fast_": 96, "faster_": 96, "tall_": 96, "taller_": 96, "freq": [96, 137], "get_max_freq_pair": 96, "merge_symbol": 96, "max_freq_pair": 96, "new_token_freq": 96, "new_token": 96, "ta": 96, "tal": 96, "num_merg": 96, "fa": 96, "segment_bp": 96, "cur_output": 96, "tallest_": 96, "fatter_": 96, "journal": 97, "319d85e578af0cdc590547f26231e4e31cdf1e42": 97, "read_ptb": 97, "readthetrainingset": 97, "raw_text": [97, 128, 137], "42069": 97, "6719": 97, "num_token": 97, "shorten": [97, 114], "show_list_len_pair_hist": [97, 128], "compare_count": 97, "\u7684\u6570\u91cf": 97, "\u4e4b\u524d": 97, "\u4e4b\u540e": 97, "50770": 97, "3228": 97, "710": 97, "4060": [], "3922": 97, "1922": 97, "4743": 97, "get_centers_and_context": 97, "max_window_s": [97, 99], "window_s": 97, "tiny_dataset": 97, "all_cent": 97, "all_context": 97, "1500529": [], "randomgener": 97, "unnorm": 97, "sampling_weight": 97, "get_neg": 97, "all_neg": 97, "n_i": [97, 137], "m_i": 97, "contexts_neg": [97, 99], "max_i": 97, "batchifi": 97, "cur_len": 97, "load_data_ptb": [97, 99], "num_noise_word": [97, 99], "arraydataset": [], "batchify_fn": [], "ptbdataset": [], "ptb_iterable_factori": 97, "centers_batch": 97, "contexts_negatives_batch": 97, "masks_batch": 97, "labels_batch": 97, "stream_python_iter": 97, "2m": [98, 117], "breviti": 98, "num_embed": 99, "embedding_dim": [], "embedding_weight": 99, "258015": [], "459932": [], "396722": [], "147898": [], "137964": [], "166621": [], "0127203": [], "38707": [], "436326": [], "451126": [], "417826": [], "12587": [], "282096": [], "130971": [], "0280585": [], "356574": [], "163435": [], "485261": [], "311101": [], "182909": [], "216009": [], "199337": [], "235121": [], "731557": [], "contexts_and_neg": 99, "skip_gram": 99, "embed_v": 99, "embed_u": 99, "batch_dot": [], "swapax": 129, "einsum": 99, "bij": 99, "bkj": 99, "bik": 99, "sigmoidbceloss": [], "binary_cross_entropy_with_logit": [], "binary_cross_entropi": 99, "with_logit": 99, "93521": 99, "84621": 99, "sigmd": 99, "4f": 99, "9352": 99, "8462": 99, "force_reinit": [], "context_neg": 99, "002": 99, "382": [], "959": [], "624": [], "532": [], "531": 86, "dell": [], "adher": [100, 113, 121], "placehold": 100, "indefinit": 100, "cardin": 100, "setminu": 100, "log_2": 100, "boolean": 100, "hadamard": [100, 117, 125, 127], "_p": [100, 104, 117], "int_a": 100, "pdf": [100, 113], "perp": [100, 121], "condition": [100, 121, 136], "2_x": 100, "rho": [100, 101], "pearson": 100, "d_": [100, 115], "kl": 100, "leaki": [101, 103, 111], "greek": 101, "rmsprop": [101, 103, 105, 106, 142], "du": [101, 113, 115], "jour": 101, "init_adadelta_st": 101, "feature_dim": [101, 102, 103, 108, 109, 111], "s_w": [101, 102, 103, 111], "s_b": [101, 102, 103, 111], "delta_w": 101, "delta_b": 101, "hyperparam": [101, 102, 103, 108, 109, 111], "no_grad": [], "zero_": [], "get_data_ch11": [101, 102, 103, 108, 109, 111], "train_ch11": [101, 102, 103, 108, 109, 111], "242": [101, 102, 111], "013": 103, "liner": 101, "train_concise_ch11": [101, 102, 103, 108, 109, 111], "243": [101, 103, 108, 109], "012": 101, "prop": 101, "hack": [102, 126, 135], "redress": 102, "eta_0": [102, 107, 112], "eta_i": [102, 112], "sparsiti": 102, "qualifi": 102, "crude": 102, "gentl": [102, 117], "understood": [102, 108, 113, 132], "eigendecomposit": 102, "kappa": 102, "_d": 102, "couldn": 102, "distort": [102, 109], "eigenvector": [102, 109, 110, 130], "impract": 102, "elus": 102, "hessian": [102, 104, 105, 110], "_0": [102, 103, 109], "adagrad_2d": 102, "s1": [102, 105, 109, 111, 112], "s2": [102, 105, 109, 111, 112], "g1": [102, 105, 111, 112], "g2": [102, 105, 111, 112], "f_2d": [102, 105, 109, 111], "show_trace_2d": [102, 105, 109, 111, 112], "train_2d": [102, 105, 109, 111, 112], "382563": 102, "158591": 102, "002295": 102, "000000": [102, 111], "init_adagrad_st": 102, "uneven": 102, "gerschgorin": 102, "lambda_i": [102, 109, 130], "jk": 102, "recap": [103, 117], "precondition": [103, 105, 111], "hotfix": 103, "beta_1": 103, "beta_2": 103, "999": 103, "correspondingli": [103, 105, 108, 127], "anticlimact": 103, "debia": 103, "daunt": 103, "init_adam_st": 103, "v_w": [103, 109], "beta1": 103, "beta2": 103, "v_bias_corr": 103, "s_bias_corr": 103, "244": 103, "sgn": 103, "advis": [103, 108], "pointwis": 103, "ewma": 103, "mpl_toolkit": [104, 110], "mplot3d": [104, 110], "strengthen": 104, "cap_": 104, "emptyset": [104, 121], "parabola": 104, "alpha_i": [104, 112, 121], "e_x": 104, "unobserv": 104, "foremost": 104, "ast": 104, "semidefinit": 104, "nabla": [104, 105, 112, 115], "succeq": 104, "nondecreas": 104, "lemma": 104, "c_2": 104, "graviti": 104, "exert": [104, 113, 135], "alpha_1": 104, "alpha_n": 104, "lagrang": 104, "satisfact": [104, 113], "onto": [104, 119, 121, 135], "proj": 104, "diamond": 104, "irrelev": [105, 127, 129], "lessapprox": 105, "declin": [105, 108, 136], "f_grad": [105, 112], "gd": [105, 108], "060466": 105, "show_trac": 105, "f_line": 105, "486784": 105, "overshoot": 105, "61": 105, "917364": 105, "528166": 105, "univari": 105, "bigg": 105, "steepest": [105, 109], "2x_2": [105, 111], "2x_1": 105, "4x_2": 105, "ff7f0e": 105, "1f77b4": 105, "f_2d_grad": 105, "gd_2d": [105, 109], "057646": 105, "000073": [105, 109], "oscil": [105, 109], "curvatur": 105, "mimic": 105, "cosh": 105, "sinh": 105, "f_hess": 105, "01948e": 105, "8341": 105, "spectacularli": [105, 136], "defeat": 105, "cautiou": [105, 109], "flatter": 105, "26986": 105, "proof": [105, 106, 112, 115], "caveat": 105, "entireti": 105, "millimet": 105, "kilomet": 105, "meter": [105, 121], "terribl": 105, "conjunct": 105, "bewar": 105, "oneself": 106, "incant": 106, "primer": 106, "precondit": 106, "adadelta": [106, 142], "secondli": 107, "bounc": 107, "pertain": 107, "monik": 107, "cyclic": [107, 131], "maxpool": 107, "averagepool": 107, "train_loss": 107, "net_fn": 107, "__module__": [], "learningrateschedul": [], "custom_callback": [], "device_nam": [], "_device_nam": [], "onedevicestrategi": [], "sparsecategoricalcrossentropi": [], "from_logit": [], "traincallback": [], "eu": [], "idx3": [], "ubyt": [], "2mib": [], "271": [], "7kib": [], "t10k": [], "5mib": [], "idx1": [], "0kib": [], "116": [], "7mib": [], "976": [], "885": [], "downward": 107, "dummy_model": [], "squarerootschedul": 107, "num_upd": 107, "pow": [107, 129], "412": 25, "862": 25, "844": [], "stepsiz": 107, "gentli": 107, "warm": [107, 135], "eta_": 107, "eta_t": [107, 108, 109, 112], "factorschedul": 107, "stop_factor_lr": 107, "base_lr": 107, "multifactorschedul": [], "multisteplr": [], "mileston": [], "get_lr": [], "get_last_lr": [], "perplex": [107, 123, 125, 127, 131, 134, 135], "cosineschedul": 107, "max_upd": 107, "final_lr": 107, "warmup_step": 107, "warmup_begin_lr": 107, "base_lr_orig": 107, "max_step": 107, "get_warmup_lr": 107, "432": [], "858": [], "834": [], "cool": 107, "454": [], "823": [], "perplexingli": 107, "gluoncv": 107, "polyschedul": 107, "langevin": 107, "l1": 108, "2ghz": 108, "avx": 108, "midrang": 108, "chiplet": 108, "allevi": [108, 127, 128, 130], "tik": 108, "cumsum": [108, 117, 121], "bc": 108, "tensordot": [108, 114, 117], "3341822624206543": [], "0008111000061035156": [], "2mnp": 108, "fuse": 108, "gigaflop": 108, "985": 88, "2465": [], "787": [], "578": [], "behalf": 108, "36314": [], "nasa": 108, "wing": 108, "aircraft": 108, "airfoil": 108, "airfoil_self_nois": 108, "dat": 108, "76e5be1548fd8222e5074cf0faae75edff8cf93f": 108, "1500": 108, "genfromtxt": 108, "trainer_fn": 108, "train_sgd": 108, "gd_re": 108, "254": [], "sgd_re": 108, "005": [108, 109], "074": [], "mini1_r": 108, "mini2_r": 108, "009": [108, 109], "meansquarederror": 108, "evil": 108, "geni": 108, "replic": [108, 119], "lenient": 109, "canyon": 109, "expositori": 109, "geometr": [109, 132], "pleasant": 109, "ellipsoid": 109, "943467": 109, "387814": 109, "1673": 109, "365109": 109, "momentum_2d": 109, "v2": 109, "007188": 109, "002553": 109, "126340": 109, "186632": 109, "init_momentum_st": 109, "features_dim": [], "sgd_momentum": 109, "train_momentum": 109, "02": [109, 121], "246": [108, 109], "contriv": [109, 114], "succ": 109, "eigensystem": 109, "eigenspac": 109, "x_t": [109, 129, 130, 132, 133, 135, 136], "x_0": 109, "lam": 109, "v_0": [109, 141], "downweight": 109, "xytext": 110, "arrowprop": 110, "arrowstyl": 110, "nempir": 110, "77": 110, "knock": 110, "dislodg": 110, "add_subplot": 110, "plot_wirefram": 110, "rstride": 110, "cstride": 110, "rx": 110, "tick": 110, "ytick": 110, "set_ztick": 110, "sadli": 110, "nil": [110, 113], "0013": 110, "beginn": [110, 113], "thereof": [110, 127], "reparametr": 110, "1x_1": 111, "rmsprop_2d": 111, "010599": 111, "init_rmsprop_st": 111, "gamma1": 111, "f_i": [112, 115], "constant_lr": 112, "226452": [], "119619": [], "conflict": [112, 113], "prematur": 112, "t_i": [112, 136], "t_": 112, "exponential_lr": 112, "874176": [], "048605": [], "polynomial_lr": 112, "205997": [], "052413": [], "tibshirani": 112, "whichev": [112, 129], "telescop": 112, "jensen": 112, "loos": 112, "pretend": 112, "legion": 113, "headlin": 113, "newspap": 113, "outmod": 113, "biomed": 113, "catalyz": 113, "clarifi": 113, "player": 113, "astrophys": 113, "climat": [113, 136], "biomedicin": 113, "onboard": 113, "exemplar": 113, "aid": 113, "entrepreneur": 113, "breadth": 113, "runnabl": 113, "repositori": [113, 120], "sporad": 113, "clueless": 113, "paywal": 113, "complement": [113, 121], "latex": 113, "javascript": 113, "sec_how_to_contribut": 113, "sphinx": 113, "compromis": [113, 122, 136], "thoroughli": 113, "outset": 113, "tast": [113, 114, 136], "esoter": 113, "organiz": 113, "taught": 113, "ammunit": 113, "curatori": 113, "elementari": [113, 117, 121], "lai": 113, "groundwork": 113, "tread": 113, "inquiri": 113, "kick": 113, "gear": 113, "edit": 113, "eclips": 113, "sec_d2l": 113, "sy": 113, "matplotlib_inlin": [113, 115], "backend_inlin": [113, 115], "dataclass": 113, "functool": 113, "flax": 113, "linen": 113, "train_stat": 113, "jnp": 113, "optax": 113, "tensorflow_dataset": 113, "tfd": 113, "functiontyp": 113, "huggingface_hub": 113, "undergradu": 113, "appendix": [113, 142], "happili": 113, "terrif": 113, "joe": 113, "blitzstein": 113, "gem": 113, "perus": 113, "indebt": 113, "draft": 113, "anirudh": 113, "dagar": 113, "yuan": 113, "tang": 113, "juli": 113, "2021": 113, "gaosheng": 113, "wu": 113, "liujun": 113, "ge": 113, "jiehang": 113, "xie": 113, "baidu": 113, "paddlepaddl": 113, "shuai": 113, "alxnorden": 113, "avinashingit": 113, "bowen0701": 113, "brettkoonc": 113, "chaitanya": 113, "prakash": 113, "bapat": 113, "cryptonaut": 113, "david": 113, "fiocco": 113, "edgarroman": 113, "gkutiel": 113, "mitro": 113, "liang": 113, "pu": 113, "rahul": 113, "agarw": 113, "moham": 113, "jamaoui": 113, "michael": 113, "stu": 113, "stewart": 113, "mike": 113, "m\u00fcller": 113, "nrauschmayr": 113, "prakhar": 113, "srivastav": 113, "sad": 113, "sfermigi": 113, "sheng": 113, "zha": 113, "sundeepteki": 113, "topecongiro": 113, "tpdi": 113, "vermicelli": 113, "vishaal": 113, "kapoor": 113, "vishwesh": 113, "ravi": 113, "shrimali": 113, "yayab": 113, "yuhong": 113, "chen": 113, "evgenii": 113, "smirnov": 113, "lgov": 113, "corston": 113, "oliv": 113, "igor": 113, "dzreyev": 113, "nguyen": 113, "pmuen": 113, "andrei": 113, "lukovenko": 113, "senorcinco": 113, "vfdev": 113, "dsweet": 113, "mohammad": 113, "mahdi": 113, "abhishek": 113, "gupta": 113, "uwsd": 113, "domkm": 113, "lisa": 113, "oaklei": 113, "bowen": 113, "aarush": 113, "ahuja": 113, "prasanth": 113, "buddareddygari": 113, "brianhende": 113, "mani2106": 113, "mtn": 113, "lkevinzc": 113, "caojilin": 113, "lakshya": 113, "fiet": 113, "l\u00fcer": 113, "surbhi": 113, "vijayvargeeya": 113, "muhyun": 113, "kim": 113, "dennismalmgren": 113, "adursun": 113, "liqingnz": 113, "pedro": 113, "larroi": 113, "ozgur": 113, "jun": 113, "blume": 113, "lin": 113, "geogunow": 113, "josh": 113, "gardner": 113, "maximilian": 113, "b\u00f6ther": 113, "rakib": 113, "islam": 113, "leonard": 113, "lausen": 113, "abhinav": 113, "upadhyai": 113, "rongruosong": 113, "steve": 113, "sedlmey": 113, "ruslan": 113, "baratov": 113, "rafael": 113, "schlatter": 113, "liusy182": 113, "gianni": 113, "pappa": 113, "qbaza": 113, "dchoi77": 113, "gerson": 113, "phuc": 113, "le": 113, "atwood": 113, "christabella": 113, "vn09": 113, "haibin": 113, "jjangga0214": 113, "richychen": 113, "noelo": 113, "hansent": 113, "giel": 113, "dop": 113, "dvincent1337": 113, "whited3vil": 113, "kulit": 113, "codypenta": 113, "joseppinilla": 113, "ahmaurya": 113, "karolszk": 113, "heytitl": 113, "goetz": 113, "rigtorp": 113, "tiep": 113, "vu": 113, "sfilip": 113, "mlxd": 113, "kale": 113, "tessera": 113, "sanjar": 113, "adilov": 113, "matteoferrara": 113, "hsneto": 113, "katarzyna": 113, "biesialska": 113, "gregori": 113, "bruss": 113, "dui": 113, "thanh": 113, "doan": 113, "paulaurel": 113, "graytown": 113, "duc": 113, "pham": 113, "sl7423": 113, "jaedong": 113, "hwang": 113, "yida": 113, "wang": 113, "cys4": 113, "clhm": 113, "jean": 113, "kaddour": 113, "austinmw": 113, "trebeljahr": 113, "tbaum": 113, "cuong": 113, "pavelkomarov": 113, "vzlamal": 113, "notanothersystem": 113, "arun": 113, "jancio": 113, "eldarkurt": 113, "shazbot": 113, "doctorcolossu": 113, "gducharm": 113, "cclauss": 113, "daniel": 113, "mietchen": 113, "hoonos": 113, "biagiom": 113, "abhinavsp0730": 113, "jonathanhrandal": 113, "ysraell": 113, "nodar": 113, "okroshiashvili": 113, "ugurkap": 113, "jiyang": 113, "kang": 113, "stevenjok": 113, "tomer": 113, "kaftan": 113, "liweiwp": 113, "netyst": 113, "ypandya": 113, "nishanttharani": 113, "heiligerl": 113, "sportsthu": 113, "hoa": 113, "manuel": 113, "arno": 113, "korfmann": 113, "webentwicklung": 113, "aterzi": 113, "nxby": 113, "xiaot": 113, "josiah": 113, "yoder": 113, "mathresearch": 113, "mzz2017": 113, "jroberayala": 113, "iluu": 113, "ghejc": 113, "bsharmi": 113, "vkramdev": 113, "simonwardjon": 113, "lakshkd": 113, "talneoran": 113, "djliden": 113, "nikhil95": 113, "oren": 113, "barkan": 113, "guowei": 113, "haozhu233": 113, "pratikhack": 113, "yue": 113, "ying": 113, "tayfunun": 113, "steinsag": 113, "charleybel": 113, "lumsdain": 113, "jiekui": 113, "deepak": 113, "pathak": 113, "florian": 113, "donhaus": 113, "tim": 113, "adriaan": 113, "tijssel": 113, "ron": 113, "medina": 113, "gaurav": 113, "saha": 113, "murat": 113, "semerci": 113, "lei": 113, "mao": 113, "levi": 113, "mcclenni": 113, "joshua": 113, "broyd": 113, "jake221": 113, "jonbal": 113, "zyhazwraith": 113, "brian": 113, "pulfer": 113, "nick": 113, "tomasino": 113, "lefan": 113, "hongshen": 113, "yang": 113, "vinnei": 113, "cavallo": 113, "yuntai": 113, "yuanxiang": 113, "zhu": 113, "amarazov": 113, "pasricha": 113, "ben": 113, "greenawald": 113, "shivam": 113, "quanshangz": 113, "biswajit": 113, "sahoo": 113, "parth": 113, "pandit": 113, "ishan": 113, "kumar": 113, "homunculusk": 113, "lane": 113, "schwartz": 113, "varadgunj": 113, "jason": 113, "wiener": 113, "armin": 113, "gholampoor": 113, "shreshtha13": 113, "eigen": 113, "arnav": 113, "hyeonggyu": 113, "emilyong": 113, "b\u00e1lint": 113, "mucs\u00e1nyi": 113, "duboi": 113, "juntian": 113, "tao": 113, "wenxiang": 113, "xu": 113, "lifu": 113, "huang": 113, "filevich": 113, "quake2005": 113, "werner": 113, "marsel": 113, "khisamutdinov": 113, "francesco": 113, "fuma": 113, "fumag": 113, "peilin": 113, "vincent": 113, "gurgul": 113, "qingfengtommi": 113, "janmei": 113, "shukla": 113, "mo": 113, "shan": 113, "kaan": 113, "sancak": 113, "regob": 113, "alexsau": 113, "gopalakrishna": 113, "ramachandra": 113, "tobia": 113, "uelwer": 113, "chao": 113, "tian": 113, "cao": 113, "nicola": 113, "corthorn": 113, "akash5474": 113, "kxxt": 113, "zxydi1992": 113, "britton": 113, "shuangchi": 113, "zhmou": 113, "krahet": 113, "jie": 113, "han": 113, "atishai": 113, "garg": 113, "marcel": 113, "flygar": 113, "adtygan": 113, "nik": 113, "vaessen": 113, "loui": 113, "schlessing": 113, "balaji": 113, "varatharajan": 113, "atgctg": 113, "kaixin": 113, "victor": 113, "barbaro": 113, "riccardo": 113, "musto": 113, "elizabeth": 113, "ho": [113, 127], "azimjonn": 113, "guilherm": 113, "miotto": 113, "alessandro": 113, "finamor": 113, "joji": 113, "joseph": 113, "anthoni": 113, "biel": 113, "zeme": 113, "zhao": 113, "shjustinbaek": 113, "gab": 113, "nantekoto": 113, "yutaro": 113, "nishiyama": 113, "amsalem": 113, "maomao": 113, "amin": 113, "allahyar": 113, "gij": 113, "van": 113, "tulder": 113, "mikhail": 113, "berkov": 113, "iamorphen": 113, "matthew": 113, "caser": 113, "walsh": 113, "pggpl": 113, "rohankarthikeyan": 113, "ryan": 113, "choi": 113, "likun": 113, "wen": 113, "ming": 113, "karypi": 113, "swami": 113, "sivasubramanian": 113, "desanti": 113, "selipski": 113, "jassi": 113, "cambridg": 113, "commiss": 113, "tranah": 113, "prose": 113, "prone": 114, "plate": 114, "phd": 114, "thesi": [114, 127], "julia": 114, "x_grad": 114, "jacobian": 114, "clearer": 114, "wipe": 114, "ancestor": 114, "maze": 114, "d_grad": 114, "booster": 114, "liber": 114, "expedi": [114, 117], "attach": 114, "ancient": 115, "greec": 115, "archimed": 115, "inscrib": 115, "polygon": 115, "arc": 115, "secant": 115, "auc": 115, "3x": 115, "01000": 115, "03000": 115, "00100": 115, "00300": 115, "00010": 115, "00030": 115, "00003": 115, "d_x": 115, "quotient": 115, "6x": 115, "svg": 115, "crisper": 115, "set_matplotlib_format": 115, "rcparam": 115, "overlai": 115, "has_one_axi": 115, "d_i": 115, "u_1": 115, "u_2": 115, "u_m": 115, "g_i": 115, "u_": 115, "3x_1": 115, "fluenci": 116, "vii": 116, "aptitud": 116, "coin": 116, "palo": 117, "balmi": 117, "fahrenheit": 117, "celsiu": 117, "cholesterol": 117, "st": 117, "oftentim": [117, 120], "1n": 117, "m2": 117, "font": 117, "rd": 117, "operand": 117, "333333": 117, "666667": 117, "416667": 117, "deserv": 117, "\u5f53ax": 117, "0\u65f6": 117, "\u76f8\u5f53\u4e8enumpi": 117, "outer": [117, 121], "top_": 117, "top_m": 117, "top_i": 117, "hang": [117, 131], "1k": 117, "2k": 117, "n1": 117, "n2": 117, "nk": 117, "1m": 117, "k1": 117, "k2": 117, "km": 117, "top_n": 117, "school": [117, 120, 121], "hypotenus": 117, "manhattan": 117, "ord": 117, "revenu": 117, "chunk": 117, "eager": 117, "cubic": 117, "commut": 117, "dir": 118, "__doc__": 118, "__loader__": 118, "__package__": 118, "__spec__": 118, "gumbel": 118, "laplac": 118, "truncated_norm": 118, "__": 118, "hazard": 118, "nb_func": 118, "nanobind": 118, "unspecifi": 118, "breez": 119, "killer": 119, "reconfigur": 119, "19016": 119, "09969": 119, "443679": 119, "59847": 119, "391895": 119, "69262": 119, "460184": 119, "06858": 119, "214382": 119, "98983": 119, "67893": 119, "273626": 119, "outermost": [119, 135], "unari": 119, "71828": 119, "38906": 119, "8103": 119, "22026": 119, "59874": 119, "elabor": [119, 127], "derefer": 119, "referenc": [119, 121], "lest": 119, "spring": 119, "overwrit": 119, "4507520512": 119, "comma": [120, 121], "spreadsheet": 120, "march": 120, "1879": 120, "ulm": 120, "feder": 120, "polytechn": 120, "gravit": 120, "house_tini": 120, "numroom": 120, "rooftyp": 120, "data_fil": 120, "127500": 120, "106000": 120, "slate": 120, "178100": 120, "270000": 120, "bed": 120, "menac": 120, "imput": 120, "rooftype_sl": 120, "rooftype_nan": 120, "to_numpi": 120, "faulti": 120, "seaborn": 120, "bokeh": 120, "abalon": 120, "pillow": 120, "Or": [121, 137], "unsupervis": [121, 136], "uncontroversi": 121, "frequentist": 121, "dam": 121, "hunt": 121, "theses": 121, "depart": 121, "tail": [121, 137], "1000000": 121, "inextric": [121, 131], "intertwin": 121, "num_toss": 121, "fair_prob": 121, "unfair": 121, "5085": 121, "4915": 121, "cum_count": 121, "axhlin": 121, "preoccupi": 121, "manufactur": 121, "countabl": 121, "bigcup_": 121, "axiom": 121, "alarm": 121, "burgl": 121, "suspect": 121, "clunki": 121, "shorthand": 121, "planet": 121, "801392782910287192": 121, "biologist": 121, "breath": 121, "smell": 121, "covid": 121, "sum_v": 121, "renorm": 121, "bay": 121, "implic": 121, "lung": 121, "shoe": [121, 137], "doctor": 121, "hiv": 121, "d_1": 121, "0015": 121, "011485": 121, "1306": 121, "terrifi": 121, "physician": 121, "clariti": 121, "d_2": 121, "requisit": 121, "00176955": 121, "8307": 121, "dp": 121, "sum_x": 121, "economist": 121, "disutil": 121, "100k": 121, "rent": 121, "homeless": 121, "200k": 121, "genuin": 121, "quantif": 121, "tenfold": 121, "chebyshev": 121, "z_m": 121, "venn": 121, "infect": 121, "asset": 121, "portfolio": 121, "nobel": 121, "markovitz": 121, "borrow": 122, "overestim": [122, 137, 140], "undemand": 122, "bang": 122, "buck": 122, "greedili": 122, "048": 122, "miracul": 122, "times10": 122, "ce": 122, "abd": 122, "ced": 122, "y_2": [122, 129], "y_3": 122, "phi_l": 123, "xh": [123, 125, 133], "hh": [123, 125, 130, 133], "hq": [123, 133], "2056": 123, "rnnscratch": [123, 134, 135], "stackedrnnscratch": 123, "timemachin": [123, 125, 127, 132, 134, 135, 137], "rnn_block": 123, "rnnlmscratch": [123, 125, 127, 134, 135], "stackedgru": 123, "stackedgruscratch": 123, "gruscratch": [123, 125], "rnnlm": [123, 125, 127, 134], "flavor": [123, 128], "leftward": [124, 136], "enc_all_output": [124, 129], "encoderdecod": [124, 129], "enc_x": 124, "dec_x": 124, "dec_stat": [124, 129], "xr": 125, "hr": 125, "xz": 125, "hz": 125, "w_xz": 125, "w_hz": 125, "b_z": 125, "w_xr": 125, "w_hr": 125, "b_r": 125, "w_xh": [125, 133, 135], "w_hh": [125, 133, 135], "b_h": [125, 135], "h_tild": 125, "lighter": [125, 126], "notori": 126, "typifi": 126, "difficulti": [126, 136], "cascad": 126, "phonem": 126, "handwrit": [126, 131], "beam": [126, 129, 142], "teacher": 126, "shortli": 127, "elman": 127, "articul": 127, "1991": 127, "ephemer": 127, "inclus": 127, "flush": 127, "temporari": 127, "xf": 127, "xo": 127, "xc": 127, "forev": 127, "uninhibit": 127, "dictat": 127, "lstmscratch": 127, "w_xi": 127, "w_hi": 127, "w_xf": 127, "w_hf": 127, "b_f": 127, "w_xo": 127, "w_ho": 127, "b_o": 127, "w_xc": 127, "w_hc": 127, "b_c": 127, "h_c": 127, "c_tild": 127, "1997": 127, "rose": [127, 131], "victori": 127, "2011": 127, "tranform": 127, "lump": 128, "bilingu": [128, 129], "tatoeba": 128, "_download": [128, 132, 137], "salut": 128, "cour": 128, "courez": 128, "qui": 128, "wow": 128, "\u00e7a": 128, "alor": 128, "_preprocess": [128, 137], "_token": [128, 137], "max_exampl": 128, "src": [128, 129], "tgt": [128, 129], "xlist": 128, "ylist": 128, "set_hatch": 128, "_build_arrai": 128, "is_tgt": 128, "pad_or_trim": 128, "168": 128, "src_sentenc": 128, "tgt_sentenc": 128, "bucket": 128, "japanes": 128, "enc_stat": 129, "seq2seqdecod": 129, "embs_and_context": 129, "dec_output": 129, "save_attention_weight": 129, "understudi": 129, "p_n": 129, "p_3": 129, "p_4": 129, "pred_seq": 129, "label_seq": 129, "pred_token": 129, "label_token": 129, "len_pr": 129, "len_label": 129, "num_match": 129, "label_sub": 129, "rerun": 129, "destabil": 130, "unrol": [130, 131], "feedforward": [130, 131], "h_t": [130, 133, 136], "o_t": 130, "h_": [130, 133, 136], "trickier": 130, "a_t": [130, 139, 140, 141], "b_t": 130, "c_t": 130, "butterfli": 130, "disproportion": 130, "backpropg": 130, "xi_t": 130, "pi_t": 130, "z_t": 130, "regularli": 130, "hx": 130, "qh": 130, "flexibli": 130, "lambda_": 130, "protyp": 131, "synthesi": 131, "unfold": [131, 136], "publicli": 131, "cede": 131, "stapl": 131, "abc": 131, "pave": 131, "exploratori": 131, "monkei": 132, "typewrit": 132, "wreck": 132, "beach": 132, "outlandish": 132, "worthwhil": 132, "bite": 132, "grandma": 132, "disturb": 132, "benign": 132, "fun": 132, "unigram": [132, 137], "bigram": [132, 137], "trigram": [132, 137], "gutenberg": 132, "singleton": 132, "epsilon_1": [132, 136], "epsilon_2": [132, 136], "epsilon_3": 132, "felin": 132, "rain": 132, "piouw": 132, "kcj": 132, "pwepoiut": 132, "nonsens": [132, 134], "tolstoi": 132, "magnum": 132, "opu": 132, "war": [132, 135], "peac": 132, "inevit": 132, "saint": 132, "exuperi": 132, "princ": 132, "reciproc": 132, "601254": 133, "11369": 133, "495389": 133, "99709": 133, "14128": 133, "137718": 133, "38278": 133, "35254": 133, "14624": 133, "117833": 133, "545724": 133, "6013": 133, "achin": 133, "heck": 134, "init_param": [134, 135], "output_lay": [134, 135], "hasllllllllllllllllllll": 134, "check_len": 135, "w_hq": 135, "b_q": 135, "ppl": 135, "remot": 135, "mlx_one_hot": 135, "original_shap": 135, "one_hot_matrix": 135, "one_hot": 135, "rnn_output": 135, "ineleg": 135, "lipschitz": 135, "undo": 135, "spike": 135, "bestow": 135, "grad_clip_v": 135, "sec_rnn": 135, "grad_leav": 135, "autocomplet": 135, "num_pr": 135, "fou": 135, "whip": 135, "10th": 136, "transpir": 136, "bother": 136, "client": 136, "imperfectli": 136, "recoveri": 136, "ftse": 136, "strateg": 136, "revolv": 136, "obviat": 136, "arab": 136, "hebrew": 136, "onestep_pr": 136, "604": 136, "n_train": 136, "609": 136, "605": 136, "601": 136, "602": 136, "603": 136, "606": 136, "607": 136, "608": 136, "multistep": 136, "multistep_pr": 136, "k_step_pr": 136, "extrapol": 136, "investor": 136, "090b5e7e70c295757f55df93cb0a180b9691891a": 137, "1898": 137, "nnnnninnnth": 137, "tra": 137, "za": 137, "atom": 137, "173428": 137, "2261": 137, "1267": 137, "1245": 137, "1155": 137, "816": [86, 137], "695": 137, "552": 137, "541": 137, "443": 137, "440": [26, 137], "pronoun": 137, "preposit": 137, "zipfian": 137, "zipf": 137, "bigram_token": 137, "bigram_vocab": 137, "309": 137, "169": 137, "109": 137, "85": 137, "78": 137, "73": 137, "trigram_token": 137, "trigram_vocab": 137, "59": 137, "me": 137, "bigram_freq": 137, "trigram_freq": 137, "scrape": 137, "pratik": 138, "chaudhari": 138, "pennsylvania": 138, "rasool": 138, "fakoor": 138, "kavosh": 138, "asadi": 138, "doorstep": 138, "warehous": 138, "transport": 138, "citi": 138, "deliveri": 138, "datum": 138, "instant": [138, 141], "uncontrol": 138, "discount": [138, 140, 141], "gridworld": 139, "timestep": [139, 140], "s_0": [139, 140, 141], "r_0": [139, 141], "s_t": [139, 140, 141], "r_t": 139, "gridwold": 139, "newton": 139, "markovian": 139, "mountaincar": 139, "pong": 139, "required_lib": [140, 141], "setuptool": [140, 141], "embodi": 140, "max_": [140, 141], "q_k": [140, 141], "subvert": 140, "pi_e": 140, "min_q": 140, "nt": 140, "afteral": 140, "tie": [140, 141], "dqn": 140, "chapet": 140, "lear": 140, "epsilion": 140, "greadi": 140, "uparrow": [140, 141], "e_greedi": 140, "q_learn": 140, "next_stat": 140, "epicent": 140, "lake": 141, "equiv": 141, "underset": 141, "mnemon": 141, "sate": 141, "richard": 141, "bellman": 141, "1950": 141, "v_k": 141, "q_0": 141, "pi_0": 141, "pi_": 141, "pi_k": 141, "value_iter": 141, "prob_idx": 141, "pr": 141, "prefac": 142, "builder": 142, "111892": 21, "825": 21, "00977603": 22, "0811494": 22, "0325737": 22, "0512224": 22, "0480075": 22, "0975347": 22, "0292623": 22, "026238": 22, "0556498": 22, "0857315": 22, "0923511": 22, "0124245": 22, "922": 22, "916": 22, "194": 22, "377": 22, "838": 22, "815": 22, "195": 22, "502": 23, "826": 23, "664": 23, "4865": 23, "514": 25, "837": 25, "2194": 25, "1216": 25, "347": 26, "466": 26, "367": 26, "07e": 32, "789": 86, "11071": 86, "545903": 86, "306881": 86, "130977": 86, "052": 88, "861": [88, 107], "2152": 88, "081": [92, 108], "699": 92, "5713": 92, "109139": 92, "0253232": 92, "867328": 92, "100949": 92, "0350644": 92, "892001": 92, "2079": 97, "1773": 97, "993": 97, "6079": 97, "1500748": 97, "0621401": 99, "515306": 99, "149054": 99, "195119": 99, "541183": 99, "41583": 99, "615067": 99, "501261": 99, "198281": 99, "296762": 99, "784606": 99, "0265169": 99, "788474": 99, "438938": 99, "257211": 99, "52742": 99, "314468": 99, "289532": 99, "568899": 99, "681304": 99, "646986": 99, "374493": 99, "0788575": 99, "0965961": 99, "381": 99, "941": 99, "591": 99, "motorola": 99, "161": 107, "969": 107, "895": 107, "428": 107, "422": 107, "841": 107, "836": 107, "3288869857788086": 108, "0008697509765625": 108, "2299": 108, "509": 108, "543": 108, "31300": 108, "776": 108, "006": 108, "069": 108, "008": 108, "169916": 112, "216402": 112, "786625": 112, "054956": 112, "101411": 112, "160576": 112}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"appendix": 0, "tool": 0, "deep": [0, 34, 35, 57, 58, 77, 110, 123, 142], "learn": [0, 34, 41, 47, 57, 58, 60, 61, 77, 102, 105, 107, 110, 112, 113, 129, 132, 138, 140, 142], "util": [1, 72, 115], "function": [1, 3, 25, 26, 28, 32, 34, 39, 49, 52, 54, 55, 58, 64, 69, 70, 71, 80, 91, 100, 104, 109, 114, 118, 129, 141], "class": [1, 19, 31, 32, 39, 59, 85, 118], "attent": [2, 3, 4, 5, 7, 9, 86], "pool": [2, 45, 88], "similar": [2, 95], "kernel": [2, 41, 47, 49], "data": [2, 19, 31, 34, 58, 72, 73, 79, 87, 119, 120, 137], "via": 2, "nadaraya": 2, "watson": 2, "regress": [2, 47, 58, 64, 65, 66, 68, 69, 70, 71, 73, 74, 83], "adapt": [2, 105], "summari": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 39, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 119, 122, 123, 124, 125, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 139, 140, 141], "exercis": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 139, 140, 141], "score": 3, "dot": [3, 117], "product": [3, 117], "conveni": 3, "mask": [3, 30, 90, 91, 129], "softmax": [3, 64, 65, 66, 89], "oper": [3, 33, 41, 100, 119], "batch": [3, 35, 60], "matrix": [3, 33, 117], "multipl": [3, 19, 23, 32, 33, 40, 45, 117, 121], "scale": [3, 6, 32], "addit": 3, "The": [4, 10, 15, 21, 29, 31, 32, 41, 49, 52, 58, 59, 61, 62, 64, 66, 69, 85, 86, 88, 91, 93, 96, 97, 98, 99, 101, 102, 103, 109, 111, 124, 136, 140], "bahdanau": 4, "mechan": [4, 5], "model": [4, 6, 7, 10, 11, 17, 21, 22, 25, 26, 32, 36, 37, 39, 58, 59, 64, 65, 66, 67, 69, 70, 71, 72, 74, 76, 79, 80, 81, 86, 88, 90, 91, 93, 96, 98, 99, 125, 127, 132, 133, 134, 135, 136], "defin": [4, 22, 25, 26, 28, 32, 65, 70, 71, 74, 76, 85, 88, 91, 99, 125, 134], "decod": [4, 6, 10, 124, 129, 135, 136], "train": [4, 10, 11, 19, 21, 23, 25, 26, 28, 32, 34, 35, 36, 37, 39, 43, 65, 66, 67, 70, 71, 72, 74, 75, 76, 81, 86, 88, 89, 97, 98, 99, 125, 127, 129, 134, 135, 136], "transform": [5, 6, 10, 11, 90, 91, 135], "larg": 6, "pretrain": [6, 26, 88, 90, 91, 92, 94, 95, 97, 99], "encod": [6, 9, 10, 11, 90, 96, 124, 129, 135], "onli": 6, "bert": [6, 83, 90, 91, 92], "fine": [6, 22, 26, 83], "tune": [6, 22, 26, 83], "t5": 6, "gpt": 6, "2": 6, "3": 6, "beyond": [6, 82], "scalabl": 6, "languag": [6, 84, 85, 86, 90, 91, 94, 132, 133, 135, 137], "discuss": [6, 11, 34, 35, 36, 37, 39, 40, 44, 46, 64, 79, 80, 114, 115, 117, 120, 121, 132, 139], "multi": [7, 23, 37, 56, 107], "head": 7, "implement": [7, 35, 65, 66, 70, 71, 72, 73, 74, 76, 81, 101, 102, 103, 108, 109, 111, 123, 125, 127, 134, 135, 140, 141], "queri": 8, "kei": [8, 58], "valu": [8, 141], "visual": [8, 54, 55, 62, 115], "self": [9, 58, 60, 98, 140], "posit": 9, "compar": [9, 51, 86, 130], "cnn": [9, 30], "rnn": [9, 130, 133, 135], "absolut": 9, "inform": [9, 64, 100], "rel": 9, "architectur": [10, 34, 124], "positionwis": 10, "feed": 10, "forward": [10, 15, 75, 99], "network": [10, 18, 21, 32, 34, 35, 36, 37, 38, 39, 42, 43, 49, 51, 63, 68, 69, 75, 77, 88, 123, 126, 131, 133, 134, 135], "residu": [10, 39], "connect": [10, 33, 35, 36, 46], "layer": [10, 12, 15, 21, 32, 35, 36, 40, 41, 46, 80, 99], "normal": [10, 35, 69], "vision": [11, 24], "patch": 11, "embed": [11, 93, 96, 97, 98, 99], "put": [11, 31, 85, 86, 87, 90, 97, 124, 137], "It": [11, 31, 85, 86, 87, 90, 97, 137], "all": [11, 16, 31, 85, 86, 87, 90, 97, 137], "togeth": [11, 31, 85, 86, 87, 90, 97, 124, 137], "custom": [12, 14, 15, 31], "without": [12, 74, 133], "paramet": [12, 14, 16, 17, 81, 82, 99, 125, 127], "builder": 13, "guid": 13, "initi": [14, 21, 22, 28, 32, 81, 82, 99, 125, 127], "built": 14, "modul": [15, 118], "A": [15, 49, 58, 60, 114, 121], "sequenti": 15, "execut": 15, "code": [15, 57, 113], "propag": [15, 75, 99], "method": [15, 23, 28, 77, 105, 109], "manag": 16, "access": [16, 79], "target": [16, 113], "onc": 16, "ti": 16, "file": 17, "i": [17, 52], "o": 17, "load": [17, 62, 85, 88, 95, 97, 128], "save": [17, 119], "tensor": [17, 18, 117, 120], "gpu": [18, 23], "comput": [18, 24, 75, 114, 130], "devic": 18, "storag": 18, "copi": 18, "side": 18, "note": 18, "neural": [18, 28, 34, 38, 42, 43, 49, 51, 63, 68, 69, 75, 88, 123, 126, 131, 133, 134, 135], "anchor": [19, 27], "box": [19, 20, 27, 32], "gener": [19, 61, 67, 73, 77, 91], "intersect": 19, "over": [19, 88], "union": 19, "iou": 19, "label": [19, 52, 58, 60, 93], "assign": 19, "ground": 19, "truth": 19, "bound": [19, 20, 32], "offset": 19, "an": [19, 58, 109, 121, 139, 140], "exampl": [19, 47, 51, 58, 60, 97, 121], "predict": [19, 21, 32, 35, 47, 66, 69, 79, 90, 91, 127, 129, 134, 136], "non": [19, 114, 117], "maximum": [19, 45], "suppress": 19, "object": [20, 27, 29, 41, 52, 54, 55, 58, 72, 100, 112, 119], "detect": [20, 27, 29, 32, 41], "fulli": [21, 35, 46], "convolut": [21, 33, 34, 35, 38, 40, 41, 42, 43, 46, 51, 88], "transpos": [21, 33], "read": [21, 22, 25, 26, 28, 29, 31, 32, 62, 73, 79, 85, 86, 87, 97, 108, 120, 128, 137], "dataset": [21, 22, 25, 26, 29, 31, 32, 62, 67, 73, 79, 85, 86, 87, 91, 97, 108, 120, 128, 137], "step": [22, 130], "hot": [22, 98, 135], "dog": [22, 26], "recognit": 22, "imag": [23, 25, 26, 28, 31, 41, 62], "augment": [23, 25, 26], "common": 23, "flip": 23, "crop": 23, "chang": 23, "color": 23, "combin": [23, 90, 113], "classif": [25, 58, 59, 61, 62, 63, 64, 83], "cifar": 25, "10": 25, "kaggl": [25, 26, 79], "obtain": [25, 26], "organ": [25, 26], "download": [25, 26, 29, 57, 79, 128], "valid": [25, 26, 67, 79], "classifi": [25, 26, 59], "test": [25, 26, 61], "set": [25, 26, 61, 100, 104], "submit": [25, 26, 79], "result": [25, 26], "breed": 26, "identif": 26, "imagenet": 26, "multiscal": 27, "style": 28, "transfer": 28, "content": [28, 113], "preprocess": [28, 31, 34, 79, 87, 120, 128], "postprocess": 28, "extract": [28, 97], "featur": [28, 41, 102], "loss": [28, 32, 64, 66, 69, 70, 71, 99, 129], "total": 28, "variat": 28, "synthes": 28, "demonstr": 29, "region": 30, "base": [30, 32, 59, 133, 135], "r": 30, "fast": 30, "faster": 30, "semant": 31, "segment": 31, "instanc": 31, "pascal": 31, "voc2012": 31, "singl": [32, 83], "shot": 32, "multibox": 32, "concaten": 32, "downsampl": 32, "block": [32, 36, 37, 39], "complet": 32, "evalu": [32, 86, 88, 129, 141], "basic": [33, 64, 69, 109, 117], "pad": [33, 44, 45], "stride": [33, 44, 45], "channel": [33, 40, 45, 46], "transposit": 33, "alexnet": 34, "represent": [34, 90], "miss": 34, "ingredi": 34, "hardwar": 34, "activ": [34, 80], "capac": 34, "control": [34, 60, 114], "dure": 35, "from": [35, 36, 46, 47, 49, 66, 71, 74, 76, 77, 80, 81, 90, 93, 102, 108, 109, 111, 123, 125, 127, 135], "scratch": [35, 47, 66, 71, 74, 76, 81, 102, 108, 109, 111, 123, 125, 127, 135], "lenet": [35, 43], "concis": [35, 65, 70, 73, 74, 76, 81, 102, 108, 109, 111, 123, 125, 127, 134], "dens": 36, "densenet": 36, "resnet": [36, 39], "transit": 36, "branch": 37, "googlenet": 37, "incept": 37, "modern": [38, 126], "resnext": 39, "input": [40, 90, 127], "output": [40, 127, 135], "1": 40, "time": [40, 88, 130], "cross": [41, 64, 66, 67, 79, 99], "correl": 41, "edg": 41, "map": 41, "recept": 41, "field": 41, "averag": [45, 109], "invari": 46, "constrain": 46, "mlp": 46, "translat": [46, 128, 129], "local": [46, 104, 105, 110], "gaussian": [47, 48, 49, 50], "process": [47, 48, 49, 50, 54, 55, 84, 94, 139], "infer": [47, 85, 86], "posterior": 47, "equat": 47, "make": 47, "hyperparamet": [47, 51, 52, 53, 56], "gp": 47, "interpret": [47, 93], "work": [47, 136], "life": 47, "easi": 47, "gpytorch": 47, "introduct": [48, 58], "prior": 49, "definit": [49, 104, 139], "simpl": [49, 114, 121], "weight": [49, 74, 109], "space": [49, 52], "radial": 49, "basi": 49, "rbf": 49, "optim": [51, 52, 53, 54, 55, 56, 58, 70, 71, 106, 110, 140, 141], "api": 51, "searcher": 51, "schedul": [51, 54, 55, 107], "tuner": 51, "bookkeep": 51, "perform": 51, "hpo": 51, "algorithm": [51, 58, 70, 71, 101, 102, 103, 106, 111, 140], "what": 52, "problem": [52, 58, 60, 107, 109, 140], "configur": 52, "tab_example_configspac": 52, "random": [52, 54, 121, 130], "search": [52, 54, 58, 105, 122], "asynchron": [54, 55], "success": [55, 56, 58], "halv": [55, 56], "fidel": 56, "instal": 57, "miniconda": 57, "framework": 57, "d2l": 57, "packag": 57, "run": 57, "motiv": 58, "compon": 58, "kind": 58, "machin": [58, 60, 128, 129], "supervis": [58, 98], "tag": [58, 83], "recommend": 58, "system": 58, "sequenc": [58, 83, 128, 129, 132, 136, 137], "unsupervis": 58, "interact": 58, "environ": [58, 60], "reinforc": [58, 60, 138], "root": 58, "road": 58, "tab_intro_decad": 58, "stori": 58, "essenc": 58, "accuraci": 59, "distribut": [60, 69], "shift": 60, "type": 60, "covari": 60, "concept": 60, "medic": 60, "diagnost": 60, "drive": 60, "car": 60, "nonstationari": 60, "more": [60, 121], "anecdot": 60, "correct": [60, 140], "empir": 60, "risk": 60, "taxonomi": 60, "onlin": 60, "bandit": 60, "consid": 60, "fair": 60, "account": 60, "transpar": 60, "reus": 61, "statist": [61, 93, 121, 137], "theori": [61, 64, 100], "minibatch": [62, 69, 97, 108], "linear": [63, 64, 68, 69, 70, 71, 74, 80, 117], "vector": [64, 69, 88, 93, 95, 98, 108, 117], "log": 64, "likelihood": 64, "entropi": [64, 66, 99], "surpris": 64, "revisit": [64, 65, 77], "error": [67, 79], "complex": 67, "underfit": 67, "overfit": [67, 77], "polynomi": 67, "curv": 67, "fit": 67, "size": 67, "select": [67, 79], "analyt": 69, "solut": 69, "stochast": [69, 108, 112, 141], "gradient": [69, 82, 105, 108, 110, 112, 114, 115, 130, 135], "descent": [69, 105, 108, 112], "speed": 69, "squar": 69, "biologi": 69, "orient": 72, "design": 72, "synthet": 73, "loader": 73, "decai": 74, "norm": [74, 117], "high": 74, "dimension": [74, 88, 105], "ell_2": 74, "penalti": [74, 104], "regular": [74, 77], "us": [74, 86, 88], "backward": [75, 114], "graph": 75, "backpropag": [75, 130], "dropout": 76, "practic": [76, 109], "inspir": 77, "nonparametr": 77, "earli": 77, "stop": 77, "classic": 77, "multilay": [78, 80, 81], "perceptron": [78, 80, 81], "hous": 79, "price": 79, "measur": 79, "k": 79, "fold": 79, "hidden": [80, 125, 127, 133], "limit": 80, "incorpor": 80, "nonlinear": 80, "univers": 80, "approxim": [80, 89], "relu": 80, "sigmoid": 80, "tanh": 80, "numer": [82, 100], "stabil": 82, "vanish": [82, 110], "explod": 82, "break": 82, "symmetri": 82, "default": 82, "xavier": 82, "level": [83, 133], "token": [83, 128, 137], "applic": [83, 84], "text": [83, 91, 92, 137], "pair": [83, 96], "question": 83, "answer": 83, "natur": [84, 85, 86, 94], "stanford": 85, "snli": 85, "attend": 86, "aggreg": 86, "creat": [86, 87], "sentiment": [87, 88], "analysi": [87, 88, 105, 109, 112, 130], "iter": [87, 141], "One": [88, 98, 105, 113, 135], "max": 88, "textcnn": 88, "word": [88, 93, 95, 97, 98, 99, 132], "neg": [89, 97], "sampl": [89, 97, 109, 112], "hierarch": 89, "bidirect": 90, "context": [90, 97], "independ": 90, "sensit": 90, "task": [90, 91], "specif": [90, 118], "agnost": 90, "best": 90, "both": 90, "world": 90, "next": [90, 91], "sentenc": [90, 91], "helper": 91, "repres": 92, "global": [93, 104], "glove": 93, "skip": [93, 98, 99], "gram": [93, 98, 99, 132], "corpu": 93, "ratio": 93, "co": 93, "occurr": 93, "probabl": [93, 100, 121], "tab_glov": 93, "analogi": 95, "appli": [95, 99], "subword": 96, "fasttext": 96, "byte": 96, "subsampl": 97, "center": 97, "word2vec": [98, 99], "ar": [98, 104], "bad": 98, "choic": 98, "continu": 98, "bag": 98, "cbow": 98, "binari": 99, "loop": 99, "notat": 100, "calculu": [100, 115], "adadelta": 101, "adagrad": 102, "spars": 102, "rate": [102, 105, 107, 112], "precondit": [102, 105], "adam": 103, "yogi": 103, "convex": [104, 109, 112], "jensen": 104, "": [104, 105], "inequ": 104, "properti": [104, 117, 140], "minima": [104, 105, 110], "below": 104, "second": 104, "deriv": [104, 115], "constraint": 104, "lagrangian": 104, "project": 104, "multivari": 105, "newton": 105, "converg": [105, 112], "line": 105, "toi": 107, "polici": [107, 141], "factor": [107, 139], "cosin": 107, "warmup": 107, "cach": 108, "momentum": 109, "leaki": 109, "ill": 109, "condit": 109, "effect": 109, "experi": 109, "theoret": 109, "quadrat": 109, "scalar": [109, 114, 117], "goal": 110, "challeng": 110, "saddl": 110, "point": 110, "rmsprop": 111, "updat": [112, 125], "dynam": [112, 141], "finit": 112, "prefac": 113, "about": 113, "thi": 113, "book": 113, "medium": 113, "math": 113, "html": 113, "do": 113, "structur": 113, "audienc": 113, "notebook": 113, "websit": 113, "github": 113, "forum": 113, "acknowledg": 113, "automat": 114, "differenti": [114, 115], "variabl": [114, 121], "detach": 114, "python": [114, 119], "flow": 114, "partial": 115, "chain": 115, "rule": 115, "preliminari": 116, "algebra": 117, "matric": 117, "arithmet": 117, "reduct": 117, "sum": 117, "document": 118, "manipul": 119, "get": 119, "start": 119, "index": 119, "slice": 119, "broadcast": 119, "memori": [119, 127], "convers": [119, 120], "other": 119, "prepar": 120, "format": 120, "toss": 121, "coin": 121, "formal": 121, "treatment": 121, "expect": 121, "beam": 122, "greedi": 122, "exhaust": 122, "recurr": [123, 125, 126, 131, 133, 134, 135], "gate": [125, 127], "unit": 125, "gru": 125, "reset": 125, "candid": 125, "state": [125, 127, 133], "long": 127, "short": 127, "term": 127, "lstm": 127, "cell": 127, "forget": 127, "node": 127, "intern": 127, "fix": 128, "length": 128, "teacher": 129, "forc": 129, "through": 130, "full": 130, "truncat": 130, "strategi": 130, "detail": 130, "markov": [132, 136, 139], "n": 132, "frequenc": 132, "laplac": 132, "smooth": 132, "perplex": 132, "partit": 132, "charact": 133, "clip": 135, "autoregress": 136, "order": 136, "convert": 137, "raw": 137, "vocabulari": 137, "exploratori": 137, "decis": 139, "mdp": 139, "return": 139, "discount": 139, "assumpt": 139, "q": 140, "underli": 140, "explor": 140, "action": 141, "principl": 141, "program": 141, "dive": 142}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinxcontrib.bibtex": 9, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Queries, Keys, and Values": [[8, "queries-keys-and-values"]], "Visualization": [[8, "visualization"], [62, "visualization"]], "Summary": [[8, "summary"], [14, "summary"], [3, "summary"], [4, "summary"], [7, "summary"], [10, "summary"], [9, "summary"], [12, "summary"], [15, "summary"], [17, "summary"], [16, "summary"], [2, "summary"], [48, "summary"], [47, "summary"], [43, "summary"], [51, "summary"], [52, "summary"], [45, "summary"], [49, "summary"], [41, "summary"], [18, "summary"], [65, "summary"], [58, "summary"], [70, "summary"], [55, "summary"], [60, "summary"], [66, "summary"], [59, "summary"], [56, "summary"], [67, "summary"], [69, "summary"], [61, "summary"], [71, "summary"], [62, "summary"], [139, "summary"], [140, "summary"], [129, "summary"], [141, "summary"], [128, "summary"], [133, "summary"], [134, "summary"], [136, "summary"], [137, "summary"], [127, "summary"], [130, "summary"], [135, "summary"], [72, "summary"], [76, "summary"], [74, "summary"], [89, "summary"], [73, "summary"], [77, "summary"], [75, "summary"], [83, "summary"], [81, "summary"], [82, "summary"], [124, "summary"], [122, "summary"], [125, "summary"], [119, "summary"], [123, "summary"], [113, "summary"], [98, "summary"], [93, "summary"], [26, "summary"], [23, "summary"], [21, "summary"], [20, "summary"], [22, "summary"], [27, "summary"], [19, "summary"], [25, "summary"], [85, "summary"], [28, "summary"], [33, "summary"], [54, "summary"], [29, "summary"], [30, "summary"], [31, "summary"], [32, "summary"], [87, "summary"], [91, "summary"], [88, "summary"], [95, "summary"], [96, "summary"], [92, "summary"], [97, "summary"], [99, "summary"], [86, "summary"], [90, "summary"], [101, "summary"], [105, "summary"], [103, "summary"], [104, "summary"], [108, "summary"], [111, "summary"], [110, "summary"], [107, "summary"], [109, "summary"], [102, "summary"], [112, "summary"]], "Exercises": [[8, "exercises"], [14, "exercises"], [3, "exercises"], [4, "exercises"], [7, "exercises"], [10, "exercises"], [9, "exercises"], [12, "exercises"], [15, "exercises"], [17, "exercises"], [16, "exercises"], [6, "exercises"], [2, "exercises"], [11, "exercises"], [48, "exercises"], [36, "exercises"], [47, "exercises"], [43, "exercises"], [51, "exercises"], [52, "exercises"], [45, "exercises"], [44, "exercises"], [39, "exercises"], [46, "exercises"], [49, "exercises"], [37, "exercises"], [41, "exercises"], [40, "exercises"], [18, "exercises"], [34, "exercises"], [35, "exercises"], [65, "exercises"], [58, "exercises"], [70, "exercises"], [60, "exercises"], [66, "exercises"], [59, "exercises"], [64, "exercises"], [67, "exercises"], [69, "exercises"], [61, "exercises"], [71, "exercises"], [62, "exercises"], [132, "exercises"], [139, "exercises"], [140, "exercises"], [129, "exercises"], [141, "exercises"], [128, "exercises"], [133, "exercises"], [134, "exercises"], [136, "exercises"], [137, "exercises"], [127, "exercises"], [130, "exercises"], [135, "exercises"], [72, "exercises"], [76, "exercises"], [74, "exercises"], [79, "exercises"], [80, "exercises"], [89, "exercises"], [73, "exercises"], [77, "exercises"], [75, "exercises"], [83, "exercises"], [81, "exercises"], [82, "exercises"], [124, "exercises"], [122, "exercises"], [125, "exercises"], [120, "exercises"], [115, "exercises"], [117, "exercises"], [119, "exercises"], [123, "exercises"], [114, "exercises"], [121, "exercises"], [113, "exercises"], [98, "exercises"], [93, "exercises"], [26, "exercises"], [23, "exercises"], [21, "exercises"], [20, "exercises"], [22, "exercises"], [27, "exercises"], [19, "exercises"], [25, "exercises"], [85, "exercises"], [28, "exercises"], [33, "exercises"], [54, "exercises"], [29, "exercises"], [30, "exercises"], [31, "exercises"], [32, "exercises"], [87, "exercises"], [91, "exercises"], [88, "exercises"], [95, "exercises"], [96, "exercises"], [92, "exercises"], [97, "exercises"], [99, "exercises"], [86, "exercises"], [90, "exercises"], [101, "exercises"], [105, "exercises"], [103, "exercises"], [104, "exercises"], [108, "exercises"], [111, "exercises"], [110, "exercises"], [107, "exercises"], [109, "exercises"], [102, "exercises"], [112, "exercises"]], "Parameter Initialization": [[14, "parameter-initialization"], [82, "parameter-initialization"]], "Built-in Initialization": [[14, "built-in-initialization"]], "Custom Initialization": [[14, "custom-initialization"]], "Attention Scoring Functions": [[3, "attention-scoring-functions"]], "Dot Product Attention": [[3, "dot-product-attention"]], "Convenience Functions": [[3, "convenience-functions"]], "Masked Softmax Operation": [[3, "masked-softmax-operation"]], "Batch Matrix Multiplication": [[3, "batch-matrix-multiplication"]], "Scaled Dot Product Attention": [[3, "scaled-dot-product-attention"]], "Additive Attention": [[3, "additive-attention"]], "The Bahdanau Attention Mechanism": [[4, "the-bahdanau-attention-mechanism"]], "Model": [[4, "model"], [7, "model"], [10, "model"], [11, "model"], [69, "model"], [81, "model"], [81, "id1"], [32, "model"]], "Defining the Decoder with Attention": [[4, "defining-the-decoder-with-attention"]], "Training": [[4, "training"], [10, "training"], [11, "training"], [36, "training"], [43, "training"], [39, "training"], [37, "training"], [34, "training"], [65, "training"], [70, "training"], [66, "training"], [71, "training"], [129, "training"], [136, "training"], [135, "training"], [72, "training"], [76, "training"], [81, "training"], [81, "id2"], [125, "training"], [98, "training"], [98, "id3"], [21, "training"], [28, "training"], [32, "training"], [99, "training"]], "Multi-Head Attention": [[7, "multi-head-attention"]], "Implementation": [[7, "implementation"], [101, "implementation"], [103, "implementation"]], "The Transformer Architecture": [[10, "the-transformer-architecture"]], "Positionwise Feed-Forward Networks": [[10, "positionwise-feed-forward-networks"]], "Residual Connection and Layer Normalization": [[10, "residual-connection-and-layer-normalization"]], "Encoder": [[10, "encoder"], [129, "encoder"], [124, "encoder"]], "Decoder": [[10, "decoder"], [129, "decoder"], [124, "decoder"]], "Self-Attention and Positional Encoding": [[9, "self-attention-and-positional-encoding"]], "Self-Attention": [[9, "self-attention"]], "Comparing CNNs, RNNs, and Self-Attention": [[9, "comparing-cnns-rnns-and-self-attention"]], "Positional Encoding": [[9, "positional-encoding"]], "Absolute Positional Information": [[9, "absolute-positional-information"]], "Relative Positional Information": [[9, "relative-positional-information"]], "Custom Layers": [[12, "custom-layers"]], "Layers without Parameters": [[12, "layers-without-parameters"]], "Layers with Parameters": [[12, "layers-with-parameters"]], "Layers and Modules": [[15, "layers-and-modules"]], "A Custom Module": [[15, "a-custom-module"]], "The Sequential Module": [[15, "the-sequential-module"]], "Executing Code in the Forward Propagation Method": [[15, "executing-code-in-the-forward-propagation-method"]], "File I/O": [[17, "file-i-o"]], "Loading and Saving Tensors": [[17, "loading-and-saving-tensors"]], "Loading and Saving Model Parameters": [[17, "loading-and-saving-model-parameters"]], "Attention Mechanisms and Transformers": [[5, "attention-mechanisms-and-transformers"]], "Parameter Management": [[16, "parameter-management"]], "Parameter Access": [[16, "parameter-access"]], "Targeted Parameters": [[16, "targeted-parameters"]], "All Parameters at Once": [[16, "all-parameters-at-once"]], "Tied Parameters": [[16, "tied-parameters"]], "Large-Scale Pretraining with Transformers": [[6, "large-scale-pretraining-with-transformers"]], "Encoder-Only": [[6, "encoder-only"]], "Pretraining BERT": [[6, "pretraining-bert"], [92, "pretraining-bert"], [92, "id1"]], "Fine-Tuning BERT": [[6, "fine-tuning-bert"]], "Encoder\u2013Decoder": [[6, "encoderdecoder"]], "Pretraining T5": [[6, "pretraining-t5"]], "Fine-Tuning T5": [[6, "fine-tuning-t5"]], "Decoder-Only": [[6, "decoder-only"]], "GPT and GPT-2": [[6, "gpt-and-gpt-2"]], "GPT-3 and Beyond": [[6, "gpt-3-and-beyond"]], "Scalability": [[6, "scalability"]], "Large Language Models": [[6, "large-language-models"]], "Summary and Discussion": [[6, "summary-and-discussion"], [11, "summary-and-discussion"], [36, "summary-and-discussion"], [44, "summary-and-discussion"], [39, "summary-and-discussion"], [46, "summary-and-discussion"], [64, "summary-and-discussion"], [132, "summary-and-discussion"], [79, "summary-and-discussion"], [80, "summary-and-discussion"]], "Attention Pooling by Similarity": [[2, "attention-pooling-by-similarity"]], "Kernels and Data": [[2, "kernels-and-data"]], "Attention Pooling via Nadaraya\u2013Watson Regression": [[2, "attention-pooling-via-nadarayawatson-regression"]], "Adapting Attention Pooling": [[2, "adapting-attention-pooling"]], "Utility Functions and Classes": [[1, "utility-functions-and-classes"]], "Transformers for Vision": [[11, "transformers-for-vision"]], "Patch Embedding": [[11, "patch-embedding"]], "Vision Transformer Encoder": [[11, "vision-transformer-encoder"]], "Putting It All Together": [[11, "putting-it-all-together"], [137, "putting-it-all-together"], [85, "putting-it-all-together"], [31, "putting-it-all-together"], [87, "putting-it-all-together"], [97, "putting-it-all-together"], [86, "putting-it-all-together"], [90, "putting-it-all-together"]], "Introduction to Gaussian Processes": [[48, "introduction-to-gaussian-processes"]], "Gaussian Processes": [[50, "gaussian-processes"]], "Densely Connected Networks (DenseNet)": [[36, "densely-connected-networks-densenet"]], "From ResNet to DenseNet": [[36, "from-resnet-to-densenet"]], "Dense Blocks": [[36, "dense-blocks"]], "Transition Layers": [[36, "transition-layers"]], "DenseNet Model": [[36, "densenet-model"]], "Gaussian Process Inference": [[47, "gaussian-process-inference"]], "Posterior Inference for Regression": [[47, "posterior-inference-for-regression"]], "Equations for Making Predictions and Learning Kernel Hyperparameters in GP Regression": [[47, "equations-for-making-predictions-and-learning-kernel-hyperparameters-in-gp-regression"]], "Interpreting Equations for Learning and Predictions": [[47, "interpreting-equations-for-learning-and-predictions"]], "Worked Example from Scratch": [[47, "worked-example-from-scratch"]], "Making Life Easy with GPyTorch": [[47, "making-life-easy-with-gpytorch"]], "Convolutional Neural Networks": [[42, "convolutional-neural-networks"]], "Convolutional Neural Networks (LeNet)": [[43, "convolutional-neural-networks-lenet"]], "LeNet": [[43, "lenet"]], "Hyperparameter Optimization API": [[51, "hyperparameter-optimization-api"]], "Searcher": [[51, "searcher"]], "Scheduler": [[51, "scheduler"]], "Tuner": [[51, "tuner"]], "Bookkeeping the Performance of HPO Algorithms": [[51, "bookkeeping-the-performance-of-hpo-algorithms"]], "Example: Optimizing the Hyperparameters of a Convolutional Neural Network": [[51, "example-optimizing-the-hyperparameters-of-a-convolutional-neural-network"]], "Comparing HPO Algorithms": [[51, "comparing-hpo-algorithms"]], "What Is Hyperparameter Optimization?": [[52, "what-is-hyperparameter-optimization"]], "The Optimization Problem": [[52, "the-optimization-problem"]], "The Objective Function": [[52, "the-objective-function"]], "The Configuration Space": [[52, "the-configuration-space"]], "label:tab_example_configspace": [[52, "id11"]], "Random Search": [[52, "random-search"]], "Hyperparameter Optimization": [[53, "hyperparameter-optimization"]], "Pooling": [[45, "pooling"]], "Maximum Pooling and Average Pooling": [[45, "maximum-pooling-and-average-pooling"]], "Padding and Stride": [[45, "padding-and-stride"], [44, "padding-and-stride"]], "Multiple Channels": [[45, "multiple-channels"]], "Padding": [[44, "padding"]], "Stride": [[44, "stride"]], "Residual Networks (ResNet) and ResNeXt": [[39, "residual-networks-resnet-and-resnext"]], "Function Classes": [[39, "function-classes"]], "Residual Blocks": [[39, "residual-blocks"]], "ResNet Model": [[39, "resnet-model"]], "ResNeXt": [[39, "resnext"]], "From Fully Connected Layers to Convolutions": [[46, "from-fully-connected-layers-to-convolutions"]], "Invariance": [[46, "invariance"]], "Constraining the MLP": [[46, "constraining-the-mlp"]], "Translation Invariance": [[46, "translation-invariance"]], "Locality": [[46, "locality"]], "Convolutions": [[46, "convolutions"]], "Channels": [[46, "channels"]], "Gaussian Process Priors": [[49, "gaussian-process-priors"]], "Definition": [[49, "definition"]], "A Simple Gaussian Process": [[49, "a-simple-gaussian-process"]], "From Weight Space to Function Space": [[49, "from-weight-space-to-function-space"]], "The Radial Basis Function (RBF) Kernel": [[49, "the-radial-basis-function-rbf-kernel"]], "The Neural Network Kernel": [[49, "the-neural-network-kernel"]], "Multi-Branch Networks (GoogLeNet)": [[37, "multi-branch-networks-googlenet"]], "Inception Blocks": [[37, "inception-blocks"]], "GoogLeNet Model": [[37, "googlenet-model"]], "Discussion": [[37, "discussion"], [40, "discussion"], [34, "discussion"], [35, "discussion"], [120, "discussion"], [115, "discussion"], [117, "discussion"], [114, "discussion"], [121, "discussion"]], "Convolutions for Images": [[41, "convolutions-for-images"]], "The Cross-Correlation Operation": [[41, "the-cross-correlation-operation"]], "Convolutional Layers": [[41, "convolutional-layers"], [35, "convolutional-layers"]], "Object Edge Detection in Images": [[41, "object-edge-detection-in-images"]], "Learning a Kernel": [[41, "learning-a-kernel"]], "Cross-Correlation and Convolution": [[41, "cross-correlation-and-convolution"]], "Feature Map and Receptive Field": [[41, "feature-map-and-receptive-field"]], "Multiple Input and Multiple Output Channels": [[40, "multiple-input-and-multiple-output-channels"]], "Multiple Input Channels": [[40, "multiple-input-channels"]], "Multiple Output Channels": [[40, "multiple-output-channels"]], "1\\times 1 Convolutional Layer": [[40, "times-1-convolutional-layer"]], "GPUs": [[18, "gpus"]], "Computing Devices": [[18, "computing-devices"]], "Tensors and GPUs": [[18, "tensors-and-gpus"]], "Storage on the GPU": [[18, "storage-on-the-gpu"]], "Copying": [[18, "copying"]], "Side Notes": [[18, "side-notes"]], "Neural Networks and GPUs": [[18, "neural-networks-and-gpus"]], "Deep Convolutional Neural Networks (AlexNet)": [[34, "deep-convolutional-neural-networks-alexnet"]], "Representation Learning": [[34, "representation-learning"]], "Missing Ingredient: Data": [[34, "missing-ingredient-data"]], "Missing Ingredient: Hardware": [[34, "missing-ingredient-hardware"]], "AlexNet": [[34, "alexnet"]], "Architecture": [[34, "architecture"]], "Activation Functions": [[34, "activation-functions"], [80, "activation-functions"]], "Capacity Control and Preprocessing": [[34, "capacity-control-and-preprocessing"]], "Batch Normalization": [[35, "batch-normalization"]], "Training Deep Networks": [[35, "training-deep-networks"]], "Batch Normalization Layers": [[35, "batch-normalization-layers"]], "Fully Connected Layers": [[35, "fully-connected-layers"]], "Layer Normalization": [[35, "layer-normalization"]], "Batch Normalization During Prediction": [[35, "batch-normalization-during-prediction"]], "Implementation from Scratch": [[35, "implementation-from-scratch"], [127, "implementation-from-scratch"], [76, "implementation-from-scratch"], [74, "implementation-from-scratch"], [81, "implementation-from-scratch"], [125, "implementation-from-scratch"], [123, "implementation-from-scratch"], [108, "implementation-from-scratch"], [111, "implementation-from-scratch"], [109, "implementation-from-scratch"], [102, "implementation-from-scratch"]], "LeNet with Batch Normalization": [[35, "lenet-with-batch-normalization"]], "Concise Implementation": [[35, "concise-implementation"], [127, "concise-implementation"], [76, "concise-implementation"], [74, "concise-implementation"], [81, "concise-implementation"], [125, "concise-implementation"], [123, "concise-implementation"], [108, "concise-implementation"], [111, "concise-implementation"], [109, "concise-implementation"], [102, "concise-implementation"]], "Computer Vision": [[24, "computer-vision"]], "Linear Neural Networks for Regression": [[68, "linear-neural-networks-for-regression"]], "Concise Implementation of Softmax Regression": [[65, "concise-implementation-of-softmax-regression"]], "Defining the Model": [[65, "defining-the-model"], [70, "defining-the-model"], [71, "defining-the-model"], [134, "defining-the-model"], [76, "defining-the-model"], [74, "defining-the-model"], [125, "defining-the-model"], [25, "defining-the-model"], [88, "defining-the-model"]], "Softmax Revisited": [[65, "softmax-revisited"]], "Installation": [[57, "installation"]], "Installing Miniconda": [[57, "installing-miniconda"]], "Installing the Deep Learning Framework and the d2l Package": [[57, "installing-the-deep-learning-framework-and-the-d2l-package"]], "Downloading and Running the Code": [[57, "downloading-and-running-the-code"]], "Introduction": [[58, "introduction"]], "A Motivating Example": [[58, "a-motivating-example"]], "Key Components": [[58, "key-components"]], "Data": [[58, "data"], [72, "data"]], "Models": [[58, "models"], [72, "models"]], "Objective Functions": [[58, "objective-functions"]], "Optimization Algorithms": [[58, "optimization-algorithms"], [106, "optimization-algorithms"]], "Kinds of Machine Learning Problems": [[58, "kinds-of-machine-learning-problems"]], "Supervised Learning": [[58, "supervised-learning"]], "Regression": [[58, "regression"]], "Classification": [[58, "classification"], [64, "classification"]], "Tagging": [[58, "tagging"]], "Search": [[58, "search"]], "Recommender Systems": [[58, "recommender-systems"]], "Sequence Learning": [[58, "sequence-learning"]], "Unsupervised and Self-Supervised Learning": [[58, "unsupervised-and-self-supervised-learning"]], "Interacting with an Environment": [[58, "interacting-with-an-environment"]], "Reinforcement Learning": [[58, "reinforcement-learning"], [60, "reinforcement-learning"], [138, "reinforcement-learning"]], "Roots": [[58, "roots"]], "The Road to Deep Learning": [[58, "the-road-to-deep-learning"]], "label:tab_intro_decade": [[58, "id59"]], "Success Stories": [[58, "success-stories"]], "The Essence of Deep Learning": [[58, "the-essence-of-deep-learning"]], "Concise Implementation of Linear Regression": [[70, "concise-implementation-of-linear-regression"]], "Defining the Loss Function": [[70, "defining-the-loss-function"], [71, "defining-the-loss-function"], [28, "defining-the-loss-function"]], "Defining the Optimization Algorithm": [[70, "defining-the-optimization-algorithm"], [71, "defining-the-optimization-algorithm"]], "Asynchronous Successive Halving": [[55, "asynchronous-successive-halving"]], "Objective Function": [[55, "objective-function"], [54, "objective-function"]], "Asynchronous Scheduler": [[55, "asynchronous-scheduler"], [54, "asynchronous-scheduler"]], "Visualize the Optimization Process": [[55, "visualize-the-optimization-process"]], "Environment and Distribution Shift": [[60, "environment-and-distribution-shift"]], "Types of Distribution Shift": [[60, "types-of-distribution-shift"]], "Covariate Shift": [[60, "covariate-shift"]], "Label Shift": [[60, "label-shift"]], "Concept Shift": [[60, "concept-shift"]], "Examples of Distribution Shift": [[60, "examples-of-distribution-shift"]], "Medical Diagnostics": [[60, "medical-diagnostics"]], "Self-Driving Cars": [[60, "self-driving-cars"]], "Nonstationary Distributions": [[60, "nonstationary-distributions"]], "More Anecdotes": [[60, "more-anecdotes"]], "Correction of Distribution Shift": [[60, "correction-of-distribution-shift"]], "Empirical Risk and Risk": [[60, "empirical-risk-and-risk"]], "Covariate Shift Correction": [[60, "covariate-shift-correction"]], "Label Shift Correction": [[60, "label-shift-correction"]], "Concept Shift Correction": [[60, "concept-shift-correction"]], "A Taxonomy of Learning Problems": [[60, "a-taxonomy-of-learning-problems"]], "Batch Learning": [[60, "batch-learning"]], "Online Learning": [[60, "online-learning"]], "Bandits": [[60, "bandits"]], "Control": [[60, "control"]], "Considering the Environment": [[60, "considering-the-environment"]], "Fairness, Accountability, and Transparency in Machine Learning": [[60, "fairness-accountability-and-transparency-in-machine-learning"]], "Softmax Regression Implementation from Scratch": [[66, "softmax-regression-implementation-from-scratch"]], "The Softmax": [[66, "the-softmax"], [64, "the-softmax"]], "The Model": [[66, "the-model"], [21, "the-model"], [86, "the-model"]], "The Cross-Entropy Loss": [[66, "the-cross-entropy-loss"]], "Prediction": [[66, "prediction"], [129, "prediction"], [136, "prediction"], [21, "prediction"], [32, "prediction"]], "The Base Classification Model": [[59, "the-base-classification-model"]], "The Classifier Class": [[59, "the-classifier-class"]], "Accuracy": [[59, "accuracy"]], "Multi-Fidelity Hyperparameter Optimization": [[56, "multi-fidelity-hyperparameter-optimization"]], "Successive Halving": [[56, "successive-halving"]], "Linear Neural Networks for Classification": [[63, "linear-neural-networks-for-classification"]], "Softmax Regression": [[64, "softmax-regression"]], "Linear Model": [[64, "linear-model"]], "Vectorization": [[64, "vectorization"]], "Loss Function": [[64, "loss-function"], [69, "loss-function"], [28, "loss-function"]], "Log-Likelihood": [[64, "log-likelihood"]], "Softmax and Cross-Entropy Loss": [[64, "softmax-and-cross-entropy-loss"]], "Information Theory Basics": [[64, "information-theory-basics"]], "Entropy": [[64, "entropy"]], "Surprisal": [[64, "surprisal"]], "Cross-Entropy Revisited": [[64, "cross-entropy-revisited"]], "Generalization": [[67, "generalization"]], "Training Error and Generalization Error": [[67, "training-error-and-generalization-error"]], "Model Complexity": [[67, "model-complexity"]], "Underfitting or Overfitting?": [[67, "underfitting-or-overfitting"]], "Polynomial Curve Fitting": [[67, "polynomial-curve-fitting"]], "Dataset Size": [[67, "dataset-size"]], "Model Selection": [[67, "model-selection"], [79, "model-selection"]], "Cross-Validation": [[67, "cross-validation"]], "Linear Regression": [[69, "linear-regression"]], "Basics": [[69, "basics"], [109, "basics"]], "Analytic Solution": [[69, "analytic-solution"]], "Minibatch Stochastic Gradient Descent": [[69, "minibatch-stochastic-gradient-descent"], [108, "minibatch-stochastic-gradient-descent"]], "Predictions": [[69, "predictions"]], "Vectorization for Speed": [[69, "vectorization-for-speed"]], "The Normal Distribution and Squared Loss": [[69, "the-normal-distribution-and-squared-loss"]], "Linear Regression as a Neural Network": [[69, "linear-regression-as-a-neural-network"]], "Biology": [[69, "biology"]], "Generalization in Classification": [[61, "generalization-in-classification"]], "The Test Set": [[61, "the-test-set"]], "Test Set Reuse": [[61, "test-set-reuse"]], "Statistical Learning Theory": [[61, "statistical-learning-theory"]], "Linear Regression Implementation from Scratch": [[71, "linear-regression-implementation-from-scratch"]], "The Image Classification Dataset": [[62, "the-image-classification-dataset"]], "Loading the Dataset": [[62, "loading-the-dataset"]], "Reading a Minibatch": [[62, "reading-a-minibatch"]], "Language Models": [[132, "language-models"]], "Learning Language Models": [[132, "learning-language-models"]], "Markov Models and n-grams": [[132, "markov-models-and-n-grams"]], "Word Frequency": [[132, "word-frequency"]], "Laplace Smoothing": [[132, "laplace-smoothing"]], "Perplexity": [[132, "perplexity"]], "Partitioning Sequences": [[132, "partitioning-sequences"]], "Recurrent Neural Networks": [[131, "recurrent-neural-networks"], [133, "recurrent-neural-networks"]], "Markov Decision Process (MDP)": [[139, "markov-decision-process-mdp"]], "Definition of an MDP": [[139, "definition-of-an-mdp"]], "Return and Discount Factor": [[139, "return-and-discount-factor"]], "Discussion of the Markov Assumption": [[139, "discussion-of-the-markov-assumption"]], "Q-Learning": [[140, "q-learning"]], "The Q-Learning Algorithm": [[140, "the-q-learning-algorithm"]], "An Optimization Problem Underlying Q-Learning": [[140, "an-optimization-problem-underlying-q-learning"]], "Exploration in Q-Learning": [[140, "exploration-in-q-learning"]], "The \u201cSelf-correcting\u201d Property of Q-Learning": [[140, "the-self-correcting-property-of-q-learning"]], "Implementation of Q-Learning": [[140, "implementation-of-q-learning"]], "Sequence-to-Sequence Learning for Machine Translation": [[129, "sequence-to-sequence-learning-for-machine-translation"]], "Teacher Forcing": [[129, "teacher-forcing"]], "Encoder\u2013Decoder for Sequence-to-Sequence Learning": [[129, "encoderdecoder-for-sequence-to-sequence-learning"]], "Loss Function with Masking": [[129, "loss-function-with-masking"]], "Evaluation of Predicted Sequences": [[129, "evaluation-of-predicted-sequences"]], "Value Iteration": [[141, "value-iteration"], [141, "id2"]], "Stochastic Policy": [[141, "stochastic-policy"]], "Value Function": [[141, "value-function"]], "Action-Value Function": [[141, "action-value-function"]], "Optimal Stochastic Policy": [[141, "optimal-stochastic-policy"]], "Principle of Dynamic Programming": [[141, "principle-of-dynamic-programming"]], "Policy Evaluation": [[141, "policy-evaluation"]], "Implementation of Value Iteration": [[141, "implementation-of-value-iteration"]], "Machine Translation and the Dataset": [[128, "machine-translation-and-the-dataset"]], "Downloading and Preprocessing the Dataset": [[128, "downloading-and-preprocessing-the-dataset"]], "Tokenization": [[128, "tokenization"], [137, "tokenization"]], "Loading Sequences of Fixed Length": [[128, "loading-sequences-of-fixed-length"]], "Reading the Dataset": [[128, "reading-the-dataset"], [137, "reading-the-dataset"], [73, "reading-the-dataset"], [120, "reading-the-dataset"], [26, "reading-the-dataset"], [21, "reading-the-dataset"], [22, "reading-the-dataset"], [25, "reading-the-dataset"], [85, "reading-the-dataset"], [29, "reading-the-dataset"], [31, "reading-the-dataset"], [87, "reading-the-dataset"], [97, "reading-the-dataset"], [108, "reading-the-dataset"]], "Neural Networks without Hidden States": [[133, "neural-networks-without-hidden-states"]], "Recurrent Neural Networks with Hidden States": [[133, "recurrent-neural-networks-with-hidden-states"]], "RNN-Based Character-Level Language Models": [[133, "rnn-based-character-level-language-models"]], "Concise Implementation of Recurrent Neural Networks": [[134, "concise-implementation-of-recurrent-neural-networks"]], "Training and Predicting": [[134, "training-and-predicting"]], "Working with Sequences": [[136, "working-with-sequences"]], "Autoregressive Models": [[136, "autoregressive-models"]], "Sequence Models": [[136, "sequence-models"]], "Markov Models": [[136, "markov-models"]], "The Order of Decoding": [[136, "the-order-of-decoding"]], "Converting Raw Text into Sequence Data": [[137, "converting-raw-text-into-sequence-data"]], "Vocabulary": [[137, "vocabulary"]], "Exploratory Language Statistics": [[137, "exploratory-language-statistics"]], "Long Short-Term Memory (LSTM)": [[127, "long-short-term-memory-lstm"]], "Gated Memory Cell": [[127, "gated-memory-cell"]], "Gated Hidden State": [[127, "gated-hidden-state"]], "Input Gate, Forget Gate, and Output Gate": [[127, "input-gate-forget-gate-and-output-gate"]], "Input Node": [[127, "input-node"]], "Memory Cell Internal State": [[127, "memory-cell-internal-state"]], "Hidden State": [[127, "hidden-state"], [125, "hidden-state"]], "Initializing Model Parameters": [[127, "initializing-model-parameters"], [81, "initializing-model-parameters"], [125, "initializing-model-parameters"], [99, "initializing-model-parameters"]], "Training and Prediction": [[127, "training-and-prediction"]], "Backpropagation Through Time": [[130, "backpropagation-through-time"]], "Analysis of Gradients in RNNs": [[130, "analysis-of-gradients-in-rnns"]], "Full Computation": [[130, "full-computation"]], "Truncating Time Steps": [[130, "truncating-time-steps"]], "Randomized Truncation": [[130, "randomized-truncation"]], "Comparing Strategies": [[130, "comparing-strategies"]], "Backpropagation Through Time in Detail": [[130, "backpropagation-through-time-in-detail"]], "Recurrent Neural Network Implementation from Scratch": [[135, "recurrent-neural-network-implementation-from-scratch"]], "RNN Model": [[135, "rnn-model"]], "RNN-Based Language Model": [[135, "rnn-based-language-model"]], "One-Hot Encoding": [[135, "one-hot-encoding"]], "Transforming RNN Outputs": [[135, "transforming-rnn-outputs"]], "Gradient Clipping": [[135, "gradient-clipping"]], "Decoding": [[135, "decoding"]], "Object-Oriented Design for Implementation": [[72, "object-oriented-design-for-implementation"]], "Utilities": [[72, "utilities"]], "Dropout": [[76, "dropout"]], "Dropout in Practice": [[76, "dropout-in-practice"]], "Weight Decay": [[74, "weight-decay"]], "Norms and Weight Decay": [[74, "norms-and-weight-decay"]], "High-Dimensional Linear Regression": [[74, "high-dimensional-linear-regression"]], "Defining \\ell_2 Norm Penalty": [[74, "defining-ell-2-norm-penalty"]], "Training without Regularization": [[74, "training-without-regularization"]], "Using Weight Decay": [[74, "using-weight-decay"]], "Multilayer Perceptrons": [[78, "multilayer-perceptrons"], [80, "multilayer-perceptrons"]], "Predicting House Prices on Kaggle": [[79, "predicting-house-prices-on-kaggle"]], "Downloading Data": [[79, "downloading-data"]], "Kaggle": [[79, "kaggle"]], "Accessing and Reading the Dataset": [[79, "accessing-and-reading-the-dataset"]], "Data Preprocessing": [[79, "data-preprocessing"], [120, "data-preprocessing"], [31, "data-preprocessing"]], "Error Measure": [[79, "error-measure"]], "K-Fold Cross-Validation": [[79, "k-fold-cross-validation"]], "Submitting Predictions on Kaggle": [[79, "submitting-predictions-on-kaggle"]], "Hidden Layers": [[80, "hidden-layers"]], "Limitations of Linear Models": [[80, "limitations-of-linear-models"]], "Incorporating Hidden Layers": [[80, "incorporating-hidden-layers"]], "From Linear to Nonlinear": [[80, "from-linear-to-nonlinear"]], "Universal Approximators": [[80, "universal-approximators"]], "ReLU Function": [[80, "relu-function"]], "Sigmoid Function": [[80, "sigmoid-function"]], "Tanh Function": [[80, "tanh-function"]], "Approximate Training": [[89, "approximate-training"]], "Negative Sampling": [[89, "negative-sampling"], [97, "negative-sampling"]], "Hierarchical Softmax": [[89, "hierarchical-softmax"]], "Synthetic Regression Data": [[73, "synthetic-regression-data"]], "Generating the Dataset": [[73, "generating-the-dataset"]], "Concise Implementation of the Data Loader": [[73, "concise-implementation-of-the-data-loader"]], "Generalization in Deep Learning": [[77, "generalization-in-deep-learning"]], "Revisiting Overfitting and Regularization": [[77, "revisiting-overfitting-and-regularization"]], "Inspiration from Nonparametrics": [[77, "inspiration-from-nonparametrics"]], "Early Stopping": [[77, "early-stopping"]], "Classical Regularization Methods for Deep Networks": [[77, "classical-regularization-methods-for-deep-networks"]], "Forward Propagation, Backward Propagation, and Computational Graphs": [[75, "forward-propagation-backward-propagation-and-computational-graphs"]], "Forward Propagation": [[75, "forward-propagation"]], "Computational Graph of Forward Propagation": [[75, "computational-graph-of-forward-propagation"]], "Backpropagation": [[75, "backpropagation"]], "Training Neural Networks": [[75, "training-neural-networks"]], "Fine-Tuning BERT for Sequence-Level and Token-Level Applications": [[83, "fine-tuning-bert-for-sequence-level-and-token-level-applications"]], "Single Text Classification": [[83, "single-text-classification"]], "Text Pair Classification or Regression": [[83, "text-pair-classification-or-regression"]], "Text Tagging": [[83, "text-tagging"]], "Question Answering": [[83, "question-answering"]], "Implementation of Multilayer Perceptrons": [[81, "implementation-of-multilayer-perceptrons"]], "Numerical Stability and Initialization": [[82, "numerical-stability-and-initialization"]], "Vanishing and Exploding Gradients": [[82, "vanishing-and-exploding-gradients"]], "Vanishing Gradients": [[82, "vanishing-gradients"], [110, "vanishing-gradients"]], "Exploding Gradients": [[82, "exploding-gradients"]], "Breaking the Symmetry": [[82, "breaking-the-symmetry"]], "Default Initialization": [[82, "default-initialization"]], "Xavier Initialization": [[82, "xavier-initialization"]], "Beyond": [[82, "beyond"]], "The Encoder\u2013Decoder Architecture": [[124, "the-encoderdecoder-architecture"]], "Putting the Encoder and Decoder Together": [[124, "putting-the-encoder-and-decoder-together"]], "Preliminaries": [[116, "preliminaries"]], "Beam Search": [[122, "beam-search"], [122, "id1"]], "Greedy Search": [[122, "greedy-search"]], "Exhaustive Search": [[122, "exhaustive-search"]], "Gated Recurrent Units (GRU)": [[125, "gated-recurrent-units-gru"]], "Reset Gate and Update Gate": [[125, "reset-gate-and-update-gate"]], "Candidate Hidden State": [[125, "candidate-hidden-state"]], "Data Preparation": [[120, "data-preparation"]], "Conversion to the Tensor Format": [[120, "conversion-to-the-tensor-format"]], "Documentation": [[118, "documentation"]], "Functions and Classes in a Module": [[118, "functions-and-classes-in-a-module"]], "Specific Functions and Classes": [[118, "specific-functions-and-classes"]], "Calculus": [[115, "calculus"], [100, "calculus"]], "Derivatives and Differentiation": [[115, "derivatives-and-differentiation"]], "Visualization Utilities": [[115, "visualization-utilities"]], "Partial Derivatives and Gradients": [[115, "partial-derivatives-and-gradients"]], "Chain Rule": [[115, "chain-rule"]], "Linear Algebra": [[117, "linear-algebra"]], "Scalars": [[117, "scalars"]], "Vectors": [[117, "vectors"]], "Matrices": [[117, "matrices"]], "Tensors": [[117, "tensors"]], "Basic Properties of Tensor Arithmetic": [[117, "basic-properties-of-tensor-arithmetic"]], "Reduction": [[117, "reduction"]], "Non-Reduction Sum": [[117, "non-reduction-sum"]], "Dot Products": [[117, "dot-products"]], "Matrix\u2013Vector Products": [[117, "matrixvector-products"]], "Matrix\u2013Matrix Multiplication": [[117, "matrixmatrix-multiplication"]], "Norms": [[117, "norms"]], "Data Manipulation": [[119, "data-manipulation"]], "Getting Started": [[119, "getting-started"]], "Indexing and Slicing": [[119, "indexing-and-slicing"]], "Operations": [[119, "operations"]], "Broadcasting": [[119, "broadcasting"]], "Saving Memory": [[119, "saving-memory"]], "Conversion to Other Python Objects": [[119, "conversion-to-other-python-objects"]], "Deep Recurrent Neural Networks": [[123, "deep-recurrent-neural-networks"]], "Automatic Differentiation": [[114, "automatic-differentiation"]], "A Simple Function": [[114, "a-simple-function"]], "Backward for Non-Scalar Variables": [[114, "backward-for-non-scalar-variables"]], "Detaching Computation": [[114, "detaching-computation"]], "Gradients and Python Control Flow": [[114, "gradients-and-python-control-flow"]], "Probability and Statistics": [[121, "probability-and-statistics"]], "A Simple Example: Tossing Coins": [[121, "a-simple-example-tossing-coins"]], "A More Formal Treatment": [[121, "a-more-formal-treatment"]], "Random Variables": [[121, "random-variables"]], "Multiple Random Variables": [[121, "multiple-random-variables"]], "An Example": [[121, "an-example"], [19, "an-example"]], "Expectations": [[121, "expectations"]], "Preface": [[113, "preface"]], "About This Book": [[113, "about-this-book"]], "One Medium Combining Code, Math, and HTML": [[113, "one-medium-combining-code-math-and-html"]], "Learning by Doing": [[113, "learning-by-doing"]], "Content and Structure": [[113, "content-and-structure"]], "Code": [[113, "code"]], "Target Audience": [[113, "target-audience"]], "Notebooks, Website, GitHub, and Forum": [[113, "notebooks-website-github-and-forum"]], "Acknowledgments": [[113, "acknowledgments"]], "Word Embedding (word2vec)": [[98, "word-embedding-word2vec"]], "One-Hot Vectors Are a Bad Choice": [[98, "one-hot-vectors-are-a-bad-choice"]], "Self-Supervised word2vec": [[98, "self-supervised-word2vec"]], "The Skip-Gram Model": [[98, "the-skip-gram-model"], [99, "the-skip-gram-model"]], "The Continuous Bag of Words (CBOW) Model": [[98, "the-continuous-bag-of-words-cbow-model"]], "Notation": [[100, "notation"]], "Numerical Objects": [[100, "numerical-objects"]], "Set Theory": [[100, "set-theory"]], "Functions and Operators": [[100, "functions-and-operators"]], "Probability and Information Theory": [[100, "probability-and-information-theory"]], "Natural Language Processing: Pretraining": [[94, "natural-language-processing-pretraining"]], "Word Embedding with Global Vectors (GloVe)": [[93, "word-embedding-with-global-vectors-glove"]], "Skip-Gram with Global Corpus Statistics": [[93, "skip-gram-with-global-corpus-statistics"]], "The GloVe Model": [[93, "the-glove-model"]], "Interpreting GloVe from the Ratio of Co-occurrence Probabilities": [[93, "interpreting-glove-from-the-ratio-of-co-occurrence-probabilities"]], "label:tab_glove": [[93, "id4"]], "Dog Breed Identification (ImageNet Dogs) on Kaggle": [[26, "dog-breed-identification-imagenet-dogs-on-kaggle"]], "Obtaining and Organizing the Dataset": [[26, "obtaining-and-organizing-the-dataset"], [25, "obtaining-and-organizing-the-dataset"]], "Downloading the Dataset": [[26, "downloading-the-dataset"], [25, "downloading-the-dataset"], [29, "downloading-the-dataset"]], "Organizing the Dataset": [[26, "organizing-the-dataset"], [25, "organizing-the-dataset"]], "Image Augmentation": [[26, "image-augmentation"], [23, "image-augmentation"], [25, "image-augmentation"]], "Fine-Tuning a Pretrained Model": [[26, "fine-tuning-a-pretrained-model"]], "Defining the Training Function": [[26, "defining-the-training-function"], [25, "defining-the-training-function"]], "Training and Validating the Model": [[26, "training-and-validating-the-model"], [25, "training-and-validating-the-model"]], "Classifying the Testing Set and Submitting Results on Kaggle": [[26, "classifying-the-testing-set-and-submitting-results-on-kaggle"], [25, "classifying-the-testing-set-and-submitting-results-on-kaggle"]], "Common Image Augmentation Methods": [[23, "common-image-augmentation-methods"]], "Flipping and Cropping": [[23, "flipping-and-cropping"]], "Changing Colors": [[23, "changing-colors"]], "Combining Multiple Image Augmentation Methods": [[23, "combining-multiple-image-augmentation-methods"]], "Training with Image Augmentation": [[23, "training-with-image-augmentation"]], "Multi-GPU Training": [[23, "multi-gpu-training"]], "Fully Convolutional Networks": [[21, "fully-convolutional-networks"]], "Initializing Transposed Convolutional Layers": [[21, "initializing-transposed-convolutional-layers"]], "Builders\u2019 Guide": [[13, "builders-guide"]], "Object Detection and Bounding Boxes": [[20, "object-detection-and-bounding-boxes"]], "Bounding Boxes": [[20, "bounding-boxes"]], "Fine-Tuning": [[22, "fine-tuning"]], "Steps": [[22, "steps"]], "Hot Dog Recognition": [[22, "hot-dog-recognition"]], "Defining and Initializing the Model": [[22, "defining-and-initializing-the-model"]], "Fine-Tuning the Model": [[22, "fine-tuning-the-model"]], "Multiscale Object Detection": [[27, "multiscale-object-detection"]], "Multiscale Anchor Boxes": [[27, "multiscale-anchor-boxes"]], "Multiscale Detection": [[27, "multiscale-detection"]], "Appendix: Tools for Deep Learning": [[0, "appendix-tools-for-deep-learning"]], "Anchor Boxes": [[19, "anchor-boxes"]], "Generating Multiple Anchor Boxes": [[19, "generating-multiple-anchor-boxes"]], "Intersection over Union (IoU)": [[19, "intersection-over-union-iou"]], "Labeling Anchor Boxes in Training Data": [[19, "labeling-anchor-boxes-in-training-data"]], "Assigning Ground-Truth Bounding Boxes to Anchor Boxes": [[19, "assigning-ground-truth-bounding-boxes-to-anchor-boxes"]], "Labeling Classes and Offsets": [[19, "labeling-classes-and-offsets"]], "Predicting Bounding Boxes with Non-Maximum Suppression": [[19, "predicting-bounding-boxes-with-non-maximum-suppression"]], "Image Classification (CIFAR-10) on Kaggle": [[25, "image-classification-cifar-10-on-kaggle"]], "Natural Language Inference and the Dataset": [[85, "natural-language-inference-and-the-dataset"]], "Natural Language Inference": [[85, "natural-language-inference"]], "The Stanford Natural Language Inference (SNLI) Dataset": [[85, "the-stanford-natural-language-inference-snli-dataset"]], "Defining a Class for Loading the Dataset": [[85, "defining-a-class-for-loading-the-dataset"]], "Neural Style Transfer": [[28, "neural-style-transfer"]], "Method": [[28, "method"]], "Reading the Content and Style Images": [[28, "reading-the-content-and-style-images"]], "Preprocessing and Postprocessing": [[28, "preprocessing-and-postprocessing"]], "Extracting Features": [[28, "extracting-features"]], "Content Loss": [[28, "content-loss"]], "Style Loss": [[28, "style-loss"]], "Total Variation Loss": [[28, "total-variation-loss"]], "Initializing the Synthesized Image": [[28, "initializing-the-synthesized-image"]], "Natural Language Processing: Applications": [[84, "natural-language-processing-applications"]], "Transposed Convolution": [[33, "transposed-convolution"]], "Basic Operation": [[33, "basic-operation"]], "Padding, Strides, and Multiple Channels": [[33, "padding-strides-and-multiple-channels"]], "Connection to Matrix Transposition": [[33, "connection-to-matrix-transposition"]], "Asynchronous Random Search": [[54, "asynchronous-random-search"]], "Visualize the Asynchronous Optimization Process": [[54, "visualize-the-asynchronous-optimization-process"]], "Modern Convolutional Neural Networks": [[38, "modern-convolutional-neural-networks"]], "The Object Detection Dataset": [[29, "the-object-detection-dataset"]], "Demonstration": [[29, "demonstration"]], "Region-based CNNs (R-CNNs)": [[30, "region-based-cnns-r-cnns"]], "R-CNNs": [[30, "r-cnns"]], "Fast R-CNN": [[30, "fast-r-cnn"]], "Faster R-CNN": [[30, "faster-r-cnn"]], "Mask R-CNN": [[30, "mask-r-cnn"]], "Semantic Segmentation and the Dataset": [[31, "semantic-segmentation-and-the-dataset"]], "Image Segmentation and Instance Segmentation": [[31, "image-segmentation-and-instance-segmentation"]], "The Pascal VOC2012 Semantic Segmentation Dataset": [[31, "the-pascal-voc2012-semantic-segmentation-dataset"]], "Custom Semantic Segmentation Dataset Class": [[31, "custom-semantic-segmentation-dataset-class"]], "Single Shot Multibox Detection": [[32, "single-shot-multibox-detection"]], "Class Prediction Layer": [[32, "class-prediction-layer"]], "Bounding Box Prediction Layer": [[32, "bounding-box-prediction-layer"]], "Concatenating Predictions for Multiple Scales": [[32, "concatenating-predictions-for-multiple-scales"]], "Downsampling Block": [[32, "downsampling-block"]], "Base Network Block": [[32, "base-network-block"]], "The Complete Model": [[32, "the-complete-model"]], "Reading the Dataset and Initializing the Model": [[32, "reading-the-dataset-and-initializing-the-model"]], "Defining Loss and Evaluation Functions": [[32, "defining-loss-and-evaluation-functions"]], "Training the Model": [[32, "training-the-model"]], "Sentiment Analysis and the Dataset": [[87, "sentiment-analysis-and-the-dataset"]], "Preprocessing the Dataset": [[87, "preprocessing-the-dataset"]], "Creating Data Iterators": [[87, "creating-data-iterators"]], "The Dataset for Pretraining BERT": [[91, "the-dataset-for-pretraining-bert"]], "Defining Helper Functions for Pretraining Tasks": [[91, "defining-helper-functions-for-pretraining-tasks"]], "Generating the Next Sentence Prediction Task": [[91, "generating-the-next-sentence-prediction-task"]], "Generating the Masked Language Modeling Task": [[91, "generating-the-masked-language-modeling-task"]], "Transforming Text into the Pretraining Dataset": [[91, "transforming-text-into-the-pretraining-dataset"]], "Sentiment Analysis: Using Convolutional Neural Networks": [[88, "sentiment-analysis-using-convolutional-neural-networks"]], "One-Dimensional Convolutions": [[88, "one-dimensional-convolutions"]], "Max-Over-Time Pooling": [[88, "max-over-time-pooling"]], "The textCNN Model": [[88, "the-textcnn-model"]], "Loading Pretrained Word Vectors": [[88, "loading-pretrained-word-vectors"], [95, "loading-pretrained-word-vectors"]], "Training and Evaluating the Model": [[88, "training-and-evaluating-the-model"], [86, "training-and-evaluating-the-model"], [86, "id2"]], "Word Similarity and Analogy": [[95, "word-similarity-and-analogy"]], "Applying Pretrained Word Vectors": [[95, "applying-pretrained-word-vectors"]], "Word Similarity": [[95, "word-similarity"]], "Word Analogy": [[95, "word-analogy"]], "Subword Embedding": [[96, "subword-embedding"]], "The fastText Model": [[96, "the-fasttext-model"]], "Byte Pair Encoding": [[96, "byte-pair-encoding"]], "Representing Text with BERT": [[92, "representing-text-with-bert"]], "The Dataset for Pretraining Word Embeddings": [[97, "the-dataset-for-pretraining-word-embeddings"]], "Subsampling": [[97, "subsampling"]], "Extracting Center Words and Context Words": [[97, "extracting-center-words-and-context-words"]], "Loading Training Examples in Minibatches": [[97, "loading-training-examples-in-minibatches"]], "Pretraining word2vec": [[99, "pretraining-word2vec"]], "Embedding Layer": [[99, "embedding-layer"]], "Defining the Forward Propagation": [[99, "defining-the-forward-propagation"]], "Binary Cross-Entropy Loss": [[99, "binary-cross-entropy-loss"]], "Defining the Training Loop": [[99, "defining-the-training-loop"]], "Applying Word Embeddings": [[99, "applying-word-embeddings"]], "Natural Language Inference: Using Attention": [[86, "natural-language-inference-using-attention"]], "Attending": [[86, "attending"]], "Comparing": [[86, "comparing"]], "Aggregating": [[86, "aggregating"]], "Reading the dataset": [[86, "reading-the-dataset"]], "Creating the Model": [[86, "creating-the-model"]], "Using the Model": [[86, "using-the-model"]], "Bidirectional Encoder Representations from Transformers (BERT)": [[90, "bidirectional-encoder-representations-from-transformers-bert"]], "From Context-Independent to Context-Sensitive": [[90, "from-context-independent-to-context-sensitive"]], "From Task-Specific to Task-Agnostic": [[90, "from-task-specific-to-task-agnostic"]], "BERT: Combining the Best of Both Worlds": [[90, "bert-combining-the-best-of-both-worlds"]], "Input Representation": [[90, "input-representation"]], "Pretraining Tasks": [[90, "pretraining-tasks"]], "Masked Language Modeling": [[90, "masked-language-modeling"]], "Next Sentence Prediction": [[90, "next-sentence-prediction"]], "Adadelta": [[101, "adadelta"]], "The Algorithm": [[101, "the-algorithm"], [103, "the-algorithm"], [111, "the-algorithm"], [102, "the-algorithm"]], "Gradient Descent": [[105, "gradient-descent"]], "One-Dimensional Gradient Descent": [[105, "one-dimensional-gradient-descent"]], "Learning Rate": [[105, "learning-rate"]], "Local Minima": [[105, "local-minima"], [110, "local-minima"]], "Multivariate Gradient Descent": [[105, "multivariate-gradient-descent"]], "Adaptive Methods": [[105, "adaptive-methods"]], "Newton\u2019s Method": [[105, "newtons-method"]], "Convergence Analysis": [[105, "convergence-analysis"]], "Preconditioning": [[105, "preconditioning"], [102, "preconditioning"]], "Gradient Descent with Line Search": [[105, "gradient-descent-with-line-search"]], "Adam": [[103, "adam"]], "Yogi": [[103, "yogi"]], "Convexity": [[104, "convexity"]], "Definitions": [[104, "definitions"]], "Convex Sets": [[104, "convex-sets"]], "Convex Functions": [[104, "convex-functions"]], "Jensen\u2019s Inequality": [[104, "jensens-inequality"]], "Properties": [[104, "properties"]], "Local Minima Are Global Minima": [[104, "local-minima-are-global-minima"]], "Below Sets of Convex Functions Are Convex": [[104, "below-sets-of-convex-functions-are-convex"]], "Convexity and Second Derivatives": [[104, "convexity-and-second-derivatives"]], "Constraints": [[104, "constraints"]], "Lagrangian": [[104, "lagrangian"]], "Penalties": [[104, "penalties"]], "Projections": [[104, "projections"]], "Vectorization and Caches": [[108, "vectorization-and-caches"]], "Minibatches": [[108, "minibatches"]], "RMSProp": [[111, "rmsprop"]], "Optimization and Deep Learning": [[110, "optimization-and-deep-learning"]], "Goal of Optimization": [[110, "goal-of-optimization"]], "Optimization Challenges in Deep Learning": [[110, "optimization-challenges-in-deep-learning"]], "Saddle Points": [[110, "saddle-points"]], "Learning Rate Scheduling": [[107, "learning-rate-scheduling"]], "Toy Problem": [[107, "toy-problem"]], "Schedulers": [[107, "schedulers"]], "Policies": [[107, "policies"]], "Factor Scheduler": [[107, "factor-scheduler"]], "Multi Factor Scheduler": [[107, "multi-factor-scheduler"]], "Cosine Scheduler": [[107, "cosine-scheduler"]], "Warmup": [[107, "warmup"]], "Momentum": [[109, "momentum"]], "Leaky Averages": [[109, "leaky-averages"]], "An Ill-conditioned Problem": [[109, "an-ill-conditioned-problem"]], "The Momentum Method": [[109, "the-momentum-method"]], "Effective Sample Weight": [[109, "effective-sample-weight"]], "Practical Experiments": [[109, "practical-experiments"]], "Theoretical Analysis": [[109, "theoretical-analysis"]], "Quadratic Convex Functions": [[109, "quadratic-convex-functions"]], "Scalar Functions": [[109, "scalar-functions"]], "Adagrad": [[102, "adagrad"]], "Sparse Features and Learning Rates": [[102, "sparse-features-and-learning-rates"]], "Stochastic Gradient Descent": [[112, "stochastic-gradient-descent"]], "Stochastic Gradient Updates": [[112, "stochastic-gradient-updates"]], "Dynamic Learning Rate": [[112, "dynamic-learning-rate"]], "Convergence Analysis for Convex Objectives": [[112, "convergence-analysis-for-convex-objectives"]], "Stochastic Gradients and Finite Samples": [[112, "stochastic-gradients-and-finite-samples"]], "Modern Recurrent Neural Networks": [[126, "modern-recurrent-neural-networks"]], "Dive into Deep Learning": [[142, "dive-into-deep-learning"]]}, "indexentries": {}})